<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Analysing pubmed abstracts</title>

<script src="data:application/x-javascript;base64,/*! jQuery v1.11.3 | (c) 2005, 2015 jQuery Foundation, Inc. | jquery.org/license */
!function(a,b){"object"==typeof module&&"object"==typeof module.exports?module.exports=a.document?b(a,!0):function(a){if(!a.document)throw new Error("jQuery requires a window with a document");return b(a)}:b(a)}("undefined"!=typeof window?window:this,function(a,b){var c=[],d=c.slice,e=c.concat,f=c.push,g=c.indexOf,h={},i=h.toString,j=h.hasOwnProperty,k={},l="1.11.3",m=function(a,b){return new m.fn.init(a,b)},n=/^[\s\uFEFF\xA0]+|[\s\uFEFF\xA0]+$/g,o=/^-ms-/,p=/-([\da-z])/gi,q=function(a,b){return b.toUpperCase()};m.fn=m.prototype={jquery:l,constructor:m,selector:"",length:0,toArray:function(){return d.call(this)},get:function(a){return null!=a?0>a?this[a+this.length]:this[a]:d.call(this)},pushStack:function(a){var b=m.merge(this.constructor(),a);return b.prevObject=this,b.context=this.context,b},each:function(a,b){return m.each(this,a,b)},map:function(a){return this.pushStack(m.map(this,function(b,c){return a.call(b,c,b)}))},slice:function(){return this.pushStack(d.apply(this,arguments))},first:function(){return this.eq(0)},last:function(){return this.eq(-1)},eq:function(a){var b=this.length,c=+a+(0>a?b:0);return this.pushStack(c>=0&&b>c?[this[c]]:[])},end:function(){return this.prevObject||this.constructor(null)},push:f,sort:c.sort,splice:c.splice},m.extend=m.fn.extend=function(){var a,b,c,d,e,f,g=arguments[0]||{},h=1,i=arguments.length,j=!1;for("boolean"==typeof g&&(j=g,g=arguments[h]||{},h++),"object"==typeof g||m.isFunction(g)||(g={}),h===i&&(g=this,h--);i>h;h++)if(null!=(e=arguments[h]))for(d in e)a=g[d],c=e[d],g!==c&&(j&&c&&(m.isPlainObject(c)||(b=m.isArray(c)))?(b?(b=!1,f=a&&m.isArray(a)?a:[]):f=a&&m.isPlainObject(a)?a:{},g[d]=m.extend(j,f,c)):void 0!==c&&(g[d]=c));return g},m.extend({expando:"jQuery"+(l+Math.random()).replace(/\D/g,""),isReady:!0,error:function(a){throw new Error(a)},noop:function(){},isFunction:function(a){return"function"===m.type(a)},isArray:Array.isArray||function(a){return"array"===m.type(a)},isWindow:function(a){return null!=a&&a==a.window},isNumeric:function(a){return!m.isArray(a)&&a-parseFloat(a)+1>=0},isEmptyObject:function(a){var b;for(b in a)return!1;return!0},isPlainObject:function(a){var b;if(!a||"object"!==m.type(a)||a.nodeType||m.isWindow(a))return!1;try{if(a.constructor&&!j.call(a,"constructor")&&!j.call(a.constructor.prototype,"isPrototypeOf"))return!1}catch(c){return!1}if(k.ownLast)for(b in a)return j.call(a,b);for(b in a);return void 0===b||j.call(a,b)},type:function(a){return null==a?a+"":"object"==typeof a||"function"==typeof a?h[i.call(a)]||"object":typeof a},globalEval:function(b){b&&m.trim(b)&&(a.execScript||function(b){a.eval.call(a,b)})(b)},camelCase:function(a){return a.replace(o,"ms-").replace(p,q)},nodeName:function(a,b){return a.nodeName&&a.nodeName.toLowerCase()===b.toLowerCase()},each:function(a,b,c){var d,e=0,f=a.length,g=r(a);if(c){if(g){for(;f>e;e++)if(d=b.apply(a[e],c),d===!1)break}else for(e in a)if(d=b.apply(a[e],c),d===!1)break}else if(g){for(;f>e;e++)if(d=b.call(a[e],e,a[e]),d===!1)break}else for(e in a)if(d=b.call(a[e],e,a[e]),d===!1)break;return a},trim:function(a){return null==a?"":(a+"").replace(n,"")},makeArray:function(a,b){var c=b||[];return null!=a&&(r(Object(a))?m.merge(c,"string"==typeof a?[a]:a):f.call(c,a)),c},inArray:function(a,b,c){var d;if(b){if(g)return g.call(b,a,c);for(d=b.length,c=c?0>c?Math.max(0,d+c):c:0;d>c;c++)if(c in b&&b[c]===a)return c}return-1},merge:function(a,b){var c=+b.length,d=0,e=a.length;while(c>d)a[e++]=b[d++];if(c!==c)while(void 0!==b[d])a[e++]=b[d++];return a.length=e,a},grep:function(a,b,c){for(var d,e=[],f=0,g=a.length,h=!c;g>f;f++)d=!b(a[f],f),d!==h&&e.push(a[f]);return e},map:function(a,b,c){var d,f=0,g=a.length,h=r(a),i=[];if(h)for(;g>f;f++)d=b(a[f],f,c),null!=d&&i.push(d);else for(f in a)d=b(a[f],f,c),null!=d&&i.push(d);return e.apply([],i)},guid:1,proxy:function(a,b){var c,e,f;return"string"==typeof b&&(f=a[b],b=a,a=f),m.isFunction(a)?(c=d.call(arguments,2),e=function(){return a.apply(b||this,c.concat(d.call(arguments)))},e.guid=a.guid=a.guid||m.guid++,e):void 0},now:function(){return+new Date},support:k}),m.each("Boolean Number String Function Array Date RegExp Object Error".split(" "),function(a,b){h["[object "+b+"]"]=b.toLowerCase()});function r(a){var b="length"in a&&a.length,c=m.type(a);return"function"===c||m.isWindow(a)?!1:1===a.nodeType&&b?!0:"array"===c||0===b||"number"==typeof b&&b>0&&b-1 in a}var s=function(a){var b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u="sizzle"+1*new Date,v=a.document,w=0,x=0,y=ha(),z=ha(),A=ha(),B=function(a,b){return a===b&&(l=!0),0},C=1<<31,D={}.hasOwnProperty,E=[],F=E.pop,G=E.push,H=E.push,I=E.slice,J=function(a,b){for(var c=0,d=a.length;d>c;c++)if(a[c]===b)return c;return-1},K="checked|selected|async|autofocus|autoplay|controls|defer|disabled|hidden|ismap|loop|multiple|open|readonly|required|scoped",L="[\\x20\\t\\r\\n\\f]",M="(?:\\\\.|[\\w-]|[^\\x00-\\xa0])+",N=M.replace("w","w#"),O="\\["+L+"*("+M+")(?:"+L+"*([*^$|!~]?=)"+L+"*(?:'((?:\\\\.|[^\\\\'])*)'|\"((?:\\\\.|[^\\\\\"])*)\"|("+N+"))|)"+L+"*\\]",P=":("+M+")(?:\\((('((?:\\\\.|[^\\\\'])*)'|\"((?:\\\\.|[^\\\\\"])*)\")|((?:\\\\.|[^\\\\()[\\]]|"+O+")*)|.*)\\)|)",Q=new RegExp(L+"+","g"),R=new RegExp("^"+L+"+|((?:^|[^\\\\])(?:\\\\.)*)"+L+"+$","g"),S=new RegExp("^"+L+"*,"+L+"*"),T=new RegExp("^"+L+"*([>+~]|"+L+")"+L+"*"),U=new RegExp("="+L+"*([^\\]'\"]*?)"+L+"*\\]","g"),V=new RegExp(P),W=new RegExp("^"+N+"$"),X={ID:new RegExp("^#("+M+")"),CLASS:new RegExp("^\\.("+M+")"),TAG:new RegExp("^("+M.replace("w","w*")+")"),ATTR:new RegExp("^"+O),PSEUDO:new RegExp("^"+P),CHILD:new RegExp("^:(only|first|last|nth|nth-last)-(child|of-type)(?:\\("+L+"*(even|odd|(([+-]|)(\\d*)n|)"+L+"*(?:([+-]|)"+L+"*(\\d+)|))"+L+"*\\)|)","i"),bool:new RegExp("^(?:"+K+")$","i"),needsContext:new RegExp("^"+L+"*[>+~]|:(even|odd|eq|gt|lt|nth|first|last)(?:\\("+L+"*((?:-\\d)?\\d*)"+L+"*\\)|)(?=[^-]|$)","i")},Y=/^(?:input|select|textarea|button)$/i,Z=/^h\d$/i,$=/^[^{]+\{\s*\[native \w/,_=/^(?:#([\w-]+)|(\w+)|\.([\w-]+))$/,aa=/[+~]/,ba=/'|\\/g,ca=new RegExp("\\\\([\\da-f]{1,6}"+L+"?|("+L+")|.)","ig"),da=function(a,b,c){var d="0x"+b-65536;return d!==d||c?b:0>d?String.fromCharCode(d+65536):String.fromCharCode(d>>10|55296,1023&d|56320)},ea=function(){m()};try{H.apply(E=I.call(v.childNodes),v.childNodes),E[v.childNodes.length].nodeType}catch(fa){H={apply:E.length?function(a,b){G.apply(a,I.call(b))}:function(a,b){var c=a.length,d=0;while(a[c++]=b[d++]);a.length=c-1}}}function ga(a,b,d,e){var f,h,j,k,l,o,r,s,w,x;if((b?b.ownerDocument||b:v)!==n&&m(b),b=b||n,d=d||[],k=b.nodeType,"string"!=typeof a||!a||1!==k&&9!==k&&11!==k)return d;if(!e&&p){if(11!==k&&(f=_.exec(a)))if(j=f[1]){if(9===k){if(h=b.getElementById(j),!h||!h.parentNode)return d;if(h.id===j)return d.push(h),d}else if(b.ownerDocument&&(h=b.ownerDocument.getElementById(j))&&t(b,h)&&h.id===j)return d.push(h),d}else{if(f[2])return H.apply(d,b.getElementsByTagName(a)),d;if((j=f[3])&&c.getElementsByClassName)return H.apply(d,b.getElementsByClassName(j)),d}if(c.qsa&&(!q||!q.test(a))){if(s=r=u,w=b,x=1!==k&&a,1===k&&"object"!==b.nodeName.toLowerCase()){o=g(a),(r=b.getAttribute("id"))?s=r.replace(ba,"\\$&"):b.setAttribute("id",s),s="[id='"+s+"'] ",l=o.length;while(l--)o[l]=s+ra(o[l]);w=aa.test(a)&&pa(b.parentNode)||b,x=o.join(",")}if(x)try{return H.apply(d,w.querySelectorAll(x)),d}catch(y){}finally{r||b.removeAttribute("id")}}}return i(a.replace(R,"$1"),b,d,e)}function ha(){var a=[];function b(c,e){return a.push(c+" ")>d.cacheLength&&delete b[a.shift()],b[c+" "]=e}return b}function ia(a){return a[u]=!0,a}function ja(a){var b=n.createElement("div");try{return!!a(b)}catch(c){return!1}finally{b.parentNode&&b.parentNode.removeChild(b),b=null}}function ka(a,b){var c=a.split("|"),e=a.length;while(e--)d.attrHandle[c[e]]=b}function la(a,b){var c=b&&a,d=c&&1===a.nodeType&&1===b.nodeType&&(~b.sourceIndex||C)-(~a.sourceIndex||C);if(d)return d;if(c)while(c=c.nextSibling)if(c===b)return-1;return a?1:-1}function ma(a){return function(b){var c=b.nodeName.toLowerCase();return"input"===c&&b.type===a}}function na(a){return function(b){var c=b.nodeName.toLowerCase();return("input"===c||"button"===c)&&b.type===a}}function oa(a){return ia(function(b){return b=+b,ia(function(c,d){var e,f=a([],c.length,b),g=f.length;while(g--)c[e=f[g]]&&(c[e]=!(d[e]=c[e]))})})}function pa(a){return a&&"undefined"!=typeof a.getElementsByTagName&&a}c=ga.support={},f=ga.isXML=function(a){var b=a&&(a.ownerDocument||a).documentElement;return b?"HTML"!==b.nodeName:!1},m=ga.setDocument=function(a){var b,e,g=a?a.ownerDocument||a:v;return g!==n&&9===g.nodeType&&g.documentElement?(n=g,o=g.documentElement,e=g.defaultView,e&&e!==e.top&&(e.addEventListener?e.addEventListener("unload",ea,!1):e.attachEvent&&e.attachEvent("onunload",ea)),p=!f(g),c.attributes=ja(function(a){return a.className="i",!a.getAttribute("className")}),c.getElementsByTagName=ja(function(a){return a.appendChild(g.createComment("")),!a.getElementsByTagName("*").length}),c.getElementsByClassName=$.test(g.getElementsByClassName),c.getById=ja(function(a){return o.appendChild(a).id=u,!g.getElementsByName||!g.getElementsByName(u).length}),c.getById?(d.find.ID=function(a,b){if("undefined"!=typeof b.getElementById&&p){var c=b.getElementById(a);return c&&c.parentNode?[c]:[]}},d.filter.ID=function(a){var b=a.replace(ca,da);return function(a){return a.getAttribute("id")===b}}):(delete d.find.ID,d.filter.ID=function(a){var b=a.replace(ca,da);return function(a){var c="undefined"!=typeof a.getAttributeNode&&a.getAttributeNode("id");return c&&c.value===b}}),d.find.TAG=c.getElementsByTagName?function(a,b){return"undefined"!=typeof b.getElementsByTagName?b.getElementsByTagName(a):c.qsa?b.querySelectorAll(a):void 0}:function(a,b){var c,d=[],e=0,f=b.getElementsByTagName(a);if("*"===a){while(c=f[e++])1===c.nodeType&&d.push(c);return d}return f},d.find.CLASS=c.getElementsByClassName&&function(a,b){return p?b.getElementsByClassName(a):void 0},r=[],q=[],(c.qsa=$.test(g.querySelectorAll))&&(ja(function(a){o.appendChild(a).innerHTML="<a id='"+u+"'></a><select id='"+u+"-\f]' msallowcapture=''><option selected=''></option></select>",a.querySelectorAll("[msallowcapture^='']").length&&q.push("[*^$]="+L+"*(?:''|\"\")"),a.querySelectorAll("[selected]").length||q.push("\\["+L+"*(?:value|"+K+")"),a.querySelectorAll("[id~="+u+"-]").length||q.push("~="),a.querySelectorAll(":checked").length||q.push(":checked"),a.querySelectorAll("a#"+u+"+*").length||q.push(".#.+[+~]")}),ja(function(a){var b=g.createElement("input");b.setAttribute("type","hidden"),a.appendChild(b).setAttribute("name","D"),a.querySelectorAll("[name=d]").length&&q.push("name"+L+"*[*^$|!~]?="),a.querySelectorAll(":enabled").length||q.push(":enabled",":disabled"),a.querySelectorAll("*,:x"),q.push(",.*:")})),(c.matchesSelector=$.test(s=o.matches||o.webkitMatchesSelector||o.mozMatchesSelector||o.oMatchesSelector||o.msMatchesSelector))&&ja(function(a){c.disconnectedMatch=s.call(a,"div"),s.call(a,"[s!='']:x"),r.push("!=",P)}),q=q.length&&new RegExp(q.join("|")),r=r.length&&new RegExp(r.join("|")),b=$.test(o.compareDocumentPosition),t=b||$.test(o.contains)?function(a,b){var c=9===a.nodeType?a.documentElement:a,d=b&&b.parentNode;return a===d||!(!d||1!==d.nodeType||!(c.contains?c.contains(d):a.compareDocumentPosition&&16&a.compareDocumentPosition(d)))}:function(a,b){if(b)while(b=b.parentNode)if(b===a)return!0;return!1},B=b?function(a,b){if(a===b)return l=!0,0;var d=!a.compareDocumentPosition-!b.compareDocumentPosition;return d?d:(d=(a.ownerDocument||a)===(b.ownerDocument||b)?a.compareDocumentPosition(b):1,1&d||!c.sortDetached&&b.compareDocumentPosition(a)===d?a===g||a.ownerDocument===v&&t(v,a)?-1:b===g||b.ownerDocument===v&&t(v,b)?1:k?J(k,a)-J(k,b):0:4&d?-1:1)}:function(a,b){if(a===b)return l=!0,0;var c,d=0,e=a.parentNode,f=b.parentNode,h=[a],i=[b];if(!e||!f)return a===g?-1:b===g?1:e?-1:f?1:k?J(k,a)-J(k,b):0;if(e===f)return la(a,b);c=a;while(c=c.parentNode)h.unshift(c);c=b;while(c=c.parentNode)i.unshift(c);while(h[d]===i[d])d++;return d?la(h[d],i[d]):h[d]===v?-1:i[d]===v?1:0},g):n},ga.matches=function(a,b){return ga(a,null,null,b)},ga.matchesSelector=function(a,b){if((a.ownerDocument||a)!==n&&m(a),b=b.replace(U,"='$1']"),!(!c.matchesSelector||!p||r&&r.test(b)||q&&q.test(b)))try{var d=s.call(a,b);if(d||c.disconnectedMatch||a.document&&11!==a.document.nodeType)return d}catch(e){}return ga(b,n,null,[a]).length>0},ga.contains=function(a,b){return(a.ownerDocument||a)!==n&&m(a),t(a,b)},ga.attr=function(a,b){(a.ownerDocument||a)!==n&&m(a);var e=d.attrHandle[b.toLowerCase()],f=e&&D.call(d.attrHandle,b.toLowerCase())?e(a,b,!p):void 0;return void 0!==f?f:c.attributes||!p?a.getAttribute(b):(f=a.getAttributeNode(b))&&f.specified?f.value:null},ga.error=function(a){throw new Error("Syntax error, unrecognized expression: "+a)},ga.uniqueSort=function(a){var b,d=[],e=0,f=0;if(l=!c.detectDuplicates,k=!c.sortStable&&a.slice(0),a.sort(B),l){while(b=a[f++])b===a[f]&&(e=d.push(f));while(e--)a.splice(d[e],1)}return k=null,a},e=ga.getText=function(a){var b,c="",d=0,f=a.nodeType;if(f){if(1===f||9===f||11===f){if("string"==typeof a.textContent)return a.textContent;for(a=a.firstChild;a;a=a.nextSibling)c+=e(a)}else if(3===f||4===f)return a.nodeValue}else while(b=a[d++])c+=e(b);return c},d=ga.selectors={cacheLength:50,createPseudo:ia,match:X,attrHandle:{},find:{},relative:{">":{dir:"parentNode",first:!0}," ":{dir:"parentNode"},"+":{dir:"previousSibling",first:!0},"~":{dir:"previousSibling"}},preFilter:{ATTR:function(a){return a[1]=a[1].replace(ca,da),a[3]=(a[3]||a[4]||a[5]||"").replace(ca,da),"~="===a[2]&&(a[3]=" "+a[3]+" "),a.slice(0,4)},CHILD:function(a){return a[1]=a[1].toLowerCase(),"nth"===a[1].slice(0,3)?(a[3]||ga.error(a[0]),a[4]=+(a[4]?a[5]+(a[6]||1):2*("even"===a[3]||"odd"===a[3])),a[5]=+(a[7]+a[8]||"odd"===a[3])):a[3]&&ga.error(a[0]),a},PSEUDO:function(a){var b,c=!a[6]&&a[2];return X.CHILD.test(a[0])?null:(a[3]?a[2]=a[4]||a[5]||"":c&&V.test(c)&&(b=g(c,!0))&&(b=c.indexOf(")",c.length-b)-c.length)&&(a[0]=a[0].slice(0,b),a[2]=c.slice(0,b)),a.slice(0,3))}},filter:{TAG:function(a){var b=a.replace(ca,da).toLowerCase();return"*"===a?function(){return!0}:function(a){return a.nodeName&&a.nodeName.toLowerCase()===b}},CLASS:function(a){var b=y[a+" "];return b||(b=new RegExp("(^|"+L+")"+a+"("+L+"|$)"))&&y(a,function(a){return b.test("string"==typeof a.className&&a.className||"undefined"!=typeof a.getAttribute&&a.getAttribute("class")||"")})},ATTR:function(a,b,c){return function(d){var e=ga.attr(d,a);return null==e?"!="===b:b?(e+="","="===b?e===c:"!="===b?e!==c:"^="===b?c&&0===e.indexOf(c):"*="===b?c&&e.indexOf(c)>-1:"$="===b?c&&e.slice(-c.length)===c:"~="===b?(" "+e.replace(Q," ")+" ").indexOf(c)>-1:"|="===b?e===c||e.slice(0,c.length+1)===c+"-":!1):!0}},CHILD:function(a,b,c,d,e){var f="nth"!==a.slice(0,3),g="last"!==a.slice(-4),h="of-type"===b;return 1===d&&0===e?function(a){return!!a.parentNode}:function(b,c,i){var j,k,l,m,n,o,p=f!==g?"nextSibling":"previousSibling",q=b.parentNode,r=h&&b.nodeName.toLowerCase(),s=!i&&!h;if(q){if(f){while(p){l=b;while(l=l[p])if(h?l.nodeName.toLowerCase()===r:1===l.nodeType)return!1;o=p="only"===a&&!o&&"nextSibling"}return!0}if(o=[g?q.firstChild:q.lastChild],g&&s){k=q[u]||(q[u]={}),j=k[a]||[],n=j[0]===w&&j[1],m=j[0]===w&&j[2],l=n&&q.childNodes[n];while(l=++n&&l&&l[p]||(m=n=0)||o.pop())if(1===l.nodeType&&++m&&l===b){k[a]=[w,n,m];break}}else if(s&&(j=(b[u]||(b[u]={}))[a])&&j[0]===w)m=j[1];else while(l=++n&&l&&l[p]||(m=n=0)||o.pop())if((h?l.nodeName.toLowerCase()===r:1===l.nodeType)&&++m&&(s&&((l[u]||(l[u]={}))[a]=[w,m]),l===b))break;return m-=e,m===d||m%d===0&&m/d>=0}}},PSEUDO:function(a,b){var c,e=d.pseudos[a]||d.setFilters[a.toLowerCase()]||ga.error("unsupported pseudo: "+a);return e[u]?e(b):e.length>1?(c=[a,a,"",b],d.setFilters.hasOwnProperty(a.toLowerCase())?ia(function(a,c){var d,f=e(a,b),g=f.length;while(g--)d=J(a,f[g]),a[d]=!(c[d]=f[g])}):function(a){return e(a,0,c)}):e}},pseudos:{not:ia(function(a){var b=[],c=[],d=h(a.replace(R,"$1"));return d[u]?ia(function(a,b,c,e){var f,g=d(a,null,e,[]),h=a.length;while(h--)(f=g[h])&&(a[h]=!(b[h]=f))}):function(a,e,f){return b[0]=a,d(b,null,f,c),b[0]=null,!c.pop()}}),has:ia(function(a){return function(b){return ga(a,b).length>0}}),contains:ia(function(a){return a=a.replace(ca,da),function(b){return(b.textContent||b.innerText||e(b)).indexOf(a)>-1}}),lang:ia(function(a){return W.test(a||"")||ga.error("unsupported lang: "+a),a=a.replace(ca,da).toLowerCase(),function(b){var c;do if(c=p?b.lang:b.getAttribute("xml:lang")||b.getAttribute("lang"))return c=c.toLowerCase(),c===a||0===c.indexOf(a+"-");while((b=b.parentNode)&&1===b.nodeType);return!1}}),target:function(b){var c=a.location&&a.location.hash;return c&&c.slice(1)===b.id},root:function(a){return a===o},focus:function(a){return a===n.activeElement&&(!n.hasFocus||n.hasFocus())&&!!(a.type||a.href||~a.tabIndex)},enabled:function(a){return a.disabled===!1},disabled:function(a){return a.disabled===!0},checked:function(a){var b=a.nodeName.toLowerCase();return"input"===b&&!!a.checked||"option"===b&&!!a.selected},selected:function(a){return a.parentNode&&a.parentNode.selectedIndex,a.selected===!0},empty:function(a){for(a=a.firstChild;a;a=a.nextSibling)if(a.nodeType<6)return!1;return!0},parent:function(a){return!d.pseudos.empty(a)},header:function(a){return Z.test(a.nodeName)},input:function(a){return Y.test(a.nodeName)},button:function(a){var b=a.nodeName.toLowerCase();return"input"===b&&"button"===a.type||"button"===b},text:function(a){var b;return"input"===a.nodeName.toLowerCase()&&"text"===a.type&&(null==(b=a.getAttribute("type"))||"text"===b.toLowerCase())},first:oa(function(){return[0]}),last:oa(function(a,b){return[b-1]}),eq:oa(function(a,b,c){return[0>c?c+b:c]}),even:oa(function(a,b){for(var c=0;b>c;c+=2)a.push(c);return a}),odd:oa(function(a,b){for(var c=1;b>c;c+=2)a.push(c);return a}),lt:oa(function(a,b,c){for(var d=0>c?c+b:c;--d>=0;)a.push(d);return a}),gt:oa(function(a,b,c){for(var d=0>c?c+b:c;++d<b;)a.push(d);return a})}},d.pseudos.nth=d.pseudos.eq;for(b in{radio:!0,checkbox:!0,file:!0,password:!0,image:!0})d.pseudos[b]=ma(b);for(b in{submit:!0,reset:!0})d.pseudos[b]=na(b);function qa(){}qa.prototype=d.filters=d.pseudos,d.setFilters=new qa,g=ga.tokenize=function(a,b){var c,e,f,g,h,i,j,k=z[a+" "];if(k)return b?0:k.slice(0);h=a,i=[],j=d.preFilter;while(h){(!c||(e=S.exec(h)))&&(e&&(h=h.slice(e[0].length)||h),i.push(f=[])),c=!1,(e=T.exec(h))&&(c=e.shift(),f.push({value:c,type:e[0].replace(R," ")}),h=h.slice(c.length));for(g in d.filter)!(e=X[g].exec(h))||j[g]&&!(e=j[g](e))||(c=e.shift(),f.push({value:c,type:g,matches:e}),h=h.slice(c.length));if(!c)break}return b?h.length:h?ga.error(a):z(a,i).slice(0)};function ra(a){for(var b=0,c=a.length,d="";c>b;b++)d+=a[b].value;return d}function sa(a,b,c){var d=b.dir,e=c&&"parentNode"===d,f=x++;return b.first?function(b,c,f){while(b=b[d])if(1===b.nodeType||e)return a(b,c,f)}:function(b,c,g){var h,i,j=[w,f];if(g){while(b=b[d])if((1===b.nodeType||e)&&a(b,c,g))return!0}else while(b=b[d])if(1===b.nodeType||e){if(i=b[u]||(b[u]={}),(h=i[d])&&h[0]===w&&h[1]===f)return j[2]=h[2];if(i[d]=j,j[2]=a(b,c,g))return!0}}}function ta(a){return a.length>1?function(b,c,d){var e=a.length;while(e--)if(!a[e](b,c,d))return!1;return!0}:a[0]}function ua(a,b,c){for(var d=0,e=b.length;e>d;d++)ga(a,b[d],c);return c}function va(a,b,c,d,e){for(var f,g=[],h=0,i=a.length,j=null!=b;i>h;h++)(f=a[h])&&(!c||c(f,d,e))&&(g.push(f),j&&b.push(h));return g}function wa(a,b,c,d,e,f){return d&&!d[u]&&(d=wa(d)),e&&!e[u]&&(e=wa(e,f)),ia(function(f,g,h,i){var j,k,l,m=[],n=[],o=g.length,p=f||ua(b||"*",h.nodeType?[h]:h,[]),q=!a||!f&&b?p:va(p,m,a,h,i),r=c?e||(f?a:o||d)?[]:g:q;if(c&&c(q,r,h,i),d){j=va(r,n),d(j,[],h,i),k=j.length;while(k--)(l=j[k])&&(r[n[k]]=!(q[n[k]]=l))}if(f){if(e||a){if(e){j=[],k=r.length;while(k--)(l=r[k])&&j.push(q[k]=l);e(null,r=[],j,i)}k=r.length;while(k--)(l=r[k])&&(j=e?J(f,l):m[k])>-1&&(f[j]=!(g[j]=l))}}else r=va(r===g?r.splice(o,r.length):r),e?e(null,g,r,i):H.apply(g,r)})}function xa(a){for(var b,c,e,f=a.length,g=d.relative[a[0].type],h=g||d.relative[" "],i=g?1:0,k=sa(function(a){return a===b},h,!0),l=sa(function(a){return J(b,a)>-1},h,!0),m=[function(a,c,d){var e=!g&&(d||c!==j)||((b=c).nodeType?k(a,c,d):l(a,c,d));return b=null,e}];f>i;i++)if(c=d.relative[a[i].type])m=[sa(ta(m),c)];else{if(c=d.filter[a[i].type].apply(null,a[i].matches),c[u]){for(e=++i;f>e;e++)if(d.relative[a[e].type])break;return wa(i>1&&ta(m),i>1&&ra(a.slice(0,i-1).concat({value:" "===a[i-2].type?"*":""})).replace(R,"$1"),c,e>i&&xa(a.slice(i,e)),f>e&&xa(a=a.slice(e)),f>e&&ra(a))}m.push(c)}return ta(m)}function ya(a,b){var c=b.length>0,e=a.length>0,f=function(f,g,h,i,k){var l,m,o,p=0,q="0",r=f&&[],s=[],t=j,u=f||e&&d.find.TAG("*",k),v=w+=null==t?1:Math.random()||.1,x=u.length;for(k&&(j=g!==n&&g);q!==x&&null!=(l=u[q]);q++){if(e&&l){m=0;while(o=a[m++])if(o(l,g,h)){i.push(l);break}k&&(w=v)}c&&((l=!o&&l)&&p--,f&&r.push(l))}if(p+=q,c&&q!==p){m=0;while(o=b[m++])o(r,s,g,h);if(f){if(p>0)while(q--)r[q]||s[q]||(s[q]=F.call(i));s=va(s)}H.apply(i,s),k&&!f&&s.length>0&&p+b.length>1&&ga.uniqueSort(i)}return k&&(w=v,j=t),r};return c?ia(f):f}return h=ga.compile=function(a,b){var c,d=[],e=[],f=A[a+" "];if(!f){b||(b=g(a)),c=b.length;while(c--)f=xa(b[c]),f[u]?d.push(f):e.push(f);f=A(a,ya(e,d)),f.selector=a}return f},i=ga.select=function(a,b,e,f){var i,j,k,l,m,n="function"==typeof a&&a,o=!f&&g(a=n.selector||a);if(e=e||[],1===o.length){if(j=o[0]=o[0].slice(0),j.length>2&&"ID"===(k=j[0]).type&&c.getById&&9===b.nodeType&&p&&d.relative[j[1].type]){if(b=(d.find.ID(k.matches[0].replace(ca,da),b)||[])[0],!b)return e;n&&(b=b.parentNode),a=a.slice(j.shift().value.length)}i=X.needsContext.test(a)?0:j.length;while(i--){if(k=j[i],d.relative[l=k.type])break;if((m=d.find[l])&&(f=m(k.matches[0].replace(ca,da),aa.test(j[0].type)&&pa(b.parentNode)||b))){if(j.splice(i,1),a=f.length&&ra(j),!a)return H.apply(e,f),e;break}}}return(n||h(a,o))(f,b,!p,e,aa.test(a)&&pa(b.parentNode)||b),e},c.sortStable=u.split("").sort(B).join("")===u,c.detectDuplicates=!!l,m(),c.sortDetached=ja(function(a){return 1&a.compareDocumentPosition(n.createElement("div"))}),ja(function(a){return a.innerHTML="<a href='#'></a>","#"===a.firstChild.getAttribute("href")})||ka("type|href|height|width",function(a,b,c){return c?void 0:a.getAttribute(b,"type"===b.toLowerCase()?1:2)}),c.attributes&&ja(function(a){return a.innerHTML="<input/>",a.firstChild.setAttribute("value",""),""===a.firstChild.getAttribute("value")})||ka("value",function(a,b,c){return c||"input"!==a.nodeName.toLowerCase()?void 0:a.defaultValue}),ja(function(a){return null==a.getAttribute("disabled")})||ka(K,function(a,b,c){var d;return c?void 0:a[b]===!0?b.toLowerCase():(d=a.getAttributeNode(b))&&d.specified?d.value:null}),ga}(a);m.find=s,m.expr=s.selectors,m.expr[":"]=m.expr.pseudos,m.unique=s.uniqueSort,m.text=s.getText,m.isXMLDoc=s.isXML,m.contains=s.contains;var t=m.expr.match.needsContext,u=/^<(\w+)\s*\/?>(?:<\/\1>|)$/,v=/^.[^:#\[\.,]*$/;function w(a,b,c){if(m.isFunction(b))return m.grep(a,function(a,d){return!!b.call(a,d,a)!==c});if(b.nodeType)return m.grep(a,function(a){return a===b!==c});if("string"==typeof b){if(v.test(b))return m.filter(b,a,c);b=m.filter(b,a)}return m.grep(a,function(a){return m.inArray(a,b)>=0!==c})}m.filter=function(a,b,c){var d=b[0];return c&&(a=":not("+a+")"),1===b.length&&1===d.nodeType?m.find.matchesSelector(d,a)?[d]:[]:m.find.matches(a,m.grep(b,function(a){return 1===a.nodeType}))},m.fn.extend({find:function(a){var b,c=[],d=this,e=d.length;if("string"!=typeof a)return this.pushStack(m(a).filter(function(){for(b=0;e>b;b++)if(m.contains(d[b],this))return!0}));for(b=0;e>b;b++)m.find(a,d[b],c);return c=this.pushStack(e>1?m.unique(c):c),c.selector=this.selector?this.selector+" "+a:a,c},filter:function(a){return this.pushStack(w(this,a||[],!1))},not:function(a){return this.pushStack(w(this,a||[],!0))},is:function(a){return!!w(this,"string"==typeof a&&t.test(a)?m(a):a||[],!1).length}});var x,y=a.document,z=/^(?:\s*(<[\w\W]+>)[^>]*|#([\w-]*))$/,A=m.fn.init=function(a,b){var c,d;if(!a)return this;if("string"==typeof a){if(c="<"===a.charAt(0)&&">"===a.charAt(a.length-1)&&a.length>=3?[null,a,null]:z.exec(a),!c||!c[1]&&b)return!b||b.jquery?(b||x).find(a):this.constructor(b).find(a);if(c[1]){if(b=b instanceof m?b[0]:b,m.merge(this,m.parseHTML(c[1],b&&b.nodeType?b.ownerDocument||b:y,!0)),u.test(c[1])&&m.isPlainObject(b))for(c in b)m.isFunction(this[c])?this[c](b[c]):this.attr(c,b[c]);return this}if(d=y.getElementById(c[2]),d&&d.parentNode){if(d.id!==c[2])return x.find(a);this.length=1,this[0]=d}return this.context=y,this.selector=a,this}return a.nodeType?(this.context=this[0]=a,this.length=1,this):m.isFunction(a)?"undefined"!=typeof x.ready?x.ready(a):a(m):(void 0!==a.selector&&(this.selector=a.selector,this.context=a.context),m.makeArray(a,this))};A.prototype=m.fn,x=m(y);var B=/^(?:parents|prev(?:Until|All))/,C={children:!0,contents:!0,next:!0,prev:!0};m.extend({dir:function(a,b,c){var d=[],e=a[b];while(e&&9!==e.nodeType&&(void 0===c||1!==e.nodeType||!m(e).is(c)))1===e.nodeType&&d.push(e),e=e[b];return d},sibling:function(a,b){for(var c=[];a;a=a.nextSibling)1===a.nodeType&&a!==b&&c.push(a);return c}}),m.fn.extend({has:function(a){var b,c=m(a,this),d=c.length;return this.filter(function(){for(b=0;d>b;b++)if(m.contains(this,c[b]))return!0})},closest:function(a,b){for(var c,d=0,e=this.length,f=[],g=t.test(a)||"string"!=typeof a?m(a,b||this.context):0;e>d;d++)for(c=this[d];c&&c!==b;c=c.parentNode)if(c.nodeType<11&&(g?g.index(c)>-1:1===c.nodeType&&m.find.matchesSelector(c,a))){f.push(c);break}return this.pushStack(f.length>1?m.unique(f):f)},index:function(a){return a?"string"==typeof a?m.inArray(this[0],m(a)):m.inArray(a.jquery?a[0]:a,this):this[0]&&this[0].parentNode?this.first().prevAll().length:-1},add:function(a,b){return this.pushStack(m.unique(m.merge(this.get(),m(a,b))))},addBack:function(a){return this.add(null==a?this.prevObject:this.prevObject.filter(a))}});function D(a,b){do a=a[b];while(a&&1!==a.nodeType);return a}m.each({parent:function(a){var b=a.parentNode;return b&&11!==b.nodeType?b:null},parents:function(a){return m.dir(a,"parentNode")},parentsUntil:function(a,b,c){return m.dir(a,"parentNode",c)},next:function(a){return D(a,"nextSibling")},prev:function(a){return D(a,"previousSibling")},nextAll:function(a){return m.dir(a,"nextSibling")},prevAll:function(a){return m.dir(a,"previousSibling")},nextUntil:function(a,b,c){return m.dir(a,"nextSibling",c)},prevUntil:function(a,b,c){return m.dir(a,"previousSibling",c)},siblings:function(a){return m.sibling((a.parentNode||{}).firstChild,a)},children:function(a){return m.sibling(a.firstChild)},contents:function(a){return m.nodeName(a,"iframe")?a.contentDocument||a.contentWindow.document:m.merge([],a.childNodes)}},function(a,b){m.fn[a]=function(c,d){var e=m.map(this,b,c);return"Until"!==a.slice(-5)&&(d=c),d&&"string"==typeof d&&(e=m.filter(d,e)),this.length>1&&(C[a]||(e=m.unique(e)),B.test(a)&&(e=e.reverse())),this.pushStack(e)}});var E=/\S+/g,F={};function G(a){var b=F[a]={};return m.each(a.match(E)||[],function(a,c){b[c]=!0}),b}m.Callbacks=function(a){a="string"==typeof a?F[a]||G(a):m.extend({},a);var b,c,d,e,f,g,h=[],i=!a.once&&[],j=function(l){for(c=a.memory&&l,d=!0,f=g||0,g=0,e=h.length,b=!0;h&&e>f;f++)if(h[f].apply(l[0],l[1])===!1&&a.stopOnFalse){c=!1;break}b=!1,h&&(i?i.length&&j(i.shift()):c?h=[]:k.disable())},k={add:function(){if(h){var d=h.length;!function f(b){m.each(b,function(b,c){var d=m.type(c);"function"===d?a.unique&&k.has(c)||h.push(c):c&&c.length&&"string"!==d&&f(c)})}(arguments),b?e=h.length:c&&(g=d,j(c))}return this},remove:function(){return h&&m.each(arguments,function(a,c){var d;while((d=m.inArray(c,h,d))>-1)h.splice(d,1),b&&(e>=d&&e--,f>=d&&f--)}),this},has:function(a){return a?m.inArray(a,h)>-1:!(!h||!h.length)},empty:function(){return h=[],e=0,this},disable:function(){return h=i=c=void 0,this},disabled:function(){return!h},lock:function(){return i=void 0,c||k.disable(),this},locked:function(){return!i},fireWith:function(a,c){return!h||d&&!i||(c=c||[],c=[a,c.slice?c.slice():c],b?i.push(c):j(c)),this},fire:function(){return k.fireWith(this,arguments),this},fired:function(){return!!d}};return k},m.extend({Deferred:function(a){var b=[["resolve","done",m.Callbacks("once memory"),"resolved"],["reject","fail",m.Callbacks("once memory"),"rejected"],["notify","progress",m.Callbacks("memory")]],c="pending",d={state:function(){return c},always:function(){return e.done(arguments).fail(arguments),this},then:function(){var a=arguments;return m.Deferred(function(c){m.each(b,function(b,f){var g=m.isFunction(a[b])&&a[b];e[f[1]](function(){var a=g&&g.apply(this,arguments);a&&m.isFunction(a.promise)?a.promise().done(c.resolve).fail(c.reject).progress(c.notify):c[f[0]+"With"](this===d?c.promise():this,g?[a]:arguments)})}),a=null}).promise()},promise:function(a){return null!=a?m.extend(a,d):d}},e={};return d.pipe=d.then,m.each(b,function(a,f){var g=f[2],h=f[3];d[f[1]]=g.add,h&&g.add(function(){c=h},b[1^a][2].disable,b[2][2].lock),e[f[0]]=function(){return e[f[0]+"With"](this===e?d:this,arguments),this},e[f[0]+"With"]=g.fireWith}),d.promise(e),a&&a.call(e,e),e},when:function(a){var b=0,c=d.call(arguments),e=c.length,f=1!==e||a&&m.isFunction(a.promise)?e:0,g=1===f?a:m.Deferred(),h=function(a,b,c){return function(e){b[a]=this,c[a]=arguments.length>1?d.call(arguments):e,c===i?g.notifyWith(b,c):--f||g.resolveWith(b,c)}},i,j,k;if(e>1)for(i=new Array(e),j=new Array(e),k=new Array(e);e>b;b++)c[b]&&m.isFunction(c[b].promise)?c[b].promise().done(h(b,k,c)).fail(g.reject).progress(h(b,j,i)):--f;return f||g.resolveWith(k,c),g.promise()}});var H;m.fn.ready=function(a){return m.ready.promise().done(a),this},m.extend({isReady:!1,readyWait:1,holdReady:function(a){a?m.readyWait++:m.ready(!0)},ready:function(a){if(a===!0?!--m.readyWait:!m.isReady){if(!y.body)return setTimeout(m.ready);m.isReady=!0,a!==!0&&--m.readyWait>0||(H.resolveWith(y,[m]),m.fn.triggerHandler&&(m(y).triggerHandler("ready"),m(y).off("ready")))}}});function I(){y.addEventListener?(y.removeEventListener("DOMContentLoaded",J,!1),a.removeEventListener("load",J,!1)):(y.detachEvent("onreadystatechange",J),a.detachEvent("onload",J))}function J(){(y.addEventListener||"load"===event.type||"complete"===y.readyState)&&(I(),m.ready())}m.ready.promise=function(b){if(!H)if(H=m.Deferred(),"complete"===y.readyState)setTimeout(m.ready);else if(y.addEventListener)y.addEventListener("DOMContentLoaded",J,!1),a.addEventListener("load",J,!1);else{y.attachEvent("onreadystatechange",J),a.attachEvent("onload",J);var c=!1;try{c=null==a.frameElement&&y.documentElement}catch(d){}c&&c.doScroll&&!function e(){if(!m.isReady){try{c.doScroll("left")}catch(a){return setTimeout(e,50)}I(),m.ready()}}()}return H.promise(b)};var K="undefined",L;for(L in m(k))break;k.ownLast="0"!==L,k.inlineBlockNeedsLayout=!1,m(function(){var a,b,c,d;c=y.getElementsByTagName("body")[0],c&&c.style&&(b=y.createElement("div"),d=y.createElement("div"),d.style.cssText="position:absolute;border:0;width:0;height:0;top:0;left:-9999px",c.appendChild(d).appendChild(b),typeof b.style.zoom!==K&&(b.style.cssText="display:inline;margin:0;border:0;padding:1px;width:1px;zoom:1",k.inlineBlockNeedsLayout=a=3===b.offsetWidth,a&&(c.style.zoom=1)),c.removeChild(d))}),function(){var a=y.createElement("div");if(null==k.deleteExpando){k.deleteExpando=!0;try{delete a.test}catch(b){k.deleteExpando=!1}}a=null}(),m.acceptData=function(a){var b=m.noData[(a.nodeName+" ").toLowerCase()],c=+a.nodeType||1;return 1!==c&&9!==c?!1:!b||b!==!0&&a.getAttribute("classid")===b};var M=/^(?:\{[\w\W]*\}|\[[\w\W]*\])$/,N=/([A-Z])/g;function O(a,b,c){if(void 0===c&&1===a.nodeType){var d="data-"+b.replace(N,"-$1").toLowerCase();if(c=a.getAttribute(d),"string"==typeof c){try{c="true"===c?!0:"false"===c?!1:"null"===c?null:+c+""===c?+c:M.test(c)?m.parseJSON(c):c}catch(e){}m.data(a,b,c)}else c=void 0}return c}function P(a){var b;for(b in a)if(("data"!==b||!m.isEmptyObject(a[b]))&&"toJSON"!==b)return!1;

return!0}function Q(a,b,d,e){if(m.acceptData(a)){var f,g,h=m.expando,i=a.nodeType,j=i?m.cache:a,k=i?a[h]:a[h]&&h;if(k&&j[k]&&(e||j[k].data)||void 0!==d||"string"!=typeof b)return k||(k=i?a[h]=c.pop()||m.guid++:h),j[k]||(j[k]=i?{}:{toJSON:m.noop}),("object"==typeof b||"function"==typeof b)&&(e?j[k]=m.extend(j[k],b):j[k].data=m.extend(j[k].data,b)),g=j[k],e||(g.data||(g.data={}),g=g.data),void 0!==d&&(g[m.camelCase(b)]=d),"string"==typeof b?(f=g[b],null==f&&(f=g[m.camelCase(b)])):f=g,f}}function R(a,b,c){if(m.acceptData(a)){var d,e,f=a.nodeType,g=f?m.cache:a,h=f?a[m.expando]:m.expando;if(g[h]){if(b&&(d=c?g[h]:g[h].data)){m.isArray(b)?b=b.concat(m.map(b,m.camelCase)):b in d?b=[b]:(b=m.camelCase(b),b=b in d?[b]:b.split(" ")),e=b.length;while(e--)delete d[b[e]];if(c?!P(d):!m.isEmptyObject(d))return}(c||(delete g[h].data,P(g[h])))&&(f?m.cleanData([a],!0):k.deleteExpando||g!=g.window?delete g[h]:g[h]=null)}}}m.extend({cache:{},noData:{"applet ":!0,"embed ":!0,"object ":"clsid:D27CDB6E-AE6D-11cf-96B8-444553540000"},hasData:function(a){return a=a.nodeType?m.cache[a[m.expando]]:a[m.expando],!!a&&!P(a)},data:function(a,b,c){return Q(a,b,c)},removeData:function(a,b){return R(a,b)},_data:function(a,b,c){return Q(a,b,c,!0)},_removeData:function(a,b){return R(a,b,!0)}}),m.fn.extend({data:function(a,b){var c,d,e,f=this[0],g=f&&f.attributes;if(void 0===a){if(this.length&&(e=m.data(f),1===f.nodeType&&!m._data(f,"parsedAttrs"))){c=g.length;while(c--)g[c]&&(d=g[c].name,0===d.indexOf("data-")&&(d=m.camelCase(d.slice(5)),O(f,d,e[d])));m._data(f,"parsedAttrs",!0)}return e}return"object"==typeof a?this.each(function(){m.data(this,a)}):arguments.length>1?this.each(function(){m.data(this,a,b)}):f?O(f,a,m.data(f,a)):void 0},removeData:function(a){return this.each(function(){m.removeData(this,a)})}}),m.extend({queue:function(a,b,c){var d;return a?(b=(b||"fx")+"queue",d=m._data(a,b),c&&(!d||m.isArray(c)?d=m._data(a,b,m.makeArray(c)):d.push(c)),d||[]):void 0},dequeue:function(a,b){b=b||"fx";var c=m.queue(a,b),d=c.length,e=c.shift(),f=m._queueHooks(a,b),g=function(){m.dequeue(a,b)};"inprogress"===e&&(e=c.shift(),d--),e&&("fx"===b&&c.unshift("inprogress"),delete f.stop,e.call(a,g,f)),!d&&f&&f.empty.fire()},_queueHooks:function(a,b){var c=b+"queueHooks";return m._data(a,c)||m._data(a,c,{empty:m.Callbacks("once memory").add(function(){m._removeData(a,b+"queue"),m._removeData(a,c)})})}}),m.fn.extend({queue:function(a,b){var c=2;return"string"!=typeof a&&(b=a,a="fx",c--),arguments.length<c?m.queue(this[0],a):void 0===b?this:this.each(function(){var c=m.queue(this,a,b);m._queueHooks(this,a),"fx"===a&&"inprogress"!==c[0]&&m.dequeue(this,a)})},dequeue:function(a){return this.each(function(){m.dequeue(this,a)})},clearQueue:function(a){return this.queue(a||"fx",[])},promise:function(a,b){var c,d=1,e=m.Deferred(),f=this,g=this.length,h=function(){--d||e.resolveWith(f,[f])};"string"!=typeof a&&(b=a,a=void 0),a=a||"fx";while(g--)c=m._data(f[g],a+"queueHooks"),c&&c.empty&&(d++,c.empty.add(h));return h(),e.promise(b)}});var S=/[+-]?(?:\d*\.|)\d+(?:[eE][+-]?\d+|)/.source,T=["Top","Right","Bottom","Left"],U=function(a,b){return a=b||a,"none"===m.css(a,"display")||!m.contains(a.ownerDocument,a)},V=m.access=function(a,b,c,d,e,f,g){var h=0,i=a.length,j=null==c;if("object"===m.type(c)){e=!0;for(h in c)m.access(a,b,h,c[h],!0,f,g)}else if(void 0!==d&&(e=!0,m.isFunction(d)||(g=!0),j&&(g?(b.call(a,d),b=null):(j=b,b=function(a,b,c){return j.call(m(a),c)})),b))for(;i>h;h++)b(a[h],c,g?d:d.call(a[h],h,b(a[h],c)));return e?a:j?b.call(a):i?b(a[0],c):f},W=/^(?:checkbox|radio)$/i;!function(){var a=y.createElement("input"),b=y.createElement("div"),c=y.createDocumentFragment();if(b.innerHTML="  <link/><table></table><a href='/a'>a</a><input type='checkbox'/>",k.leadingWhitespace=3===b.firstChild.nodeType,k.tbody=!b.getElementsByTagName("tbody").length,k.htmlSerialize=!!b.getElementsByTagName("link").length,k.html5Clone="<:nav></:nav>"!==y.createElement("nav").cloneNode(!0).outerHTML,a.type="checkbox",a.checked=!0,c.appendChild(a),k.appendChecked=a.checked,b.innerHTML="<textarea>x</textarea>",k.noCloneChecked=!!b.cloneNode(!0).lastChild.defaultValue,c.appendChild(b),b.innerHTML="<input type='radio' checked='checked' name='t'/>",k.checkClone=b.cloneNode(!0).cloneNode(!0).lastChild.checked,k.noCloneEvent=!0,b.attachEvent&&(b.attachEvent("onclick",function(){k.noCloneEvent=!1}),b.cloneNode(!0).click()),null==k.deleteExpando){k.deleteExpando=!0;try{delete b.test}catch(d){k.deleteExpando=!1}}}(),function(){var b,c,d=y.createElement("div");for(b in{submit:!0,change:!0,focusin:!0})c="on"+b,(k[b+"Bubbles"]=c in a)||(d.setAttribute(c,"t"),k[b+"Bubbles"]=d.attributes[c].expando===!1);d=null}();var X=/^(?:input|select|textarea)$/i,Y=/^key/,Z=/^(?:mouse|pointer|contextmenu)|click/,$=/^(?:focusinfocus|focusoutblur)$/,_=/^([^.]*)(?:\.(.+)|)$/;function aa(){return!0}function ba(){return!1}function ca(){try{return y.activeElement}catch(a){}}m.event={global:{},add:function(a,b,c,d,e){var f,g,h,i,j,k,l,n,o,p,q,r=m._data(a);if(r){c.handler&&(i=c,c=i.handler,e=i.selector),c.guid||(c.guid=m.guid++),(g=r.events)||(g=r.events={}),(k=r.handle)||(k=r.handle=function(a){return typeof m===K||a&&m.event.triggered===a.type?void 0:m.event.dispatch.apply(k.elem,arguments)},k.elem=a),b=(b||"").match(E)||[""],h=b.length;while(h--)f=_.exec(b[h])||[],o=q=f[1],p=(f[2]||"").split(".").sort(),o&&(j=m.event.special[o]||{},o=(e?j.delegateType:j.bindType)||o,j=m.event.special[o]||{},l=m.extend({type:o,origType:q,data:d,handler:c,guid:c.guid,selector:e,needsContext:e&&m.expr.match.needsContext.test(e),namespace:p.join(".")},i),(n=g[o])||(n=g[o]=[],n.delegateCount=0,j.setup&&j.setup.call(a,d,p,k)!==!1||(a.addEventListener?a.addEventListener(o,k,!1):a.attachEvent&&a.attachEvent("on"+o,k))),j.add&&(j.add.call(a,l),l.handler.guid||(l.handler.guid=c.guid)),e?n.splice(n.delegateCount++,0,l):n.push(l),m.event.global[o]=!0);a=null}},remove:function(a,b,c,d,e){var f,g,h,i,j,k,l,n,o,p,q,r=m.hasData(a)&&m._data(a);if(r&&(k=r.events)){b=(b||"").match(E)||[""],j=b.length;while(j--)if(h=_.exec(b[j])||[],o=q=h[1],p=(h[2]||"").split(".").sort(),o){l=m.event.special[o]||{},o=(d?l.delegateType:l.bindType)||o,n=k[o]||[],h=h[2]&&new RegExp("(^|\\.)"+p.join("\\.(?:.*\\.|)")+"(\\.|$)"),i=f=n.length;while(f--)g=n[f],!e&&q!==g.origType||c&&c.guid!==g.guid||h&&!h.test(g.namespace)||d&&d!==g.selector&&("**"!==d||!g.selector)||(n.splice(f,1),g.selector&&n.delegateCount--,l.remove&&l.remove.call(a,g));i&&!n.length&&(l.teardown&&l.teardown.call(a,p,r.handle)!==!1||m.removeEvent(a,o,r.handle),delete k[o])}else for(o in k)m.event.remove(a,o+b[j],c,d,!0);m.isEmptyObject(k)&&(delete r.handle,m._removeData(a,"events"))}},trigger:function(b,c,d,e){var f,g,h,i,k,l,n,o=[d||y],p=j.call(b,"type")?b.type:b,q=j.call(b,"namespace")?b.namespace.split("."):[];if(h=l=d=d||y,3!==d.nodeType&&8!==d.nodeType&&!$.test(p+m.event.triggered)&&(p.indexOf(".")>=0&&(q=p.split("."),p=q.shift(),q.sort()),g=p.indexOf(":")<0&&"on"+p,b=b[m.expando]?b:new m.Event(p,"object"==typeof b&&b),b.isTrigger=e?2:3,b.namespace=q.join("."),b.namespace_re=b.namespace?new RegExp("(^|\\.)"+q.join("\\.(?:.*\\.|)")+"(\\.|$)"):null,b.result=void 0,b.target||(b.target=d),c=null==c?[b]:m.makeArray(c,[b]),k=m.event.special[p]||{},e||!k.trigger||k.trigger.apply(d,c)!==!1)){if(!e&&!k.noBubble&&!m.isWindow(d)){for(i=k.delegateType||p,$.test(i+p)||(h=h.parentNode);h;h=h.parentNode)o.push(h),l=h;l===(d.ownerDocument||y)&&o.push(l.defaultView||l.parentWindow||a)}n=0;while((h=o[n++])&&!b.isPropagationStopped())b.type=n>1?i:k.bindType||p,f=(m._data(h,"events")||{})[b.type]&&m._data(h,"handle"),f&&f.apply(h,c),f=g&&h[g],f&&f.apply&&m.acceptData(h)&&(b.result=f.apply(h,c),b.result===!1&&b.preventDefault());if(b.type=p,!e&&!b.isDefaultPrevented()&&(!k._default||k._default.apply(o.pop(),c)===!1)&&m.acceptData(d)&&g&&d[p]&&!m.isWindow(d)){l=d[g],l&&(d[g]=null),m.event.triggered=p;try{d[p]()}catch(r){}m.event.triggered=void 0,l&&(d[g]=l)}return b.result}},dispatch:function(a){a=m.event.fix(a);var b,c,e,f,g,h=[],i=d.call(arguments),j=(m._data(this,"events")||{})[a.type]||[],k=m.event.special[a.type]||{};if(i[0]=a,a.delegateTarget=this,!k.preDispatch||k.preDispatch.call(this,a)!==!1){h=m.event.handlers.call(this,a,j),b=0;while((f=h[b++])&&!a.isPropagationStopped()){a.currentTarget=f.elem,g=0;while((e=f.handlers[g++])&&!a.isImmediatePropagationStopped())(!a.namespace_re||a.namespace_re.test(e.namespace))&&(a.handleObj=e,a.data=e.data,c=((m.event.special[e.origType]||{}).handle||e.handler).apply(f.elem,i),void 0!==c&&(a.result=c)===!1&&(a.preventDefault(),a.stopPropagation()))}return k.postDispatch&&k.postDispatch.call(this,a),a.result}},handlers:function(a,b){var c,d,e,f,g=[],h=b.delegateCount,i=a.target;if(h&&i.nodeType&&(!a.button||"click"!==a.type))for(;i!=this;i=i.parentNode||this)if(1===i.nodeType&&(i.disabled!==!0||"click"!==a.type)){for(e=[],f=0;h>f;f++)d=b[f],c=d.selector+" ",void 0===e[c]&&(e[c]=d.needsContext?m(c,this).index(i)>=0:m.find(c,this,null,[i]).length),e[c]&&e.push(d);e.length&&g.push({elem:i,handlers:e})}return h<b.length&&g.push({elem:this,handlers:b.slice(h)}),g},fix:function(a){if(a[m.expando])return a;var b,c,d,e=a.type,f=a,g=this.fixHooks[e];g||(this.fixHooks[e]=g=Z.test(e)?this.mouseHooks:Y.test(e)?this.keyHooks:{}),d=g.props?this.props.concat(g.props):this.props,a=new m.Event(f),b=d.length;while(b--)c=d[b],a[c]=f[c];return a.target||(a.target=f.srcElement||y),3===a.target.nodeType&&(a.target=a.target.parentNode),a.metaKey=!!a.metaKey,g.filter?g.filter(a,f):a},props:"altKey bubbles cancelable ctrlKey currentTarget eventPhase metaKey relatedTarget shiftKey target timeStamp view which".split(" "),fixHooks:{},keyHooks:{props:"char charCode key keyCode".split(" "),filter:function(a,b){return null==a.which&&(a.which=null!=b.charCode?b.charCode:b.keyCode),a}},mouseHooks:{props:"button buttons clientX clientY fromElement offsetX offsetY pageX pageY screenX screenY toElement".split(" "),filter:function(a,b){var c,d,e,f=b.button,g=b.fromElement;return null==a.pageX&&null!=b.clientX&&(d=a.target.ownerDocument||y,e=d.documentElement,c=d.body,a.pageX=b.clientX+(e&&e.scrollLeft||c&&c.scrollLeft||0)-(e&&e.clientLeft||c&&c.clientLeft||0),a.pageY=b.clientY+(e&&e.scrollTop||c&&c.scrollTop||0)-(e&&e.clientTop||c&&c.clientTop||0)),!a.relatedTarget&&g&&(a.relatedTarget=g===a.target?b.toElement:g),a.which||void 0===f||(a.which=1&f?1:2&f?3:4&f?2:0),a}},special:{load:{noBubble:!0},focus:{trigger:function(){if(this!==ca()&&this.focus)try{return this.focus(),!1}catch(a){}},delegateType:"focusin"},blur:{trigger:function(){return this===ca()&&this.blur?(this.blur(),!1):void 0},delegateType:"focusout"},click:{trigger:function(){return m.nodeName(this,"input")&&"checkbox"===this.type&&this.click?(this.click(),!1):void 0},_default:function(a){return m.nodeName(a.target,"a")}},beforeunload:{postDispatch:function(a){void 0!==a.result&&a.originalEvent&&(a.originalEvent.returnValue=a.result)}}},simulate:function(a,b,c,d){var e=m.extend(new m.Event,c,{type:a,isSimulated:!0,originalEvent:{}});d?m.event.trigger(e,null,b):m.event.dispatch.call(b,e),e.isDefaultPrevented()&&c.preventDefault()}},m.removeEvent=y.removeEventListener?function(a,b,c){a.removeEventListener&&a.removeEventListener(b,c,!1)}:function(a,b,c){var d="on"+b;a.detachEvent&&(typeof a[d]===K&&(a[d]=null),a.detachEvent(d,c))},m.Event=function(a,b){return this instanceof m.Event?(a&&a.type?(this.originalEvent=a,this.type=a.type,this.isDefaultPrevented=a.defaultPrevented||void 0===a.defaultPrevented&&a.returnValue===!1?aa:ba):this.type=a,b&&m.extend(this,b),this.timeStamp=a&&a.timeStamp||m.now(),void(this[m.expando]=!0)):new m.Event(a,b)},m.Event.prototype={isDefaultPrevented:ba,isPropagationStopped:ba,isImmediatePropagationStopped:ba,preventDefault:function(){var a=this.originalEvent;this.isDefaultPrevented=aa,a&&(a.preventDefault?a.preventDefault():a.returnValue=!1)},stopPropagation:function(){var a=this.originalEvent;this.isPropagationStopped=aa,a&&(a.stopPropagation&&a.stopPropagation(),a.cancelBubble=!0)},stopImmediatePropagation:function(){var a=this.originalEvent;this.isImmediatePropagationStopped=aa,a&&a.stopImmediatePropagation&&a.stopImmediatePropagation(),this.stopPropagation()}},m.each({mouseenter:"mouseover",mouseleave:"mouseout",pointerenter:"pointerover",pointerleave:"pointerout"},function(a,b){m.event.special[a]={delegateType:b,bindType:b,handle:function(a){var c,d=this,e=a.relatedTarget,f=a.handleObj;return(!e||e!==d&&!m.contains(d,e))&&(a.type=f.origType,c=f.handler.apply(this,arguments),a.type=b),c}}}),k.submitBubbles||(m.event.special.submit={setup:function(){return m.nodeName(this,"form")?!1:void m.event.add(this,"click._submit keypress._submit",function(a){var b=a.target,c=m.nodeName(b,"input")||m.nodeName(b,"button")?b.form:void 0;c&&!m._data(c,"submitBubbles")&&(m.event.add(c,"submit._submit",function(a){a._submit_bubble=!0}),m._data(c,"submitBubbles",!0))})},postDispatch:function(a){a._submit_bubble&&(delete a._submit_bubble,this.parentNode&&!a.isTrigger&&m.event.simulate("submit",this.parentNode,a,!0))},teardown:function(){return m.nodeName(this,"form")?!1:void m.event.remove(this,"._submit")}}),k.changeBubbles||(m.event.special.change={setup:function(){return X.test(this.nodeName)?(("checkbox"===this.type||"radio"===this.type)&&(m.event.add(this,"propertychange._change",function(a){"checked"===a.originalEvent.propertyName&&(this._just_changed=!0)}),m.event.add(this,"click._change",function(a){this._just_changed&&!a.isTrigger&&(this._just_changed=!1),m.event.simulate("change",this,a,!0)})),!1):void m.event.add(this,"beforeactivate._change",function(a){var b=a.target;X.test(b.nodeName)&&!m._data(b,"changeBubbles")&&(m.event.add(b,"change._change",function(a){!this.parentNode||a.isSimulated||a.isTrigger||m.event.simulate("change",this.parentNode,a,!0)}),m._data(b,"changeBubbles",!0))})},handle:function(a){var b=a.target;return this!==b||a.isSimulated||a.isTrigger||"radio"!==b.type&&"checkbox"!==b.type?a.handleObj.handler.apply(this,arguments):void 0},teardown:function(){return m.event.remove(this,"._change"),!X.test(this.nodeName)}}),k.focusinBubbles||m.each({focus:"focusin",blur:"focusout"},function(a,b){var c=function(a){m.event.simulate(b,a.target,m.event.fix(a),!0)};m.event.special[b]={setup:function(){var d=this.ownerDocument||this,e=m._data(d,b);e||d.addEventListener(a,c,!0),m._data(d,b,(e||0)+1)},teardown:function(){var d=this.ownerDocument||this,e=m._data(d,b)-1;e?m._data(d,b,e):(d.removeEventListener(a,c,!0),m._removeData(d,b))}}}),m.fn.extend({on:function(a,b,c,d,e){var f,g;if("object"==typeof a){"string"!=typeof b&&(c=c||b,b=void 0);for(f in a)this.on(f,b,c,a[f],e);return this}if(null==c&&null==d?(d=b,c=b=void 0):null==d&&("string"==typeof b?(d=c,c=void 0):(d=c,c=b,b=void 0)),d===!1)d=ba;else if(!d)return this;return 1===e&&(g=d,d=function(a){return m().off(a),g.apply(this,arguments)},d.guid=g.guid||(g.guid=m.guid++)),this.each(function(){m.event.add(this,a,d,c,b)})},one:function(a,b,c,d){return this.on(a,b,c,d,1)},off:function(a,b,c){var d,e;if(a&&a.preventDefault&&a.handleObj)return d=a.handleObj,m(a.delegateTarget).off(d.namespace?d.origType+"."+d.namespace:d.origType,d.selector,d.handler),this;if("object"==typeof a){for(e in a)this.off(e,b,a[e]);return this}return(b===!1||"function"==typeof b)&&(c=b,b=void 0),c===!1&&(c=ba),this.each(function(){m.event.remove(this,a,c,b)})},trigger:function(a,b){return this.each(function(){m.event.trigger(a,b,this)})},triggerHandler:function(a,b){var c=this[0];return c?m.event.trigger(a,b,c,!0):void 0}});function da(a){var b=ea.split("|"),c=a.createDocumentFragment();if(c.createElement)while(b.length)c.createElement(b.pop());return c}var ea="abbr|article|aside|audio|bdi|canvas|data|datalist|details|figcaption|figure|footer|header|hgroup|mark|meter|nav|output|progress|section|summary|time|video",fa=/ jQuery\d+="(?:null|\d+)"/g,ga=new RegExp("<(?:"+ea+")[\\s/>]","i"),ha=/^\s+/,ia=/<(?!area|br|col|embed|hr|img|input|link|meta|param)(([\w:]+)[^>]*)\/>/gi,ja=/<([\w:]+)/,ka=/<tbody/i,la=/<|&#?\w+;/,ma=/<(?:script|style|link)/i,na=/checked\s*(?:[^=]|=\s*.checked.)/i,oa=/^$|\/(?:java|ecma)script/i,pa=/^true\/(.*)/,qa=/^\s*<!(?:\[CDATA\[|--)|(?:\]\]|--)>\s*$/g,ra={option:[1,"<select multiple='multiple'>","</select>"],legend:[1,"<fieldset>","</fieldset>"],area:[1,"<map>","</map>"],param:[1,"<object>","</object>"],thead:[1,"<table>","</table>"],tr:[2,"<table><tbody>","</tbody></table>"],col:[2,"<table><tbody></tbody><colgroup>","</colgroup></table>"],td:[3,"<table><tbody><tr>","</tr></tbody></table>"],_default:k.htmlSerialize?[0,"",""]:[1,"X<div>","</div>"]},sa=da(y),ta=sa.appendChild(y.createElement("div"));ra.optgroup=ra.option,ra.tbody=ra.tfoot=ra.colgroup=ra.caption=ra.thead,ra.th=ra.td;function ua(a,b){var c,d,e=0,f=typeof a.getElementsByTagName!==K?a.getElementsByTagName(b||"*"):typeof a.querySelectorAll!==K?a.querySelectorAll(b||"*"):void 0;if(!f)for(f=[],c=a.childNodes||a;null!=(d=c[e]);e++)!b||m.nodeName(d,b)?f.push(d):m.merge(f,ua(d,b));return void 0===b||b&&m.nodeName(a,b)?m.merge([a],f):f}function va(a){W.test(a.type)&&(a.defaultChecked=a.checked)}function wa(a,b){return m.nodeName(a,"table")&&m.nodeName(11!==b.nodeType?b:b.firstChild,"tr")?a.getElementsByTagName("tbody")[0]||a.appendChild(a.ownerDocument.createElement("tbody")):a}function xa(a){return a.type=(null!==m.find.attr(a,"type"))+"/"+a.type,a}function ya(a){var b=pa.exec(a.type);return b?a.type=b[1]:a.removeAttribute("type"),a}function za(a,b){for(var c,d=0;null!=(c=a[d]);d++)m._data(c,"globalEval",!b||m._data(b[d],"globalEval"))}function Aa(a,b){if(1===b.nodeType&&m.hasData(a)){var c,d,e,f=m._data(a),g=m._data(b,f),h=f.events;if(h){delete g.handle,g.events={};for(c in h)for(d=0,e=h[c].length;e>d;d++)m.event.add(b,c,h[c][d])}g.data&&(g.data=m.extend({},g.data))}}function Ba(a,b){var c,d,e;if(1===b.nodeType){if(c=b.nodeName.toLowerCase(),!k.noCloneEvent&&b[m.expando]){e=m._data(b);for(d in e.events)m.removeEvent(b,d,e.handle);b.removeAttribute(m.expando)}"script"===c&&b.text!==a.text?(xa(b).text=a.text,ya(b)):"object"===c?(b.parentNode&&(b.outerHTML=a.outerHTML),k.html5Clone&&a.innerHTML&&!m.trim(b.innerHTML)&&(b.innerHTML=a.innerHTML)):"input"===c&&W.test(a.type)?(b.defaultChecked=b.checked=a.checked,b.value!==a.value&&(b.value=a.value)):"option"===c?b.defaultSelected=b.selected=a.defaultSelected:("input"===c||"textarea"===c)&&(b.defaultValue=a.defaultValue)}}m.extend({clone:function(a,b,c){var d,e,f,g,h,i=m.contains(a.ownerDocument,a);if(k.html5Clone||m.isXMLDoc(a)||!ga.test("<"+a.nodeName+">")?f=a.cloneNode(!0):(ta.innerHTML=a.outerHTML,ta.removeChild(f=ta.firstChild)),!(k.noCloneEvent&&k.noCloneChecked||1!==a.nodeType&&11!==a.nodeType||m.isXMLDoc(a)))for(d=ua(f),h=ua(a),g=0;null!=(e=h[g]);++g)d[g]&&Ba(e,d[g]);if(b)if(c)for(h=h||ua(a),d=d||ua(f),g=0;null!=(e=h[g]);g++)Aa(e,d[g]);else Aa(a,f);return d=ua(f,"script"),d.length>0&&za(d,!i&&ua(a,"script")),d=h=e=null,f},buildFragment:function(a,b,c,d){for(var e,f,g,h,i,j,l,n=a.length,o=da(b),p=[],q=0;n>q;q++)if(f=a[q],f||0===f)if("object"===m.type(f))m.merge(p,f.nodeType?[f]:f);else if(la.test(f)){h=h||o.appendChild(b.createElement("div")),i=(ja.exec(f)||["",""])[1].toLowerCase(),l=ra[i]||ra._default,h.innerHTML=l[1]+f.replace(ia,"<$1></$2>")+l[2],e=l[0];while(e--)h=h.lastChild;if(!k.leadingWhitespace&&ha.test(f)&&p.push(b.createTextNode(ha.exec(f)[0])),!k.tbody){f="table"!==i||ka.test(f)?"<table>"!==l[1]||ka.test(f)?0:h:h.firstChild,e=f&&f.childNodes.length;while(e--)m.nodeName(j=f.childNodes[e],"tbody")&&!j.childNodes.length&&f.removeChild(j)}m.merge(p,h.childNodes),h.textContent="";while(h.firstChild)h.removeChild(h.firstChild);h=o.lastChild}else p.push(b.createTextNode(f));h&&o.removeChild(h),k.appendChecked||m.grep(ua(p,"input"),va),q=0;while(f=p[q++])if((!d||-1===m.inArray(f,d))&&(g=m.contains(f.ownerDocument,f),h=ua(o.appendChild(f),"script"),g&&za(h),c)){e=0;while(f=h[e++])oa.test(f.type||"")&&c.push(f)}return h=null,o},cleanData:function(a,b){for(var d,e,f,g,h=0,i=m.expando,j=m.cache,l=k.deleteExpando,n=m.event.special;null!=(d=a[h]);h++)if((b||m.acceptData(d))&&(f=d[i],g=f&&j[f])){if(g.events)for(e in g.events)n[e]?m.event.remove(d,e):m.removeEvent(d,e,g.handle);j[f]&&(delete j[f],l?delete d[i]:typeof d.removeAttribute!==K?d.removeAttribute(i):d[i]=null,c.push(f))}}}),m.fn.extend({text:function(a){return V(this,function(a){return void 0===a?m.text(this):this.empty().append((this[0]&&this[0].ownerDocument||y).createTextNode(a))},null,a,arguments.length)},append:function(){return this.domManip(arguments,function(a){if(1===this.nodeType||11===this.nodeType||9===this.nodeType){var b=wa(this,a);b.appendChild(a)}})},prepend:function(){return this.domManip(arguments,function(a){if(1===this.nodeType||11===this.nodeType||9===this.nodeType){var b=wa(this,a);b.insertBefore(a,b.firstChild)}})},before:function(){return this.domManip(arguments,function(a){this.parentNode&&this.parentNode.insertBefore(a,this)})},after:function(){return this.domManip(arguments,function(a){this.parentNode&&this.parentNode.insertBefore(a,this.nextSibling)})},remove:function(a,b){for(var c,d=a?m.filter(a,this):this,e=0;null!=(c=d[e]);e++)b||1!==c.nodeType||m.cleanData(ua(c)),c.parentNode&&(b&&m.contains(c.ownerDocument,c)&&za(ua(c,"script")),c.parentNode.removeChild(c));return this},empty:function(){for(var a,b=0;null!=(a=this[b]);b++){1===a.nodeType&&m.cleanData(ua(a,!1));while(a.firstChild)a.removeChild(a.firstChild);a.options&&m.nodeName(a,"select")&&(a.options.length=0)}return this},clone:function(a,b){return a=null==a?!1:a,b=null==b?a:b,this.map(function(){return m.clone(this,a,b)})},html:function(a){return V(this,function(a){var b=this[0]||{},c=0,d=this.length;if(void 0===a)return 1===b.nodeType?b.innerHTML.replace(fa,""):void 0;if(!("string"!=typeof a||ma.test(a)||!k.htmlSerialize&&ga.test(a)||!k.leadingWhitespace&&ha.test(a)||ra[(ja.exec(a)||["",""])[1].toLowerCase()])){a=a.replace(ia,"<$1></$2>");try{for(;d>c;c++)b=this[c]||{},1===b.nodeType&&(m.cleanData(ua(b,!1)),b.innerHTML=a);b=0}catch(e){}}b&&this.empty().append(a)},null,a,arguments.length)},replaceWith:function(){var a=arguments[0];return this.domManip(arguments,function(b){a=this.parentNode,m.cleanData(ua(this)),a&&a.replaceChild(b,this)}),a&&(a.length||a.nodeType)?this:this.remove()},detach:function(a){return this.remove(a,!0)},domManip:function(a,b){a=e.apply([],a);var c,d,f,g,h,i,j=0,l=this.length,n=this,o=l-1,p=a[0],q=m.isFunction(p);if(q||l>1&&"string"==typeof p&&!k.checkClone&&na.test(p))return this.each(function(c){var d=n.eq(c);q&&(a[0]=p.call(this,c,d.html())),d.domManip(a,b)});if(l&&(i=m.buildFragment(a,this[0].ownerDocument,!1,this),c=i.firstChild,1===i.childNodes.length&&(i=c),c)){for(g=m.map(ua(i,"script"),xa),f=g.length;l>j;j++)d=i,j!==o&&(d=m.clone(d,!0,!0),f&&m.merge(g,ua(d,"script"))),b.call(this[j],d,j);if(f)for(h=g[g.length-1].ownerDocument,m.map(g,ya),j=0;f>j;j++)d=g[j],oa.test(d.type||"")&&!m._data(d,"globalEval")&&m.contains(h,d)&&(d.src?m._evalUrl&&m._evalUrl(d.src):m.globalEval((d.text||d.textContent||d.innerHTML||"").replace(qa,"")));i=c=null}return this}}),m.each({appendTo:"append",prependTo:"prepend",insertBefore:"before",insertAfter:"after",replaceAll:"replaceWith"},function(a,b){m.fn[a]=function(a){for(var c,d=0,e=[],g=m(a),h=g.length-1;h>=d;d++)c=d===h?this:this.clone(!0),m(g[d])[b](c),f.apply(e,c.get());return this.pushStack(e)}});var Ca,Da={};function Ea(b,c){var d,e=m(c.createElement(b)).appendTo(c.body),f=a.getDefaultComputedStyle&&(d=a.getDefaultComputedStyle(e[0]))?d.display:m.css(e[0],"display");return e.detach(),f}function Fa(a){var b=y,c=Da[a];return c||(c=Ea(a,b),"none"!==c&&c||(Ca=(Ca||m("<iframe frameborder='0' width='0' height='0'/>")).appendTo(b.documentElement),b=(Ca[0].contentWindow||Ca[0].contentDocument).document,b.write(),b.close(),c=Ea(a,b),Ca.detach()),Da[a]=c),c}!function(){var a;k.shrinkWrapBlocks=function(){if(null!=a)return a;a=!1;var b,c,d;return c=y.getElementsByTagName("body")[0],c&&c.style?(b=y.createElement("div"),d=y.createElement("div"),d.style.cssText="position:absolute;border:0;width:0;height:0;top:0;left:-9999px",c.appendChild(d).appendChild(b),typeof b.style.zoom!==K&&(b.style.cssText="-webkit-box-sizing:content-box;-moz-box-sizing:content-box;box-sizing:content-box;display:block;margin:0;border:0;padding:1px;width:1px;zoom:1",b.appendChild(y.createElement("div")).style.width="5px",a=3!==b.offsetWidth),c.removeChild(d),a):void 0}}();var Ga=/^margin/,Ha=new RegExp("^("+S+")(?!px)[a-z%]+$","i"),Ia,Ja,Ka=/^(top|right|bottom|left)$/;a.getComputedStyle?(Ia=function(b){return b.ownerDocument.defaultView.opener?b.ownerDocument.defaultView.getComputedStyle(b,null):a.getComputedStyle(b,null)},Ja=function(a,b,c){var d,e,f,g,h=a.style;return c=c||Ia(a),g=c?c.getPropertyValue(b)||c[b]:void 0,c&&(""!==g||m.contains(a.ownerDocument,a)||(g=m.style(a,b)),Ha.test(g)&&Ga.test(b)&&(d=h.width,e=h.minWidth,f=h.maxWidth,h.minWidth=h.maxWidth=h.width=g,g=c.width,h.width=d,h.minWidth=e,h.maxWidth=f)),void 0===g?g:g+""}):y.documentElement.currentStyle&&(Ia=function(a){return a.currentStyle},Ja=function(a,b,c){var d,e,f,g,h=a.style;return c=c||Ia(a),g=c?c[b]:void 0,null==g&&h&&h[b]&&(g=h[b]),Ha.test(g)&&!Ka.test(b)&&(d=h.left,e=a.runtimeStyle,f=e&&e.left,f&&(e.left=a.currentStyle.left),h.left="fontSize"===b?"1em":g,g=h.pixelLeft+"px",h.left=d,f&&(e.left=f)),void 0===g?g:g+""||"auto"});function La(a,b){return{get:function(){var c=a();if(null!=c)return c?void delete this.get:(this.get=b).apply(this,arguments)}}}!function(){var b,c,d,e,f,g,h;if(b=y.createElement("div"),b.innerHTML="  <link/><table></table><a href='/a'>a</a><input type='checkbox'/>",d=b.getElementsByTagName("a")[0],c=d&&d.style){c.cssText="float:left;opacity:.5",k.opacity="0.5"===c.opacity,k.cssFloat=!!c.cssFloat,b.style.backgroundClip="content-box",b.cloneNode(!0).style.backgroundClip="",k.clearCloneStyle="content-box"===b.style.backgroundClip,k.boxSizing=""===c.boxSizing||""===c.MozBoxSizing||""===c.WebkitBoxSizing,m.extend(k,{reliableHiddenOffsets:function(){return null==g&&i(),g},boxSizingReliable:function(){return null==f&&i(),f},pixelPosition:function(){return null==e&&i(),e},reliableMarginRight:function(){return null==h&&i(),h}});function i(){var b,c,d,i;c=y.getElementsByTagName("body")[0],c&&c.style&&(b=y.createElement("div"),d=y.createElement("div"),d.style.cssText="position:absolute;border:0;width:0;height:0;top:0;left:-9999px",c.appendChild(d).appendChild(b),b.style.cssText="-webkit-box-sizing:border-box;-moz-box-sizing:border-box;box-sizing:border-box;display:block;margin-top:1%;top:1%;border:1px;padding:1px;width:4px;position:absolute",e=f=!1,h=!0,a.getComputedStyle&&(e="1%"!==(a.getComputedStyle(b,null)||{}).top,f="4px"===(a.getComputedStyle(b,null)||{width:"4px"}).width,i=b.appendChild(y.createElement("div")),i.style.cssText=b.style.cssText="-webkit-box-sizing:content-box;-moz-box-sizing:content-box;box-sizing:content-box;display:block;margin:0;border:0;padding:0",i.style.marginRight=i.style.width="0",b.style.width="1px",h=!parseFloat((a.getComputedStyle(i,null)||{}).marginRight),b.removeChild(i)),b.innerHTML="<table><tr><td></td><td>t</td></tr></table>",i=b.getElementsByTagName("td"),i[0].style.cssText="margin:0;border:0;padding:0;display:none",g=0===i[0].offsetHeight,g&&(i[0].style.display="",i[1].style.display="none",g=0===i[0].offsetHeight),c.removeChild(d))}}}(),m.swap=function(a,b,c,d){var e,f,g={};for(f in b)g[f]=a.style[f],a.style[f]=b[f];e=c.apply(a,d||[]);for(f in b)a.style[f]=g[f];return e};var Ma=/alpha\([^)]*\)/i,Na=/opacity\s*=\s*([^)]*)/,Oa=/^(none|table(?!-c[ea]).+)/,Pa=new RegExp("^("+S+")(.*)$","i"),Qa=new RegExp("^([+-])=("+S+")","i"),Ra={position:"absolute",visibility:"hidden",display:"block"},Sa={letterSpacing:"0",fontWeight:"400"},Ta=["Webkit","O","Moz","ms"];function Ua(a,b){if(b in a)return b;var c=b.charAt(0).toUpperCase()+b.slice(1),d=b,e=Ta.length;while(e--)if(b=Ta[e]+c,b in a)return b;return d}function Va(a,b){for(var c,d,e,f=[],g=0,h=a.length;h>g;g++)d=a[g],d.style&&(f[g]=m._data(d,"olddisplay"),c=d.style.display,b?(f[g]||"none"!==c||(d.style.display=""),""===d.style.display&&U(d)&&(f[g]=m._data(d,"olddisplay",Fa(d.nodeName)))):(e=U(d),(c&&"none"!==c||!e)&&m._data(d,"olddisplay",e?c:m.css(d,"display"))));for(g=0;h>g;g++)d=a[g],d.style&&(b&&"none"!==d.style.display&&""!==d.style.display||(d.style.display=b?f[g]||"":"none"));return a}function Wa(a,b,c){var d=Pa.exec(b);return d?Math.max(0,d[1]-(c||0))+(d[2]||"px"):b}function Xa(a,b,c,d,e){for(var f=c===(d?"border":"content")?4:"width"===b?1:0,g=0;4>f;f+=2)"margin"===c&&(g+=m.css(a,c+T[f],!0,e)),d?("content"===c&&(g-=m.css(a,"padding"+T[f],!0,e)),"margin"!==c&&(g-=m.css(a,"border"+T[f]+"Width",!0,e))):(g+=m.css(a,"padding"+T[f],!0,e),"padding"!==c&&(g+=m.css(a,"border"+T[f]+"Width",!0,e)));return g}function Ya(a,b,c){var d=!0,e="width"===b?a.offsetWidth:a.offsetHeight,f=Ia(a),g=k.boxSizing&&"border-box"===m.css(a,"boxSizing",!1,f);if(0>=e||null==e){if(e=Ja(a,b,f),(0>e||null==e)&&(e=a.style[b]),Ha.test(e))return e;d=g&&(k.boxSizingReliable()||e===a.style[b]),e=parseFloat(e)||0}return e+Xa(a,b,c||(g?"border":"content"),d,f)+"px"}m.extend({cssHooks:{opacity:{get:function(a,b){if(b){var c=Ja(a,"opacity");return""===c?"1":c}}}},cssNumber:{columnCount:!0,fillOpacity:!0,flexGrow:!0,flexShrink:!0,fontWeight:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,widows:!0,zIndex:!0,zoom:!0},cssProps:{"float":k.cssFloat?"cssFloat":"styleFloat"},style:function(a,b,c,d){if(a&&3!==a.nodeType&&8!==a.nodeType&&a.style){var e,f,g,h=m.camelCase(b),i=a.style;if(b=m.cssProps[h]||(m.cssProps[h]=Ua(i,h)),g=m.cssHooks[b]||m.cssHooks[h],void 0===c)return g&&"get"in g&&void 0!==(e=g.get(a,!1,d))?e:i[b];if(f=typeof c,"string"===f&&(e=Qa.exec(c))&&(c=(e[1]+1)*e[2]+parseFloat(m.css(a,b)),f="number"),null!=c&&c===c&&("number"!==f||m.cssNumber[h]||(c+="px"),k.clearCloneStyle||""!==c||0!==b.indexOf("background")||(i[b]="inherit"),!(g&&"set"in g&&void 0===(c=g.set(a,c,d)))))try{i[b]=c}catch(j){}}},css:function(a,b,c,d){var e,f,g,h=m.camelCase(b);return b=m.cssProps[h]||(m.cssProps[h]=Ua(a.style,h)),g=m.cssHooks[b]||m.cssHooks[h],g&&"get"in g&&(f=g.get(a,!0,c)),void 0===f&&(f=Ja(a,b,d)),"normal"===f&&b in Sa&&(f=Sa[b]),""===c||c?(e=parseFloat(f),c===!0||m.isNumeric(e)?e||0:f):f}}),m.each(["height","width"],function(a,b){m.cssHooks[b]={get:function(a,c,d){return c?Oa.test(m.css(a,"display"))&&0===a.offsetWidth?m.swap(a,Ra,function(){return Ya(a,b,d)}):Ya(a,b,d):void 0},set:function(a,c,d){var e=d&&Ia(a);return Wa(a,c,d?Xa(a,b,d,k.boxSizing&&"border-box"===m.css(a,"boxSizing",!1,e),e):0)}}}),k.opacity||(m.cssHooks.opacity={get:function(a,b){return Na.test((b&&a.currentStyle?a.currentStyle.filter:a.style.filter)||"")?.01*parseFloat(RegExp.$1)+"":b?"1":""},set:function(a,b){var c=a.style,d=a.currentStyle,e=m.isNumeric(b)?"alpha(opacity="+100*b+")":"",f=d&&d.filter||c.filter||"";c.zoom=1,(b>=1||""===b)&&""===m.trim(f.replace(Ma,""))&&c.removeAttribute&&(c.removeAttribute("filter"),""===b||d&&!d.filter)||(c.filter=Ma.test(f)?f.replace(Ma,e):f+" "+e)}}),m.cssHooks.marginRight=La(k.reliableMarginRight,function(a,b){return b?m.swap(a,{display:"inline-block"},Ja,[a,"marginRight"]):void 0}),m.each({margin:"",padding:"",border:"Width"},function(a,b){m.cssHooks[a+b]={expand:function(c){for(var d=0,e={},f="string"==typeof c?c.split(" "):[c];4>d;d++)e[a+T[d]+b]=f[d]||f[d-2]||f[0];return e}},Ga.test(a)||(m.cssHooks[a+b].set=Wa)}),m.fn.extend({css:function(a,b){return V(this,function(a,b,c){var d,e,f={},g=0;if(m.isArray(b)){for(d=Ia(a),e=b.length;e>g;g++)f[b[g]]=m.css(a,b[g],!1,d);return f}return void 0!==c?m.style(a,b,c):m.css(a,b)},a,b,arguments.length>1)},show:function(){return Va(this,!0)},hide:function(){return Va(this)},toggle:function(a){return"boolean"==typeof a?a?this.show():this.hide():this.each(function(){U(this)?m(this).show():m(this).hide()})}});function Za(a,b,c,d,e){
return new Za.prototype.init(a,b,c,d,e)}m.Tween=Za,Za.prototype={constructor:Za,init:function(a,b,c,d,e,f){this.elem=a,this.prop=c,this.easing=e||"swing",this.options=b,this.start=this.now=this.cur(),this.end=d,this.unit=f||(m.cssNumber[c]?"":"px")},cur:function(){var a=Za.propHooks[this.prop];return a&&a.get?a.get(this):Za.propHooks._default.get(this)},run:function(a){var b,c=Za.propHooks[this.prop];return this.options.duration?this.pos=b=m.easing[this.easing](a,this.options.duration*a,0,1,this.options.duration):this.pos=b=a,this.now=(this.end-this.start)*b+this.start,this.options.step&&this.options.step.call(this.elem,this.now,this),c&&c.set?c.set(this):Za.propHooks._default.set(this),this}},Za.prototype.init.prototype=Za.prototype,Za.propHooks={_default:{get:function(a){var b;return null==a.elem[a.prop]||a.elem.style&&null!=a.elem.style[a.prop]?(b=m.css(a.elem,a.prop,""),b&&"auto"!==b?b:0):a.elem[a.prop]},set:function(a){m.fx.step[a.prop]?m.fx.step[a.prop](a):a.elem.style&&(null!=a.elem.style[m.cssProps[a.prop]]||m.cssHooks[a.prop])?m.style(a.elem,a.prop,a.now+a.unit):a.elem[a.prop]=a.now}}},Za.propHooks.scrollTop=Za.propHooks.scrollLeft={set:function(a){a.elem.nodeType&&a.elem.parentNode&&(a.elem[a.prop]=a.now)}},m.easing={linear:function(a){return a},swing:function(a){return.5-Math.cos(a*Math.PI)/2}},m.fx=Za.prototype.init,m.fx.step={};var $a,_a,ab=/^(?:toggle|show|hide)$/,bb=new RegExp("^(?:([+-])=|)("+S+")([a-z%]*)$","i"),cb=/queueHooks$/,db=[ib],eb={"*":[function(a,b){var c=this.createTween(a,b),d=c.cur(),e=bb.exec(b),f=e&&e[3]||(m.cssNumber[a]?"":"px"),g=(m.cssNumber[a]||"px"!==f&&+d)&&bb.exec(m.css(c.elem,a)),h=1,i=20;if(g&&g[3]!==f){f=f||g[3],e=e||[],g=+d||1;do h=h||".5",g/=h,m.style(c.elem,a,g+f);while(h!==(h=c.cur()/d)&&1!==h&&--i)}return e&&(g=c.start=+g||+d||0,c.unit=f,c.end=e[1]?g+(e[1]+1)*e[2]:+e[2]),c}]};function fb(){return setTimeout(function(){$a=void 0}),$a=m.now()}function gb(a,b){var c,d={height:a},e=0;for(b=b?1:0;4>e;e+=2-b)c=T[e],d["margin"+c]=d["padding"+c]=a;return b&&(d.opacity=d.width=a),d}function hb(a,b,c){for(var d,e=(eb[b]||[]).concat(eb["*"]),f=0,g=e.length;g>f;f++)if(d=e[f].call(c,b,a))return d}function ib(a,b,c){var d,e,f,g,h,i,j,l,n=this,o={},p=a.style,q=a.nodeType&&U(a),r=m._data(a,"fxshow");c.queue||(h=m._queueHooks(a,"fx"),null==h.unqueued&&(h.unqueued=0,i=h.empty.fire,h.empty.fire=function(){h.unqueued||i()}),h.unqueued++,n.always(function(){n.always(function(){h.unqueued--,m.queue(a,"fx").length||h.empty.fire()})})),1===a.nodeType&&("height"in b||"width"in b)&&(c.overflow=[p.overflow,p.overflowX,p.overflowY],j=m.css(a,"display"),l="none"===j?m._data(a,"olddisplay")||Fa(a.nodeName):j,"inline"===l&&"none"===m.css(a,"float")&&(k.inlineBlockNeedsLayout&&"inline"!==Fa(a.nodeName)?p.zoom=1:p.display="inline-block")),c.overflow&&(p.overflow="hidden",k.shrinkWrapBlocks()||n.always(function(){p.overflow=c.overflow[0],p.overflowX=c.overflow[1],p.overflowY=c.overflow[2]}));for(d in b)if(e=b[d],ab.exec(e)){if(delete b[d],f=f||"toggle"===e,e===(q?"hide":"show")){if("show"!==e||!r||void 0===r[d])continue;q=!0}o[d]=r&&r[d]||m.style(a,d)}else j=void 0;if(m.isEmptyObject(o))"inline"===("none"===j?Fa(a.nodeName):j)&&(p.display=j);else{r?"hidden"in r&&(q=r.hidden):r=m._data(a,"fxshow",{}),f&&(r.hidden=!q),q?m(a).show():n.done(function(){m(a).hide()}),n.done(function(){var b;m._removeData(a,"fxshow");for(b in o)m.style(a,b,o[b])});for(d in o)g=hb(q?r[d]:0,d,n),d in r||(r[d]=g.start,q&&(g.end=g.start,g.start="width"===d||"height"===d?1:0))}}function jb(a,b){var c,d,e,f,g;for(c in a)if(d=m.camelCase(c),e=b[d],f=a[c],m.isArray(f)&&(e=f[1],f=a[c]=f[0]),c!==d&&(a[d]=f,delete a[c]),g=m.cssHooks[d],g&&"expand"in g){f=g.expand(f),delete a[d];for(c in f)c in a||(a[c]=f[c],b[c]=e)}else b[d]=e}function kb(a,b,c){var d,e,f=0,g=db.length,h=m.Deferred().always(function(){delete i.elem}),i=function(){if(e)return!1;for(var b=$a||fb(),c=Math.max(0,j.startTime+j.duration-b),d=c/j.duration||0,f=1-d,g=0,i=j.tweens.length;i>g;g++)j.tweens[g].run(f);return h.notifyWith(a,[j,f,c]),1>f&&i?c:(h.resolveWith(a,[j]),!1)},j=h.promise({elem:a,props:m.extend({},b),opts:m.extend(!0,{specialEasing:{}},c),originalProperties:b,originalOptions:c,startTime:$a||fb(),duration:c.duration,tweens:[],createTween:function(b,c){var d=m.Tween(a,j.opts,b,c,j.opts.specialEasing[b]||j.opts.easing);return j.tweens.push(d),d},stop:function(b){var c=0,d=b?j.tweens.length:0;if(e)return this;for(e=!0;d>c;c++)j.tweens[c].run(1);return b?h.resolveWith(a,[j,b]):h.rejectWith(a,[j,b]),this}}),k=j.props;for(jb(k,j.opts.specialEasing);g>f;f++)if(d=db[f].call(j,a,k,j.opts))return d;return m.map(k,hb,j),m.isFunction(j.opts.start)&&j.opts.start.call(a,j),m.fx.timer(m.extend(i,{elem:a,anim:j,queue:j.opts.queue})),j.progress(j.opts.progress).done(j.opts.done,j.opts.complete).fail(j.opts.fail).always(j.opts.always)}m.Animation=m.extend(kb,{tweener:function(a,b){m.isFunction(a)?(b=a,a=["*"]):a=a.split(" ");for(var c,d=0,e=a.length;e>d;d++)c=a[d],eb[c]=eb[c]||[],eb[c].unshift(b)},prefilter:function(a,b){b?db.unshift(a):db.push(a)}}),m.speed=function(a,b,c){var d=a&&"object"==typeof a?m.extend({},a):{complete:c||!c&&b||m.isFunction(a)&&a,duration:a,easing:c&&b||b&&!m.isFunction(b)&&b};return d.duration=m.fx.off?0:"number"==typeof d.duration?d.duration:d.duration in m.fx.speeds?m.fx.speeds[d.duration]:m.fx.speeds._default,(null==d.queue||d.queue===!0)&&(d.queue="fx"),d.old=d.complete,d.complete=function(){m.isFunction(d.old)&&d.old.call(this),d.queue&&m.dequeue(this,d.queue)},d},m.fn.extend({fadeTo:function(a,b,c,d){return this.filter(U).css("opacity",0).show().end().animate({opacity:b},a,c,d)},animate:function(a,b,c,d){var e=m.isEmptyObject(a),f=m.speed(b,c,d),g=function(){var b=kb(this,m.extend({},a),f);(e||m._data(this,"finish"))&&b.stop(!0)};return g.finish=g,e||f.queue===!1?this.each(g):this.queue(f.queue,g)},stop:function(a,b,c){var d=function(a){var b=a.stop;delete a.stop,b(c)};return"string"!=typeof a&&(c=b,b=a,a=void 0),b&&a!==!1&&this.queue(a||"fx",[]),this.each(function(){var b=!0,e=null!=a&&a+"queueHooks",f=m.timers,g=m._data(this);if(e)g[e]&&g[e].stop&&d(g[e]);else for(e in g)g[e]&&g[e].stop&&cb.test(e)&&d(g[e]);for(e=f.length;e--;)f[e].elem!==this||null!=a&&f[e].queue!==a||(f[e].anim.stop(c),b=!1,f.splice(e,1));(b||!c)&&m.dequeue(this,a)})},finish:function(a){return a!==!1&&(a=a||"fx"),this.each(function(){var b,c=m._data(this),d=c[a+"queue"],e=c[a+"queueHooks"],f=m.timers,g=d?d.length:0;for(c.finish=!0,m.queue(this,a,[]),e&&e.stop&&e.stop.call(this,!0),b=f.length;b--;)f[b].elem===this&&f[b].queue===a&&(f[b].anim.stop(!0),f.splice(b,1));for(b=0;g>b;b++)d[b]&&d[b].finish&&d[b].finish.call(this);delete c.finish})}}),m.each(["toggle","show","hide"],function(a,b){var c=m.fn[b];m.fn[b]=function(a,d,e){return null==a||"boolean"==typeof a?c.apply(this,arguments):this.animate(gb(b,!0),a,d,e)}}),m.each({slideDown:gb("show"),slideUp:gb("hide"),slideToggle:gb("toggle"),fadeIn:{opacity:"show"},fadeOut:{opacity:"hide"},fadeToggle:{opacity:"toggle"}},function(a,b){m.fn[a]=function(a,c,d){return this.animate(b,a,c,d)}}),m.timers=[],m.fx.tick=function(){var a,b=m.timers,c=0;for($a=m.now();c<b.length;c++)a=b[c],a()||b[c]!==a||b.splice(c--,1);b.length||m.fx.stop(),$a=void 0},m.fx.timer=function(a){m.timers.push(a),a()?m.fx.start():m.timers.pop()},m.fx.interval=13,m.fx.start=function(){_a||(_a=setInterval(m.fx.tick,m.fx.interval))},m.fx.stop=function(){clearInterval(_a),_a=null},m.fx.speeds={slow:600,fast:200,_default:400},m.fn.delay=function(a,b){return a=m.fx?m.fx.speeds[a]||a:a,b=b||"fx",this.queue(b,function(b,c){var d=setTimeout(b,a);c.stop=function(){clearTimeout(d)}})},function(){var a,b,c,d,e;b=y.createElement("div"),b.setAttribute("className","t"),b.innerHTML="  <link/><table></table><a href='/a'>a</a><input type='checkbox'/>",d=b.getElementsByTagName("a")[0],c=y.createElement("select"),e=c.appendChild(y.createElement("option")),a=b.getElementsByTagName("input")[0],d.style.cssText="top:1px",k.getSetAttribute="t"!==b.className,k.style=/top/.test(d.getAttribute("style")),k.hrefNormalized="/a"===d.getAttribute("href"),k.checkOn=!!a.value,k.optSelected=e.selected,k.enctype=!!y.createElement("form").enctype,c.disabled=!0,k.optDisabled=!e.disabled,a=y.createElement("input"),a.setAttribute("value",""),k.input=""===a.getAttribute("value"),a.value="t",a.setAttribute("type","radio"),k.radioValue="t"===a.value}();var lb=/\r/g;m.fn.extend({val:function(a){var b,c,d,e=this[0];{if(arguments.length)return d=m.isFunction(a),this.each(function(c){var e;1===this.nodeType&&(e=d?a.call(this,c,m(this).val()):a,null==e?e="":"number"==typeof e?e+="":m.isArray(e)&&(e=m.map(e,function(a){return null==a?"":a+""})),b=m.valHooks[this.type]||m.valHooks[this.nodeName.toLowerCase()],b&&"set"in b&&void 0!==b.set(this,e,"value")||(this.value=e))});if(e)return b=m.valHooks[e.type]||m.valHooks[e.nodeName.toLowerCase()],b&&"get"in b&&void 0!==(c=b.get(e,"value"))?c:(c=e.value,"string"==typeof c?c.replace(lb,""):null==c?"":c)}}}),m.extend({valHooks:{option:{get:function(a){var b=m.find.attr(a,"value");return null!=b?b:m.trim(m.text(a))}},select:{get:function(a){for(var b,c,d=a.options,e=a.selectedIndex,f="select-one"===a.type||0>e,g=f?null:[],h=f?e+1:d.length,i=0>e?h:f?e:0;h>i;i++)if(c=d[i],!(!c.selected&&i!==e||(k.optDisabled?c.disabled:null!==c.getAttribute("disabled"))||c.parentNode.disabled&&m.nodeName(c.parentNode,"optgroup"))){if(b=m(c).val(),f)return b;g.push(b)}return g},set:function(a,b){var c,d,e=a.options,f=m.makeArray(b),g=e.length;while(g--)if(d=e[g],m.inArray(m.valHooks.option.get(d),f)>=0)try{d.selected=c=!0}catch(h){d.scrollHeight}else d.selected=!1;return c||(a.selectedIndex=-1),e}}}}),m.each(["radio","checkbox"],function(){m.valHooks[this]={set:function(a,b){return m.isArray(b)?a.checked=m.inArray(m(a).val(),b)>=0:void 0}},k.checkOn||(m.valHooks[this].get=function(a){return null===a.getAttribute("value")?"on":a.value})});var mb,nb,ob=m.expr.attrHandle,pb=/^(?:checked|selected)$/i,qb=k.getSetAttribute,rb=k.input;m.fn.extend({attr:function(a,b){return V(this,m.attr,a,b,arguments.length>1)},removeAttr:function(a){return this.each(function(){m.removeAttr(this,a)})}}),m.extend({attr:function(a,b,c){var d,e,f=a.nodeType;if(a&&3!==f&&8!==f&&2!==f)return typeof a.getAttribute===K?m.prop(a,b,c):(1===f&&m.isXMLDoc(a)||(b=b.toLowerCase(),d=m.attrHooks[b]||(m.expr.match.bool.test(b)?nb:mb)),void 0===c?d&&"get"in d&&null!==(e=d.get(a,b))?e:(e=m.find.attr(a,b),null==e?void 0:e):null!==c?d&&"set"in d&&void 0!==(e=d.set(a,c,b))?e:(a.setAttribute(b,c+""),c):void m.removeAttr(a,b))},removeAttr:function(a,b){var c,d,e=0,f=b&&b.match(E);if(f&&1===a.nodeType)while(c=f[e++])d=m.propFix[c]||c,m.expr.match.bool.test(c)?rb&&qb||!pb.test(c)?a[d]=!1:a[m.camelCase("default-"+c)]=a[d]=!1:m.attr(a,c,""),a.removeAttribute(qb?c:d)},attrHooks:{type:{set:function(a,b){if(!k.radioValue&&"radio"===b&&m.nodeName(a,"input")){var c=a.value;return a.setAttribute("type",b),c&&(a.value=c),b}}}}}),nb={set:function(a,b,c){return b===!1?m.removeAttr(a,c):rb&&qb||!pb.test(c)?a.setAttribute(!qb&&m.propFix[c]||c,c):a[m.camelCase("default-"+c)]=a[c]=!0,c}},m.each(m.expr.match.bool.source.match(/\w+/g),function(a,b){var c=ob[b]||m.find.attr;ob[b]=rb&&qb||!pb.test(b)?function(a,b,d){var e,f;return d||(f=ob[b],ob[b]=e,e=null!=c(a,b,d)?b.toLowerCase():null,ob[b]=f),e}:function(a,b,c){return c?void 0:a[m.camelCase("default-"+b)]?b.toLowerCase():null}}),rb&&qb||(m.attrHooks.value={set:function(a,b,c){return m.nodeName(a,"input")?void(a.defaultValue=b):mb&&mb.set(a,b,c)}}),qb||(mb={set:function(a,b,c){var d=a.getAttributeNode(c);return d||a.setAttributeNode(d=a.ownerDocument.createAttribute(c)),d.value=b+="","value"===c||b===a.getAttribute(c)?b:void 0}},ob.id=ob.name=ob.coords=function(a,b,c){var d;return c?void 0:(d=a.getAttributeNode(b))&&""!==d.value?d.value:null},m.valHooks.button={get:function(a,b){var c=a.getAttributeNode(b);return c&&c.specified?c.value:void 0},set:mb.set},m.attrHooks.contenteditable={set:function(a,b,c){mb.set(a,""===b?!1:b,c)}},m.each(["width","height"],function(a,b){m.attrHooks[b]={set:function(a,c){return""===c?(a.setAttribute(b,"auto"),c):void 0}}})),k.style||(m.attrHooks.style={get:function(a){return a.style.cssText||void 0},set:function(a,b){return a.style.cssText=b+""}});var sb=/^(?:input|select|textarea|button|object)$/i,tb=/^(?:a|area)$/i;m.fn.extend({prop:function(a,b){return V(this,m.prop,a,b,arguments.length>1)},removeProp:function(a){return a=m.propFix[a]||a,this.each(function(){try{this[a]=void 0,delete this[a]}catch(b){}})}}),m.extend({propFix:{"for":"htmlFor","class":"className"},prop:function(a,b,c){var d,e,f,g=a.nodeType;if(a&&3!==g&&8!==g&&2!==g)return f=1!==g||!m.isXMLDoc(a),f&&(b=m.propFix[b]||b,e=m.propHooks[b]),void 0!==c?e&&"set"in e&&void 0!==(d=e.set(a,c,b))?d:a[b]=c:e&&"get"in e&&null!==(d=e.get(a,b))?d:a[b]},propHooks:{tabIndex:{get:function(a){var b=m.find.attr(a,"tabindex");return b?parseInt(b,10):sb.test(a.nodeName)||tb.test(a.nodeName)&&a.href?0:-1}}}}),k.hrefNormalized||m.each(["href","src"],function(a,b){m.propHooks[b]={get:function(a){return a.getAttribute(b,4)}}}),k.optSelected||(m.propHooks.selected={get:function(a){var b=a.parentNode;return b&&(b.selectedIndex,b.parentNode&&b.parentNode.selectedIndex),null}}),m.each(["tabIndex","readOnly","maxLength","cellSpacing","cellPadding","rowSpan","colSpan","useMap","frameBorder","contentEditable"],function(){m.propFix[this.toLowerCase()]=this}),k.enctype||(m.propFix.enctype="encoding");var ub=/[\t\r\n\f]/g;m.fn.extend({addClass:function(a){var b,c,d,e,f,g,h=0,i=this.length,j="string"==typeof a&&a;if(m.isFunction(a))return this.each(function(b){m(this).addClass(a.call(this,b,this.className))});if(j)for(b=(a||"").match(E)||[];i>h;h++)if(c=this[h],d=1===c.nodeType&&(c.className?(" "+c.className+" ").replace(ub," "):" ")){f=0;while(e=b[f++])d.indexOf(" "+e+" ")<0&&(d+=e+" ");g=m.trim(d),c.className!==g&&(c.className=g)}return this},removeClass:function(a){var b,c,d,e,f,g,h=0,i=this.length,j=0===arguments.length||"string"==typeof a&&a;if(m.isFunction(a))return this.each(function(b){m(this).removeClass(a.call(this,b,this.className))});if(j)for(b=(a||"").match(E)||[];i>h;h++)if(c=this[h],d=1===c.nodeType&&(c.className?(" "+c.className+" ").replace(ub," "):"")){f=0;while(e=b[f++])while(d.indexOf(" "+e+" ")>=0)d=d.replace(" "+e+" "," ");g=a?m.trim(d):"",c.className!==g&&(c.className=g)}return this},toggleClass:function(a,b){var c=typeof a;return"boolean"==typeof b&&"string"===c?b?this.addClass(a):this.removeClass(a):this.each(m.isFunction(a)?function(c){m(this).toggleClass(a.call(this,c,this.className,b),b)}:function(){if("string"===c){var b,d=0,e=m(this),f=a.match(E)||[];while(b=f[d++])e.hasClass(b)?e.removeClass(b):e.addClass(b)}else(c===K||"boolean"===c)&&(this.className&&m._data(this,"__className__",this.className),this.className=this.className||a===!1?"":m._data(this,"__className__")||"")})},hasClass:function(a){for(var b=" "+a+" ",c=0,d=this.length;d>c;c++)if(1===this[c].nodeType&&(" "+this[c].className+" ").replace(ub," ").indexOf(b)>=0)return!0;return!1}}),m.each("blur focus focusin focusout load resize scroll unload click dblclick mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave change select submit keydown keypress keyup error contextmenu".split(" "),function(a,b){m.fn[b]=function(a,c){return arguments.length>0?this.on(b,null,a,c):this.trigger(b)}}),m.fn.extend({hover:function(a,b){return this.mouseenter(a).mouseleave(b||a)},bind:function(a,b,c){return this.on(a,null,b,c)},unbind:function(a,b){return this.off(a,null,b)},delegate:function(a,b,c,d){return this.on(b,a,c,d)},undelegate:function(a,b,c){return 1===arguments.length?this.off(a,"**"):this.off(b,a||"**",c)}});var vb=m.now(),wb=/\?/,xb=/(,)|(\[|{)|(}|])|"(?:[^"\\\r\n]|\\["\\\/bfnrt]|\\u[\da-fA-F]{4})*"\s*:?|true|false|null|-?(?!0\d)\d+(?:\.\d+|)(?:[eE][+-]?\d+|)/g;m.parseJSON=function(b){if(a.JSON&&a.JSON.parse)return a.JSON.parse(b+"");var c,d=null,e=m.trim(b+"");return e&&!m.trim(e.replace(xb,function(a,b,e,f){return c&&b&&(d=0),0===d?a:(c=e||b,d+=!f-!e,"")}))?Function("return "+e)():m.error("Invalid JSON: "+b)},m.parseXML=function(b){var c,d;if(!b||"string"!=typeof b)return null;try{a.DOMParser?(d=new DOMParser,c=d.parseFromString(b,"text/xml")):(c=new ActiveXObject("Microsoft.XMLDOM"),c.async="false",c.loadXML(b))}catch(e){c=void 0}return c&&c.documentElement&&!c.getElementsByTagName("parsererror").length||m.error("Invalid XML: "+b),c};var yb,zb,Ab=/#.*$/,Bb=/([?&])_=[^&]*/,Cb=/^(.*?):[ \t]*([^\r\n]*)\r?$/gm,Db=/^(?:about|app|app-storage|.+-extension|file|res|widget):$/,Eb=/^(?:GET|HEAD)$/,Fb=/^\/\//,Gb=/^([\w.+-]+:)(?:\/\/(?:[^\/?#]*@|)([^\/?#:]*)(?::(\d+)|)|)/,Hb={},Ib={},Jb="*/".concat("*");try{zb=location.href}catch(Kb){zb=y.createElement("a"),zb.href="",zb=zb.href}yb=Gb.exec(zb.toLowerCase())||[];function Lb(a){return function(b,c){"string"!=typeof b&&(c=b,b="*");var d,e=0,f=b.toLowerCase().match(E)||[];if(m.isFunction(c))while(d=f[e++])"+"===d.charAt(0)?(d=d.slice(1)||"*",(a[d]=a[d]||[]).unshift(c)):(a[d]=a[d]||[]).push(c)}}function Mb(a,b,c,d){var e={},f=a===Ib;function g(h){var i;return e[h]=!0,m.each(a[h]||[],function(a,h){var j=h(b,c,d);return"string"!=typeof j||f||e[j]?f?!(i=j):void 0:(b.dataTypes.unshift(j),g(j),!1)}),i}return g(b.dataTypes[0])||!e["*"]&&g("*")}function Nb(a,b){var c,d,e=m.ajaxSettings.flatOptions||{};for(d in b)void 0!==b[d]&&((e[d]?a:c||(c={}))[d]=b[d]);return c&&m.extend(!0,a,c),a}function Ob(a,b,c){var d,e,f,g,h=a.contents,i=a.dataTypes;while("*"===i[0])i.shift(),void 0===e&&(e=a.mimeType||b.getResponseHeader("Content-Type"));if(e)for(g in h)if(h[g]&&h[g].test(e)){i.unshift(g);break}if(i[0]in c)f=i[0];else{for(g in c){if(!i[0]||a.converters[g+" "+i[0]]){f=g;break}d||(d=g)}f=f||d}return f?(f!==i[0]&&i.unshift(f),c[f]):void 0}function Pb(a,b,c,d){var e,f,g,h,i,j={},k=a.dataTypes.slice();if(k[1])for(g in a.converters)j[g.toLowerCase()]=a.converters[g];f=k.shift();while(f)if(a.responseFields[f]&&(c[a.responseFields[f]]=b),!i&&d&&a.dataFilter&&(b=a.dataFilter(b,a.dataType)),i=f,f=k.shift())if("*"===f)f=i;else if("*"!==i&&i!==f){if(g=j[i+" "+f]||j["* "+f],!g)for(e in j)if(h=e.split(" "),h[1]===f&&(g=j[i+" "+h[0]]||j["* "+h[0]])){g===!0?g=j[e]:j[e]!==!0&&(f=h[0],k.unshift(h[1]));break}if(g!==!0)if(g&&a["throws"])b=g(b);else try{b=g(b)}catch(l){return{state:"parsererror",error:g?l:"No conversion from "+i+" to "+f}}}return{state:"success",data:b}}m.extend({active:0,lastModified:{},etag:{},ajaxSettings:{url:zb,type:"GET",isLocal:Db.test(yb[1]),global:!0,processData:!0,async:!0,contentType:"application/x-www-form-urlencoded; charset=UTF-8",accepts:{"*":Jb,text:"text/plain",html:"text/html",xml:"application/xml, text/xml",json:"application/json, text/javascript"},contents:{xml:/xml/,html:/html/,json:/json/},responseFields:{xml:"responseXML",text:"responseText",json:"responseJSON"},converters:{"* text":String,"text html":!0,"text json":m.parseJSON,"text xml":m.parseXML},flatOptions:{url:!0,context:!0}},ajaxSetup:function(a,b){return b?Nb(Nb(a,m.ajaxSettings),b):Nb(m.ajaxSettings,a)},ajaxPrefilter:Lb(Hb),ajaxTransport:Lb(Ib),ajax:function(a,b){"object"==typeof a&&(b=a,a=void 0),b=b||{};var c,d,e,f,g,h,i,j,k=m.ajaxSetup({},b),l=k.context||k,n=k.context&&(l.nodeType||l.jquery)?m(l):m.event,o=m.Deferred(),p=m.Callbacks("once memory"),q=k.statusCode||{},r={},s={},t=0,u="canceled",v={readyState:0,getResponseHeader:function(a){var b;if(2===t){if(!j){j={};while(b=Cb.exec(f))j[b[1].toLowerCase()]=b[2]}b=j[a.toLowerCase()]}return null==b?null:b},getAllResponseHeaders:function(){return 2===t?f:null},setRequestHeader:function(a,b){var c=a.toLowerCase();return t||(a=s[c]=s[c]||a,r[a]=b),this},overrideMimeType:function(a){return t||(k.mimeType=a),this},statusCode:function(a){var b;if(a)if(2>t)for(b in a)q[b]=[q[b],a[b]];else v.always(a[v.status]);return this},abort:function(a){var b=a||u;return i&&i.abort(b),x(0,b),this}};if(o.promise(v).complete=p.add,v.success=v.done,v.error=v.fail,k.url=((a||k.url||zb)+"").replace(Ab,"").replace(Fb,yb[1]+"//"),k.type=b.method||b.type||k.method||k.type,k.dataTypes=m.trim(k.dataType||"*").toLowerCase().match(E)||[""],null==k.crossDomain&&(c=Gb.exec(k.url.toLowerCase()),k.crossDomain=!(!c||c[1]===yb[1]&&c[2]===yb[2]&&(c[3]||("http:"===c[1]?"80":"443"))===(yb[3]||("http:"===yb[1]?"80":"443")))),k.data&&k.processData&&"string"!=typeof k.data&&(k.data=m.param(k.data,k.traditional)),Mb(Hb,k,b,v),2===t)return v;h=m.event&&k.global,h&&0===m.active++&&m.event.trigger("ajaxStart"),k.type=k.type.toUpperCase(),k.hasContent=!Eb.test(k.type),e=k.url,k.hasContent||(k.data&&(e=k.url+=(wb.test(e)?"&":"?")+k.data,delete k.data),k.cache===!1&&(k.url=Bb.test(e)?e.replace(Bb,"$1_="+vb++):e+(wb.test(e)?"&":"?")+"_="+vb++)),k.ifModified&&(m.lastModified[e]&&v.setRequestHeader("If-Modified-Since",m.lastModified[e]),m.etag[e]&&v.setRequestHeader("If-None-Match",m.etag[e])),(k.data&&k.hasContent&&k.contentType!==!1||b.contentType)&&v.setRequestHeader("Content-Type",k.contentType),v.setRequestHeader("Accept",k.dataTypes[0]&&k.accepts[k.dataTypes[0]]?k.accepts[k.dataTypes[0]]+("*"!==k.dataTypes[0]?", "+Jb+"; q=0.01":""):k.accepts["*"]);for(d in k.headers)v.setRequestHeader(d,k.headers[d]);if(k.beforeSend&&(k.beforeSend.call(l,v,k)===!1||2===t))return v.abort();u="abort";for(d in{success:1,error:1,complete:1})v[d](k[d]);if(i=Mb(Ib,k,b,v)){v.readyState=1,h&&n.trigger("ajaxSend",[v,k]),k.async&&k.timeout>0&&(g=setTimeout(function(){v.abort("timeout")},k.timeout));try{t=1,i.send(r,x)}catch(w){if(!(2>t))throw w;x(-1,w)}}else x(-1,"No Transport");function x(a,b,c,d){var j,r,s,u,w,x=b;2!==t&&(t=2,g&&clearTimeout(g),i=void 0,f=d||"",v.readyState=a>0?4:0,j=a>=200&&300>a||304===a,c&&(u=Ob(k,v,c)),u=Pb(k,u,v,j),j?(k.ifModified&&(w=v.getResponseHeader("Last-Modified"),w&&(m.lastModified[e]=w),w=v.getResponseHeader("etag"),w&&(m.etag[e]=w)),204===a||"HEAD"===k.type?x="nocontent":304===a?x="notmodified":(x=u.state,r=u.data,s=u.error,j=!s)):(s=x,(a||!x)&&(x="error",0>a&&(a=0))),v.status=a,v.statusText=(b||x)+"",j?o.resolveWith(l,[r,x,v]):o.rejectWith(l,[v,x,s]),v.statusCode(q),q=void 0,h&&n.trigger(j?"ajaxSuccess":"ajaxError",[v,k,j?r:s]),p.fireWith(l,[v,x]),h&&(n.trigger("ajaxComplete",[v,k]),--m.active||m.event.trigger("ajaxStop")))}return v},getJSON:function(a,b,c){return m.get(a,b,c,"json")},getScript:function(a,b){return m.get(a,void 0,b,"script")}}),m.each(["get","post"],function(a,b){m[b]=function(a,c,d,e){return m.isFunction(c)&&(e=e||d,d=c,c=void 0),m.ajax({url:a,type:b,dataType:e,data:c,success:d})}}),m._evalUrl=function(a){return m.ajax({url:a,type:"GET",dataType:"script",async:!1,global:!1,"throws":!0})},m.fn.extend({wrapAll:function(a){if(m.isFunction(a))return this.each(function(b){m(this).wrapAll(a.call(this,b))});if(this[0]){var b=m(a,this[0].ownerDocument).eq(0).clone(!0);this[0].parentNode&&b.insertBefore(this[0]),b.map(function(){var a=this;while(a.firstChild&&1===a.firstChild.nodeType)a=a.firstChild;return a}).append(this)}return this},wrapInner:function(a){return this.each(m.isFunction(a)?function(b){m(this).wrapInner(a.call(this,b))}:function(){var b=m(this),c=b.contents();c.length?c.wrapAll(a):b.append(a)})},wrap:function(a){var b=m.isFunction(a);return this.each(function(c){m(this).wrapAll(b?a.call(this,c):a)})},unwrap:function(){return this.parent().each(function(){m.nodeName(this,"body")||m(this).replaceWith(this.childNodes)}).end()}}),m.expr.filters.hidden=function(a){return a.offsetWidth<=0&&a.offsetHeight<=0||!k.reliableHiddenOffsets()&&"none"===(a.style&&a.style.display||m.css(a,"display"))},m.expr.filters.visible=function(a){return!m.expr.filters.hidden(a)};var Qb=/%20/g,Rb=/\[\]$/,Sb=/\r?\n/g,Tb=/^(?:submit|button|image|reset|file)$/i,Ub=/^(?:input|select|textarea|keygen)/i;function Vb(a,b,c,d){var e;if(m.isArray(b))m.each(b,function(b,e){c||Rb.test(a)?d(a,e):Vb(a+"["+("object"==typeof e?b:"")+"]",e,c,d)});else if(c||"object"!==m.type(b))d(a,b);else for(e in b)Vb(a+"["+e+"]",b[e],c,d)}m.param=function(a,b){var c,d=[],e=function(a,b){b=m.isFunction(b)?b():null==b?"":b,d[d.length]=encodeURIComponent(a)+"="+encodeURIComponent(b)};if(void 0===b&&(b=m.ajaxSettings&&m.ajaxSettings.traditional),m.isArray(a)||a.jquery&&!m.isPlainObject(a))m.each(a,function(){e(this.name,this.value)});else for(c in a)Vb(c,a[c],b,e);return d.join("&").replace(Qb,"+")},m.fn.extend({serialize:function(){return m.param(this.serializeArray())},serializeArray:function(){return this.map(function(){var a=m.prop(this,"elements");return a?m.makeArray(a):this}).filter(function(){var a=this.type;return this.name&&!m(this).is(":disabled")&&Ub.test(this.nodeName)&&!Tb.test(a)&&(this.checked||!W.test(a))}).map(function(a,b){var c=m(this).val();return null==c?null:m.isArray(c)?m.map(c,function(a){return{name:b.name,value:a.replace(Sb,"\r\n")}}):{name:b.name,value:c.replace(Sb,"\r\n")}}).get()}}),m.ajaxSettings.xhr=void 0!==a.ActiveXObject?function(){return!this.isLocal&&/^(get|post|head|put|delete|options)$/i.test(this.type)&&Zb()||$b()}:Zb;var Wb=0,Xb={},Yb=m.ajaxSettings.xhr();a.attachEvent&&a.attachEvent("onunload",function(){for(var a in Xb)Xb[a](void 0,!0)}),k.cors=!!Yb&&"withCredentials"in Yb,Yb=k.ajax=!!Yb,Yb&&m.ajaxTransport(function(a){if(!a.crossDomain||k.cors){var b;return{send:function(c,d){var e,f=a.xhr(),g=++Wb;if(f.open(a.type,a.url,a.async,a.username,a.password),a.xhrFields)for(e in a.xhrFields)f[e]=a.xhrFields[e];a.mimeType&&f.overrideMimeType&&f.overrideMimeType(a.mimeType),a.crossDomain||c["X-Requested-With"]||(c["X-Requested-With"]="XMLHttpRequest");for(e in c)void 0!==c[e]&&f.setRequestHeader(e,c[e]+"");f.send(a.hasContent&&a.data||null),b=function(c,e){var h,i,j;if(b&&(e||4===f.readyState))if(delete Xb[g],b=void 0,f.onreadystatechange=m.noop,e)4!==f.readyState&&f.abort();else{j={},h=f.status,"string"==typeof f.responseText&&(j.text=f.responseText);try{i=f.statusText}catch(k){i=""}h||!a.isLocal||a.crossDomain?1223===h&&(h=204):h=j.text?200:404}j&&d(h,i,j,f.getAllResponseHeaders())},a.async?4===f.readyState?setTimeout(b):f.onreadystatechange=Xb[g]=b:b()},abort:function(){b&&b(void 0,!0)}}}});function Zb(){try{return new a.XMLHttpRequest}catch(b){}}function $b(){try{return new a.ActiveXObject("Microsoft.XMLHTTP")}catch(b){}}m.ajaxSetup({accepts:{script:"text/javascript, application/javascript, application/ecmascript, application/x-ecmascript"},contents:{script:/(?:java|ecma)script/},converters:{"text script":function(a){return m.globalEval(a),a}}}),m.ajaxPrefilter("script",function(a){void 0===a.cache&&(a.cache=!1),a.crossDomain&&(a.type="GET",a.global=!1)}),m.ajaxTransport("script",function(a){if(a.crossDomain){var b,c=y.head||m("head")[0]||y.documentElement;return{send:function(d,e){b=y.createElement("script"),b.async=!0,a.scriptCharset&&(b.charset=a.scriptCharset),b.src=a.url,b.onload=b.onreadystatechange=function(a,c){(c||!b.readyState||/loaded|complete/.test(b.readyState))&&(b.onload=b.onreadystatechange=null,b.parentNode&&b.parentNode.removeChild(b),b=null,c||e(200,"success"))},c.insertBefore(b,c.firstChild)},abort:function(){b&&b.onload(void 0,!0)}}}});var _b=[],ac=/(=)\?(?=&|$)|\?\?/;m.ajaxSetup({jsonp:"callback",jsonpCallback:function(){var a=_b.pop()||m.expando+"_"+vb++;return this[a]=!0,a}}),m.ajaxPrefilter("json jsonp",function(b,c,d){var e,f,g,h=b.jsonp!==!1&&(ac.test(b.url)?"url":"string"==typeof b.data&&!(b.contentType||"").indexOf("application/x-www-form-urlencoded")&&ac.test(b.data)&&"data");return h||"jsonp"===b.dataTypes[0]?(e=b.jsonpCallback=m.isFunction(b.jsonpCallback)?b.jsonpCallback():b.jsonpCallback,h?b[h]=b[h].replace(ac,"$1"+e):b.jsonp!==!1&&(b.url+=(wb.test(b.url)?"&":"?")+b.jsonp+"="+e),b.converters["script json"]=function(){return g||m.error(e+" was not called"),g[0]},b.dataTypes[0]="json",f=a[e],a[e]=function(){g=arguments},d.always(function(){a[e]=f,b[e]&&(b.jsonpCallback=c.jsonpCallback,_b.push(e)),g&&m.isFunction(f)&&f(g[0]),g=f=void 0}),"script"):void 0}),m.parseHTML=function(a,b,c){if(!a||"string"!=typeof a)return null;"boolean"==typeof b&&(c=b,b=!1),b=b||y;var d=u.exec(a),e=!c&&[];return d?[b.createElement(d[1])]:(d=m.buildFragment([a],b,e),e&&e.length&&m(e).remove(),m.merge([],d.childNodes))};var bc=m.fn.load;m.fn.load=function(a,b,c){if("string"!=typeof a&&bc)return bc.apply(this,arguments);var d,e,f,g=this,h=a.indexOf(" ");return h>=0&&(d=m.trim(a.slice(h,a.length)),a=a.slice(0,h)),m.isFunction(b)?(c=b,b=void 0):b&&"object"==typeof b&&(f="POST"),g.length>0&&m.ajax({url:a,type:f,dataType:"html",data:b}).done(function(a){e=arguments,g.html(d?m("<div>").append(m.parseHTML(a)).find(d):a)}).complete(c&&function(a,b){g.each(c,e||[a.responseText,b,a])}),this},m.each(["ajaxStart","ajaxStop","ajaxComplete","ajaxError","ajaxSuccess","ajaxSend"],function(a,b){m.fn[b]=function(a){return this.on(b,a)}}),m.expr.filters.animated=function(a){return m.grep(m.timers,function(b){return a===b.elem}).length};var cc=a.document.documentElement;function dc(a){return m.isWindow(a)?a:9===a.nodeType?a.defaultView||a.parentWindow:!1}m.offset={setOffset:function(a,b,c){var d,e,f,g,h,i,j,k=m.css(a,"position"),l=m(a),n={};"static"===k&&(a.style.position="relative"),h=l.offset(),f=m.css(a,"top"),i=m.css(a,"left"),j=("absolute"===k||"fixed"===k)&&m.inArray("auto",[f,i])>-1,j?(d=l.position(),g=d.top,e=d.left):(g=parseFloat(f)||0,e=parseFloat(i)||0),m.isFunction(b)&&(b=b.call(a,c,h)),null!=b.top&&(n.top=b.top-h.top+g),null!=b.left&&(n.left=b.left-h.left+e),"using"in b?b.using.call(a,n):l.css(n)}},m.fn.extend({offset:function(a){if(arguments.length)return void 0===a?this:this.each(function(b){m.offset.setOffset(this,a,b)});var b,c,d={top:0,left:0},e=this[0],f=e&&e.ownerDocument;if(f)return b=f.documentElement,m.contains(b,e)?(typeof e.getBoundingClientRect!==K&&(d=e.getBoundingClientRect()),c=dc(f),{top:d.top+(c.pageYOffset||b.scrollTop)-(b.clientTop||0),left:d.left+(c.pageXOffset||b.scrollLeft)-(b.clientLeft||0)}):d},position:function(){if(this[0]){var a,b,c={top:0,left:0},d=this[0];return"fixed"===m.css(d,"position")?b=d.getBoundingClientRect():(a=this.offsetParent(),b=this.offset(),m.nodeName(a[0],"html")||(c=a.offset()),c.top+=m.css(a[0],"borderTopWidth",!0),c.left+=m.css(a[0],"borderLeftWidth",!0)),{top:b.top-c.top-m.css(d,"marginTop",!0),left:b.left-c.left-m.css(d,"marginLeft",!0)}}},offsetParent:function(){return this.map(function(){var a=this.offsetParent||cc;while(a&&!m.nodeName(a,"html")&&"static"===m.css(a,"position"))a=a.offsetParent;return a||cc})}}),m.each({scrollLeft:"pageXOffset",scrollTop:"pageYOffset"},function(a,b){var c=/Y/.test(b);m.fn[a]=function(d){return V(this,function(a,d,e){var f=dc(a);return void 0===e?f?b in f?f[b]:f.document.documentElement[d]:a[d]:void(f?f.scrollTo(c?m(f).scrollLeft():e,c?e:m(f).scrollTop()):a[d]=e)},a,d,arguments.length,null)}}),m.each(["top","left"],function(a,b){m.cssHooks[b]=La(k.pixelPosition,function(a,c){return c?(c=Ja(a,b),Ha.test(c)?m(a).position()[b]+"px":c):void 0})}),m.each({Height:"height",Width:"width"},function(a,b){m.each({padding:"inner"+a,content:b,"":"outer"+a},function(c,d){m.fn[d]=function(d,e){var f=arguments.length&&(c||"boolean"!=typeof d),g=c||(d===!0||e===!0?"margin":"border");return V(this,function(b,c,d){var e;return m.isWindow(b)?b.document.documentElement["client"+a]:9===b.nodeType?(e=b.documentElement,Math.max(b.body["scroll"+a],e["scroll"+a],b.body["offset"+a],e["offset"+a],e["client"+a])):void 0===d?m.css(b,c,g):m.style(b,c,d,g)},b,f?d:void 0,f,null)}})}),m.fn.size=function(){return this.length},m.fn.andSelf=m.fn.addBack,"function"==typeof define&&define.amd&&define("jquery",[],function(){return m});var ec=a.jQuery,fc=a.$;return m.noConflict=function(b){return a.$===m&&(a.$=fc),b&&a.jQuery===m&&(a.jQuery=ec),m},typeof b===K&&(a.jQuery=a.$=m),m});
"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="data:text/css;charset=utf-8,html%7Bfont%2Dfamily%3Asans%2Dserif%3B%2Dwebkit%2Dtext%2Dsize%2Dadjust%3A100%25%3B%2Dms%2Dtext%2Dsize%2Dadjust%3A100%25%7Dbody%7Bmargin%3A0%7Darticle%2Caside%2Cdetails%2Cfigcaption%2Cfigure%2Cfooter%2Cheader%2Chgroup%2Cmain%2Cmenu%2Cnav%2Csection%2Csummary%7Bdisplay%3Ablock%7Daudio%2Ccanvas%2Cprogress%2Cvideo%7Bdisplay%3Ainline%2Dblock%3Bvertical%2Dalign%3Abaseline%7Daudio%3Anot%28%5Bcontrols%5D%29%7Bdisplay%3Anone%3Bheight%3A0%7D%5Bhidden%5D%2Ctemplate%7Bdisplay%3Anone%7Da%7Bbackground%2Dcolor%3Atransparent%7Da%3Aactive%2Ca%3Ahover%7Boutline%3A0%7Dabbr%5Btitle%5D%7Bborder%2Dbottom%3A1px%20dotted%7Db%2Cstrong%7Bfont%2Dweight%3A700%7Ddfn%7Bfont%2Dstyle%3Aitalic%7Dh1%7Bmargin%3A%2E67em%200%3Bfont%2Dsize%3A2em%7Dmark%7Bcolor%3A%23000%3Bbackground%3A%23ff0%7Dsmall%7Bfont%2Dsize%3A80%25%7Dsub%2Csup%7Bposition%3Arelative%3Bfont%2Dsize%3A75%25%3Bline%2Dheight%3A0%3Bvertical%2Dalign%3Abaseline%7Dsup%7Btop%3A%2D%2E5em%7Dsub%7Bbottom%3A%2D%2E25em%7Dimg%7Bborder%3A0%7Dsvg%3Anot%28%3Aroot%29%7Boverflow%3Ahidden%7Dfigure%7Bmargin%3A1em%2040px%7Dhr%7Bheight%3A0%3B%2Dwebkit%2Dbox%2Dsizing%3Acontent%2Dbox%3B%2Dmoz%2Dbox%2Dsizing%3Acontent%2Dbox%3Bbox%2Dsizing%3Acontent%2Dbox%7Dpre%7Boverflow%3Aauto%7Dcode%2Ckbd%2Cpre%2Csamp%7Bfont%2Dfamily%3Amonospace%2Cmonospace%3Bfont%2Dsize%3A1em%7Dbutton%2Cinput%2Coptgroup%2Cselect%2Ctextarea%7Bmargin%3A0%3Bfont%3Ainherit%3Bcolor%3Ainherit%7Dbutton%7Boverflow%3Avisible%7Dbutton%2Cselect%7Btext%2Dtransform%3Anone%7Dbutton%2Chtml%20input%5Btype%3Dbutton%5D%2Cinput%5Btype%3Dreset%5D%2Cinput%5Btype%3Dsubmit%5D%7B%2Dwebkit%2Dappearance%3Abutton%3Bcursor%3Apointer%7Dbutton%5Bdisabled%5D%2Chtml%20input%5Bdisabled%5D%7Bcursor%3Adefault%7Dbutton%3A%3A%2Dmoz%2Dfocus%2Dinner%2Cinput%3A%3A%2Dmoz%2Dfocus%2Dinner%7Bpadding%3A0%3Bborder%3A0%7Dinput%7Bline%2Dheight%3Anormal%7Dinput%5Btype%3Dcheckbox%5D%2Cinput%5Btype%3Dradio%5D%7B%2Dwebkit%2Dbox%2Dsizing%3Aborder%2Dbox%3B%2Dmoz%2Dbox%2Dsizing%3Aborder%2Dbox%3Bbox%2Dsizing%3Aborder%2Dbox%3Bpadding%3A0%7Dinput%5Btype%3Dnumber%5D%3A%3A%2Dwebkit%2Dinner%2Dspin%2Dbutton%2Cinput%5Btype%3Dnumber%5D%3A%3A%2Dwebkit%2Douter%2Dspin%2Dbutton%7Bheight%3Aauto%7Dinput%5Btype%3Dsearch%5D%7B%2Dwebkit%2Dbox%2Dsizing%3Acontent%2Dbox%3B%2Dmoz%2Dbox%2Dsizing%3Acontent%2Dbox%3Bbox%2Dsizing%3Acontent%2Dbox%3B%2Dwebkit%2Dappearance%3Atextfield%7Dinput%5Btype%3Dsearch%5D%3A%3A%2Dwebkit%2Dsearch%2Dcancel%2Dbutton%2Cinput%5Btype%3Dsearch%5D%3A%3A%2Dwebkit%2Dsearch%2Ddecoration%7B%2Dwebkit%2Dappearance%3Anone%7Dfieldset%7Bpadding%3A%2E35em%20%2E625em%20%2E75em%3Bmargin%3A0%202px%3Bborder%3A1px%20solid%20silver%7Dlegend%7Bpadding%3A0%3Bborder%3A0%7Dtextarea%7Boverflow%3Aauto%7Doptgroup%7Bfont%2Dweight%3A700%7Dtable%7Bborder%2Dspacing%3A0%3Bborder%2Dcollapse%3Acollapse%7Dtd%2Cth%7Bpadding%3A0%7D%40media%20print%7B%2A%2C%3Aafter%2C%3Abefore%7Bcolor%3A%23000%21important%3Btext%2Dshadow%3Anone%21important%3Bbackground%3A0%200%21important%3B%2Dwebkit%2Dbox%2Dshadow%3Anone%21important%3Bbox%2Dshadow%3Anone%21important%7Da%2Ca%3Avisited%7Btext%2Ddecoration%3Aunderline%7Da%5Bhref%5D%3Aafter%7Bcontent%3A%22%20%28%22%20attr%28href%29%20%22%29%22%7Dabbr%5Btitle%5D%3Aafter%7Bcontent%3A%22%20%28%22%20attr%28title%29%20%22%29%22%7Da%5Bhref%5E%3D%22javascript%3A%22%5D%3Aafter%2Ca%5Bhref%5E%3D%22%23%22%5D%3Aafter%7Bcontent%3A%22%22%7Dblockquote%2Cpre%7Bborder%3A1px%20solid%20%23999%3Bpage%2Dbreak%2Dinside%3Aavoid%7Dthead%7Bdisplay%3Atable%2Dheader%2Dgroup%7Dimg%2Ctr%7Bpage%2Dbreak%2Dinside%3Aavoid%7Dimg%7Bmax%2Dwidth%3A100%25%21important%7Dh2%2Ch3%2Cp%7Borphans%3A3%3Bwidows%3A3%7Dh2%2Ch3%7Bpage%2Dbreak%2Dafter%3Aavoid%7D%2Enavbar%7Bdisplay%3Anone%7D%2Ebtn%3E%2Ecaret%2C%2Edropup%3E%2Ebtn%3E%2Ecaret%7Bborder%2Dtop%2Dcolor%3A%23000%21important%7D%2Elabel%7Bborder%3A1px%20solid%20%23000%7D%2Etable%7Bborder%2Dcollapse%3Acollapse%21important%7D%2Etable%20td%2C%2Etable%20th%7Bbackground%2Dcolor%3A%23fff%21important%7D%2Etable%2Dbordered%20td%2C%2Etable%2Dbordered%20th%7Bborder%3A1px%20solid%20%23ddd%21important%7D%7D%40font%2Dface%7Bfont%2Dfamily%3A%27Glyphicons%20Halflings%27%3Bsrc%3Aurl%28data%3Aapplication%2Fvnd%2Ems%2Dfontobject%3Bbase64%2Cn04AAEFNAAACAAIABAAAAAAABQAAAAAAAAABAJABAAAEAExQAAAAAAAAAAIAAAAAAAAAAAEAAAAAAAAAJxJ%2FLAAAAAAAAAAAAAAAAAAAAAAAACgARwBMAFkAUABIAEkAQwBPAE4AUwAgAEgAYQBsAGYAbABpAG4AZwBzAAAADgBSAGUAZwB1AGwAYQByAAAAeABWAGUAcgBzAGkAbwBuACAAMQAuADAAMAA5ADsAUABTACAAMAAwADEALgAwADAAOQA7AGgAbwB0AGMAbwBuAHYAIAAxAC4AMAAuADcAMAA7AG0AYQBrAGUAbwB0AGYALgBsAGkAYgAyAC4ANQAuADUAOAAzADIAOQAAADgARwBMAFkAUABIAEkAQwBPAE4AUwAgAEgAYQBsAGYAbABpAG4AZwBzACAAUgBlAGcAdQBsAGEAcgAAAAAAQlNHUAAAAAAAAAAAAAAAAAAAAAADAKncAE0TAE0ZAEbuFM3pjM%2FSEdmjKHUbyow8ATBE40IvWA3vTu8LiABDQ%2BpexwUMcm1SMnNryctQSiI1K5ZnbOlXKmnVV5YvRe6RnNMFNCOs1KNVpn6yZhCJkRtVRNzEufeIq7HgSrcx4S8h%2Fv4vnrrKc6oCNxmSk2uKlZQHBii6iKFoH0746ThvkO1kJHlxjrkxs%2BLWORaDQBEtiYJIR5IB9Bi1UyL4Rmr0BNigNkMzlKQmnofBHviqVzUxwdMb3NdCn69hy%2BpRYVKGVS%2F1tnsqv4LL7wCCPZZAZPT4aCShHjHJVNuXbmMrY5LeQaGnvAkXlVrJgKRAUdFjrWEah9XebPeQMj7KS7DIBAFt8ycgC5PLGUOHSE3ErGZCiViNLL5ZARfywnCoZaKQCu6NuFX42AEeKtKUGnr%2FCm2Cy8tpFhBPMW5Fxi4Qm4TkDWh4IWFDClhU2hRWosUWqcKLlgyXB%2BlSHaWaHiWlBAR8SeSgSPCQxdVQgzUixWKSTrIQEbU94viDctkvX%2BVSjJuUmV8L4CXShI11esnp0pjWNZIyxKHS4wVQ2ime1P4RnhvGw0aDN1OLAXGERsB7buFpFGGBAre4QEQR0HOIO5oYH305G%2BKspT%2FFupEGGafCCwxSe6ZUa%2B073rXHnNdVXE6eWvibUS27XtRzkH838mYLMBmYysZTM0EM3A1fbpCBYFccN1B%2FEnCYu%2FTgCGmr7bMh8GfYL%2BBfcLvB0gRagC09w9elfldaIy%2FhNCBLRgBgtCC7jAF63wLSMAfbfAlEggYU0bUA7ACCJmTDpEmJtI78w4%2FBO7dN7JR7J7ZvbYaUbaILSQsRBiF3HGk5fEg6p9unwLvn98r%2BvnsV%2B372uf1xBLq4qU%2F45fTuqaAP%2BpssmCCCTF0mhEow8ZXZOS8D7Q85JsxZ%2BAzok7B7O%2Ff6J8AzYBySZQB%2FQHYUSA%2BEeQhEWiS6AIQzgcsDiER4MjgMBAWDV4AgQ3g1eBgIdweCQmCjJEMkJ%2BPKRWyFHHmg1Wi%2F6xzUgA0LREoKJChwnQa9B%2B5RQZRB3IlBlkAnxyQNaANwHMowzlYSMCBgnbpzvqpl0iTJNCQidDI9ZrSYNIRBhHtUa5YHMHxyGEik9hDE0AKj72AbTCaxtHPUaKZdAZSnQTyjGqGLsmBStCejApUhg4uBMU6mATujEl%2BKdDPbI6Ag4vLr%2BhjY6lbjBeoLKnZl0UZgRX8gTySOeynZVz1wOq7e1hFGYIq%2BMhrGxDLak0PrwYzSXtcuyhXEhwOYofiW%2BEcI%2Fjw8P6IY6ed%2BetAbuqKp5QIapT77LnAe505lMuqL79a0ut4rWexzFttsOsLDy7zvtQzcq3U1qabe7tB0wHWVXji%2BzDbo8x8HyIRUbXnwUcklFv51fvTymiV%2BMXLSmGH9d9%2BaXpD5X6lao41anWGig7IwIdnoBY2ht%2FpO9mClLo4NdXHAsefqWUKlXJkbqPOFhMoR4aiA1BXqhRNbB2Xwi%2B7u%2FjpAoOpKJ0UX24EsrzMfHXViakCNcKjBxuQX8BO0ZqjJ3xXzf%2B61t2VXOSgJ8xu65QKgtN6FibPmPYsXbJRHHqbgATcSZxBqGiDiU4NNNsYBsKD0MIP%2FOfKnlk%2FLkaid%2FO2NbKeuQrwOB2Gq3YHyr6ALgzym5wIBnsdC1ZkoBFZSQXChZvlesPqvK2c5oHHT3Q65jYpNxnQcGF0EHbvYqoFw60WNlXIHQF2HQB7zD6lWjZ9rVqUKBXUT6hrkZOle0RFYII0V5ZYGl1JAP0Ud1fZZMvSomBzJ710j4Me8mjQDwEre5Uv2wQfk1ifDwb5ksuJQQ3xt423lbuQjvoIQByQrNDh1JxGFkOdlJvu%2FgFtuW0wR4cgd%2BZKesSV7QkNE2kw6AV4hoIuC02LGmTomyf8PiO6CZzOTLTPQ%2BHW06H%2Btx%2BbQ8LmDYg1pTFrp2oJXgkZTyeRJZM0C8aE2LpFrNVDuhARsN543%2FFV6klQ6Tv1OoZGXLv0igKrl%2FCmJxRmX7JJbJ998VSIPQRyDBICzl4JJlYHbdql30NvYcOuZ7a10uWRrgoieOdgIm4rlq6vNOQBuqESLbXG5lzdJGHw2m0sDYmODXbYGTfSTGRKpssTO95fothJCjUGQgEL4yKoGAF%2F0SrpUDNn8CBgBcSDQByAeNkCXp4S4Ro2Xh4OeaGRgR66PVOsU8bc6TR5%2FxTcn4IVMLOkXSWiXxkZQCbvKfmoAvQaKjO3EDKwkwqHChCDEM5loQRPd5ACBki1TjF772oaQhQbQ5C0lcWXPFOzrfsDGUXGrpxasbG4iab6eByaQkQfm0VFlP0ZsDkvvqCL6QXMUwCjdMx1ZOyKhTJ7a1GWAdOUcJ8RSejxNVyGs31OKMyRyBVoZFjqIkmKlLQ5eHMeEL4MkUf23cQ%2F1SgRCJ1dk4UdBT7OoyuNgLs0oCd8RnrEIb6QdMxT2QjD4zMrJkfgx5aDMcA4orsTtKCqWb%2FVeyceqa5OGSmB28YwH4rFbkQaLoUN8OQQYnD3w2eXpI4ScQfbCUZiJ4yMOIKLyyTc7BQ4uXUw6Ee6%2FxM%2B4Y67ngNBknxIPwuppgIhFcwJyr6EIj%2BLzNj%2FmfR2vhhRlx0BILZoAYruF0caWQ7YxO66UmeguDREAFHYuC7HJviRgVO6ruJH59h%2FC%2FPkgSle8xNzZJULLWq9JMDTE2fjGE146a1Us6PZDGYle6ldWRqn%2FpdpgHKNGrGIdkRK%2BKPETT9nKT6kLyDI8xd9A1FgWmXWRAIHwZ37WyZHOVyCadJEmMVz0MadMjDrPho%2BEIochkVC2xgGiwwsQ6DMv2P7UXqT4x7CdcYGId2BJQQa85EQKmCmwcRejQ9Bm4oATENFPkxPXILHpMPUyWTI5rjNOsIlmEeMbcOCEqInpXACYQ9DDxmFo9vcmsDblcMtg4tqBerNngkIKaFJmrQAPnq1dEzsMXcwjcHdfdCibcAxxA%2Bq%2Fj9m3LM%2FO7WJka4tSidVCjsvo2lQ%2F2ewyoYyXwAYyr2PlRoR5MpgVmSUIrM3PQxXPbgjBOaDQFIyFMJvx3Pc5RSYj12ySVF9fwFPQu2e2KWVoL9q3Ayv3IzpGHUdvdPdrNUdicjsTQ2ISy7QU3DrEytIjvbzJnAkmANXjAFERA0MUoPF3%2F5KFmW14bBNOhwircYgMqoDpUMcDtCmBE82QM2YtdjVLB4kBuKho%2FbcwQdeboqfQartuU3CsCf%2BcXkgYAqp%2F0Ee3RorAZt0AvvOCSI4JICIlGlsV0bsSid%2FNIEALAAzb6HAgyWHBps6xAOwkJIGcB82CxRQq4sJf3FzA70A%2BTRqcqjEMETCoez3mkPcpnoALs0ugJY8kQwrC%2BJE5ik3w9rzrvDRjAQnqgEVvdGrNwlanR0SOKWzxOJOvLJhcd8Cl4AshACUkv9czdMkJCVQSQhp6kp7StAlpVRpK0t0SW6LHeBJnE2QchB5Ccu8kxRghZXGIgZIiSj7gEKMJDClcnX6hgoqJMwiQDigIXg3ioFLCgDgjPtYHYpsF5EiA4kcnN18MZtOrY866dEQAb0FB34OGKHGZQjwW%2FWDHA60cYFaI%2FPjpzquUqdaYGcIq%2BmLez3WLFFCtNBN2QJcrlcoELgiPku5R5dSlJFaCEqEZle1AQzAKC%2B1SotMcBNyQUFuRHRF6OlimSBgjZeTBCwLyc6A%2BP%2FoFRchXTz5ADknYJHxzrJ5pGuIKRQISU6WyKTBBjD8WozmVYWIsto1AS5rxzKlvJu4E%2FvwOiKxRtCWsDM%2BeTHUrmwrCK5BIfMzGkD%2B0Fk5LzBs0jMYXktNDblB06LMNJ09U8pzSLmo14MS0OMjcdrZ31pyQqxJJpRImlSvfYAK8inkYU52QY2FPEVsjoWewpwhRp5yAuNpkqhdb7ku9Seefl2D0B8SMTFD90xi4CSOwwZy9IKkpMtI3FmFUg3%2FkFutpQGNc3pCR7gvC4sgwbupDu3DyEN%2BW6YGLNM21jpB49irxy9BSlHrVDlnihGKHwPrbVFtc%2Bh1rVQKZduxIyojccZIIcOCmhEnC7UkY68WXKQgLi2JCDQkQWJRQuk60hZp0D3rtCTINSeY9Ej2kIKYfGxwOs4j9qMM7fYZiipzgcf7TamnehqdhsiMiCawXnz4xAbyCkLAx5EGbo3Ax1u3dUIKnTxIaxwQTHehPl3V491H0%2BbC5zgpGz7Io%2BmjdhKlPJ01EeMpM7UsRJMi1nGjmJg35i6bQBAAxjO%2FENJubU2mg3ONySEoWklCwdABETcs7ck3jgiuU9pcKKpbgn%2B3YlzV1FzIkB6pmEDOSSyDfPPlQskznctFji0kpgZjW5RZe6x9kYT4KJcXg0bNiCyif%2BpZACCyRMmYsfiKmN9tSO65F0R2OO6ytlEhY5Sj6uRKfFxw0ijJaAx%2Fk3QgnAFSq27%2F2i4GEBA%2BUvTJKK%2F9eISNvG46Em5RZfjTYLdeD8kdXHyrwId%2FDQZUaMCY4gGbke2C8vfjgV%2FY9kkRQOJIn%2FxM9INZSpiBnqX0Q9GlQPpPKAyO5y%2BW5NMPSRdBCUlmuxl40ZfMCnf2Cp044uI9WLFtCi4YVxKjuRCOBWIb4XbIsGdbo4qtMQnNOQz4XDSui7W%2FN6l54qOynCqD3DpWQ%2BmpD7C40D8BZEWGJX3tlAaZBMj1yjvDYKwCJBa201u6nBKE5UE%2B7QSEhCwrXfbRZylAaAkplhBWX50dumrElePyNMRYUrC99UmcSSNgImhFhDI4BXjMtiqkgizUGCrZ8iwFxU6fQ8GEHCFdLewwxYWxgScAYMdMLmcZR6b7rZl95eQVDGVoUKcRMM1ixXQtXNkBETZkVVPg8LoSrdetHzkuM7DjZRHP02tCxA1fmkXKF3VzfN1pc1cv%2F8lbTIkkYpqKM9VOhp65ktYk%2BQ46myFWBapDfyWUCnsnI00QTBQmuFjMZTcd0V2NQ768Fhpby04k2IzNR1wKabuGJqYWwSly6ocMFGTeeI%2BejsWDYgEvr66QgqdcIbFYDNgsm0x9UHY6SCd5%2B7tpsLpKdvhahIDyYmEJQCqMqtCF6UlrE5GXRmbu%2Bvtm3BFSxI6ND6UxIE7GsGMgWqghXxSnaRJuGFveTcK5ZVSPJyjUxe1dKgI6kNF7EZhIZs8y8FVqwEfbM0Xk2ltORVDKZZM40SD3qQoQe0orJEKwPfZwm3YPqwixhUMOndis6MhbmfvLBKjC8sKKIZKbJk8L11oNkCQzCgvjhyyEiQSuJcgCQSG4Mocfgc0Hkwcjal1UNgP0CBPikYqBIk9tONv4kLtBswH07vUCjEaHiFGlLf8MgXKzSgjp2HolRRccAOh0ILHz9qlGgIFkwAnzHJRjWFhlA7ROwINyB5HFj59PRZHFor6voq7l23EPNRwdWhgawqbivLSjRA4htEYUFkjESu67icTg5S0aW1sOkCiIysfJ9UnIWevOOLGpepcBxy1wEhd2WI3AZg7sr9WBmHWyasxMcvY%2FiOmsLtHSWNUWEGk9hScMPShasUA1AcHOtRZlqMeQ0OzYS9vQvYUjOLrzP07BUAFikcJNMi7gIxEw4pL1G54TcmmmoAQ5s7TGWErJZ2Io4yQ0ljRYhL8H5e62oDtLF8aDpnIvZ5R3GWJyAugdiiJW9hQAVTsnCBHhwu7rkBlBX6r3b7ejEY0k5GGeyKv66v%2B6dg7mcJTrWHbtMywbedYqCQ0FPwoytmSWsL8WTtChZCKKzEF7vP6De4x2BJkkniMgSdWhbeBSLtJZR9CTHetK1xb34AYIJ37OegYIoPVbXgJ%2FqDQK%2BbfCtxQRVKQu77WzOoM6SGL7MaZwCGJVk46aImai9fmam%2BWpHG%2B0BtQPWUgZ7RIAlPq6lkECUhZQ2gqWkMYKcYMYaIc4gYCDFHYa2d1nzp3%2BJ1eCBay8IYZ0wQRKGAqvCuZ%2FUgbQPyllosq%2BXtfKIZOzmeJqRazpmmoP%2F76YfkjzV2NlXTDSBYB04SVlNQsFTbGPk1t%2FI4Jktu0XSgifO2ozFOiwd%2F0SssJDn0dn4xqk4GDTTKX73%2FwQyBLdqgJ%2BWx6AQaba3BA9CKEzjtQYIfAsiYamapq80LAamYjinlKXUkxdpIDk0puXUEYzSalfRibAeDAKpNiqQ0FTwoxuGYzRnisyTotdVTclis1LHRQCy%2FqqL8oUaQzWRxilq5Mi0IJGtMY02cGLD69vGjkj3p6pGePKI8bkBv5evq8SjjyU04vJR2cQXQwSJyoinDsUJHCQ50jrFTT7yRdbdYQMB3MYCb6uBzJ9ewhXYPAIZSXfeEQBZZ3GPN3Nbhh%2FwkvAJLXnQMdi5NYYZ5GHE400GS5rXkOZSQsdZgIbzRnF9ueLnsfQ47wHAsirITnTlkCcuWWIUhJSbpM3wWhXNHvt2xUsKKMpdBSbJnBMcihkoDqAd1Zml%2FR4yrzow1Q2A5G%2Bkzo%2FRhRxQS2lCSDRV8LlYLBOOoo1bF4jwJAwKMK1tWLHlu9i0j4Ig8qVm6wE1DxXwAwQwsaBWUg2pOOol2dHxyt6npwJEdLDDVYyRc2D0HbcbLUJQj8gPevQBUBOUHXPrsAPBERICpnYESeu2OHotpXQxRGlCCtLdIsu23MhZVEoJg8Qumj%2FUMMc34IBqTKLDTp76WzL%2FdMjCxK7MjhiGjeYAC%2Fkj%2FjY%2FRde7hpSM1xChrog6yZ7OWTuD56xBJnGFE%2BpT2ElSyCnJcwVzCjkqeNLfMEJqKW0G7OFIp0G%2B9mh50I9o8k1tpCY0xYqFNIALgIfc2me4n1bmJnRZ89oepgLPT0NTMLNZsvSCZAc3TXaNB07vail36%2FdBySis4m9%2FDR8izaLJW6bWCkVgm5T%2Bius3ZXq4xI%2BGnbveLbdRwF2mNtsrE0JjYc1AXknCOrLSu7Te%2Fr4dPYMCl5qtiHNTn%2BTPbh1jCBHH%2BdMJNhwNgs3nT%2BOhQoQ0vYif56BMG6WowAcHR3DjQolxLzyVekHj00PBAaW7IIAF1EF%2BuRIWyXjQMAs2chdpaKPNaB%2BkSezYt0%2BCA04sOg5vx8Fr7Ofa9sUv87h7SLAUFSzbetCCZ9pmyLt6l6%2FTzoA1%2FZBG9bIUVHLAbi%2FkdBFgYGyGwRQGBpkqCEg2ah9UD6EedEcEL3j4y0BQQCiExEnocA3SZboh%2Bepgd3YsOkHskZwPuQ5OoyA0fTA5AXrHcUOQF%2BzkJHIA7PwCDk1gGVmGUZSSoPhNf%2BTklauz98QofOlCIQ%2FtCD4dosHYPqtPCXB3agggQQIqQJsSkB%2Bqn0rkQ1toJjON%2FOtCIB9RYv3PqRA4C4U68ZMlZn6BdgEvi2ziU%2BTQ6NIw3ej%2BAtDwMGEZk7e2IjxUWKdAxyaw9OCwSmeADTPPleyk6UhGDNXQb%2B%2BW6Uk4q6F7%2Frg6WVTo82IoCxSIsFDrav4EPHphD3u4hR53WKVvYZUwNCCeM4PMBWzK%2BEfIthZOkuAwPo5C5jgoZgn6dUdvx5rIDmd58cXXdKNfw3l%2BwM2UjgrDJeQHhbD7HW2QDoZMCujgIUkk5Fg8VCsdyjOtnGRx8wgKRPZN5dR0zPUyfGZFVihbFRniXZFOZGKPnEQzU3AnD1KfR6weHW2XS6KbPJxUkOTZsAB9vTVp3Le1F8q5l%2BDMcLiIq78jxAImD2pGFw0VHfRatScGlK6SMu8leTmhUSMy8Uhdd6xBiH3Gdman4tjQGLboJfqz6fL2WKHTmrfsKZRYX6BTDjDldKMosaSTLdQS7oDisJNqAUhw1PfTlnacCO8vl8706Km1FROgLDmudzxg%2BEWTiArtHgLsRrAXYWdB0NmToNCJdKm0KWycZQqb%2BMw76Qy29iQ5up%2FX7oyw8QZ75kP5F6iJAJz6KCmqxz8fEa%2FxnsMYcIO%2FvEkGRuMckhr4rIeLrKaXnmIzlNLxbFspOphkcnJdnz%2FChp%2FVlpj2P7jJQmQRwGnltkTV5dbF9fE3%2FfxoSqTROgq9wFUlbuYzYcasE0ouzBo%2BdDCDzxKAfhbAZYxQiHrLzV2iVexnDX%2FQnT1fsT%2Fxuhu1ui5qIytgbGmRoQkeQooO8eJNNZsf0iALur8QxZFH0nCMnjerYQqG1pIfjyVZWxhVRznmmfLG00BcBWJE6hzQWRyFknuJnXuk8A5FRDCulwrWASSNoBtR%2BCtGdkPwYN2o7DOw%2FVGlCZPusRBFXODQdUM5zeHDIVuAJBLqbO%2Ff9Qua%2BpDqEPk230Sob9lEZ8BHiCorjVghuI0lI4JDgHGRDD%2FprQ84B1pVGkIpVUAHCG%2Biz3Bn3qm2AVrYcYWhock4jso5%2BJ7HfHVj4WMIQdGctq3psBCVVzupQOEioBGA2Bk%2BUILT7%2BVoX5mdxxA5fS42gISQVi%2FHTzrgMxu0fY6hE1ocUwwbsbWcezrY2n6S8%2F6cxXkOH4prpmPuFoikTzY7T85C4T2XYlbxLglSv2uLCgFv8Quk%2FwdesUdWPeHYIH0R729JIisN9Apdd4eB10aqwXrPt%2BSu9mA8k8n1sjMwnfsfF2j3jMUzXepSHmZ%2FBfqXvzgUNQQWOXO8YEuFBh4QTYCkOAPxywpYu1VxiDyJmKVcmJPGWk%2Fgc3Pov02StyYDahwmzw3E1gYC9wkupyWfDqDSUMpCTH5e5N8B%2F%2FlHiMuIkTNw4USHrJU67bjXGqNav6PBuQSoqTxc8avHoGmvqNtXzIaoyMIQIiiUHIM64cXieouplhNYln7qgc4wBVAYR104kO%2BCvKqsg4yIUlFNThVUAKZxZt1XA34h3TCUUiXVkZ0w8Hh2R0Z5L0b4LZvPd%2Fp1gi%2F07h8qfwHrByuSxglc9cI4QIg2oqvC%2Fqm0i7tjPLTgDhoWTAKDO2ONW5oe%2B%2FeKB9vZB8K6C25yCZ9RFVMnb6NRdRjyVK57CHHSkJBfnM2%2Fj4ODUwRkqrtBBCrDsDpt8jhZdXoy%2F1BCqw3sSGhgGGy0a5Jw6BP%2FTExoCmNFYjZl248A0osgPyGEmRA%2BfAsqPVaNAfytu0vuQJ7rk3J4kTDTR2AlCHJ5cls26opZM4w3jMULh2YXKpcqGBtuleAlOZnaZGbD6DHzMd6i2oFeJ8z9XYmalg1Szd%2FocZDc1C7Y6vcALJz2lYnTXiWEr2wawtoR4g3jvWUU2Ngjd1cewtFzEvM1NiHZPeLlIXFbBPawxNgMwwAlyNSuGF3zizVeOoC9bag1qRAQKQE%2FEZBWC2J8mnXAN2aTBboZ7HewnObE8CwROudZHmUM5oZ%2FUgd%2FJZQK8lvAm43uDRAbyW8gZ%2BZGq0EVerVGUKUSm%2FIdn8AQHdR4m7bue88WBwft9mSCeMOt1ncBwziOmJYI2ZR7ewNMPiCugmSsE4EyQ%2BQATJG6qORMGd4snEzc6B4shPIo4G1T7PgSm8PY5eUkPdF8JZ0VBtadbHXoJgnEhZQaODPj2gpODKJY5Yp4DOsLBFxWbvXN755KWylJm%2BoOd4zEL9Hpubuy2gyyfxh8oEfFutnYWdfB8PdESLWYvSqbElP9qo3u6KTmkhoacDauMNNjj0oy40DFV7Ql0aZj77xfGl7TJNHnIwgqOkenruYYNo6h724%2BzUQ7%2BvkCpZB%2BpGA562hYQiDxHVWOq0oDQl%2FQsoiY%2BcuI7iWq%2FZIBtHcXJ7kks%2Bh2fCNUPA82BzjnqktNts%2BRLdk1VSu%2BtqEn7QZCCsvEqk6FkfiOYkrsw092J8jsfIuEKypNjLxrKA9kiA19mxBD2suxQKCzwXGws7kEJvlhUiV9tArLIdZW0IORcxEzdzKmjtFhsjKy%2F44XYXdI5noQoRcvjZ1RMPACRqYg2V1%2BOwOepcOknRLLFdYgTkT5UApt%2FJhLM3jeFYprZV%2BZow2g8fP%2BU68hkKFWJj2yBbKqsrp25xkZX1DAjUw52IMYWaOhab8Kp05VrdNftqwRrymWF4OQSjbdfzmRZirK8FMJELEgER2PHjEAN9pGfLhCUiTJFbd5LBkOBMaxLr%2FA1SY9dXFz4RjzoU9ExfJCmx%2FI9FKEGT3n2cmzl2X42L3Jh%2BAbQq6sA%2BSs1kitoa4TAYgKHaoybHUDJ51oETdeI%2F9ThSmjWGkyLi5QAGWhL0BG1UsTyRGRJOldKBrYJeB8ljLJHfATWTEQBXBDnQexOHTB%2BUn44zExFE4vLytcu5NwpWrUxO%2F0ZICUGM7hGABXym0V6ZvDST0E370St9MIWQOTWngeoQHUTdCJUP04spMBMS8LSker9cReVQkULFDIZDFPrhTzBl6sed9wcZQTbL%2BBDqMyaN3RJPh%2Fanbx%2BIv%2BqgQdAa3M9Z5JmvYlh4qop%2BHo1F1W5gbOE9YKLgAnWytXElU4G8GtW47lhgFE6gaSs%2Bgs37sFvi0PPVvA5dnCBgILTwoKd%2F%2BDoL9F6inlM7H4rOTzD79KJgKlZO%2FZgt22UsKhrAaXU5ZcLrAglTVKJEmNJvORGN1vqrcfSMizfpsgbIe9zno%2BgBoKVXgIL%2FVI8dB1O5o%2FR3Suez%2FgD7M781ShjKpIIORM%2FnxG%2BjjhhgPwsn2IoXsPGPqYHXA63zJ07M2GPEykQwJBYLK808qYxuIew4frk52nhCsnCYmXiR6CuapvE1IwRB4%2FQftDbEn%2BAucIr1oxrLabRj9q4ae0%2BfXkHnteAJwXRbVkR0mctVSwEbqhJiMSZUp9DNbEDMmjX22m3ABpkrPQQTP3S1sib5pD2VRKRd%2BeNAjLYyT0hGrdjWJZy24OYXRoWQAIhGBZRxuBFMjjZQhpgrWo8SiFYbojcHO8V5DyscJpLTHyx9Fimassyo5U6WNtquUMYgccaHY5amgR3PQzq3ToNM5ABnoB9kuxsebqmYZm0R9qxJbFXCQ1UPyFIbxoUraTJFDpCk0Wk9GaYJKz%2F6oHwEP0Q14lMtlddQsOAU9zlYdMVHiT7RQP3XCmWYDcHCGbVRHGnHuwzScA0BaSBOGkz3lM8CArjrBsyEoV6Ys4qgDK3ykQQPZ3hCRGNXQTNNXbEb6tDiTDLKOyMzRhCFT%2BmAUmiYbV3YQVqFVp9dorv%2BTsLeCykS2b5yyu8AV7IS9cxcL8z4Kfwp%2BxJyYLv1OsxQCZwTB4a8BZ%2F5EdxTBJthApqyfd9u3ifr%2FWILTqq5VqgwMT9SOxbSGWLQJUUWCVi4k9tho9nEsbUh7U6NUsLmkYFXOhZ0kmamaJLRNJzSj%2Fqn4Mso6zb6iLLBXoaZ6AqeWCjHQm2lztnejYYM2eubnpBdKVLORZhudH3JF1waBJKA9%2BW8EhMj3Kzf0L4vi4k6RoHh3Z5YgmSZmk6ns4fjScjAoL8GoOECgqgYEBYUGFVO4FUv4%2FYtowhEmTs0vrvlD%2FCrisnoBNDAcUi%2FteY7OctFlmARQzjOItrrlKuPO6E2Ox93L4O%2F4DcgV%2FdZ7qR3VBwVQxP1GCieA4RIpweYJ5FoYrHxqRBdJjnqbsikA2Ictbb8vE1GYIo9dacK0REgDX4smy6GAkxlH1yCGGsk%2BtgiDhNKuKu3yNrMdxafmKTF632F8Vx4BNK57GvlFisrkjN9WDAtjsWA0ENT2e2nETUb%2Fn7qwhvGnrHuf5bX6Vh%2Fn3xffU3PeHdR%2BFA92i6ufT3AlyAREoNDh6chiMWTvjKjHDeRhOa9YkOQRq1vQXEMppAQVwHCuIcV2g5rBn6GmZZpTR7vnSD6ZmhdSl176gqKTXu5E%2BYbfL0adwNtHP7dT7t7b46DVZIkzaRJOM%2BS6KcrzYVg%2BT3wSRFRQashjfU18NutrKa%2F7PXbtuJvpIjbgPeqd%2BpjmRw6YKpnANFSQcpzTZgpSNJ6J7uiagAbir%2F8tNXJ%2FOsOnRh6iuIexxrmkIneAgz8QoLmiaJ8sLQrELVK2yn3wOHp57BAZJhDZjTBzyoRAuuZ4eoxHruY1pSb7qq79cIeAdOwin4GdgMeIMHeG%2BFZWYaiUQQyC5b50zKjYw97dFjAeY2I4Bnl105Iku1y0lMA1ZHolLx19uZnRdILcXKlZGQx%2FGdEqSsMRU1BIrFqRcV1qQOOHyxOLXEGcbRtAEsuAC2V4K3p5mFJ22IDWaEkk9ttf5Izb2LkD1MnrSwztXmmD%2FQi%2FEmVEFBfiKGmftsPwVaIoZanlKndMZsIBOskFYpDOq3QUs9aSbAAtL5Dbokus2G4%2FasthNMK5UQKCOhU97oaOYNGsTah%2BjfCKsZnTRn5TbhFX8ghg8CBYt%2FBjeYYYUrtUZ5jVij%2Fop7V5SsbA4mYTOwZ46hqdpbB6Qvq3AS2HHNkC15pTDIcDNGsMPXaBidXYPHc6PJAkRh29Vx8KcgX46LoUQBhRM%2B3SW6Opll%2FwgxxsPgKJKzr5QCmwkUxNbeg6Wj34SUnEzOemSuvS2OetRCO8Tyy%2BQbSKVJcqkia%2BGvDefFwMOmgnD7h81TUtMn%2BmRpyJJ349HhAnoWFTejhpYTL9G8N2nVg1qkXBeoS9Nw2fB27t7trm7d%2FQK7Cr4uoCeOQ7%2F8JfKT77KiDzLImESHw%2F0wf73QeHu74hxv7uihi4fTX%2BXEwAyQG3264dwv17aJ5N335Vt9sdrAXhPOAv8JFvzqyYXwfx8WYJaef1gMl98JRFyl5Mv5Uo%2FoVH5ww5OzLFsiTPDns7fS6EURSSWd%2F92BxMYQ8sBaH%2Bj%2BwthQPdVgDGpTfi%2BJQIWMD8xKqULliRH01rTeyF8x8q%2FGBEEEBrAJMPf25UQwi0b8tmqRXY7kIvNkzrkvRWLnxoGYEJsz8u4oOyMp8cHyaybb1HdMCaLApUE%2B%2F7xLIZGP6H9xuSEXp1zLIdjk5nBaMuV%2FyTDRRP8Y2ww5RO6d2D94o%2B6ucWIqUAvgHIHXhZsmDhjVLczmZ3ca0Cb3PpKwt2UtHVQ0BgFJsqqTsnzZPlKahRUkEu4qmkJt%2Bkqdae76ViWe3STan69yaF9%2BfESD2lcQshLHWVu4ovItXxO69bqC5p1nZLvI8NdQB9s9UNaJGlQ5mG947ipdDA0eTIw%2FA1zEdjWquIsQXXGIVEH0thC5M%2BW9pZe7IhAVnPJkYCCXN5a32HjN6nsvokEqRS44tGIs7s2LVTvcrHAF%2BRVmI8L4HUYk4x%2B67AxSMJKqCg8zrGOgvK9kNMdDrNiUtSWuHFpC8%2Fp5qIQrEo%2FH%2B1l%2F0cAwQ2nKmpWxKcMIuHY44Y6DlkpO48tRuUGBWT0FyHwSKO72Ud%2BtJUfdaZ4CWNijzZtlRa8%2BCkmO%2FEwHYfPZFU%2FhzjFWH7vnzHRMo%2BaF9u8qHSAiEkA2HjoNQPEwHsDKOt6hOoK3Ce%2F%2B%2F9boMWDa44I6FrQhdgS7OnNaSzwxWKZMcyHi6LN4WC6sSj0qm2PSOGBTvDs%2FGWJS6SwEN%2FULwpb4LQo9fYjUfSXRwZkynUazlSpvX9e%2BG2zor8l%2BYaMxSEomDdLHGcD6YVQPegTaA74H8%2BV4WvJkFUrjMLGLlvSZQWvi8%2FQA7yzQ8GPno%2F%2F5SJHRP%2FOqKObPCo81s%2F%2B6WgLqykYpGAgQZhVDEBPXWgU%2FWzFZjKUhSFInufPRiMAUULC6T11yL45ZrRoB4DzOyJShKXaAJIBS9wzLYIoCEcJKQW8GVCx4fihqJ6mshBUXSw3wWVj3grrHQlGNGhIDNNzsxQ3M%2BGWn6ASobIWC%2BLbYOC6UpahVO13Zs2zOzZC8z7FmA05JhUGyBsF4tsG0drcggIFzgg%2Fkpf3%2BCnAXKiMgIE8Jk%2FMhpkc8DUJEUzDSnWlQFme3d0sHZDrg7LavtsEX3cHwjCYA17pMTfx8Ajw9hHscN67hyo%2BRJQ4458RmPywXykkVcW688oVUrQhahpPRvTWPnuI0B%2BSkQu7dCyvLRyFYlC1LG1gRCIvn3rwQeINzZQC2KXq31FaR9UmVV2QeGVqBHjmE%2BVMd3b1fhCynD0pQNhCG6%2FWCDbKPyE7NRQzL3BzQAJ0g09aUzcQA6mUp9iZFK6Sbp%2FYbHjo%2B%2B7%2FWj8S4YNa%2BZdqAw1hDrKWFXv9%2BzaXpf8ZTDSbiqsxnwN%2FCzK5tPkOr4tRh2kY3Bn9JtalbIOI4b3F7F1vPQMfoDcdxMS8CW9m%2FNCW%2FHILTUVWQIPiD0j1A6bo8vsv6P1hCESl2abrSJWDrq5sSzUpwoxaCU9FtJyYH4QFMxDBpkkBR6kn0LMPO%2B5EJ7Z6bCiRoPedRZ%2FP0SSdii7ZnPAtVwwHUidcdyspwncz5uq6vvm4IEDbJVLUFCn%2FLvIHfooUBTkFO130FC7CmmcrKdgDJcid9mvVzsDSibOoXtIf9k6ABle3PmIxejodc4aob0QKS432srrCMndbfD454q52V01G4q913mC5HOsTzWF4h2No1av1VbcUgWAqyoZl%2B11PoFYnNv2HwAODeNRkHj%2B8SF1fcvVBu6MrehHAZK1Gm69ICcTKizykHgGFx7QdowTVAsYEF2tVc0Z6wLryz2FI1sc5By2znJAAmINndoJiB4sfPdPrTC8RnkW7KRCwxC6YvXg5ahMlQuMpoCSXjOlBy0Kij%2BbsCYPbGp8BdCBiLmLSAkEQRaieWo1SYvZIKJGj9Ur%2FeWHjiB7SOVdqMAVmpBvfRiebsFjger7DC%2B8kRFGtNrTrnnGD2GAJb8rQCWkUPYHhwXsjNBSkE6lGWUj5QNhK0DMNM2l%2BkXRZ0KLZaGsFSIdQz%2FHXDxf3%2FTE30%2BDgBKWGWdxElyLccJfEpjsnszECNoDGZpdwdRgCixeg9L4EPhH%2BRptvRMVRaahu4cySjS3P5wxAUCPkmn%2BrhyASpmiTaiDeggaIxYBmtLZDDhiWIJaBgzfCsAGUF1Q1SFZYyXDt9skCaxJsxK2Ms65dmdp5WAZyxik%2FzbrTQk5KmgxCg%2Ff45L0jywebOWUYFJQAJia7XzCV0x89rpp%2Ff3AVWhSPyTanqmik2SkD8A3Ml4NhIGLAjBXtPShwKYfi2eXtrDuKLk4QlSyTw1ftXgwqA2jUuopDl%2B5tfUWZNwBpEPXghzbBggYCw%2Fdhy0ntds2yeHCDKkF%2FYxQjNIL%2FF%2F37jLPHCKBO9ibwYCmuxImIo0ijV2Wbg3kSN2psoe8IsABv3RNFaF9uMyCtCYtqcD%2BqNOhwMlfARQUdJ2tUX%2BMNJqOwIciWalZsmEjt07tfa8ma4cji9sqz%2BQ9hWfmMoKEbIHPOQORbhQRHIsrTYlnVTNvcq1imqmmPDdVDkJgRcTgB8Sb6epCQVmFZe%2BjGDiNJQLWnfx%2BdrTKYjm0G8yH0ZAGMWzEJhUEQ4Maimgf%2Fbkvo8PLVBsZl152y5S8%2BHRDfZIMCbYZ1WDp4yrdchOJw8k6R%2B%2F2pHmydK4NIK2PHdFPHtoLmHxRDwLFb7eB%2BM4zNZcB9NrAgjVyzLM7xyYSY13ykWfIEEd2n5%2FiYp3ZdrCf7fL%2Ben%2BsIJu2W7E30MrAgZBD1rAAbZHPgeAMtKCg3NpSpYQUDWJu9bT3V7tOKv%2BNRiJc8JAKqqgCA%2FPNRBR7ChpiEulyQApMK1AyqcWnpSOmYh6yLiWkGJ2mklCSPIqN7UypWj3dGi5MvsHQ87MrB4VFgypJaFriaHivwcHIpmyi5LhNqtem4q0n8awM19Qk8BOS0EsqGscuuydYsIGsbT5GHnERUiMpKJl4ON7qjB4fEqlGN%2FhCky89232UQCiaeWpDYCJINXjT6xl4Gc7DxRCtgV0i1ma4RgWLsNtnEBRQFqZggCLiuyEydmFd7WlogpkCw5G1x4ft2psm3KAREwVwr1Gzl6RT7FDAqpVal34ewVm3VH4qn5mjGj%2BbYL1NgfLNeXDwtmYSpwzbruDKpTjOdgiIHDVQSb5%2FzBgSMbHLkxWWgghIh9QTFSDILixVwg0Eg1puooBiHAt7DzwJ7m8i8%2Fi%2BjHvKf0QDnnHVkVTIqMvIQImOrzCJwhSR7qYB5gSwL6aWL9hERHCZc4G2%2BJrpgHNB8eCCmcIWIQ6rSdyPCyftXkDlErUkHafHRlkOIjxGbAktz75bnh50dU7YHk%2BMz7wwstg6RFZb%2BTZuSOx1qqP5C66c0mptQmzIC2dlpte7vZrauAMm%2F7RfBYkGtXWGiaWTtwvAQiq2oD4YixPLXE2khB2FRaNRDTk%2B9sZ6K74Ia9VntCpN4BhJGJMT4Z5c5FhSepRCRWmBXqx%2BwhVZC4me4saDs2iNqXMuCl6iAZflH8fscC1sTsy4PHeC%2BXYuqMBMUun5YezKbRKmEPwuK%2BCLzijPEQgfhahQswBBLfg%2FGBgBiI4QwAqzJkkyYAWtjzSg2ILgMAgqxYfwERRo3zruBL9WOryUArSD8sQOcD7fvIODJxKFS615KFPsb68USBEPPj1orNzFY2xoTtNBVTyzBhPbhFH0PI5AtlJBl2aSgNPYzxYLw7XTDBDinmVoENwiGzmngrMo8OmnRP0Z0i0Zrln9DDFcnmOoBZjABaQIbPOJYZGqX%2BRCMlDDbElcjaROLDoualmUIQ88Kekk3iM4OQrADcxi3rJguS4MOIBIgKgXrjd1WkbCdqxJk%2F4efRIFsavZA7KvvJQqp3Iid5Z0NFc5aiMRzGN3vrpBzaMy4JYde3wr96PjN90AYOIbyp6T4zj8LoE66OGcX1Ef4Z3KoWLAUF4BTg7ug%2FAbkG5UNQXAMkQezujSHeir2uTThgd3gpyzDrbnEdDRH2W7U6PeRvBX1ZFMP5RM%2BZu6UUZZD8hDPHldVWntTCNk7To8IeOW9yn2wx0gmurwqC60AOde4r3ETi5pVMSDK8wxhoGAoEX9NLWHIR33VbrbMveii2jAJlrxwytTHbWNu8Y4N8vCCyZjAX%2FpcsfwXbLze2%2BD%2Bu33OGBoJyAAL3jn3RuEcdp5If8O%2Ba4NKWvxOTyDltG0IWoHhwVGe7dKkCWFT%2B%2Btm%2BhaBCikRUUMrMhYKZJKYoVuv%2FbsJzO8DwfVIInQq3g3BYypiz8baogH3r3GwqCwFtZnz4xMjAVOYnyOi5HWbFA8n0qz1OjSpHWFzpQOpvkNETZBGpxN8ybhtqV%2FDMUxd9uFZmBfKXMCn%2FSqkWJyKPnT6lq%2B4zBZni6fYRByJn6OK%2BOgPBGRAJluwGSk4wxjOOzyce%2FPKODwRlsgrVkdcsEiYrqYdXo0Er2GXi2GQZd0tNJT6c9pK1EEJG1zgDJBoTVuCXGAU8BKTvCO%2FcEQ1Wjk3Zzuy90JX4m3O5IlxVFhYkSUwuQB2up7jhvkm%2BbddRQu5F9s0XftGEJ9JSuSk%2BZachCbdU45fEqbugzTIUokwoAKvpUQF%2FCvLbWW5BNQFqFkJg2f30E%2F48StNe5QwBg8zz3YAJ82FZoXBxXSv4QDooDo79NixyglO9AembuBcx5Re3CwOKTHebOPhkmFC7wNaWtoBhFuV4AkEuJ0J%2B1pT0tLkvFVZaNzfhs%2FKd3%2BA9YsImlO4XK4vpCo%2FelHQi%2F9gkFg07xxnuXLt21unCIpDV%2BbbRxb7FC6nWYTsMFF8%2B1LUg4JFjVt3vqbuhHmDKbgQ4e%2BRGizRiO8ky05LQGMdL2IKLSNar0kNG7lHJMaXr5mLdG3nykgj6vB%2FKVijd1ARWkFEf3yiUw1v%2FWaQivVUpIDdSNrrKbjO5NPnxz6qTTGgYg03HgPhDrCFyYZTi3XQw3HXCva39mpLNFtz8AiEhxAJHpWX13gCTAwgm9YTvMeiqetdNQv6IU0hH0G%2BZManTqDLPjyrOse7WiiwOJCG%2BJ0pZYULhN8NILulmYYvmVcV2MjAfA39sGKqGdjpiPo86fecg65UPyXDIAOyOkCx5NQsLeD4gGVjTVDwOHWkbbBW0GeNjDkcSOn2Nq4cEssP54t9D749A7M1AIOBl0Fi0sSO5v3P7LCBrM6ZwFY6kp2FX6AcbGUdybnfChHPyu6WlRZ2Fwv9YM0RMI7kISRgR8HpQSJJOyTfXj%2F6gQKuihPtiUtlCQVPohUgzfezTg8o1b3n9pNZeco1QucaoXe40Fa5JYhqdTspFmxGtW9h5ezLFZs3j%2FN46f%2BS2rjYNC2JySXrnSAFhvAkz9a5L3pza8eYKHNoPrvBRESpxYPJdKVUxBE39nJ1chrAFpy4MMkf0qKgYALctGg1DQI1kIymyeS2AJNT4X240d3IFQb%2F0jQbaHJ2YRK8A%2Bls6WMhWmpCXYG5jqapGs5%2FeOJErxi2%2F2KWVHiPellTgh%2FfNl%2F2KYPKb7DUcAg%2BmCOPQFCiU9Mq%2FWLcU1xxC8aLePFZZlE%2BPCLzf7ey46INWRw2kcXySR9FDgByXzfxiNKwDFbUSMMhALPFSedyjEVM5442GZ4hTrsAEvZxIieSHGSgkwFh%2FnFNdrrFD4tBH4Il7fW6ur4J8Xaz7RW9jgtuPEXQsYk7gcMs2neu3zJwTyUerHKSh1iTBkj2YJh1SSOZL5pLuQbFFAvyO4k1Hxg2h99MTC6cTUkbONQIAnEfGsGkNFWRbuRyyaEZInM5pij73EA9rPIUfU4XoqQpHT9THZkW%2BoKFLvpyvTBMM69tN1Ydwv1LIEhHsC%2BueVG%2Bw%2BkyCPsvV3erRikcscHjZCkccx6VrBkBRusTDDd8847GA7p2Ucy0y0HdSRN6YIBciYa4vuXcAZbQAuSEmzw%2BH%2FAuOx%2BaH%2BtBL88H57D0MsqyiZxhOEQkF%2F8DR1d2hSPMj%2FsNOa5rxcUnBgH8ictv2J%2Bcb4BA4v3MCShdZ2vtK30vAwkobnEWh7rsSyhmos3WC93Gn9C4nnAd%2FPjMMtQfyDNZsOPd6XcAsnBE%2FmRHtHEyJMzJfZFLE9OvQa0i9kUmToJ0ZxknTgdl%2FXPV8xoh0K7wNHHsnBdvFH3sv52lU7UFteseLG%2FVanIvcwycVA7%2BBE1Ulyb20BvwUWZcMTKhaCcmY3ROpvonVMV4N7yBXTL7IDtHzQ4CCcqF66LjF3xUqgErKzolLyCG6Kb7irP%2FMVTCCwGRxfrPGpMMGvPLgJ881PHMNMIO09T5ig7AzZTX%2F5PLlwnJLDAPfuHynSGhV4tPqR3gJ4kg4c06c%2FF1AcjGytKm2Yb5jwMotF7vro4YDLWlnMIpmPg36NgAZsGA0W1spfLSue4xxat0Gdwd0lqDBOgIaMANykwwDKejt5YaNtJYIkrSgu0KjIg0pznY0SCd1qlC6R19g97UrWDoYJGlrvCE05J%2F5wkjpkre727p5PTRX5FGrSBIfJqhJE%2FIS876PaHFkx9pGTH3oaY3jJRvLX9Iy3Edoar7cFvJqyUlOhAEiOSAyYgVEGkzHdug%2BoRHIEOXAExMiTSKU9A6nmRC8mp8iYhwWdP2U%2F5EkFAdPrZw03YA3gSyNUtMZeh7dDCu8pF5x0VORCTgKp07ehy7NZqKTpIC4UJJ89lnboyAfy5OyXzXtuDRbtAFjZRSyGFTpFrXwkpjSLIQIG3N0Vj4BtzK3wdlkBJrO18MNsgseR4BysJilI0wI6ZahLhBFA0XBmV8d4LUzEcNVb0xbLjLTETYN8OEVqNxkt10W614dd1FlFFVTIgB7%2FBQQp1sWlNolpIu4ekxUTBV7NmxOFKEBmmN%2BnA7pvF78%2FRII5ZHA09OAiE%2F66MF6HQ%2BqVEJCHxwymukkNvzqHEh52dULPbVasfQMgTDyBZzx4007YiKdBuUauQOt27Gmy8ISclPmEUCIcuLbkb1mzQSqIa3iE0PJh7UMYQbkpe%2BhXjTJKdldyt2mVPwywoODGJtBV1lJTgMsuSQBlDMwhEKIfrvsxGQjHPCEfNfMAY2oxvyKcKPUbQySkKG6tj9AQyEW3Q5rpaDJ5Sns9ScLKeizPRbvWYAw4bXkrZdmB7CQopCH8NAmqbuciZChHN8lVGaDbCnmddnqO1PQ4ieMYfcSiBE5zzMz%2BJV%2F4eyzrzTEShvqSGzgWimkNxLvUj86iAwcZuIkqdB0VaIB7wncLRmzHkiUQpPBIXbDDLHBlq7vp9xwuC9AiNkIptAYlG7Biyuk8ILdynuUM1cHWJgeB%2BK3wBP%2FineogxkvBNNQ4AkW0hvpBOQGFfeptF2YTR75MexYDUy7Q%2F9uocGsx41O4IZhViw%2F2FvAEuGO5g2kyXBUijAggWM08bRhXg5ijgMwDJy40QeY%2FcQpUDZiIzmvskQpO5G1zyGZA8WByjIQU4jRoFJt56behxtHUUE%2Fom7Rj2psYXGmq3llVOCgGYKNMo4pzwntITtapDqjvQtqpjaJwjHmDzSVGLxMt12gEXAdLi%2FcaHSM3FPRGRf7dB7YC%2BcD2ho6oL2zGDCkjlf%2FDFoQVl8GS%2F56wur3rdV6ggtzZW60MRB3g%2BU1W8o8cvqIpMkctiGVMzXUFI7FacFLrgtdz4mTEr4aRAaQ2AFQaNeG7GX0yOJgMRYFziXdJf24kg%2FgBQIZMG%2FYcPEllRTVNoDYR6oSJ8wQNLuihfw81UpiKPm714bZX1KYjcXJdfclCUOOpvTxr9AAJevTY4HK%2FG7F3mUc3GOAKqh60zM0v34v%2BELyhJZqhkaMA8UMMOU90f8RKEJFj7EqepBVwsRiLbwMo1J2zrE2UYJnsgIAscDmjPjnzI8a719Wxp757wqmSJBjXowhc46QN4RwKIxqEE6E5218OeK7RfcpGjWG1jD7qND%2B%2FGTk6M56Ig4yMsU6LUW1EWE%2BfIYycVV1thldSlbP6ltdC01y3KUfkobkt2q01YYMmxpKRvh1Z48uNKzP%2FIoRIZ%2FF6buOymSnW8gICitpJjKWBscSb9JJKaWkvEkqinAJ2kowKoqkqZftRqfRQlLtKoqvTRDi2vg%2FRrPD%2Fd3a09J8JhGZlEkOM6znTsoMCsuvTmywxTCDhw5dd0GJOHCMPbsj3QLkTE3MInsZsimDQ3HkvthT7U9VA4s6G07sID0FW4SHJmRGwCl%2BMu4xf0ezqeXD2PtPDnwMPo86sbwDV%2B9PWcgFcARUVYm3hrFQrHcgMElFGbSM2A1zUYA3baWfheJp2AINmTJLuoyYD%2FOwA4a6V0ChBN97E8YtDBerUECv0u0TlxR5yhJCXvJxgyM73Bb6pyq0jTFJDZ4p1Am1SA6sh8nADd1hAcGBMfq4d%2FUfwnmBqe0Jun1n1LzrgKuZMAnxA3NtCN7Klf4BH%2B14B7ibBmgt0TGUafVzI4uKlpF7v8NmgNjg90D6QE3tbx8AjSAC%2BOA1YJvclyPKgT27QpIEgVYpbPYGBsnyCNrGz9XUsCHkW1QAHgL2STZk12QGqmvAB0NFteERkvBIH7INDsNW9KKaAYyDMdBEMzJiWaJHZALqDxQDWRntumSDPcplyFiI1oDpT8wbwe01AHhW6%2BvAUUBoGhY3CT2tgwehdPqU%2F4Q7ZLYvhRl%2FogOvR9O2%2BwkkPKW5vCTjD2fHRYXONCoIl4Jh1bZY0ZE1O94mMGn%2FdFSWBWzQ%2FVYk%2BGezi46RgiDv3EshoTmMSlioUK6MQEN8qeyK6FRninyX8ZPeUWjjbMJChn0n%2FyJvrq5bh5UcCAcBYSafTFg7p0jDgrXo2QWLb3WpSOET%2FHh4oSadBTvyDo10IufLzxiMLAnbZ1vcUmj3w7BQuIXjEZXifwukVxrGa9j%2BDXfpi12m1RbzYLg9J2wFergEwOxFyD0%2FJstNK06ZN2XdZSGWxcJODpQHOq4iKqjqkJUmPu1VczL5xTGUfCgLEYyNBCCbMBFT%2FcUP6pE%2FmujnHsSDeWxMbhrNilS5MyYR0nJyzanWXBeVcEQrRIhQeJA6Xt4f2eQESNeLwmC10WJVHqwx8SSyrtAAjpGjidcj1E2FYN0LObUcFQhafUKTiGmHWRHGsFCB%2BHEXgrzJEB5bp0QiF8ZHh11nFX8AboTD0PS4O1LqF8XBks2MpjsQnwKHF6HgaKCVLJtcr0XjqFMRGfKv8tmmykhLRzu%2BvqQ02%2BKpJBjaLt9ye1Ab%2BBbEBhy4EVdIJDrL2naV0o4wU8YZ2Lq04FG1mWCKC%2BUwkXOoAjneU%2FxHplMQo2cXUlrVNqJYczgYlaOEczVCs%2FOCgkyvLmTmdaBJc1iBLuKwmr6qtRnhowngsDxhzKFAi02tf8bmET8BO27ovJKF1plJwm3b0JpMh38%2BxsrXXg7U74QUM8ZCIMOpXujHntKdaRtsgyEZl5MClMVMMMZkZLNxH9%2Bb8fH6%2Bb8Lev30A9TuEVj9CqAdmwAAHBPbfOBFEATAPZ2CS0OH1Pj%2F0Q7PFUcC8hDrxESWdfgFRm%2B7vvWbkEppHB4T%2F1ApWnlTIqQwjcPl0VgS1yHSmD0OdsCVST8CQVwuiew1Y%2Bg3QGFjNMzwRB2DSsAk26cmA8lp2wIU4p93AUBiUHFGOxOajAqD7Gm6NezNDjYzwLOaSXRBYcWipTSONHjUDXCY4mMI8XoVCR%2FRrs%2FJLKXgEx%2BqkmeDlFOD1%2FyTQNDClRuiUyKYCllfMiQiyFkmuTz2vLsBNyRW%2Bxz%2B5FElFxWB28VjYIGZ0Yd%2B5wIjkcoMaggxswbT0pCmckRAErbRlIlcOGdBo4djTNO8FAgQ%2BlT6vPS60BwTRSUAM3ddkEAZiwtEyArrkiDRnS7LJ%2B2hwbzd2YDQagSgACpsovmjil5wfPuXq3GuH0CyE7FK3M4FgRaFoIkaodORrPx1%2BJpI9psyNYIFuJogZa0%2F1AhOWdlHQxdAgbwacsHqPZo8u%2FngAH2GmaTdhYnBfSDbBfh8CHq6Bx5bttP2%2BRdM%2BMAaYaZ0Y%2FADkbNCZuAyAVQa2OcXOeICmDn9Q%2FeFkDeFQg5MgHEDXq%2FtVjj%2Bjtd26nhaaolWxs1ixSUgOBwrDhRIGOLyOVk2%2FBc0UxvseQCO2pQ2i%2BKrfhu%2FWeBovNb5dJxQtJRUDv2mCwYVpNl2efQM9xQHnK0JwLYt%2FU0Wf%2BphiA4uw8G91slC832pmOTCAoZXohg1fewCZqLBhkOUBofBWpMPsqg7XEXgPfAlDo2U5WXjtFdS87PIqClCK5nW6adCeXPkUiTGx0emOIDQqw1yFYGHEVx20xKjJVYe0O8iLmnQr3FA9nSIQilUKtJ4ZAdcTm7%2BExseJauyqo30hs%2B1qSW211A1SFAOUgDlCGq7eTIcMAeyZkV1SQJ4j%2Fe1Smbq4HcjqgFbLAGLyKxlMDMgZavK5NAYH19Olz3la%2FQCTiVelFnU6O%2FGCvykqS%2FwZJDhKN9gBtSOp%2F1SP5VRgJcoVj%2Bkmf2wBgv4gjrgARBWiURYx8xENV3bEVUAAWWD3dYDKAIWk5opaCFCMR5ZjJExiCAw7gYiSZ2rkyTce4eNMY3lfGn%2B8p6%2BvBckGlKEXnA6Eota69OxDO9oOsJoy28BXOR0UoXNRaJD5ceKdlWMJlOFzDdZNpc05tkMGQtqeNF2lttZqNco1VtwXgRstLSQ6tSPChgqtGV5h2DcDReIQadaNRR6AsAYKL5gSFsCJMgfsaZ7DpKh8mg8Wz8V7H%2BgDnLuMxaWEIUPevIbClgap4dqmVWSrPgVYCzAoZHIa5z2Ocx1D%2FGvDOEqMOKLrMefWIbSWHZ6jbgA8qVBhYNHpx0P%2BjAgN5TB3haSifDcApp6yymEi6Ij%2FGsEpDYUgcHATJUYDUAmC1SCkJ4cuZXSAP2DEpQsGUjQmKJfJOvlC2x%2FpChkOyLW7KEoMYc5FDC4v2FGqSoRWiLsbPCiyg1U5yiHZVm1XLkHMMZL11%2Fyxyw0UnGig3MFdZklN5FI%2FqiT65T%2BjOXOdO7XbgWurOAZR6Cv9uu1cm5LjkXX4xi6mWn5r5NjBS0gTliHhMZI2WNqSiSphEtiCAwnafS11JhseDGHYQ5%2BbqWiAYiAv6Jsf79%2FVUs4cIl%2Bn6%2BWOjcgB%2F2l5TreoAV2717JzZbQIR0W1cl%2FdEqCy5kJ3ZSIHuU0vBoHooEpiHeQWVkkkOqRX27eD1FWw4BfO9CJDdKoSogQi3hAAwsPRFrN5RbX7bqLdBJ9JYMohWrgJKHSjVl1sy2xAG0E3sNyO0oCbSGOxCNBRRXTXenYKuwAoDLfnDcQaCwehUOIDiHAu5m5hMpKeKM4sIo3vxACakIxKoH2YWF2QM84e6F5C5hJU4g8uxuFOlAYnqtwxmHyNEawLW%2FPhoawJDrGAP0JYWHgAVUByo%2FbGdiv2T2EMg8gsS14%2FrAdzlOYazFE7w4OzxeKiWdm3nSOnQRRKXSlVo8HEAbBfyJMKqoq%2BSCcTSx5NDtbFwNlh8VhjGGDu7JG5%2FTAGAvniQSSUog0pNzTim8Owc6QTuSKSTXlQqwV3eiEnklS3LeSXYPXGK2VgeZBqNcHG6tZHvA3vTINhV0ELuQdp3t1y9%2BogD8Kk%2FW7QoRN1UWPqM4%2BxdygkFDPLoTaumKReKiLWoPHOfY54m3qPx4c%2B4pgY3MRKKbljG8w4wvz8pxk3AqKsy4GMAkAtmRjRMsCxbb4Q2Ds0Ia9ci8cMT6DmsJG00XaHCIS%2Bo3F8YVVeikw13w%2BOEDaCYYhC0ZE54kA4jpjruBr5STWeqQG6M74HHL6TZ3lXrd99ZX%2B%2B7LhNatQaZosuxEf5yRA15S9gPeHskBIq3Gcw81AGb9%2FO53DYi%2F5CsQ51EmEh8Rkg4vOciClpy4d04eYsfr6fyQkBmtD%2BP8sNh6e%2BXYHJXT%2FlkXxT4KXU5F2sGxYyzfniMMQkb9OjDN2C8tRRgTyL7GwozH14PrEUZc6oz05Emne3Ts5EG7WolDmU8OB1LDG3VrpQxp%2BpT0KYV5dGtknU64JhabdqcVQbGZiAxQAnvN1u70y1AnmvOSPgLI6uB4AuDGhmAu3ATkJSw7OtS%2F2ToPjqkaq62%2F7WFG8advGlRRqxB9diP07JrXowKR9tpRa%2BjGJ91zxNTT1h8I2PcSfoUPtd7NejVoH03EUcqSBuFZPkMZhegHyo2ZAITovmm3zAIdGFWxoNNORiMRShgwdYwFzkPw5PA4a5MIIQpmq%2Bnsp3YMuXt%2FGkXxLx%2FP6%2BZJS0lFyz4MunC3eWSGE8xlCQrKvhKUPXr0hjpAN9ZK4PfEDrPMfMbGNWcHDzjA7ngMxTPnT7GMHar%2BgMQQ3NwHCv4zH4BIMYvzsdiERi6gebRmerTsVwZJTRsL8dkZgxgRxmpbgRcud%2BYlCIRpPwHShlUSwuipZnx9QCsEWziVazdDeKSYU5CF7UVPAhLer3CgJOQXl%2Fzh575R5rsrmRnKAzq4POFdgbYBuEviM4%2BLVC15ssLNFghbTtHWerS1hDt5s4qkLUha%2FqpZXhWh1C6lTQAqCNQnaDjS7UGFBC6wTu8yFnKJnExCnAs3Ok9yj5KpfZESQ4lTy5pTGTnkAUpxI%2ByjEldJfSo4y0QhG4i4IwkRFGcjWY8%2BEzgYYJUK7BXQksLxAww%2FYYWBMhJILB9e8ePEJ4OP7z%2B4%2FwOQDl64iOYDp26DaONPxpKtBxq%2FaTzRGarm3VkPYTLJKx6Z%2FMw2YbBGseJhPMwhhNswrIkyvV2BYzrvZbxLpKwcWJhYmFtVZ%2BlPEq91FzVp1HlQY1bZVLqeNR9SAUn6n0E28k%2FUuGkNpP1DBI5ch%2FEehZfjUQ9aE41NhETExoPT2gGQz0IhWJbEOvTQ4wgcXCHHFBhewYUiFHuhRSAUVmEHeCRQHQkXGFwkAgyzREJCVN7TRnTon36Zw3tPhx4EALwNdwDv%2BJ41YSP4B2CQqz0EFgARZ4ESgBHQgROwAVn9GTI%2BHYexTUevLUeta4%2FDqKrbMVS%2BYqb8hUwYCrlgKtmAq1YCrFgKrd4qpXiqZcKn1oqdWipjYKpWwVPVYqW6xUpVipKqFR3QKjagVEtAqHpxUMTitsnFaJOKx2cVhswq35RVpyiq9lFVNIKnOQVMkgqtYxVNxiqQjFS7GKlSIVIsQqPIhUWwioigFQ%2B%2BKkN8VHr49HDw9Ebo9EDo9DTo9Crg9BDg9%2FWx7gWx7YWwlobYrOGxWPNisAaAHEyALpkAVDIAeWAArsABVXACYuAD5cAF6wAKFQAQqgAbVAAsoAAlQAUaYAfkwAvogBWQACOgAD9AAHSAAKT4GUdMiOvFngBTwCn2AZ7Dv6B6k%2F90B8%2ByRnkV144AIBoAMTQATGgAjNAA4YABgwABZgB%2FmQCwyAVlwCguASlwCEuAQFwB4uAMlwBYuAJlQAUVAAhUD2KgdpUDaJgaRMDFJgX5MC1JgWJEAokQCWRAHxEAWkQBMRADpEAMkQAYROAEecC484DRpwBDTnwNOdw05tjTmiNOYwtswhYFwLA7BYG4LA2BYGOLAwRYFuLAsxYFQJAohIEyJAMwkAwiQC0JAJgkAeiQBkJAFokAPCQA0JABwcD4Dgc4cDdDgaYcDIDgYgUC6CgWgUClCgUYUAVBQBOFAEYMALgwAgDA9QYAdIn8AZzeBB2L5EcWrenUT1KXienEsuJJ7x5U8XlTjc1NVzUyXFTGb1LlpUtWlTDIjqwE4LsagowoCi2gJLKAkpoBgJQNpAIhNqaEoneI6kiiqQ6Go%2Fn6j0cS%2Ba2gEU8gIHJ%2BBwfgZX4GL%2BBd%2FgW34FZ%2BBS%2FgUH4FN6BTegTvoEv6BJegRnYEF2A79gOvYDl2BdEjCkqkGtwXp0LNToIskOTXzh%2FF062yJ7AAAAEDAWAAABWhJ%2BKPEIJgBFxMVP7w2QJBGHASQnOBKXKFIdUK4igKA9IEaYJg%29%3Bsrc%3Aurl%28data%3Aapplication%2Fvnd%2Ems%2Dfontobject%3Bbase64%2Cn04AAEFNAAACAAIABAAAAAAABQAAAAAAAAABAJABAAAEAExQAAAAAAAAAAIAAAAAAAAAAAEAAAAAAAAAJxJ%2FLAAAAAAAAAAAAAAAAAAAAAAAACgARwBMAFkAUABIAEkAQwBPAE4AUwAgAEgAYQBsAGYAbABpAG4AZwBzAAAADgBSAGUAZwB1AGwAYQByAAAAeABWAGUAcgBzAGkAbwBuACAAMQAuADAAMAA5ADsAUABTACAAMAAwADEALgAwADAAOQA7AGgAbwB0AGMAbwBuAHYAIAAxAC4AMAAuADcAMAA7AG0AYQBrAGUAbwB0AGYALgBsAGkAYgAyAC4ANQAuADUAOAAzADIAOQAAADgARwBMAFkAUABIAEkAQwBPAE4AUwAgAEgAYQBsAGYAbABpAG4AZwBzACAAUgBlAGcAdQBsAGEAcgAAAAAAQlNHUAAAAAAAAAAAAAAAAAAAAAADAKncAE0TAE0ZAEbuFM3pjM%2FSEdmjKHUbyow8ATBE40IvWA3vTu8LiABDQ%2BpexwUMcm1SMnNryctQSiI1K5ZnbOlXKmnVV5YvRe6RnNMFNCOs1KNVpn6yZhCJkRtVRNzEufeIq7HgSrcx4S8h%2Fv4vnrrKc6oCNxmSk2uKlZQHBii6iKFoH0746ThvkO1kJHlxjrkxs%2BLWORaDQBEtiYJIR5IB9Bi1UyL4Rmr0BNigNkMzlKQmnofBHviqVzUxwdMb3NdCn69hy%2BpRYVKGVS%2F1tnsqv4LL7wCCPZZAZPT4aCShHjHJVNuXbmMrY5LeQaGnvAkXlVrJgKRAUdFjrWEah9XebPeQMj7KS7DIBAFt8ycgC5PLGUOHSE3ErGZCiViNLL5ZARfywnCoZaKQCu6NuFX42AEeKtKUGnr%2FCm2Cy8tpFhBPMW5Fxi4Qm4TkDWh4IWFDClhU2hRWosUWqcKLlgyXB%2BlSHaWaHiWlBAR8SeSgSPCQxdVQgzUixWKSTrIQEbU94viDctkvX%2BVSjJuUmV8L4CXShI11esnp0pjWNZIyxKHS4wVQ2ime1P4RnhvGw0aDN1OLAXGERsB7buFpFGGBAre4QEQR0HOIO5oYH305G%2BKspT%2FFupEGGafCCwxSe6ZUa%2B073rXHnNdVXE6eWvibUS27XtRzkH838mYLMBmYysZTM0EM3A1fbpCBYFccN1B%2FEnCYu%2FTgCGmr7bMh8GfYL%2BBfcLvB0gRagC09w9elfldaIy%2FhNCBLRgBgtCC7jAF63wLSMAfbfAlEggYU0bUA7ACCJmTDpEmJtI78w4%2FBO7dN7JR7J7ZvbYaUbaILSQsRBiF3HGk5fEg6p9unwLvn98r%2BvnsV%2B372uf1xBLq4qU%2F45fTuqaAP%2BpssmCCCTF0mhEow8ZXZOS8D7Q85JsxZ%2BAzok7B7O%2Ff6J8AzYBySZQB%2FQHYUSA%2BEeQhEWiS6AIQzgcsDiER4MjgMBAWDV4AgQ3g1eBgIdweCQmCjJEMkJ%2BPKRWyFHHmg1Wi%2F6xzUgA0LREoKJChwnQa9B%2B5RQZRB3IlBlkAnxyQNaANwHMowzlYSMCBgnbpzvqpl0iTJNCQidDI9ZrSYNIRBhHtUa5YHMHxyGEik9hDE0AKj72AbTCaxtHPUaKZdAZSnQTyjGqGLsmBStCejApUhg4uBMU6mATujEl%2BKdDPbI6Ag4vLr%2BhjY6lbjBeoLKnZl0UZgRX8gTySOeynZVz1wOq7e1hFGYIq%2BMhrGxDLak0PrwYzSXtcuyhXEhwOYofiW%2BEcI%2Fjw8P6IY6ed%2BetAbuqKp5QIapT77LnAe505lMuqL79a0ut4rWexzFttsOsLDy7zvtQzcq3U1qabe7tB0wHWVXji%2BzDbo8x8HyIRUbXnwUcklFv51fvTymiV%2BMXLSmGH9d9%2BaXpD5X6lao41anWGig7IwIdnoBY2ht%2FpO9mClLo4NdXHAsefqWUKlXJkbqPOFhMoR4aiA1BXqhRNbB2Xwi%2B7u%2FjpAoOpKJ0UX24EsrzMfHXViakCNcKjBxuQX8BO0ZqjJ3xXzf%2B61t2VXOSgJ8xu65QKgtN6FibPmPYsXbJRHHqbgATcSZxBqGiDiU4NNNsYBsKD0MIP%2FOfKnlk%2FLkaid%2FO2NbKeuQrwOB2Gq3YHyr6ALgzym5wIBnsdC1ZkoBFZSQXChZvlesPqvK2c5oHHT3Q65jYpNxnQcGF0EHbvYqoFw60WNlXIHQF2HQB7zD6lWjZ9rVqUKBXUT6hrkZOle0RFYII0V5ZYGl1JAP0Ud1fZZMvSomBzJ710j4Me8mjQDwEre5Uv2wQfk1ifDwb5ksuJQQ3xt423lbuQjvoIQByQrNDh1JxGFkOdlJvu%2FgFtuW0wR4cgd%2BZKesSV7QkNE2kw6AV4hoIuC02LGmTomyf8PiO6CZzOTLTPQ%2BHW06H%2Btx%2BbQ8LmDYg1pTFrp2oJXgkZTyeRJZM0C8aE2LpFrNVDuhARsN543%2FFV6klQ6Tv1OoZGXLv0igKrl%2FCmJxRmX7JJbJ998VSIPQRyDBICzl4JJlYHbdql30NvYcOuZ7a10uWRrgoieOdgIm4rlq6vNOQBuqESLbXG5lzdJGHw2m0sDYmODXbYGTfSTGRKpssTO95fothJCjUGQgEL4yKoGAF%2F0SrpUDNn8CBgBcSDQByAeNkCXp4S4Ro2Xh4OeaGRgR66PVOsU8bc6TR5%2FxTcn4IVMLOkXSWiXxkZQCbvKfmoAvQaKjO3EDKwkwqHChCDEM5loQRPd5ACBki1TjF772oaQhQbQ5C0lcWXPFOzrfsDGUXGrpxasbG4iab6eByaQkQfm0VFlP0ZsDkvvqCL6QXMUwCjdMx1ZOyKhTJ7a1GWAdOUcJ8RSejxNVyGs31OKMyRyBVoZFjqIkmKlLQ5eHMeEL4MkUf23cQ%2F1SgRCJ1dk4UdBT7OoyuNgLs0oCd8RnrEIb6QdMxT2QjD4zMrJkfgx5aDMcA4orsTtKCqWb%2FVeyceqa5OGSmB28YwH4rFbkQaLoUN8OQQYnD3w2eXpI4ScQfbCUZiJ4yMOIKLyyTc7BQ4uXUw6Ee6%2FxM%2B4Y67ngNBknxIPwuppgIhFcwJyr6EIj%2BLzNj%2FmfR2vhhRlx0BILZoAYruF0caWQ7YxO66UmeguDREAFHYuC7HJviRgVO6ruJH59h%2FC%2FPkgSle8xNzZJULLWq9JMDTE2fjGE146a1Us6PZDGYle6ldWRqn%2FpdpgHKNGrGIdkRK%2BKPETT9nKT6kLyDI8xd9A1FgWmXWRAIHwZ37WyZHOVyCadJEmMVz0MadMjDrPho%2BEIochkVC2xgGiwwsQ6DMv2P7UXqT4x7CdcYGId2BJQQa85EQKmCmwcRejQ9Bm4oATENFPkxPXILHpMPUyWTI5rjNOsIlmEeMbcOCEqInpXACYQ9DDxmFo9vcmsDblcMtg4tqBerNngkIKaFJmrQAPnq1dEzsMXcwjcHdfdCibcAxxA%2Bq%2Fj9m3LM%2FO7WJka4tSidVCjsvo2lQ%2F2ewyoYyXwAYyr2PlRoR5MpgVmSUIrM3PQxXPbgjBOaDQFIyFMJvx3Pc5RSYj12ySVF9fwFPQu2e2KWVoL9q3Ayv3IzpGHUdvdPdrNUdicjsTQ2ISy7QU3DrEytIjvbzJnAkmANXjAFERA0MUoPF3%2F5KFmW14bBNOhwircYgMqoDpUMcDtCmBE82QM2YtdjVLB4kBuKho%2FbcwQdeboqfQartuU3CsCf%2BcXkgYAqp%2F0Ee3RorAZt0AvvOCSI4JICIlGlsV0bsSid%2FNIEALAAzb6HAgyWHBps6xAOwkJIGcB82CxRQq4sJf3FzA70A%2BTRqcqjEMETCoez3mkPcpnoALs0ugJY8kQwrC%2BJE5ik3w9rzrvDRjAQnqgEVvdGrNwlanR0SOKWzxOJOvLJhcd8Cl4AshACUkv9czdMkJCVQSQhp6kp7StAlpVRpK0t0SW6LHeBJnE2QchB5Ccu8kxRghZXGIgZIiSj7gEKMJDClcnX6hgoqJMwiQDigIXg3ioFLCgDgjPtYHYpsF5EiA4kcnN18MZtOrY866dEQAb0FB34OGKHGZQjwW%2FWDHA60cYFaI%2FPjpzquUqdaYGcIq%2BmLez3WLFFCtNBN2QJcrlcoELgiPku5R5dSlJFaCEqEZle1AQzAKC%2B1SotMcBNyQUFuRHRF6OlimSBgjZeTBCwLyc6A%2BP%2FoFRchXTz5ADknYJHxzrJ5pGuIKRQISU6WyKTBBjD8WozmVYWIsto1AS5rxzKlvJu4E%2FvwOiKxRtCWsDM%2BeTHUrmwrCK5BIfMzGkD%2B0Fk5LzBs0jMYXktNDblB06LMNJ09U8pzSLmo14MS0OMjcdrZ31pyQqxJJpRImlSvfYAK8inkYU52QY2FPEVsjoWewpwhRp5yAuNpkqhdb7ku9Seefl2D0B8SMTFD90xi4CSOwwZy9IKkpMtI3FmFUg3%2FkFutpQGNc3pCR7gvC4sgwbupDu3DyEN%2BW6YGLNM21jpB49irxy9BSlHrVDlnihGKHwPrbVFtc%2Bh1rVQKZduxIyojccZIIcOCmhEnC7UkY68WXKQgLi2JCDQkQWJRQuk60hZp0D3rtCTINSeY9Ej2kIKYfGxwOs4j9qMM7fYZiipzgcf7TamnehqdhsiMiCawXnz4xAbyCkLAx5EGbo3Ax1u3dUIKnTxIaxwQTHehPl3V491H0%2BbC5zgpGz7Io%2BmjdhKlPJ01EeMpM7UsRJMi1nGjmJg35i6bQBAAxjO%2FENJubU2mg3ONySEoWklCwdABETcs7ck3jgiuU9pcKKpbgn%2B3YlzV1FzIkB6pmEDOSSyDfPPlQskznctFji0kpgZjW5RZe6x9kYT4KJcXg0bNiCyif%2BpZACCyRMmYsfiKmN9tSO65F0R2OO6ytlEhY5Sj6uRKfFxw0ijJaAx%2Fk3QgnAFSq27%2F2i4GEBA%2BUvTJKK%2F9eISNvG46Em5RZfjTYLdeD8kdXHyrwId%2FDQZUaMCY4gGbke2C8vfjgV%2FY9kkRQOJIn%2FxM9INZSpiBnqX0Q9GlQPpPKAyO5y%2BW5NMPSRdBCUlmuxl40ZfMCnf2Cp044uI9WLFtCi4YVxKjuRCOBWIb4XbIsGdbo4qtMQnNOQz4XDSui7W%2FN6l54qOynCqD3DpWQ%2BmpD7C40D8BZEWGJX3tlAaZBMj1yjvDYKwCJBa201u6nBKE5UE%2B7QSEhCwrXfbRZylAaAkplhBWX50dumrElePyNMRYUrC99UmcSSNgImhFhDI4BXjMtiqkgizUGCrZ8iwFxU6fQ8GEHCFdLewwxYWxgScAYMdMLmcZR6b7rZl95eQVDGVoUKcRMM1ixXQtXNkBETZkVVPg8LoSrdetHzkuM7DjZRHP02tCxA1fmkXKF3VzfN1pc1cv%2F8lbTIkkYpqKM9VOhp65ktYk%2BQ46myFWBapDfyWUCnsnI00QTBQmuFjMZTcd0V2NQ768Fhpby04k2IzNR1wKabuGJqYWwSly6ocMFGTeeI%2BejsWDYgEvr66QgqdcIbFYDNgsm0x9UHY6SCd5%2B7tpsLpKdvhahIDyYmEJQCqMqtCF6UlrE5GXRmbu%2Bvtm3BFSxI6ND6UxIE7GsGMgWqghXxSnaRJuGFveTcK5ZVSPJyjUxe1dKgI6kNF7EZhIZs8y8FVqwEfbM0Xk2ltORVDKZZM40SD3qQoQe0orJEKwPfZwm3YPqwixhUMOndis6MhbmfvLBKjC8sKKIZKbJk8L11oNkCQzCgvjhyyEiQSuJcgCQSG4Mocfgc0Hkwcjal1UNgP0CBPikYqBIk9tONv4kLtBswH07vUCjEaHiFGlLf8MgXKzSgjp2HolRRccAOh0ILHz9qlGgIFkwAnzHJRjWFhlA7ROwINyB5HFj59PRZHFor6voq7l23EPNRwdWhgawqbivLSjRA4htEYUFkjESu67icTg5S0aW1sOkCiIysfJ9UnIWevOOLGpepcBxy1wEhd2WI3AZg7sr9WBmHWyasxMcvY%2FiOmsLtHSWNUWEGk9hScMPShasUA1AcHOtRZlqMeQ0OzYS9vQvYUjOLrzP07BUAFikcJNMi7gIxEw4pL1G54TcmmmoAQ5s7TGWErJZ2Io4yQ0ljRYhL8H5e62oDtLF8aDpnIvZ5R3GWJyAugdiiJW9hQAVTsnCBHhwu7rkBlBX6r3b7ejEY0k5GGeyKv66v%2B6dg7mcJTrWHbtMywbedYqCQ0FPwoytmSWsL8WTtChZCKKzEF7vP6De4x2BJkkniMgSdWhbeBSLtJZR9CTHetK1xb34AYIJ37OegYIoPVbXgJ%2FqDQK%2BbfCtxQRVKQu77WzOoM6SGL7MaZwCGJVk46aImai9fmam%2BWpHG%2B0BtQPWUgZ7RIAlPq6lkECUhZQ2gqWkMYKcYMYaIc4gYCDFHYa2d1nzp3%2BJ1eCBay8IYZ0wQRKGAqvCuZ%2FUgbQPyllosq%2BXtfKIZOzmeJqRazpmmoP%2F76YfkjzV2NlXTDSBYB04SVlNQsFTbGPk1t%2FI4Jktu0XSgifO2ozFOiwd%2F0SssJDn0dn4xqk4GDTTKX73%2FwQyBLdqgJ%2BWx6AQaba3BA9CKEzjtQYIfAsiYamapq80LAamYjinlKXUkxdpIDk0puXUEYzSalfRibAeDAKpNiqQ0FTwoxuGYzRnisyTotdVTclis1LHRQCy%2FqqL8oUaQzWRxilq5Mi0IJGtMY02cGLD69vGjkj3p6pGePKI8bkBv5evq8SjjyU04vJR2cQXQwSJyoinDsUJHCQ50jrFTT7yRdbdYQMB3MYCb6uBzJ9ewhXYPAIZSXfeEQBZZ3GPN3Nbhh%2FwkvAJLXnQMdi5NYYZ5GHE400GS5rXkOZSQsdZgIbzRnF9ueLnsfQ47wHAsirITnTlkCcuWWIUhJSbpM3wWhXNHvt2xUsKKMpdBSbJnBMcihkoDqAd1Zml%2FR4yrzow1Q2A5G%2Bkzo%2FRhRxQS2lCSDRV8LlYLBOOoo1bF4jwJAwKMK1tWLHlu9i0j4Ig8qVm6wE1DxXwAwQwsaBWUg2pOOol2dHxyt6npwJEdLDDVYyRc2D0HbcbLUJQj8gPevQBUBOUHXPrsAPBERICpnYESeu2OHotpXQxRGlCCtLdIsu23MhZVEoJg8Qumj%2FUMMc34IBqTKLDTp76WzL%2FdMjCxK7MjhiGjeYAC%2Fkj%2FjY%2FRde7hpSM1xChrog6yZ7OWTuD56xBJnGFE%2BpT2ElSyCnJcwVzCjkqeNLfMEJqKW0G7OFIp0G%2B9mh50I9o8k1tpCY0xYqFNIALgIfc2me4n1bmJnRZ89oepgLPT0NTMLNZsvSCZAc3TXaNB07vail36%2FdBySis4m9%2FDR8izaLJW6bWCkVgm5T%2Bius3ZXq4xI%2BGnbveLbdRwF2mNtsrE0JjYc1AXknCOrLSu7Te%2Fr4dPYMCl5qtiHNTn%2BTPbh1jCBHH%2BdMJNhwNgs3nT%2BOhQoQ0vYif56BMG6WowAcHR3DjQolxLzyVekHj00PBAaW7IIAF1EF%2BuRIWyXjQMAs2chdpaKPNaB%2BkSezYt0%2BCA04sOg5vx8Fr7Ofa9sUv87h7SLAUFSzbetCCZ9pmyLt6l6%2FTzoA1%2FZBG9bIUVHLAbi%2FkdBFgYGyGwRQGBpkqCEg2ah9UD6EedEcEL3j4y0BQQCiExEnocA3SZboh%2Bepgd3YsOkHskZwPuQ5OoyA0fTA5AXrHcUOQF%2BzkJHIA7PwCDk1gGVmGUZSSoPhNf%2BTklauz98QofOlCIQ%2FtCD4dosHYPqtPCXB3agggQQIqQJsSkB%2Bqn0rkQ1toJjON%2FOtCIB9RYv3PqRA4C4U68ZMlZn6BdgEvi2ziU%2BTQ6NIw3ej%2BAtDwMGEZk7e2IjxUWKdAxyaw9OCwSmeADTPPleyk6UhGDNXQb%2B%2BW6Uk4q6F7%2Frg6WVTo82IoCxSIsFDrav4EPHphD3u4hR53WKVvYZUwNCCeM4PMBWzK%2BEfIthZOkuAwPo5C5jgoZgn6dUdvx5rIDmd58cXXdKNfw3l%2BwM2UjgrDJeQHhbD7HW2QDoZMCujgIUkk5Fg8VCsdyjOtnGRx8wgKRPZN5dR0zPUyfGZFVihbFRniXZFOZGKPnEQzU3AnD1KfR6weHW2XS6KbPJxUkOTZsAB9vTVp3Le1F8q5l%2BDMcLiIq78jxAImD2pGFw0VHfRatScGlK6SMu8leTmhUSMy8Uhdd6xBiH3Gdman4tjQGLboJfqz6fL2WKHTmrfsKZRYX6BTDjDldKMosaSTLdQS7oDisJNqAUhw1PfTlnacCO8vl8706Km1FROgLDmudzxg%2BEWTiArtHgLsRrAXYWdB0NmToNCJdKm0KWycZQqb%2BMw76Qy29iQ5up%2FX7oyw8QZ75kP5F6iJAJz6KCmqxz8fEa%2FxnsMYcIO%2FvEkGRuMckhr4rIeLrKaXnmIzlNLxbFspOphkcnJdnz%2FChp%2FVlpj2P7jJQmQRwGnltkTV5dbF9fE3%2FfxoSqTROgq9wFUlbuYzYcasE0ouzBo%2BdDCDzxKAfhbAZYxQiHrLzV2iVexnDX%2FQnT1fsT%2Fxuhu1ui5qIytgbGmRoQkeQooO8eJNNZsf0iALur8QxZFH0nCMnjerYQqG1pIfjyVZWxhVRznmmfLG00BcBWJE6hzQWRyFknuJnXuk8A5FRDCulwrWASSNoBtR%2BCtGdkPwYN2o7DOw%2FVGlCZPusRBFXODQdUM5zeHDIVuAJBLqbO%2Ff9Qua%2BpDqEPk230Sob9lEZ8BHiCorjVghuI0lI4JDgHGRDD%2FprQ84B1pVGkIpVUAHCG%2Biz3Bn3qm2AVrYcYWhock4jso5%2BJ7HfHVj4WMIQdGctq3psBCVVzupQOEioBGA2Bk%2BUILT7%2BVoX5mdxxA5fS42gISQVi%2FHTzrgMxu0fY6hE1ocUwwbsbWcezrY2n6S8%2F6cxXkOH4prpmPuFoikTzY7T85C4T2XYlbxLglSv2uLCgFv8Quk%2FwdesUdWPeHYIH0R729JIisN9Apdd4eB10aqwXrPt%2BSu9mA8k8n1sjMwnfsfF2j3jMUzXepSHmZ%2FBfqXvzgUNQQWOXO8YEuFBh4QTYCkOAPxywpYu1VxiDyJmKVcmJPGWk%2Fgc3Pov02StyYDahwmzw3E1gYC9wkupyWfDqDSUMpCTH5e5N8B%2F%2FlHiMuIkTNw4USHrJU67bjXGqNav6PBuQSoqTxc8avHoGmvqNtXzIaoyMIQIiiUHIM64cXieouplhNYln7qgc4wBVAYR104kO%2BCvKqsg4yIUlFNThVUAKZxZt1XA34h3TCUUiXVkZ0w8Hh2R0Z5L0b4LZvPd%2Fp1gi%2F07h8qfwHrByuSxglc9cI4QIg2oqvC%2Fqm0i7tjPLTgDhoWTAKDO2ONW5oe%2B%2FeKB9vZB8K6C25yCZ9RFVMnb6NRdRjyVK57CHHSkJBfnM2%2Fj4ODUwRkqrtBBCrDsDpt8jhZdXoy%2F1BCqw3sSGhgGGy0a5Jw6BP%2FTExoCmNFYjZl248A0osgPyGEmRA%2BfAsqPVaNAfytu0vuQJ7rk3J4kTDTR2AlCHJ5cls26opZM4w3jMULh2YXKpcqGBtuleAlOZnaZGbD6DHzMd6i2oFeJ8z9XYmalg1Szd%2FocZDc1C7Y6vcALJz2lYnTXiWEr2wawtoR4g3jvWUU2Ngjd1cewtFzEvM1NiHZPeLlIXFbBPawxNgMwwAlyNSuGF3zizVeOoC9bag1qRAQKQE%2FEZBWC2J8mnXAN2aTBboZ7HewnObE8CwROudZHmUM5oZ%2FUgd%2FJZQK8lvAm43uDRAbyW8gZ%2BZGq0EVerVGUKUSm%2FIdn8AQHdR4m7bue88WBwft9mSCeMOt1ncBwziOmJYI2ZR7ewNMPiCugmSsE4EyQ%2BQATJG6qORMGd4snEzc6B4shPIo4G1T7PgSm8PY5eUkPdF8JZ0VBtadbHXoJgnEhZQaODPj2gpODKJY5Yp4DOsLBFxWbvXN755KWylJm%2BoOd4zEL9Hpubuy2gyyfxh8oEfFutnYWdfB8PdESLWYvSqbElP9qo3u6KTmkhoacDauMNNjj0oy40DFV7Ql0aZj77xfGl7TJNHnIwgqOkenruYYNo6h724%2BzUQ7%2BvkCpZB%2BpGA562hYQiDxHVWOq0oDQl%2FQsoiY%2BcuI7iWq%2FZIBtHcXJ7kks%2Bh2fCNUPA82BzjnqktNts%2BRLdk1VSu%2BtqEn7QZCCsvEqk6FkfiOYkrsw092J8jsfIuEKypNjLxrKA9kiA19mxBD2suxQKCzwXGws7kEJvlhUiV9tArLIdZW0IORcxEzdzKmjtFhsjKy%2F44XYXdI5noQoRcvjZ1RMPACRqYg2V1%2BOwOepcOknRLLFdYgTkT5UApt%2FJhLM3jeFYprZV%2BZow2g8fP%2BU68hkKFWJj2yBbKqsrp25xkZX1DAjUw52IMYWaOhab8Kp05VrdNftqwRrymWF4OQSjbdfzmRZirK8FMJELEgER2PHjEAN9pGfLhCUiTJFbd5LBkOBMaxLr%2FA1SY9dXFz4RjzoU9ExfJCmx%2FI9FKEGT3n2cmzl2X42L3Jh%2BAbQq6sA%2BSs1kitoa4TAYgKHaoybHUDJ51oETdeI%2F9ThSmjWGkyLi5QAGWhL0BG1UsTyRGRJOldKBrYJeB8ljLJHfATWTEQBXBDnQexOHTB%2BUn44zExFE4vLytcu5NwpWrUxO%2F0ZICUGM7hGABXym0V6ZvDST0E370St9MIWQOTWngeoQHUTdCJUP04spMBMS8LSker9cReVQkULFDIZDFPrhTzBl6sed9wcZQTbL%2BBDqMyaN3RJPh%2Fanbx%2BIv%2BqgQdAa3M9Z5JmvYlh4qop%2BHo1F1W5gbOE9YKLgAnWytXElU4G8GtW47lhgFE6gaSs%2Bgs37sFvi0PPVvA5dnCBgILTwoKd%2F%2BDoL9F6inlM7H4rOTzD79KJgKlZO%2FZgt22UsKhrAaXU5ZcLrAglTVKJEmNJvORGN1vqrcfSMizfpsgbIe9zno%2BgBoKVXgIL%2FVI8dB1O5o%2FR3Suez%2FgD7M781ShjKpIIORM%2FnxG%2BjjhhgPwsn2IoXsPGPqYHXA63zJ07M2GPEykQwJBYLK808qYxuIew4frk52nhCsnCYmXiR6CuapvE1IwRB4%2FQftDbEn%2BAucIr1oxrLabRj9q4ae0%2BfXkHnteAJwXRbVkR0mctVSwEbqhJiMSZUp9DNbEDMmjX22m3ABpkrPQQTP3S1sib5pD2VRKRd%2BeNAjLYyT0hGrdjWJZy24OYXRoWQAIhGBZRxuBFMjjZQhpgrWo8SiFYbojcHO8V5DyscJpLTHyx9Fimassyo5U6WNtquUMYgccaHY5amgR3PQzq3ToNM5ABnoB9kuxsebqmYZm0R9qxJbFXCQ1UPyFIbxoUraTJFDpCk0Wk9GaYJKz%2F6oHwEP0Q14lMtlddQsOAU9zlYdMVHiT7RQP3XCmWYDcHCGbVRHGnHuwzScA0BaSBOGkz3lM8CArjrBsyEoV6Ys4qgDK3ykQQPZ3hCRGNXQTNNXbEb6tDiTDLKOyMzRhCFT%2BmAUmiYbV3YQVqFVp9dorv%2BTsLeCykS2b5yyu8AV7IS9cxcL8z4Kfwp%2BxJyYLv1OsxQCZwTB4a8BZ%2F5EdxTBJthApqyfd9u3ifr%2FWILTqq5VqgwMT9SOxbSGWLQJUUWCVi4k9tho9nEsbUh7U6NUsLmkYFXOhZ0kmamaJLRNJzSj%2Fqn4Mso6zb6iLLBXoaZ6AqeWCjHQm2lztnejYYM2eubnpBdKVLORZhudH3JF1waBJKA9%2BW8EhMj3Kzf0L4vi4k6RoHh3Z5YgmSZmk6ns4fjScjAoL8GoOECgqgYEBYUGFVO4FUv4%2FYtowhEmTs0vrvlD%2FCrisnoBNDAcUi%2FteY7OctFlmARQzjOItrrlKuPO6E2Ox93L4O%2F4DcgV%2FdZ7qR3VBwVQxP1GCieA4RIpweYJ5FoYrHxqRBdJjnqbsikA2Ictbb8vE1GYIo9dacK0REgDX4smy6GAkxlH1yCGGsk%2BtgiDhNKuKu3yNrMdxafmKTF632F8Vx4BNK57GvlFisrkjN9WDAtjsWA0ENT2e2nETUb%2Fn7qwhvGnrHuf5bX6Vh%2Fn3xffU3PeHdR%2BFA92i6ufT3AlyAREoNDh6chiMWTvjKjHDeRhOa9YkOQRq1vQXEMppAQVwHCuIcV2g5rBn6GmZZpTR7vnSD6ZmhdSl176gqKTXu5E%2BYbfL0adwNtHP7dT7t7b46DVZIkzaRJOM%2BS6KcrzYVg%2BT3wSRFRQashjfU18NutrKa%2F7PXbtuJvpIjbgPeqd%2BpjmRw6YKpnANFSQcpzTZgpSNJ6J7uiagAbir%2F8tNXJ%2FOsOnRh6iuIexxrmkIneAgz8QoLmiaJ8sLQrELVK2yn3wOHp57BAZJhDZjTBzyoRAuuZ4eoxHruY1pSb7qq79cIeAdOwin4GdgMeIMHeG%2BFZWYaiUQQyC5b50zKjYw97dFjAeY2I4Bnl105Iku1y0lMA1ZHolLx19uZnRdILcXKlZGQx%2FGdEqSsMRU1BIrFqRcV1qQOOHyxOLXEGcbRtAEsuAC2V4K3p5mFJ22IDWaEkk9ttf5Izb2LkD1MnrSwztXmmD%2FQi%2FEmVEFBfiKGmftsPwVaIoZanlKndMZsIBOskFYpDOq3QUs9aSbAAtL5Dbokus2G4%2FasthNMK5UQKCOhU97oaOYNGsTah%2BjfCKsZnTRn5TbhFX8ghg8CBYt%2FBjeYYYUrtUZ5jVij%2Fop7V5SsbA4mYTOwZ46hqdpbB6Qvq3AS2HHNkC15pTDIcDNGsMPXaBidXYPHc6PJAkRh29Vx8KcgX46LoUQBhRM%2B3SW6Opll%2FwgxxsPgKJKzr5QCmwkUxNbeg6Wj34SUnEzOemSuvS2OetRCO8Tyy%2BQbSKVJcqkia%2BGvDefFwMOmgnD7h81TUtMn%2BmRpyJJ349HhAnoWFTejhpYTL9G8N2nVg1qkXBeoS9Nw2fB27t7trm7d%2FQK7Cr4uoCeOQ7%2F8JfKT77KiDzLImESHw%2F0wf73QeHu74hxv7uihi4fTX%2BXEwAyQG3264dwv17aJ5N335Vt9sdrAXhPOAv8JFvzqyYXwfx8WYJaef1gMl98JRFyl5Mv5Uo%2FoVH5ww5OzLFsiTPDns7fS6EURSSWd%2F92BxMYQ8sBaH%2Bj%2BwthQPdVgDGpTfi%2BJQIWMD8xKqULliRH01rTeyF8x8q%2FGBEEEBrAJMPf25UQwi0b8tmqRXY7kIvNkzrkvRWLnxoGYEJsz8u4oOyMp8cHyaybb1HdMCaLApUE%2B%2F7xLIZGP6H9xuSEXp1zLIdjk5nBaMuV%2FyTDRRP8Y2ww5RO6d2D94o%2B6ucWIqUAvgHIHXhZsmDhjVLczmZ3ca0Cb3PpKwt2UtHVQ0BgFJsqqTsnzZPlKahRUkEu4qmkJt%2Bkqdae76ViWe3STan69yaF9%2BfESD2lcQshLHWVu4ovItXxO69bqC5p1nZLvI8NdQB9s9UNaJGlQ5mG947ipdDA0eTIw%2FA1zEdjWquIsQXXGIVEH0thC5M%2BW9pZe7IhAVnPJkYCCXN5a32HjN6nsvokEqRS44tGIs7s2LVTvcrHAF%2BRVmI8L4HUYk4x%2B67AxSMJKqCg8zrGOgvK9kNMdDrNiUtSWuHFpC8%2Fp5qIQrEo%2FH%2B1l%2F0cAwQ2nKmpWxKcMIuHY44Y6DlkpO48tRuUGBWT0FyHwSKO72Ud%2BtJUfdaZ4CWNijzZtlRa8%2BCkmO%2FEwHYfPZFU%2FhzjFWH7vnzHRMo%2BaF9u8qHSAiEkA2HjoNQPEwHsDKOt6hOoK3Ce%2F%2B%2F9boMWDa44I6FrQhdgS7OnNaSzwxWKZMcyHi6LN4WC6sSj0qm2PSOGBTvDs%2FGWJS6SwEN%2FULwpb4LQo9fYjUfSXRwZkynUazlSpvX9e%2BG2zor8l%2BYaMxSEomDdLHGcD6YVQPegTaA74H8%2BV4WvJkFUrjMLGLlvSZQWvi8%2FQA7yzQ8GPno%2F%2F5SJHRP%2FOqKObPCo81s%2F%2B6WgLqykYpGAgQZhVDEBPXWgU%2FWzFZjKUhSFInufPRiMAUULC6T11yL45ZrRoB4DzOyJShKXaAJIBS9wzLYIoCEcJKQW8GVCx4fihqJ6mshBUXSw3wWVj3grrHQlGNGhIDNNzsxQ3M%2BGWn6ASobIWC%2BLbYOC6UpahVO13Zs2zOzZC8z7FmA05JhUGyBsF4tsG0drcggIFzgg%2Fkpf3%2BCnAXKiMgIE8Jk%2FMhpkc8DUJEUzDSnWlQFme3d0sHZDrg7LavtsEX3cHwjCYA17pMTfx8Ajw9hHscN67hyo%2BRJQ4458RmPywXykkVcW688oVUrQhahpPRvTWPnuI0B%2BSkQu7dCyvLRyFYlC1LG1gRCIvn3rwQeINzZQC2KXq31FaR9UmVV2QeGVqBHjmE%2BVMd3b1fhCynD0pQNhCG6%2FWCDbKPyE7NRQzL3BzQAJ0g09aUzcQA6mUp9iZFK6Sbp%2FYbHjo%2B%2B7%2FWj8S4YNa%2BZdqAw1hDrKWFXv9%2BzaXpf8ZTDSbiqsxnwN%2FCzK5tPkOr4tRh2kY3Bn9JtalbIOI4b3F7F1vPQMfoDcdxMS8CW9m%2FNCW%2FHILTUVWQIPiD0j1A6bo8vsv6P1hCESl2abrSJWDrq5sSzUpwoxaCU9FtJyYH4QFMxDBpkkBR6kn0LMPO%2B5EJ7Z6bCiRoPedRZ%2FP0SSdii7ZnPAtVwwHUidcdyspwncz5uq6vvm4IEDbJVLUFCn%2FLvIHfooUBTkFO130FC7CmmcrKdgDJcid9mvVzsDSibOoXtIf9k6ABle3PmIxejodc4aob0QKS432srrCMndbfD454q52V01G4q913mC5HOsTzWF4h2No1av1VbcUgWAqyoZl%2B11PoFYnNv2HwAODeNRkHj%2B8SF1fcvVBu6MrehHAZK1Gm69ICcTKizykHgGFx7QdowTVAsYEF2tVc0Z6wLryz2FI1sc5By2znJAAmINndoJiB4sfPdPrTC8RnkW7KRCwxC6YvXg5ahMlQuMpoCSXjOlBy0Kij%2BbsCYPbGp8BdCBiLmLSAkEQRaieWo1SYvZIKJGj9Ur%2FeWHjiB7SOVdqMAVmpBvfRiebsFjger7DC%2B8kRFGtNrTrnnGD2GAJb8rQCWkUPYHhwXsjNBSkE6lGWUj5QNhK0DMNM2l%2BkXRZ0KLZaGsFSIdQz%2FHXDxf3%2FTE30%2BDgBKWGWdxElyLccJfEpjsnszECNoDGZpdwdRgCixeg9L4EPhH%2BRptvRMVRaahu4cySjS3P5wxAUCPkmn%2BrhyASpmiTaiDeggaIxYBmtLZDDhiWIJaBgzfCsAGUF1Q1SFZYyXDt9skCaxJsxK2Ms65dmdp5WAZyxik%2FzbrTQk5KmgxCg%2Ff45L0jywebOWUYFJQAJia7XzCV0x89rpp%2Ff3AVWhSPyTanqmik2SkD8A3Ml4NhIGLAjBXtPShwKYfi2eXtrDuKLk4QlSyTw1ftXgwqA2jUuopDl%2B5tfUWZNwBpEPXghzbBggYCw%2Fdhy0ntds2yeHCDKkF%2FYxQjNIL%2FF%2F37jLPHCKBO9ibwYCmuxImIo0ijV2Wbg3kSN2psoe8IsABv3RNFaF9uMyCtCYtqcD%2BqNOhwMlfARQUdJ2tUX%2BMNJqOwIciWalZsmEjt07tfa8ma4cji9sqz%2BQ9hWfmMoKEbIHPOQORbhQRHIsrTYlnVTNvcq1imqmmPDdVDkJgRcTgB8Sb6epCQVmFZe%2BjGDiNJQLWnfx%2BdrTKYjm0G8yH0ZAGMWzEJhUEQ4Maimgf%2Fbkvo8PLVBsZl152y5S8%2BHRDfZIMCbYZ1WDp4yrdchOJw8k6R%2B%2F2pHmydK4NIK2PHdFPHtoLmHxRDwLFb7eB%2BM4zNZcB9NrAgjVyzLM7xyYSY13ykWfIEEd2n5%2FiYp3ZdrCf7fL%2Ben%2BsIJu2W7E30MrAgZBD1rAAbZHPgeAMtKCg3NpSpYQUDWJu9bT3V7tOKv%2BNRiJc8JAKqqgCA%2FPNRBR7ChpiEulyQApMK1AyqcWnpSOmYh6yLiWkGJ2mklCSPIqN7UypWj3dGi5MvsHQ87MrB4VFgypJaFriaHivwcHIpmyi5LhNqtem4q0n8awM19Qk8BOS0EsqGscuuydYsIGsbT5GHnERUiMpKJl4ON7qjB4fEqlGN%2FhCky89232UQCiaeWpDYCJINXjT6xl4Gc7DxRCtgV0i1ma4RgWLsNtnEBRQFqZggCLiuyEydmFd7WlogpkCw5G1x4ft2psm3KAREwVwr1Gzl6RT7FDAqpVal34ewVm3VH4qn5mjGj%2BbYL1NgfLNeXDwtmYSpwzbruDKpTjOdgiIHDVQSb5%2FzBgSMbHLkxWWgghIh9QTFSDILixVwg0Eg1puooBiHAt7DzwJ7m8i8%2Fi%2BjHvKf0QDnnHVkVTIqMvIQImOrzCJwhSR7qYB5gSwL6aWL9hERHCZc4G2%2BJrpgHNB8eCCmcIWIQ6rSdyPCyftXkDlErUkHafHRlkOIjxGbAktz75bnh50dU7YHk%2BMz7wwstg6RFZb%2BTZuSOx1qqP5C66c0mptQmzIC2dlpte7vZrauAMm%2F7RfBYkGtXWGiaWTtwvAQiq2oD4YixPLXE2khB2FRaNRDTk%2B9sZ6K74Ia9VntCpN4BhJGJMT4Z5c5FhSepRCRWmBXqx%2BwhVZC4me4saDs2iNqXMuCl6iAZflH8fscC1sTsy4PHeC%2BXYuqMBMUun5YezKbRKmEPwuK%2BCLzijPEQgfhahQswBBLfg%2FGBgBiI4QwAqzJkkyYAWtjzSg2ILgMAgqxYfwERRo3zruBL9WOryUArSD8sQOcD7fvIODJxKFS615KFPsb68USBEPPj1orNzFY2xoTtNBVTyzBhPbhFH0PI5AtlJBl2aSgNPYzxYLw7XTDBDinmVoENwiGzmngrMo8OmnRP0Z0i0Zrln9DDFcnmOoBZjABaQIbPOJYZGqX%2BRCMlDDbElcjaROLDoualmUIQ88Kekk3iM4OQrADcxi3rJguS4MOIBIgKgXrjd1WkbCdqxJk%2F4efRIFsavZA7KvvJQqp3Iid5Z0NFc5aiMRzGN3vrpBzaMy4JYde3wr96PjN90AYOIbyp6T4zj8LoE66OGcX1Ef4Z3KoWLAUF4BTg7ug%2FAbkG5UNQXAMkQezujSHeir2uTThgd3gpyzDrbnEdDRH2W7U6PeRvBX1ZFMP5RM%2BZu6UUZZD8hDPHldVWntTCNk7To8IeOW9yn2wx0gmurwqC60AOde4r3ETi5pVMSDK8wxhoGAoEX9NLWHIR33VbrbMveii2jAJlrxwytTHbWNu8Y4N8vCCyZjAX%2FpcsfwXbLze2%2BD%2Bu33OGBoJyAAL3jn3RuEcdp5If8O%2Ba4NKWvxOTyDltG0IWoHhwVGe7dKkCWFT%2B%2Btm%2BhaBCikRUUMrMhYKZJKYoVuv%2FbsJzO8DwfVIInQq3g3BYypiz8baogH3r3GwqCwFtZnz4xMjAVOYnyOi5HWbFA8n0qz1OjSpHWFzpQOpvkNETZBGpxN8ybhtqV%2FDMUxd9uFZmBfKXMCn%2FSqkWJyKPnT6lq%2B4zBZni6fYRByJn6OK%2BOgPBGRAJluwGSk4wxjOOzyce%2FPKODwRlsgrVkdcsEiYrqYdXo0Er2GXi2GQZd0tNJT6c9pK1EEJG1zgDJBoTVuCXGAU8BKTvCO%2FcEQ1Wjk3Zzuy90JX4m3O5IlxVFhYkSUwuQB2up7jhvkm%2BbddRQu5F9s0XftGEJ9JSuSk%2BZachCbdU45fEqbugzTIUokwoAKvpUQF%2FCvLbWW5BNQFqFkJg2f30E%2F48StNe5QwBg8zz3YAJ82FZoXBxXSv4QDooDo79NixyglO9AembuBcx5Re3CwOKTHebOPhkmFC7wNaWtoBhFuV4AkEuJ0J%2B1pT0tLkvFVZaNzfhs%2FKd3%2BA9YsImlO4XK4vpCo%2FelHQi%2F9gkFg07xxnuXLt21unCIpDV%2BbbRxb7FC6nWYTsMFF8%2B1LUg4JFjVt3vqbuhHmDKbgQ4e%2BRGizRiO8ky05LQGMdL2IKLSNar0kNG7lHJMaXr5mLdG3nykgj6vB%2FKVijd1ARWkFEf3yiUw1v%2FWaQivVUpIDdSNrrKbjO5NPnxz6qTTGgYg03HgPhDrCFyYZTi3XQw3HXCva39mpLNFtz8AiEhxAJHpWX13gCTAwgm9YTvMeiqetdNQv6IU0hH0G%2BZManTqDLPjyrOse7WiiwOJCG%2BJ0pZYULhN8NILulmYYvmVcV2MjAfA39sGKqGdjpiPo86fecg65UPyXDIAOyOkCx5NQsLeD4gGVjTVDwOHWkbbBW0GeNjDkcSOn2Nq4cEssP54t9D749A7M1AIOBl0Fi0sSO5v3P7LCBrM6ZwFY6kp2FX6AcbGUdybnfChHPyu6WlRZ2Fwv9YM0RMI7kISRgR8HpQSJJOyTfXj%2F6gQKuihPtiUtlCQVPohUgzfezTg8o1b3n9pNZeco1QucaoXe40Fa5JYhqdTspFmxGtW9h5ezLFZs3j%2FN46f%2BS2rjYNC2JySXrnSAFhvAkz9a5L3pza8eYKHNoPrvBRESpxYPJdKVUxBE39nJ1chrAFpy4MMkf0qKgYALctGg1DQI1kIymyeS2AJNT4X240d3IFQb%2F0jQbaHJ2YRK8A%2Bls6WMhWmpCXYG5jqapGs5%2FeOJErxi2%2F2KWVHiPellTgh%2FfNl%2F2KYPKb7DUcAg%2BmCOPQFCiU9Mq%2FWLcU1xxC8aLePFZZlE%2BPCLzf7ey46INWRw2kcXySR9FDgByXzfxiNKwDFbUSMMhALPFSedyjEVM5442GZ4hTrsAEvZxIieSHGSgkwFh%2FnFNdrrFD4tBH4Il7fW6ur4J8Xaz7RW9jgtuPEXQsYk7gcMs2neu3zJwTyUerHKSh1iTBkj2YJh1SSOZL5pLuQbFFAvyO4k1Hxg2h99MTC6cTUkbONQIAnEfGsGkNFWRbuRyyaEZInM5pij73EA9rPIUfU4XoqQpHT9THZkW%2BoKFLvpyvTBMM69tN1Ydwv1LIEhHsC%2BueVG%2Bw%2BkyCPsvV3erRikcscHjZCkccx6VrBkBRusTDDd8847GA7p2Ucy0y0HdSRN6YIBciYa4vuXcAZbQAuSEmzw%2BH%2FAuOx%2BaH%2BtBL88H57D0MsqyiZxhOEQkF%2F8DR1d2hSPMj%2FsNOa5rxcUnBgH8ictv2J%2Bcb4BA4v3MCShdZ2vtK30vAwkobnEWh7rsSyhmos3WC93Gn9C4nnAd%2FPjMMtQfyDNZsOPd6XcAsnBE%2FmRHtHEyJMzJfZFLE9OvQa0i9kUmToJ0ZxknTgdl%2FXPV8xoh0K7wNHHsnBdvFH3sv52lU7UFteseLG%2FVanIvcwycVA7%2BBE1Ulyb20BvwUWZcMTKhaCcmY3ROpvonVMV4N7yBXTL7IDtHzQ4CCcqF66LjF3xUqgErKzolLyCG6Kb7irP%2FMVTCCwGRxfrPGpMMGvPLgJ881PHMNMIO09T5ig7AzZTX%2F5PLlwnJLDAPfuHynSGhV4tPqR3gJ4kg4c06c%2FF1AcjGytKm2Yb5jwMotF7vro4YDLWlnMIpmPg36NgAZsGA0W1spfLSue4xxat0Gdwd0lqDBOgIaMANykwwDKejt5YaNtJYIkrSgu0KjIg0pznY0SCd1qlC6R19g97UrWDoYJGlrvCE05J%2F5wkjpkre727p5PTRX5FGrSBIfJqhJE%2FIS876PaHFkx9pGTH3oaY3jJRvLX9Iy3Edoar7cFvJqyUlOhAEiOSAyYgVEGkzHdug%2BoRHIEOXAExMiTSKU9A6nmRC8mp8iYhwWdP2U%2F5EkFAdPrZw03YA3gSyNUtMZeh7dDCu8pF5x0VORCTgKp07ehy7NZqKTpIC4UJJ89lnboyAfy5OyXzXtuDRbtAFjZRSyGFTpFrXwkpjSLIQIG3N0Vj4BtzK3wdlkBJrO18MNsgseR4BysJilI0wI6ZahLhBFA0XBmV8d4LUzEcNVb0xbLjLTETYN8OEVqNxkt10W614dd1FlFFVTIgB7%2FBQQp1sWlNolpIu4ekxUTBV7NmxOFKEBmmN%2BnA7pvF78%2FRII5ZHA09OAiE%2F66MF6HQ%2BqVEJCHxwymukkNvzqHEh52dULPbVasfQMgTDyBZzx4007YiKdBuUauQOt27Gmy8ISclPmEUCIcuLbkb1mzQSqIa3iE0PJh7UMYQbkpe%2BhXjTJKdldyt2mVPwywoODGJtBV1lJTgMsuSQBlDMwhEKIfrvsxGQjHPCEfNfMAY2oxvyKcKPUbQySkKG6tj9AQyEW3Q5rpaDJ5Sns9ScLKeizPRbvWYAw4bXkrZdmB7CQopCH8NAmqbuciZChHN8lVGaDbCnmddnqO1PQ4ieMYfcSiBE5zzMz%2BJV%2F4eyzrzTEShvqSGzgWimkNxLvUj86iAwcZuIkqdB0VaIB7wncLRmzHkiUQpPBIXbDDLHBlq7vp9xwuC9AiNkIptAYlG7Biyuk8ILdynuUM1cHWJgeB%2BK3wBP%2FineogxkvBNNQ4AkW0hvpBOQGFfeptF2YTR75MexYDUy7Q%2F9uocGsx41O4IZhViw%2F2FvAEuGO5g2kyXBUijAggWM08bRhXg5ijgMwDJy40QeY%2FcQpUDZiIzmvskQpO5G1zyGZA8WByjIQU4jRoFJt56behxtHUUE%2Fom7Rj2psYXGmq3llVOCgGYKNMo4pzwntITtapDqjvQtqpjaJwjHmDzSVGLxMt12gEXAdLi%2FcaHSM3FPRGRf7dB7YC%2BcD2ho6oL2zGDCkjlf%2FDFoQVl8GS%2F56wur3rdV6ggtzZW60MRB3g%2BU1W8o8cvqIpMkctiGVMzXUFI7FacFLrgtdz4mTEr4aRAaQ2AFQaNeG7GX0yOJgMRYFziXdJf24kg%2FgBQIZMG%2FYcPEllRTVNoDYR6oSJ8wQNLuihfw81UpiKPm714bZX1KYjcXJdfclCUOOpvTxr9AAJevTY4HK%2FG7F3mUc3GOAKqh60zM0v34v%2BELyhJZqhkaMA8UMMOU90f8RKEJFj7EqepBVwsRiLbwMo1J2zrE2UYJnsgIAscDmjPjnzI8a719Wxp757wqmSJBjXowhc46QN4RwKIxqEE6E5218OeK7RfcpGjWG1jD7qND%2B%2FGTk6M56Ig4yMsU6LUW1EWE%2BfIYycVV1thldSlbP6ltdC01y3KUfkobkt2q01YYMmxpKRvh1Z48uNKzP%2FIoRIZ%2FF6buOymSnW8gICitpJjKWBscSb9JJKaWkvEkqinAJ2kowKoqkqZftRqfRQlLtKoqvTRDi2vg%2FRrPD%2Fd3a09J8JhGZlEkOM6znTsoMCsuvTmywxTCDhw5dd0GJOHCMPbsj3QLkTE3MInsZsimDQ3HkvthT7U9VA4s6G07sID0FW4SHJmRGwCl%2BMu4xf0ezqeXD2PtPDnwMPo86sbwDV%2B9PWcgFcARUVYm3hrFQrHcgMElFGbSM2A1zUYA3baWfheJp2AINmTJLuoyYD%2FOwA4a6V0ChBN97E8YtDBerUECv0u0TlxR5yhJCXvJxgyM73Bb6pyq0jTFJDZ4p1Am1SA6sh8nADd1hAcGBMfq4d%2FUfwnmBqe0Jun1n1LzrgKuZMAnxA3NtCN7Klf4BH%2B14B7ibBmgt0TGUafVzI4uKlpF7v8NmgNjg90D6QE3tbx8AjSAC%2BOA1YJvclyPKgT27QpIEgVYpbPYGBsnyCNrGz9XUsCHkW1QAHgL2STZk12QGqmvAB0NFteERkvBIH7INDsNW9KKaAYyDMdBEMzJiWaJHZALqDxQDWRntumSDPcplyFiI1oDpT8wbwe01AHhW6%2BvAUUBoGhY3CT2tgwehdPqU%2F4Q7ZLYvhRl%2FogOvR9O2%2BwkkPKW5vCTjD2fHRYXONCoIl4Jh1bZY0ZE1O94mMGn%2FdFSWBWzQ%2FVYk%2BGezi46RgiDv3EshoTmMSlioUK6MQEN8qeyK6FRninyX8ZPeUWjjbMJChn0n%2FyJvrq5bh5UcCAcBYSafTFg7p0jDgrXo2QWLb3WpSOET%2FHh4oSadBTvyDo10IufLzxiMLAnbZ1vcUmj3w7BQuIXjEZXifwukVxrGa9j%2BDXfpi12m1RbzYLg9J2wFergEwOxFyD0%2FJstNK06ZN2XdZSGWxcJODpQHOq4iKqjqkJUmPu1VczL5xTGUfCgLEYyNBCCbMBFT%2FcUP6pE%2FmujnHsSDeWxMbhrNilS5MyYR0nJyzanWXBeVcEQrRIhQeJA6Xt4f2eQESNeLwmC10WJVHqwx8SSyrtAAjpGjidcj1E2FYN0LObUcFQhafUKTiGmHWRHGsFCB%2BHEXgrzJEB5bp0QiF8ZHh11nFX8AboTD0PS4O1LqF8XBks2MpjsQnwKHF6HgaKCVLJtcr0XjqFMRGfKv8tmmykhLRzu%2BvqQ02%2BKpJBjaLt9ye1Ab%2BBbEBhy4EVdIJDrL2naV0o4wU8YZ2Lq04FG1mWCKC%2BUwkXOoAjneU%2FxHplMQo2cXUlrVNqJYczgYlaOEczVCs%2FOCgkyvLmTmdaBJc1iBLuKwmr6qtRnhowngsDxhzKFAi02tf8bmET8BO27ovJKF1plJwm3b0JpMh38%2BxsrXXg7U74QUM8ZCIMOpXujHntKdaRtsgyEZl5MClMVMMMZkZLNxH9%2Bb8fH6%2Bb8Lev30A9TuEVj9CqAdmwAAHBPbfOBFEATAPZ2CS0OH1Pj%2F0Q7PFUcC8hDrxESWdfgFRm%2B7vvWbkEppHB4T%2F1ApWnlTIqQwjcPl0VgS1yHSmD0OdsCVST8CQVwuiew1Y%2Bg3QGFjNMzwRB2DSsAk26cmA8lp2wIU4p93AUBiUHFGOxOajAqD7Gm6NezNDjYzwLOaSXRBYcWipTSONHjUDXCY4mMI8XoVCR%2FRrs%2FJLKXgEx%2BqkmeDlFOD1%2FyTQNDClRuiUyKYCllfMiQiyFkmuTz2vLsBNyRW%2Bxz%2B5FElFxWB28VjYIGZ0Yd%2B5wIjkcoMaggxswbT0pCmckRAErbRlIlcOGdBo4djTNO8FAgQ%2BlT6vPS60BwTRSUAM3ddkEAZiwtEyArrkiDRnS7LJ%2B2hwbzd2YDQagSgACpsovmjil5wfPuXq3GuH0CyE7FK3M4FgRaFoIkaodORrPx1%2BJpI9psyNYIFuJogZa0%2F1AhOWdlHQxdAgbwacsHqPZo8u%2FngAH2GmaTdhYnBfSDbBfh8CHq6Bx5bttP2%2BRdM%2BMAaYaZ0Y%2FADkbNCZuAyAVQa2OcXOeICmDn9Q%2FeFkDeFQg5MgHEDXq%2FtVjj%2Bjtd26nhaaolWxs1ixSUgOBwrDhRIGOLyOVk2%2FBc0UxvseQCO2pQ2i%2BKrfhu%2FWeBovNb5dJxQtJRUDv2mCwYVpNl2efQM9xQHnK0JwLYt%2FU0Wf%2BphiA4uw8G91slC832pmOTCAoZXohg1fewCZqLBhkOUBofBWpMPsqg7XEXgPfAlDo2U5WXjtFdS87PIqClCK5nW6adCeXPkUiTGx0emOIDQqw1yFYGHEVx20xKjJVYe0O8iLmnQr3FA9nSIQilUKtJ4ZAdcTm7%2BExseJauyqo30hs%2B1qSW211A1SFAOUgDlCGq7eTIcMAeyZkV1SQJ4j%2Fe1Smbq4HcjqgFbLAGLyKxlMDMgZavK5NAYH19Olz3la%2FQCTiVelFnU6O%2FGCvykqS%2FwZJDhKN9gBtSOp%2F1SP5VRgJcoVj%2Bkmf2wBgv4gjrgARBWiURYx8xENV3bEVUAAWWD3dYDKAIWk5opaCFCMR5ZjJExiCAw7gYiSZ2rkyTce4eNMY3lfGn%2B8p6%2BvBckGlKEXnA6Eota69OxDO9oOsJoy28BXOR0UoXNRaJD5ceKdlWMJlOFzDdZNpc05tkMGQtqeNF2lttZqNco1VtwXgRstLSQ6tSPChgqtGV5h2DcDReIQadaNRR6AsAYKL5gSFsCJMgfsaZ7DpKh8mg8Wz8V7H%2BgDnLuMxaWEIUPevIbClgap4dqmVWSrPgVYCzAoZHIa5z2Ocx1D%2FGvDOEqMOKLrMefWIbSWHZ6jbgA8qVBhYNHpx0P%2BjAgN5TB3haSifDcApp6yymEi6Ij%2FGsEpDYUgcHATJUYDUAmC1SCkJ4cuZXSAP2DEpQsGUjQmKJfJOvlC2x%2FpChkOyLW7KEoMYc5FDC4v2FGqSoRWiLsbPCiyg1U5yiHZVm1XLkHMMZL11%2Fyxyw0UnGig3MFdZklN5FI%2FqiT65T%2BjOXOdO7XbgWurOAZR6Cv9uu1cm5LjkXX4xi6mWn5r5NjBS0gTliHhMZI2WNqSiSphEtiCAwnafS11JhseDGHYQ5%2BbqWiAYiAv6Jsf79%2FVUs4cIl%2Bn6%2BWOjcgB%2F2l5TreoAV2717JzZbQIR0W1cl%2FdEqCy5kJ3ZSIHuU0vBoHooEpiHeQWVkkkOqRX27eD1FWw4BfO9CJDdKoSogQi3hAAwsPRFrN5RbX7bqLdBJ9JYMohWrgJKHSjVl1sy2xAG0E3sNyO0oCbSGOxCNBRRXTXenYKuwAoDLfnDcQaCwehUOIDiHAu5m5hMpKeKM4sIo3vxACakIxKoH2YWF2QM84e6F5C5hJU4g8uxuFOlAYnqtwxmHyNEawLW%2FPhoawJDrGAP0JYWHgAVUByo%2FbGdiv2T2EMg8gsS14%2FrAdzlOYazFE7w4OzxeKiWdm3nSOnQRRKXSlVo8HEAbBfyJMKqoq%2BSCcTSx5NDtbFwNlh8VhjGGDu7JG5%2FTAGAvniQSSUog0pNzTim8Owc6QTuSKSTXlQqwV3eiEnklS3LeSXYPXGK2VgeZBqNcHG6tZHvA3vTINhV0ELuQdp3t1y9%2BogD8Kk%2FW7QoRN1UWPqM4%2BxdygkFDPLoTaumKReKiLWoPHOfY54m3qPx4c%2B4pgY3MRKKbljG8w4wvz8pxk3AqKsy4GMAkAtmRjRMsCxbb4Q2Ds0Ia9ci8cMT6DmsJG00XaHCIS%2Bo3F8YVVeikw13w%2BOEDaCYYhC0ZE54kA4jpjruBr5STWeqQG6M74HHL6TZ3lXrd99ZX%2B%2B7LhNatQaZosuxEf5yRA15S9gPeHskBIq3Gcw81AGb9%2FO53DYi%2F5CsQ51EmEh8Rkg4vOciClpy4d04eYsfr6fyQkBmtD%2BP8sNh6e%2BXYHJXT%2FlkXxT4KXU5F2sGxYyzfniMMQkb9OjDN2C8tRRgTyL7GwozH14PrEUZc6oz05Emne3Ts5EG7WolDmU8OB1LDG3VrpQxp%2BpT0KYV5dGtknU64JhabdqcVQbGZiAxQAnvN1u70y1AnmvOSPgLI6uB4AuDGhmAu3ATkJSw7OtS%2F2ToPjqkaq62%2F7WFG8advGlRRqxB9diP07JrXowKR9tpRa%2BjGJ91zxNTT1h8I2PcSfoUPtd7NejVoH03EUcqSBuFZPkMZhegHyo2ZAITovmm3zAIdGFWxoNNORiMRShgwdYwFzkPw5PA4a5MIIQpmq%2Bnsp3YMuXt%2FGkXxLx%2FP6%2BZJS0lFyz4MunC3eWSGE8xlCQrKvhKUPXr0hjpAN9ZK4PfEDrPMfMbGNWcHDzjA7ngMxTPnT7GMHar%2BgMQQ3NwHCv4zH4BIMYvzsdiERi6gebRmerTsVwZJTRsL8dkZgxgRxmpbgRcud%2BYlCIRpPwHShlUSwuipZnx9QCsEWziVazdDeKSYU5CF7UVPAhLer3CgJOQXl%2Fzh575R5rsrmRnKAzq4POFdgbYBuEviM4%2BLVC15ssLNFghbTtHWerS1hDt5s4qkLUha%2FqpZXhWh1C6lTQAqCNQnaDjS7UGFBC6wTu8yFnKJnExCnAs3Ok9yj5KpfZESQ4lTy5pTGTnkAUpxI%2ByjEldJfSo4y0QhG4i4IwkRFGcjWY8%2BEzgYYJUK7BXQksLxAww%2FYYWBMhJILB9e8ePEJ4OP7z%2B4%2FwOQDl64iOYDp26DaONPxpKtBxq%2FaTzRGarm3VkPYTLJKx6Z%2FMw2YbBGseJhPMwhhNswrIkyvV2BYzrvZbxLpKwcWJhYmFtVZ%2BlPEq91FzVp1HlQY1bZVLqeNR9SAUn6n0E28k%2FUuGkNpP1DBI5ch%2FEehZfjUQ9aE41NhETExoPT2gGQz0IhWJbEOvTQ4wgcXCHHFBhewYUiFHuhRSAUVmEHeCRQHQkXGFwkAgyzREJCVN7TRnTon36Zw3tPhx4EALwNdwDv%2BJ41YSP4B2CQqz0EFgARZ4ESgBHQgROwAVn9GTI%2BHYexTUevLUeta4%2FDqKrbMVS%2BYqb8hUwYCrlgKtmAq1YCrFgKrd4qpXiqZcKn1oqdWipjYKpWwVPVYqW6xUpVipKqFR3QKjagVEtAqHpxUMTitsnFaJOKx2cVhswq35RVpyiq9lFVNIKnOQVMkgqtYxVNxiqQjFS7GKlSIVIsQqPIhUWwioigFQ%2B%2BKkN8VHr49HDw9Ebo9EDo9DTo9Crg9BDg9%2FWx7gWx7YWwlobYrOGxWPNisAaAHEyALpkAVDIAeWAArsABVXACYuAD5cAF6wAKFQAQqgAbVAAsoAAlQAUaYAfkwAvogBWQACOgAD9AAHSAAKT4GUdMiOvFngBTwCn2AZ7Dv6B6k%2F90B8%2ByRnkV144AIBoAMTQATGgAjNAA4YABgwABZgB%2FmQCwyAVlwCguASlwCEuAQFwB4uAMlwBYuAJlQAUVAAhUD2KgdpUDaJgaRMDFJgX5MC1JgWJEAokQCWRAHxEAWkQBMRADpEAMkQAYROAEecC484DRpwBDTnwNOdw05tjTmiNOYwtswhYFwLA7BYG4LA2BYGOLAwRYFuLAsxYFQJAohIEyJAMwkAwiQC0JAJgkAeiQBkJAFokAPCQA0JABwcD4Dgc4cDdDgaYcDIDgYgUC6CgWgUClCgUYUAVBQBOFAEYMALgwAgDA9QYAdIn8AZzeBB2L5EcWrenUT1KXienEsuJJ7x5U8XlTjc1NVzUyXFTGb1LlpUtWlTDIjqwE4LsagowoCi2gJLKAkpoBgJQNpAIhNqaEoneI6kiiqQ6Go%2Fn6j0cS%2Ba2gEU8gIHJ%2BBwfgZX4GL%2BBd%2FgW34FZ%2BBS%2FgUH4FN6BTegTvoEv6BJegRnYEF2A79gOvYDl2BdEjCkqkGtwXp0LNToIskOTXzh%2FF062yJ7AAAAEDAWAAABWhJ%2BKPEIJgBFxMVP7w2QJBGHASQnOBKXKFIdUK4igKA9IEaYJg%29%20format%28%27embedded%2Dopentype%27%29%2Curl%28data%3Aapplication%2Ffont%2Dwoff%3Bbase64%2Cd09GRgABAAAAAFuAAA8AAAAAsVwAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAABGRlRNAAABWAAAABwAAAAcbSqX3EdERUYAAAF0AAAAHwAAACABRAAET1MvMgAAAZQAAABFAAAAYGe5a4ljbWFwAAAB3AAAAsAAAAZy2q3jgWN2dCAAAAScAAAABAAAAAQAKAL4Z2FzcAAABKAAAAAIAAAACP%2F%2FAANnbHlmAAAEqAAATRcAAJSkfV3Cb2hlYWQAAFHAAAAANAAAADYFTS%2FYaGhlYQAAUfQAAAAcAAAAJApEBBFobXR4AABSEAAAAU8AAAN00scgYGxvY2EAAFNgAAACJwAAAjBv%2B5XObWF4cAAAVYgAAAAgAAAAIAFqANhuYW1lAABVqAAAAZ4AAAOisyygm3Bvc3QAAFdIAAAELQAACtG6o%2BU1d2ViZgAAW3gAAAAGAAAABsMYVFAAAAABAAAAAMw9os8AAAAA0HaBdQAAAADQdnOXeNpjYGRgYOADYgkGEGBiYGRgZBQDkixgHgMABUgASgB42mNgZulmnMDAysDCzMN0gYGBIQpCMy5hMGLaAeQDpRCACYkd6h3ux%2BDAoPD%2FP%2FOB%2FwJAdSIM1UBhRiQlCgyMADGWCwwAAAB42u2UP2hTQRzHf5ekaVPExv6JjW3fvTQ0sa3QLA5xylBLgyBx0gzSWEUaXbIoBBQyCQGHLqXUqYNdtIIgIg5FHJxEtwqtpbnfaV1E1KFaSvX5vVwGEbW6OPngk8%2FvvXfv7pt3v4SImojIDw6BViKxRgIVBaZwVdSv%2BxvXA%2BIuzqcog2cOkkvDNE8Lbqs74k64i%2B5Sf3u8Z2AnIRLbyVCyTflVSEXVoEqrrMqrgiqqsqqqWQ5xlAc5zWOc5TwXucxVnuE5HdQhHdFRHdNJndZZndeFLc%2FzsKJLQ%2FWV6BcrCdWkwspVKZVROaw0qUqqoqZZcJhdTnGGxznHBS5xhad5VhNWCuturBTXKZ3RObuS98pb9c57k6ql9rp2v1as5deb1r6s9q1GV2IrHSt73T631424YXzjgPwqt%2BRn%2BVG%2BlRvyirwsS%2FKCPCfPytPypDwhj8mjctRZd9acF86y89x55jxxHjkPnXstXfbt%2FpNjj%2FnwXW%2BcHa6%2FSYvZ7yEwbDYazDcIgoUGzY3h2HtqgUcs1AFPWKgTXrRQF7xkoQhRf7uF9hPFeyzUTTSwY6EoUUJY6AC8bSGMS4Ys1Au3WaiPSGGsMtkdGH2rzJgYHAaYjxIwQqtB1CnYkEZ9BM6ALOpROAfyqI%2FDBQudgidBETXuqRIooz4DV0AV9UV4GsyivkTEyMMmw1UYGdhkuAYjA5sMGMvIwCbDDRgZeAz1TXgcmDy3YeRhk%2BcOjCxsMjyAkYFNhscwMrDJ8BQ2886gXoaRhedQvyTSkDZ7uA6HLLQBI5vGntAbGHugTc53cMxC7%2BE4SKL%2BACOzNpk3YWTWJid%2BiRo5NXIKM3fBItAPW55FdJLY3FeHBDr90606JCIU9Jk%2BMs3%2FY%2F8L8jUq3y79bJ%2F0%2F%2BROoP4v9v%2F4%2Fmj%2Bi7HBXUd0%2FelU6IHfHt8Aj9EPGAAoAvgAAAAB%2F%2F8AAnjaxb0JfBvVtTA%2BdxaN1hltI1m2ZVuSJVneLVlSHCdy9oTEWchqtrBEJRAgCYEsQNhC2EsbWmpI2dqkQBoSYgKlpaQthVL0yusrpW77aEubfq%2Fly%2BujvJampSTW5Dvnzmi1E%2Bjr%2F%2F3%2BXmbu3Llz77nnbuece865DMu0MAy5jGtiOEZkOp8lTNeUwyLP%2FDH%2BrEH41ZTDHAtB5lkOowWMPiwayNiUwwTjE46AI5xwhFrINPXYn%2F7ENY0dbWHfZAiTZbL8ID%2FInAd5xz2NpIH4STpDGonHIJNE3OP1KG4ISaSNeBuITAyRLgIxoiEUhFAnmUpEiXSRSGqAQEw0kuyFUIb0k2gnGSApyBFi0il2SI5YLGb5MdFjXCey4mNHzQ7WwLGEdZiPPgYR64we8THZHAt%2BwnT84D%2Fx8YTpGPgheKH4CMEDVF9xBOIeP3EbQgGH29BGgpGkIxCMTCW9qUTA0Zsir%2BQUP1mt%2BP2KusevwIO6Bx%2FIaj8%2FOD5O0VNrZW2EsqZBWbO1skRiEKE0DdlKKaSVO5VAuRpqk8VQJAqY7ydxaK44YJvrO2EWjOoDBoFYzQbDNkON%2BUbiKoRkywMWWf1j4bEY2iIY1AeMgvmEz%2FkVo9v4FSc%2FaMZMrFbjl4zWLL0%2BY5FlyzNlEVYDudJohg8gPUP7kcB%2Fmn%2BG6cd%2B5PV4Q72dXCgocWJADBgUuDTwiXiGSyZo14HOEQ2lE6k0XDIEusexDzZOMXwt1Dutz%2BtqmxTvlskNWXXUQIbhaurum9GrePqm9Yaeabjkiqf%2BbUvzDOvb2Y1E%2BEX2DnemcTP%2FzLcuu7xjQXdAtjR0Lo5n4%2FHs%2FGtntMlysHt%2B29NXbH6se%2F%2FWbFcyu%2Br28H0MwzI30DYeYTLMXIA2EG8QlHpAsyS0EfEToR0a3utIxFPJ3kiIHCCrZ66b0e2xEmL1dM9YN%2FMwS5p01N5jMX%2FBLKt%2F1R83l0LyC29M6%2BiYxo%2FUNg%2FEF7c2WyyW5tYl8WnhWg2%2FhyySbD5UhnDyS7OcU0dnrFw%2BDfGdI7v4QfYIIzOMq9hFtY55gmvC7jZ2FK7sEdrn6IXBuucYhjsGdQ8z0yEbWkkczjjsE5hNAIZrPx2zOLZDmKNXcXtg7EMqidAEEWg%2BSJCBBNwxvxJfc%2FbZa%2BKKf%2BxoKZybnq5vaqpPTye7CiF%2BZFjxZ8%2F7Qij0hfOG%2FcowPA1rT1l4ymWnrKmxxqfErTVrpgwPlz1kC%2BOy8NMDz6c%2BIO38K%2Fx0xkPnLW8Kx6qGAoQdL%2BTD9V9rb%2B%2Fctn%2F%2Ftrxz8dUrZrD%2Fzk%2FferF0cNt1BzctmX2FZPXt%2FjnFCQNz4Ah%2FiKllGiCMs1w5Lkg0kiEwj6VTXCDKsX9rMpnvIj9pcDecXAIXMnqn2dTUbN6w0XQ9ue6FV%2FnnXCH7S3lPWGltVcLsH75ub3ab7A8M28caNrIeOr3o5Q0yFsYL80xaa0EY%2FUEczV7icUMY5pnelAkmUAXmHYjvFWFGxuqlSaow3OM%2B%2FiYY7%2Fl%2FhVELF4EjRqNR%2FbvRbOY%2BDUGzGR%2FOh3EqmE%2FugIQQguGt%2FeMYz%2F%2BL0cimjeZfQDI3phXMbMQsqH%2BCjwVz%2Fhf4idHovgVmB8gLvjbicDcC%2FNypP536E%2F9N%2FpuMibExdohBmNwyiaZdJGoigos7GpF222xrfnZhML%2F7Z%2BylaqP63Hr%2Bm7bdUkQ6%2F2cXqdfmvwixY%2Bs2ksXFeXcE%2BiX0Z%2BIow76DBNgjJ7TOdUK18iPsPflfQD%2BDPsZG2Aj9VmKMMJ4fYRrhIaxhTDR0Elh2vA6h%2FAE6xUb29mj3sjmL72petXjejPy%2Boel60M99tFduCI59N3221xe7apOvxs6aHs7vab1IqY2tv7q2xsHeHGml%2FcV06u%2F8S%2FxTjJ%2BJYc0bWEX0ukW6YmIbGkJRMdjJ9mYIH5QIdJF4hvRGyK7cC7ctImQRcUET99fGXOoft35GYLMQu%2Bg2smnkgZUrH8AL%2F9Si217IssJ916nv14ZrJrvdxLkQvrvtBcjgPC0NXOicO8Qf4mcxPqh3hgUw3DDfdvLJXngg7N3dN2zbPJSaed3OfZnMU7dvmznp3C3bruO%2BNmue0LFsy7S%2B6265%2BfCKFYdvvuW6vmlblnUI8xCXp37CrOZv4B9gauDBlYp7adcUXB5DNCwYImlXOJJKkAdvExXxVvKEYnCo%2B3eIskP9qrrfIYs71CccBjfXRC52udTHHdaP1A1ui%2FVvH1otbrLrpNXBsGX5B89QghDyimlvNB2KfkxZ5C9%2Fem3%2Bd1%2Bd%2F%2FIfFp2%2B2Oxn%2Fs%2B9n%2F79p39S3s8idN6g0yZObwJOgKUpNB3GyU0Ls0PbRzIRq4lcarLKOJBkLRzJQD4j2090XrbA7DW8K3jNF5hlGS5e4V2D17zgss4T20egOJte5iD0bReM9yjTxnQxCRj3c5kFzGJmGbNKmwGw39IJDJcXJZGMkaAB4jyJAKw0jt5IAuIE%2BA%2BU3cVAZZrq9zhDyBrU8oosuxcGNTzCKJfla7JjNVmuSb%2F%2BtuzN2H%2BX4vlB%2BPpdfMXXmuVsNiub1T34SFbjYw5itEvVi0K0Nt9pNJUMI7SLGRhf2xipfCYf8z5OdlGKayOucFeVPeS%2Fdbo3lBrbSMmwUiQN5%2Fed7g0Ds1s17IuZC5kNzM3MZ6EWCa0DtekdJfAxz%2BR%2FOX28sND7yRMTBcf%2B%2Bs8mQCQWHya4qBv%2FufeMoWyslPA9DtMxUknxkH%2FyfTnm2CMYzs%2BCq3r7PxY%2FMXomrvTEsRpfEGHa%2BWN8E1AHjElb7d06ddA7oK%2F%2B5Mdsv9EtPms0jv0Z5kf1FqPxWdFtfFr0kHfgDX0Y%2B5PRSG7RUj0tQr7rmfX8DH4G5W28kKeJLtmQsQkuwMP1pk16EV4sl7vrMJATfyUWo%2FGwEco4rh4XFQgaiUX9qxZHrMQqKnz%2Fc2d8b9TysYrAuXpP%2FRf%2FGr8b1qwwc5a%2BeuLa6S6sneNXToG2XrEJi4R5SGs8Sq2S3d97bsfCRaTdaLwKClRHt37mkudvXbjwVrLhuYeGhh56bvfQkHpk2CwvwClqgWwuBfndC3c8dwmstj81KkagcUgbfPY8Zje0W%2F82VPWJHmSq6pP8hPWpotc%2FEexDOK3qU%2BwngPhOCiO9MJRm8TJefjelrzoKnG2Bn%2B1NCUmPE4gHFmBN9jrTigRIpsACrc9Gstg58ULkp9467%2BGf%2FeFnD5%2F31lNrt2967dhrm7bzI%2BVT5m%2BfzKhvf2MzpICEm79Bopkn07lt1762adNr127LwVqQLdJ5%2BlpQDcvHPQtVY5knhYrK6q8%2FJsiP6EuhGZdFdaNszjvpqvc%2BPI0CdjN0AXsFOC3ZfALDJwr4q2Xq%2BGF%2BGNbsxUg5NLLIEXi8otcDQcUts0D8eQ1iVDRAMBTsYiNdRIxE09EIBJO9A2xqgERTaW86BUFn0OD2xFO97FAgFhF6OoQ7prYt4XwSeUgQHiJyDbeke9IdQntciLQ1FlJMaYcUNvZBg%2BFB1ubjlnRNvl3o6IEU2w7fdNPhm%2Fhh%2BFLysUu6%2B%2BDLHkOkrSHYEjH0tEPe7WdD3uyDgvAgK%2Fm4szFFR7ch0toUgBTdWHr7EpaWru6%2B6dmbbnqWEbV2EtxAsXiZAPTtGPSbHsotI2leoM8TePEqgSQprs7AGFf8kuOkPdZPXGb55POAW1d%2FjLST9v5YflasP6v%2FCO7%2BGNAPC2BMZWmsOjp2NNbfHwMCJD%2BLPVL%2BD%2FOYlWEEI%2F9jpPddOFkB5d1GSuKZYggmCCd7JUxD7EXAzxyirYnNDLdDZoFdx14kivkvGc3579Jm36reTTvDgBnaO6vzyQ6chQmlsMoIkIQ2%2BbBDWBud1Va4pcCn8CPqxlh%2FfgtG8IPaPH8C5wk6%2FnZDv69jurV5QhtwE0x2iqOsj9Mx8B9%2F0EaUdiPfOYYDCi%2Fq9jhWRuupMDEU0%2BCtX0sDFxv07T%2FK5niBPqN9%2BtQjgEc31NGCXFeMcCEuQBIc%2FBK4CO78u7EPYvl3yaEfK3vcb6qP1R2tI7vUjVDDUdKubsSrNjYKY1qBEa2P50SJoaXiksIoLiCwnxS6EBuBde87botNfdEWwYvF%2FR0%2Fu5yCqhGeEOR2ynSeyXjt6ka7neyye8kryBSWE52y%2BRBgogrXPZ8E1yIHoHIFUM%2BAbJhE7lbMtt8ApL%2BxmZW7PwbjAO0fAVoXQOuiSP%2FksIVdFZ0aulsamKUzwPZ%2FNYDMJRBPCxsBqLzqHyneXF6Ej9HlIFo7%2Bpg%2BjUb3unRmGpstGkm6etOuDBGA5wCMefp1gTHcdZlvPBXlOslvYTp1cd8UjYLVd%2FJ5awNrIOKLnIt9MD9qdrKrWCvA6ALm3QV9VrsPm60Q7%2BRHJHP%2B2hqfugo%2FMvI2H%2Fmqr4b9tFnKSRY1Y5Ek80Nm%2FWIhr1ikKnxGz9TWXrokf9xwujfvcOTtNTWnxd0F37Y2W79tteBqZ4G5qLCuomw%2BnSr28QESCRVLTyYKILGJOPfcnaIFOsewhRdvv%2BrWa%2FWih0vlbX6Zb75T5C0qNKVFvH1QL%2FvazSWgC2s6oWXXIuUxQelKiJbowuJDQViatLmLijg9CQBMg8WiPgiw3LEeYRmm5f%2BXdnvkDnxLLjMLxtvX74C3OlwPQqx4xwIdpPx38LrlDphiyWUWHWKAzzxurS%2FxTo%2BP5wGFak62ap1PVFFN4v%2Fy%2BxuR39WnIO7lsWfwgVsK17wxrs9K8ltIKuhkw7f%2F6dhK6gQokFKhWX3urrjk%2FrnI0pgfpGMeuQIUaEM7%2BGF5q2iMkCaMQwxxOzcvU0eXbsnS9XknXvP7Gtw5dwPXlFu2ecvSHEZgNDsU6x%2FGdXBYXyOQjzZReSedeEPY6nEv9gJR4oBQJtFO6Kd0fwC6BO4LNHDeBujB6dSNcUQC9zIv2LnAzGk99bUDrdFY%2B9yGFQtEo0GQPNv6vS2drj4%2B1jHbv3aJSMUWP%2BQTZrmbNTjU8wyG%2FiXNNpskybLcJ3CiTF5Ir%2BJYzmJwE0mSVhlxbtbmvweB3ulB6Til5UuUZydpgiFVeobhU0WaBqpJ198d%2B%2FXeNRTZ9%2F1OPfG7%2B2hwzd5W3D%2BhmyjsRcUg%2F%2BCavb%2B%2BVh2ls3L7zT%2FetOnHNxeerv313vzLVqPai4nJv%2BK1FC6040%2F4udw7sAb3laSg0XCkAAs0npBO6VJabS4Elk%2FU%2BD4gTXW%2Bj0wnrMlqNamq4tMIYB87tE10i0FR3LZNhJsb7%2FR561btmes8YBCRkhYNByRtKd55mqTas9FYhJnbRGHuOh3M4QTdgQSqmgRxuzGdSvZGcbMxNQGk5C3ebLjoXIOFM4l%2BWKHmLTJwRv9E8GWJ6dYvf%2FFmEyEGr%2Bgyrr1p5zrgkz0Cw2j94Hv8Jdx7dIVegBSNtgsqGsRQEYiIBoXwD0LNvQ5d7s5Z00QzwNhqZA0b%2BtMG1tQq5nd84uq8R0zPvX35G8uRaze4jcOHzz0w1%2BQ2BIRvf6J6Kgatnrbiem%2BCFvAxfkrndzD9MFPP1GWTUHclpASUkCNAQkpCCcCgDSUDAhDZ%2BCuEkgn8J7i9nMA7pA4lISappxILKfAeSAbIcSDuN2bJcfZILqeO5rLs0MnngSHYRdrHjmaz7JEsEPw51ZqDJDmUIOZIe34WaQeegNsJn1qz8AIpT3yCjyEih%2FxELkuJ0lEMYTLVCiWpo5oYMleMH6USyYJcD%2BuOe%2BkWKpn1Qns34iyYDjkSLvgnZXcgVQNeqINXr48m3iS7cjm8tedyY0f1QvTnHHdsrKby%2F%2BSSbPY8%2FNH6vpl%2FEsq3Ae4ZU1HC44KFiI9o7CEgab%2FRqHbj7s5KAg06s39ZP%2FzxI%2FmVuF%2FTbTSy%2B3Fb8If9%2Fcv7%2Bwt91yy8RfP1QXtW5RzQn7qIiZyuFM5QfJ5E9uVnqT85TanFx0lkP3ukBAMprvsRyi%2FC8NAJL1xbIIirSvnSj4O5netb4JxmNANHPssHAcHMHsFRgEug816gDBeMbdfiuRcghqYcm0%2BXxx%2F5IAEtN3fqFF3LzAXqwoT0PN0OVTNqxo8sxMkd5Ig6k79Zk7VxxX6gMLOZFQgvpW2RrMW1D0BDihaXQ9wVRoBxPLfpknmkeMtoB%2FqM9cRc9IqmMD2XUmdZ7GSRKPUZvChf8BoykriM2MnKYbOHX8R7cLdNCxSFFVQqoYswnlWtlFS2mNkhswVpZiQW1J%2FUKFfipHGlUkM6UKBhMz1istELIHJLMSctu3ugzfaVSOjKvUgc%2FTHK4Sdg2Wscz69leKIkkrwuuWiOe9yGYKQXRumkC3qbRcMwrvhjNXgdZk3RxAUEhuSPvn3nnd%2B%2BU%2F3vlVOmrJzCD8JLxV1OHRjrZifbcFDOuRNTGqdgQm1tSNJ2OcQ04YiEXuxtII1ECSQRoQGYioEsgCfchB4ghAtw7FfJre4WZ9hkVi9MtjuWqtdNDlpMrfEG9fOT6q21okg%2Be4As38MfGquNt7oUws6Ysarj1%2FefE%2Byst86YUVNvDdts3Pv5c8m%2FaP0C%2Bf8%2FQb%2BIMnGq09BgwN01oIOAnAdagI8mBSrqk1gxTDUBOtk2ousEtBH2z4Ir2d3f6k8PXXVlt2qN9RODxRuoJT%2Fv27wm09jRYVc%2Fe%2B%2Biyx2tyzJb%2Fn3J0htXP87eSsQaf2Ly0s6Zmxela88REy1cf4273mI3iXNJ7KxrZibOm9xm6rl4fqy%2Ft27smU8tOfdW2ucBzg2UfmOIVyLIl3kpYlwphDISTXJXsctmiDtN7fNV6zelgxwnWxsVr83Aj%2FS5ki1jL%2Fa0GC6%2B2L6Um%2BaoddlNFuj%2BbJ8mH%2FiaLh8I0%2FU51NspIEfq0dohwyFXKgm4NggwQ4rRhCOUFtxxo8XnitT4cnGfT93IS8FaT85XE3H5LMY4zIEPL1hw443wz%2B1UmhTJyJGxZzw%2BwsKkKZgUiVtKOKMEb2AKHTv61FNc01PQFwKnvsZ%2F9pPA4RKTASWahmh%2B8MxwzHxKy74IRn5LGRjsPUUwTu64UYNY38caqd7HKucZ%2FtHnODtENw%2F2UfHRMaq1UUPDJQ0OKkWCeet5fYOhII1VRz8%2B%2FElg5j4Gxur3J8o2PJ4rg%2B2d08T%2FfwEzSVbyZ9XPro95T477lRKqUSRXQnauHNsISAl27oWi6Fv9z48JMv8r%2FaMMj8onCP%2FDuDZOuN%2BGPPr%2F%2Bp7bx%2B7JlbYdppcNhzKU%2F1Px5aiaGDn%2Fs1iGMaBcleKUo%2Fv9rcxkZj7DBEKOfrayytXNLYiUdBY%2BpleQXdnscKlQcpzuWluxsieeyuXIK6SdxozitWyGOV3vOHHjguyCQ6fpIYy2JwvrQEF%2FQa9Pdf%2FQqOSqCiE%2FEE1%2FXIVKTc2tzWbHnimrEd%2BVyz311Ml3P0GVTj7PD5aDnsvCvH36alEaPMePcMegXs7x8igTu4B9v7G9vTHvhCu%2FkzIdx%2BBxC0ay9zRSvoS0F2lIxI%2BX7klU63I40gLQ3w5ep5na%2BSFnba3z5D64zv%2BQtM4n4ffG3tq4aNHGRfxgrXPMim%2B5487abL7xhdseIRn1KDl%2B7aINixdv0OD%2BJSPwKf5%2BxoP6aiTeQIDVlIhMcL1H5R9PYXvprs3fv2bO7MOplCmweuiq2JRZ1zz%2B9a%2Fv2PH1Hfz9236w%2BZrPXvWfAxlj4NLLHpq3c%2FPQ3uvmvbrjG7fe%2Bo2y%2FcLdtE6VUlXi0ASb1VLUBVSUWSU4HdvAraTyS8xzM8NxvxFkXV6pUVRiJwcgC5zEeht4rwcp7ki0k41G0qlQhG1Vzlq8alEmnFi58caB5Q9vn988MLhqyVlHvLEWjtQFeupdiocF%2FtkkOGPW2ibWaBTkeZ%2FdvPWazXfOnnvL6jkRXpi85sFzZt%2B55ZptW3bl1cCCHZPD06MhySha7UFzjcjbp8fOecFCirzAG%2FyVjBX6OFIaadSjQq1nNhyIe8tVbaaSdHlXIWKacMeuZA1uxS95zILhyrxAdsXTL6m7kNQlx2P9uZf2qhufePFFbpI6%2FOU0WcP99RrCsrwseVot5mtytpf6Y0gm9sdeyKnPQ7onyK4nXlR%2Frg7H95M1upzu89DH6pgUcikoiihJ6NJKmRxV1x%2BMJiOA3YwhDRQrWU0u%2F0rvq0VYXnyCwsLeTJYBq3dAtJDavuzyoVpzZ99Z0%2Ba0uoiFH%2FxcqgDR7rUFeOrUn6Cywb8ZeNMbhLV5ugP9l0zv9UN5b5mFkjzxUcpPJCn3V402pRxtJd2GrnLdhtVk9ZSZh9W91fCSH5B7ofxPiWL%2Bj3D%2FuwhBRdyAyozeZwvQzs79soi%2BBKSnafLviZCcfrpBpLyimfLfTyJtbyruIQKD01tUwJyKEo%2FybaxkSNFUMdMkhQoJyRBQFhnUkDQSXhTM%2B3NmY0EDM7ffLIjqWEGt8lCO6mLia3PukFnghosJD5p5SIho%2FVDkzQfLE%2BIrYoJXkD19pdP7OwG%2FvoIUtagiWiZ4PAFTHHlTVhRZ7dYmPar%2BNJ%2B8JhmR6DFK5DV1foHoLNO%2FpHrvZfmWZ15RQlwvoVDKhCWNK3CCch9lfFBuAqUgpFSShmNaPj%2Bi5%2B%2BWZfKeViJfW5HnUakVL4UCNVkA4%2BETfIqx4B5xSaP2L1yn0zn2ltPn4%2BOqZGmwwEVCaCSqG53ldtL1oLGAhdMLd09MpCCF6tD6ZnAZBY9hDaYsP0jzZ0j5ZjKsF4i1UmLuhbJMCnYJPt5VwFNvmZawXjEvLJqIH8STonZjq7BZ8gKgR20C9MDFqJAX1H64QW2NEup6qgzLP8cvppL%2FNNTOBTCJABOHeWoXzLhw4Wuy7gaBtjKr9kgKq8ZlRYBS32Lpxc8vIhpNDTfyNXWybMJbn2RyQ5EmWc2QF9wmSZ0KYCE%2BcPuYO6b15Uotj2Kd4MItLS7gtFbkTdrFND6pvEZqv5Yv7jXAus7Pg7avo7KDot50NX3CPkP%2BKps8J9%2F3mGQIteY%2FLGPC%2BL7872SPR2br5fy8MtKBMHedGuM28%2FMZmPJMrGgi3Gb1S%2BSi1%2FL%2FzrZwO9XH1ce%2Fz7ZQ1WSoY%2F%2BpMb5FT4ua0Wm%2BJf%2F298nFmChEQ%2BTi71est4mq9VYI6RsymoRJKYidElT2FGnDTZvqtfhGAFTbeqEw68GqtfmbVa%2F1IFO1%2FjdWr%2F8BDRRtQh9XNjubEm4aWVpVonpTGR7PVGc%2BKJNoBIWF7kYi4gUV3r1U6723i6TxUl3n3%2FtM27aZfKb7THiHW9VzFSwHJ05VfK6Ar7kaB0XgPPE0BSkSFKsBUpaLihEWoA9wBt8qirh2VSOkZwXEwyrxZ5jyt2rJmSo9gX7cg6jsEUGJU9z9xJPOEM3uQQxKgkh35DNATnVyrmJ3mbCNyIB%2Fyox4wH1bg2DwN7q9kov4pFqny8oSm3RQbGgJ1QQTs6ZMLilOVYJ9v6Wha3HcJ9jddsXp9YhGUXLXt%2FqMDnvLpPNTXfNa60z5%2FyjXQOMq%2BlNmwh5egpYrdfZQZV9rI47xlRkuyTjpzsmCBSWNkAXVoK8sgYWqQJWbo1RLo6QH0YW6pxqfCnRgkd%2BRiFjUQUQ7poIaYoakgXxwFd9BuuI38H1xBxXSFb%2FpBDIKQFn7YB3dB36l7sG1FLaKiBdp1KxLvfswap%2F30lnVESgNnvjbUoT6w9N%2BXoio0qcYOIM%2Bheg940YimsucQVvli9NEcft2UZwGQwLuilj1fFr1i3NP94X%2BPE7Hpvtj6lBJfJ4R6NvWiaL6MgzWHxiN66DExa%2BdAdAbMYX6HVF8A%2B7rjEZIXAVbDe7PVI9rmN69JOLV1DOSvRPxWNPZBZf%2FNf%2BNy65BhYxxxV%2B77XJ2wfQ389%2FIQPgajXbwMsuAz%2F0IaQcXJavKbRqR2IqyZruXjVC2%2Bhdee%2F5vdnYOedpmVtR3NGXldxSzDSIiBVpkGb9by89UpEPKrSLZmyFDzMab%2FwXl2CNe7s%2FqCtTvWgG5kpBmCBlSzDS%2Fr8N4uwBwohRW63JTS1y32f0TQsPfXVGEHQrV8%2FNCfiOUVirYcBbIeA2%2BiF68rQIo3B%2FS628vYESr79ehzS7Q9LEL9UXmik9XVHb1yBO3Ngvt5935%2Bk1efkV51mzzrM0LL3%2F20avnwMeKuWyOUZg2TasSqZ%2BKcZQiOn1Iu2Vh497ALUVZiCKt%2Fgh6IvTIj1ZLRjWAkpHKOKovNwp00eqPROiAbiNEKieXwMLcXhVJ1%2FuzmLP4tfxaHR59cBdJVG1kTAgl9ze9QKUEQ946Hkb%2BokJ5JRDyf54Axur1D%2BWS49cLr0tTPEu7UmXrxcSr3XNvumv4yXzInXKH4F7Tc7p17Zt%2Bt%2FqW2%2B93k063X7VW6lALxTY7i1nBXMxcxmzQbabxz%2BtJo%2BwijYaIGMNS8AoSMgAPt84DdHOoMPfjXhF%2BkuH1tZvuFQrRCN07xGcXRX9MYxYchDe5BcHj%2BZ4i%2B42WyPc8Xofi7bbZJN5nJLJ5qr6IqRtzqNlM17SpFsnkEyTWoABEjz4JXOQvzWYuwdnV5LNGOwTM5v9r4RpQ8ZXsYodks3o31JBlzbYtNotisnm22MxiwGFXam5oN1n0TA%2FhRvshvTSDwHff4nNzRo9Dum6PaJbMXzDz%2Bx%2BFkj4L4bFNBb1asqsgH7Dyh4DvbkPtf5yMDKzEwyoaESMSNS9P9gJVA3%2FRTlwoMwZvxECFWxIPNw9gi01nOHjP32esZTtmXHnxvZd8ZtakqQ7ekajbXetpNa6ocTVxJtY%2BuSe69OLz77zh5bDR3xjZMzUz6fxrz1nqrZGcHQHfPVefN%2BfiK86LeXj%2BSc5lPKy%2Bk%2FvCUI%2FDaLFYCWHr6nbXuILTIsb5imNKY%2FrCm28fSMxPhkN1XbNMNZGuqwOBhtTSxWuTk6bw0ZaG86b1hKddePOKuBvmiguYBn4T%2FyOqOyGRBt7bKUI1GjioBC8aUKwF7Q319UgcmtFGIzCJGBqwQij0ynDsfdFGc3TS3BlNfJ25xmzniMkpXXTPvCaD3ZaZvyzjmZdudBostmhb0ORZNN2sJBeed1HXkrUsywueQH%2BL0eCPxmsa5ZpgRJSDZ11yDv%2Bjmbd86vxZfc1WcZJ3UkMq1BOOOVtvu%2F%2BpB%2Ben186d3GTwWAw2jheaJs09%2F%2BLNfZft37DALyrNj1wABMuUKbODyTVnT%2FKYbJ3Tpq8IrNh92dkxOj5P%2FYpZx4%2FycyiVcDYdn4JbEoKdQi9054iBKsygLW46FRGxAb0NPNCm8BSNCPjoKcj6EAus4SuP3rB%2BcV99%2FeTF6294dA8%2BTK6v74MHVpYNRt%2FI30e8QGTOOdfGWzzxcy%2B87a7bLjw37rHw1nPzp0KyyRSeZO%2BQQhInt3dYgvycjrPOv%2BT8s1rptaP84VeywdWX2T4ysr0%2F7TLIs6%2Bx9zib56ye1dM9e%2FXsZmePY3NDs9zlnNVt4%2BWgHJbbz3Livg4P9WWgviOMm4kCRT6I8vw0NbUUEnFvOuFKoxQW1gTsvFirsF5pb7qTUCx4i7VmtToveaDxvK9uOaedVvPRpVOnNz0Q6bry7uiSdQ8t7Vy4JQKVS%2BXPplV2ts4bvCwZu%2BKzgITtxepaPRzWdpv74muvv6RO0SorX6cu%2FdqKn%2FXWnrtp%2FZragz13DUCl5myiFW2Ycvb0PtsXnU%2Btx8pvLFbUspLX68mdegwmOif%2FNPDONajTGoUh6tU56HBJCTBASVvNUB5VIiKpc9kd7kludodSFz7xQbiOmMk5dOYk56gzL6uaf7N8a6MQOHm0ae6snZpFDfuT3%2FjdYzjzwkXXIVHoXNuCfQslQZqBZjTsoHMqrkE4jaYdgkGz2ATOgB3cPkSukD01DnV3ttb1wx%2B6arPqbkcNAHoFPzKUUQ%2BqL0k97pjbZv1I%2FegC9zTFbrrlFpNdmea%2BgIgfWW3wqkcis8ky5FAcRd1If5nNZrl2FFpungc8wpoCl1BpQV%2FScS%2BzjlASyUTVv%2FAJ46gkJI4bHX4lTnloctxPZE1ckS3%2BjG2fKIjkQFyzuo8jvYQG1OrGvJPSTu%2FnSp9PHNTl4z5hK%2F8gtXVKF6gEKiglgcKiRlCESsQCV5QIlKWKpr34lt%2FwkSx%2FJCmP5%2FcBKQfl%2F5gd%2BrOS%2F%2Bp91%2F%2BYCg5CXK2W4M9fu%2B%2F6xxX%2BvnelVuldIDCG0VQTpU9Dw4pRfei%2B6zWx0MLie0gPbyrkmRU7OwT16JGeyXLHqOLqAfVN1GPlBzWtFNzj0TRTCjogtP1NjIvu5habN5Aoa1k66wGpqriVetJgiGdwDZtKhnN0y4n9sXYnsqGmZfDSR15%2B5NLBlhoDaedEm7sxmpqRija6ZEEg2EAnTiAC8IrmFbGz1q08P9PSkjl%2F5bqzYqT9hMmptEXDgTqP3Wiye%2BsD4Wir4jCeoHbbp5hRfpB7BakUIppIlPCD30dR1GtslDz8OsqbXmejFC%2Fv8wu5X2myq7SJ8Avzv9DFUJySf5uNvq4%2BTi7W9D%2FOZrLChdwxmPNiBRqVjnpK%2FaGxRCDspVYKAW9AN1JANoo8wP4BJUlGqdgw6m1qPQ2QW3%2BOfU5%2FieLS%2FNuKpDU3uf8bcAXyBal5jMR2NEAbPAZt0K3hvxHBEDlUxfIGcD%2BN2gNSNx36nfqlAYow0puatNpRz0e4W2oahKzQHsjf2c16ad%2F3t2KTtPobnX6D8C8pd0MDP%2BKx7wnXqGGlLQcvikMErm6TmfsuxJXbSAxqNjOogJLQBLiKEHAE%2BJGTS3JoEhTrz8%2FCB%2B5YlupJ58aOat8Kv4JvregxwcU5Cp8GFAFm1FyOfto6GS2m1NGTS6CPNKkbsTdCBlnN9onMho55BX8IJZtEQ35lk%2BhtwN5A0V3RCPoD%2FyXAcv6pAtbZczRUA64JmcUf4q7Q89ZHLeJVZ5D1Ps%2Ft%2B0iCT3AHVtZC7JDCXfR7OSb%2FXja5H3zQbZL1B%2BULX1BMTEk3AseSpmnKEK4T9ekMIidUCRQFfcbj7z8gNLvzF7mbhQN8h6ZbRset%2BnQWdS%2FZX3k7WpS8P9sfo0iGS64wV516pOhjI6TZ2dApgI5%2BLhxywYoWxKUrykKJsIoDsR4mSrCTg0egMPnLW%2F3Q5Nn8BZEuzqEI7HK3n0%2BzFmuO3TtWQ5WJoG9YqCD6Gc32SxnbnVPfsxvrFXK2dILl7bLthDp6glhcsfp4bYvbSmj%2FmQ94uBTw0E73x2jbNRCvC6VL6GCFDwU7eWQDcC5FY5s0slieRDwtAbRsbLXbaXAuu14e2OJw1dc6jQ3ZdY8v7rv2%2FBWZLqvFWVvvcmwZkK9f5jS4muO9yR5res4kfkRxhV03L1RfPOiPtYi8pd7jNEsOpyTwxpaY%2FyCZu%2FAmd5Or9uS3DYaeqVOhH7gZN%2F8I%2Fwi1fEuLXvyNivibjuKvN%2B1Nc01HF%2F3h%2Bef%2FsOhox8MPd5SFucPjorQwXT%2BytA8EmA5mamHNFDVhBI5pjZbQpugBNkO8MvRub8KVDKST1Wag7D3xlin1ZF7LFP%2F79nbvCXFOY%2BPUjrT7%2FotsPXXZ4exdPzuhZuL5LUXVAn7k7PbhG89uz3b41X01gbjP1xwlu5rrvvf9%2Bpbs6E%2FVu7Nk642%2FPYRaAiUBdrmO6CDTBLPQFA1ur0uXoBR1INDMkypKpoTqnSMx5GiEdTEaSHLs0Alvu%2F19%2F5QW9Rv1U1ridT22i%2B53pzumbs%2BXFFXYC%2B%2BCGsTj5JUT%2FGCgRt3n78i2n71FHG4%2Fu6X%2B%2B9%2Braya7os3ZbDmgWfXun44e%2Bu2NZKuGZ0HiF8M4TlMPR%2BEU6rPKRJ8wOU2RFUFLex3egEsz3YqEAq0cqhAAW19dBZIlVzR61tuIdTnpXH7l%2BuXrbjPUyep%2B8cl6aXKWhPHpDcXl9KiTWDNr4mBQc8Tq%2BNzK%2FOKSbsfl79o9G20R%2BbrBXYvUg0rLHhtrc4TN81TTOWSZ0gL1ZVlOYH2ery%2F7XVUjFMbzYpg7UswcqJPQwBd0LKLabJ8IaCr2otcjSkIrGwootKECaUd4XH1%2BSdazRrfddkBU98t1htvWrbjqSqjaCguxrffM%2F5zDCpBALUycmajhd%2BR6ww4SWafuZ5eU%2BtPid4lgd3gt%2Bb%2FY9rQoZNmiXYPXyRHbRs8zX%2Ff4WIFjWZJtUdSD55AP3xtXH%2BZipC0EqdBGDA4CoYEU6gRLGPU11QhkLTBiEYPiqOeQgwTCl9aok1Qr5pFf71qEeNxjy%2F8F0GoqYPv75Yh9j3x4DuJ%2BuEzHRpAq2lMqb%2BqfTdiq6kGtzfOWsv0c7lSeMXDHBDe1MT%2BLUgx0Pg%2Fp87u2UicdIvqQi8DkxhcUwUXCedMpb4NQjwY3npTmgsURJavLwCRyEcN2HfWsDVGfv%2Fu9ZUWUx%2BPYFueUKwaNvbtu%2BXps3eVWbN1GcgVrdMnWJ7WmJz9SD66EBidag0NF1Ukep0t5A7sFCWdhzvYwHv6L%2FBehXuHqfaBwBEU7hfVLcXvS4VQv%2BT%2FvaSIl7cbeMc7ekv9i8S3e1L5xxpvMGcu1EYPbKyCiijjGXcDKckm43PqU2qNWlXusZMiqF82cuVzolUHN9NNR0HZPxFPV9V0wLtvq%2Bk4DqOwVWDlzuQLVdqFiP08cRX7aRlBVfR8cb55bWe5LExnlcsDp1vAP8Q9BucPMk1Ulh4GnN0SAdxcNHv3q9ohx1Ati4S%2FtkWjIDe3hQdkUGrGRaFBiUdiTSkI41UkMuuQHP%2BEaSQYlPQTFWJF03BNPpTu5KFAdkWgDukzsZKMG0Q1TAQQglScOaP%2FdsZ8%2BfP75D%2F9Uu5Gs3FY%2F2SxPld0DHOciXI9gqjcEidXjE%2B3BLosy0OcX3T7O5g65ROGyzQ2BZs7WbZVnO5ydLe32hMwTQ4wnnKXW6XW5LAa7oaXOIHoUl0FgLQLH2by8wSTWeAx2Y5PDazK3BqZbeJZwXGPaYhX87ZNszoDdaRxotXO1nNlpdvAPFWHDm8PqEE0sZxDEqGzxisFNnuCWetPcGrObN0p23tTZwMuRVodSV8%2BLTrOV3eRvzjQZiSjaLYS1WEJe0kNsJlZu9LFun7%2B%2BwW4gRDRbaxw2nrOGm%2BxOj9cmtbp9ZqeTM1m8UXfQQCSTVSQox6pvtjot%2FFpHvIUjJovFEoYvHYV9C5Y%2FxN9OfcalvII37UEhTbTg%2FAQIaPb4Vz6j5u8%2FaViycMod%2FfkDcpu8QZbZoeBi%2FvbzP3XPsZvOubMtaPHkD9jt6%2BU2O7vqU%2F9C9SMvgrXpQNG%2FE0oJxun%2BCiElUa0IKQSUwERxOntKSV7ekcuh9VBZBBo3VUcB58ofKBHCwLyf9qFosz9Ibf8dGqwaBMjRig4SGOZ2UkWI7UiO9OfUPdxOYFApUZyfpY7mgEc5rtNGGk2H1lPhAk1Hp%2FVAMqQEHEUfEYkkUQq1JMdzsX7kklRrTrUi1wMcDjmu1YYfATj7Y%2BpGpPEBXuoQIj8rR9mgCl4C9yqmF7xnVWxGVniNqtpVmXBvQ6iwni5YQ8a1jYrXtc2J13HvgkvqWxuva1sbr%2BP2S5ceKGyBwDv2DbrToe1u6BkAJV7xnVLUaq0sJB8pFqcUIPi3yuwxi4JuLr%2BP30f3OkPQ72aO0xYo3%2FEsmO3QO5qEF8S0qQH0UsKXv0brnl9%2B8M7jF174%2BDsfvPOl1au%2FRL5%2F9DsbNnwHL2pHR1NTRxMZhJtHktOOxLxErPF6YlLvpC9YP73x%2B4ofw%2B3xVdrHcDE0dQQCmCRgvt9b35xINDf1CDcRSfJ%2BpYl%2BSf8YcurfmXP5F%2Fkj6J82jNsrkWiEuhVlgFfyNkB3S5MUzLhoNiwSCYcxQ7Ui4J0Xh7fmqRbaPa1tzujxkBRlsEHy0%2FOM4pYLPb7g9O6BQJN6l9zQ0OGyCaZz0vMTbHOzXfQ7a2tsterTcqxeInODoemdktw%2B1SbVhKwtW9ffe8VKadK0OVuC3bWzyKm5LeddsWTeorWyY9IMtUFutdu5g%2BRn533qkocdvLs2HmhU75br%2FMmWtD8zA3OP2t1ea636jEzqYxJZGAwFiDEd61oTsrRuW3%2F3pYNi3bS%2BRd%2BGjOfVpAPNd6y64Gsz1GaZleWIPoYL%2Fv9mTeQBENVEguiF1aC4YeXxFETw6QyPfn0m9g8IrMFAvKM1EI11DARnbqibHk%2FIojy5rSdgCyZi06y8sS024PeuO4MfwQ5Y9yKRZCqyYaF30vzeHlmUprR21tR0t0yz8KZY66zWuGvxVQB%2F36kP%2BK38t2Hu6NQ9SFJfw0AdpqPEK2qTMpf2VCqJwqPoJezTL824b8akoL%2Bx03nhh%2BoNo5e77psxg9Q5LzebIKD%2BfsY34f2MtB9fk9v5b8PT6tYrgv4kRPwd0q9z3gdJSJ0653KjCYPwCaR5aUY63eW48O%2Fkdo33yxX9wCiMv2QTrk8eGSI6Ag6moG9t2P%2FF7GRNlDjl0gw7pJ5aOXXqyqn8SENnXBmbSwUYLyqJjv3UmY1nKr4t80no0faXsaIEiF%2FBRaIBnItSce4OUif7W6Vm9T9H1X9Vj71BEm%2BRdmIJQST%2FZfVdudUvh9S%2FqqNvqT98g9SQ3lHibZY0mRVHooyDN%2FFHmTgzjdozKw28NwQ0hwN6BCoPKaEk3YtKwNhwRLXuk076CGoZNXDQcRwZvreTZY9EZi%2Bd0s4%2Bztv8iei04JQl6ZbDD2eHV7X4uHuFVfPrOmcs6m6Kr7hssr%2B1VZFcEZ%2FPdJkn1hOs8SXS%2FNFFgqt94PIZzZ3tdaL6Q5vo6piSzdy737pwsX1VyxUrF15iJ4uNkq%2Brbyg1Z%2BO8VsNC1UmcvORPRfxtPrfRwL2p%2FoA1eZp6Z%2FaGffoewaXcA%2FxBlKlQLfhQL%2FoPgBGP3qsA7IQS8qDVNswHKRSheDUvA3Q7MZoRcJMxlEygujn1QdyzfPfq3dEp%2FbXh5e5YXW2Ngfvza0ZF6UgFL%2FE0fTq4LBlvTE2qb%2FKuuzYSXVnjTfM1osvqMHVbm9950quIZlbqaL6YP7jk3kUtA0GnX2nvq53f3WoSsvEdDRnULgo2fN7lNZJgI8%2FVWi33c3bBZnGY05%2Bdm%2B3qc7fNmj4YGKLj2nfqFP%2Bg7jdDlxEV5XsJQZP6hYrS1l0VQr4c69Xueixp90gnZPmE5OF22j%2BSYEWHlZ0K%2FHgsh%2FZtsbh6h2DNRlvv6jJh9XaJaHCZDiUDKNTMkvb8vsqCyf3ZNdSmO0fa0Y4baJTtpbKzuVzeeSI7fCKr2Z0WypapnXJ4gnoWy3PoUIlIQ1TXdqhQJIXp9Wx5fYdpeWh2TY5D%2BYVyKd0jw3iumwi%2FBC3cEy4o83QlZnW79MrCgCjbhWXBlRZVVZZv4rIKpXC01HFlHdHLoeWVl6UVc%2FJ5uGm6CViW5mulYMk%2BHqNYr0AyUPivLg2oMs2MPqtuhHyRyiwvNJej1Br%2BfcLyoAyu8D9B7bgmzUqfFobF5nKnK4%2Bt8MPJkI%2FxHUNWk117jugWF%2BxazTAALQn6%2BUE9lhoI5ApGA%2FiuJOsrlNP28SVVuBVajXmircLel46w2bJS1Q0Ft0KDuikDFL%2F3pYrid1Q4FvofwRIo4R9h2ftSwc6jHAMqLcCql8YPHtlzGoByNXYN6v8hXnRaOhUvx0sVLCexwupGDR4NOYC7PePa5keIPACnuAdD7dEadRuTIiS6Lb7uskb381My5yjzF8lGCjBRqdwrWJCagfB3yCy7XT1i92hbcZ5Ci1FJkgYMDf6n%2BjspIsHFjJrTOdzSMuOa9DbDcj%2FnH9N9bIoGVgzHPWIQuFuYtaMRaq8eCKI0gEF6lPOZjBz3EEvaaxwSUT9U%2F8JbJZPJJLBLolH1La%2FRbF9AbC8JJjv%2FmMnssKjLRBJyqj9QXxNko0Ux%2FX79epfiXkm6fmKwF%2Fen1HLc6LxloXWKvGa5rVCVL83VuiPcDEX%2FK5pTXOxHfx6HHB0t2FI0qI2rCZFTrvPWU67zVuS%2FkTsLnc7IKhFg30e4FOkqNSfH5PtkmUy6Cpiv%2F36k2sbqCeCFNa%2BURpoY0sZoYmCgCr3qgZz6s8I0gP1bYiR%2BD79H56NOz0EVWCTy2%2FfffvSCCx59W7uRV9995eqrX8GLesOXNm360iZ%2BT%2FEl3uZqL%2BFyzSZ8XxpTiI%2FG0nkT4zznFZ0t4ipMz5v4q9ssqbdKUZt6u82knPCrt6PZwsnn0XySVnyPR1ZXAn72yx48bWJsu7apnI3Hy8bygUK5Js32qcytapqgmn95uexccj205vGgJ%2BeuOeG2SORmKZr%2FqKzcx9SFctMJdwMUFZDJITs7dnOp1EKZCxg304Cevyfya%2BvlKqv6aXK1qIj3imL%2BL6hL%2ByvUlFfE0VKZ7E8gBY3M%2F8VoJCFgizH1W6VyC76nH6b7jiibYVxUmVIEspry%2FLgZIlCeP11Z4zs%2FAwvVwtGFEut5S1JY4lfyT0N%2FevOLo%2BrUEgjcqc9IkGpQbv3iW7Co5b%2BKgjvpzYdH85PLcc4X21ouwEGl%2FS4qnUAvoSlXUUhR1eKr2VWFTB%2BGMl6FsiQsVD1R3urlAAIoSn7JQkmiVVCHSpCwDH%2FqPepXQ0Db77CJOAImohB%2BRPWr31ev5g%2FkE%2BzTa4lbvZo8xdWPffQu9yJTPCNB66s%2BzXoJt%2F0L6hSoCuBIoK8fnBGG87OoRckJpLqyWe4YbpGi50g0%2B3I3UD85Oa0fzubfoXxPLbW3FDWzigmyJeM0tQkax7PqTy80%2BUxfUHPlBZIRVNQ%2Bv0xRm8REKPoLmNr0%2BUo48v9GFbXPKylqQ2IKm00QddgyWGMROCTxdLB9nCY8P7j2DjlsV%2F%2Bmfr0C0r%2FNkeXbbpPlOTBBwT0mVz1zx9S%2FwJecBF9Wgv3p032iP2v4VSgfgW2G%2BHUEdEXU6iq4CtpLJfIN9XQG8dwa1VoO8XC2SrPDDyCOQptXgbcPvlAgBfxBoGwftQKeKFrNTASPt3pGGqDt%2FQRasn2kri%2BH6L80MJRsmVYJrAKyDItpJUy3%2F15WYIJqcJ9Q5N%2FLFJ4c3dc1URpWl9hW6mu50MUIelg4ucTPf15zs5DFo1c0VSp1tKB9jkwIyuM45kb%2BIP8gHed%2B6jO3v0KbIknzLy636E8KPTdCuUpB0wLo9JKnAO6pv0vS31EtBha%2FfJemkgLVVnd8KCk4qBTpQ5m7FbifBKrPJcq0pZAFVG%2FXbOFz%2BTcq2MLrcmV28Nmi%2FOHskh82bau0k8eWCaPijQPWQ5lUvslwVCfHkXBMIehqUgtDNLeauH1huvZTbYmw%2BluPjyWoNGEuxRLR7LK5fSyXFUyK7PURQv2v8D3XOt2NJ6liBbmPGOsakw1kbeOs%2B31Wm5qpH%2BiJWSzqdPr2O7zc2TmtnrzCig6bBd%2FvgQmzOlz0STWIlmZEQfupogOZFHUZ7EkUnMn0RrpIMqAgHRJAOjIJ3yGw1I%2FMAp9q9S3Q%2FclADNm1wEeO%2Bxbwg5OIYHZLY3ehG5lJk2xhco%2B6JWybpEVz2wrR6hZyD0QXZbeDVB%2BonmlimpkWprdAs4WEZDSQppsDlcdCBJJESIYFuAtUnC4GIF2C3Uu2Kv7L1bdz6FxtqxpG4TqQOqOUNAJ2HLvPWA2GgDy4O4vaDrtyl6P%2B1fAll%2BSyFcQ28GHqh7fvvf37udylf0fNwhzgz87Y%2Bcf5x9GnF6ygHu18sAbipWeF0YPBgp2GaKeQduxxdEr3SgbH1kvH7tvqSLhedomOvZyts2dw8acu3dY%2Ff%2BucuMtCuP%2Fe4zC4XnH3OLZ8ZuxTWxy8dJfU5dhDeKPSlJy5pn%2F%2B7u3XrJhmr9C5CuleGflGQocKnlAUaRKp0BAHV0ZwUt9VCqk6zYOgRIuMfePJzdmBdpPJ7%2F6B23%2Bf%2Bsp9NMDZevovvfYHG5dGPISQq1DojqNckchVrCcCYz%2FQ0hI0m3NKDRfkgsrnamo%2Bp0CAq1FyvC3a3Nak%2Fs5VX282x9Ufy3E39VAx6o7LpCvO2wK%2Bch9jNqpJCutcIOooKnYWtDK8gTRVYygRQfwgzKM5%2BjP2jOZdx3r32Py7rQUPOzAnoRs95NvRAR0qLGU11Taqu1bUYSzMcWjMEir067JQQHfIrLBHsrgv00%2FWavd8HRLMEEYFSW3HCSNQehnrHztKqHcDyo4VfZ6gPKCR%2BgufwA8GegxUEo4A%2Bgd0BASHiH6jYMLIsUdQJTs%2FC641KN4oCHWolCMLlMfIdtWKScjx7SM5LD9HnfmhrGI0S139UWfUnxgOXdJFW%2BAMcGjKr6eHAttHF5sUoeArYKDcxMSYcKA%2FxUDhPiEOEAPafSIUFArN0r24ynI91EPARDXvIDYyvqZaWeroBOUABQA%2FE%2BDXC7PWafDLQY2oiwpUEyj4RQtVlUp1GrM7In2p2A7VuiOW6otMiGOo5Mrp05ejVuTy6dNX%2Fk%2F7mybZQ0nUmfrbx3U4KueDnlHm5wdh8FFeKnoaKKh%2FTK18StOPhwG9Xo5mqXAxvw%2F79YQwwDR%2BnAKQQ4izVXioB84qcppWB7IqjU45z4CE17OvF1Dw%2BoTFqxtz8dxwtogBnF9MjIl%2Fin%2BK8s3hM9laIn0TiCbTAXL0T798bPXqx36p3chrv0O%2BGC9Xaj48Ecv8U8UEeBvUEsDlTepiU5OvlpeNGvpnKF0RvUooWhIjnx6GeBapXCQYTw9DNg6%2FOC3gZjp76oNTj9Kz6Jqobxb9NDqc08vcKReOpcsQV2K8InXFaXW3aI6Ofr1k48rp7CX7rx%2Bv1UKPsfvzQU0Kc83i2VdILmd2%2FyX55zT9luN2%2BCu4nKfwPcK%2FCvDVU%2BpHh8%2BLaldIf1fA5h3ndT6Fln9%2FW%2F9Ce1vndfvJtnPVO2xhm3qbafHVCN1X363UXHq9xuVD8OSD29Z8pZ5cZrern9cAdGW%2Fuib%2Fud%2BVK0L9a42r6C90kL8KzxwLQw9NkIQJL0ASU8M%2BVG0KsUdgdvpgP%2F6NqqP0%2FgHZFUfGEijZLHpiIgvV5%2FBltrj8Qd7XQd5p4P%2B7tJo30NMO6VGBwahSPMYiaaBYoLY6uEnciyhhh1Z%2FvvacG%2Frjpsvnpzs0B1Id6fmX8119l88XnOxe%2FuGrzzHcdu7UtY3%2B2vmXN5zUyj3ZcPl8p1sZSs6%2FnGXtwrV7Ka0XZdz83fwjjINpZWYw85lL8BRK4nGyIir2RiOsEyipuEcIakpGjWgBjLiHWOgj0Yi34gW1kKPxHt2Na5q%2Blwg1RdRSpFDNzosb44YJXnAfoEOpZW%2F%2F6u1lhYA6leevezbI26zNHO811M2dc5HFxpk4i1jPC0s21%2FBWW5DnPQbn2X1WK43%2FaM2n18DfSoybbNHijFpamzXI31eRibGUOxSu%2FlT96YZlq1Yt20DaSBuG6knw2eusHs5EPBfNmVvHKdaQzcDfz9ZsXmLDWGXy2U5OsYSsIn8CS12jQIyD12KKqZrLPy7mSPdICmd6WGHG8NDZkkHuE4h9TU8FpmUO%2FVjC%2FEinToFyoNDz2p9XD6g78WgQdPG7Z3R0T%2FZ5dTM9lsL8Ktek7szl2L%2BgQwGgwkZHc2g5Su7NvVqwGy2Ua4KSXUwt1X4PaM5paaEu6jQ5zVFyNabxvUksVt2T%2F4VeamYPlLtffdQsk%2B2sUTY%2FzDXl%2F05W53%2FBz9UK3p7LjapZ2ZxOm%2BUlZXrL3HHGqO8%2BwVroDaCTTnTxitMxmiAAYQzVJQH%2Bnj3oIHnPaN6Zq6sNSLjBl8tKgVr2mj%2F9CWi9dnKca8rBQBsd5R1tzVlgrl5pbnPw6kZclCr2CHxMnHohLz%2B3KRQokzALyeIKFU1TNCiayJdoHvDYe7K6mZLm8S3uJ9dojuaJ62%2FqN%2FtjQxnSnhnKPw%2BLNrLi8ZKyJ3x1YhiI1aNAtP6NzCGzYv3DmaGh%2FLvQZnt0evgIhTFV0kE%2FPYxAnOHhCQUZdCWY5JWJwMzlAGl1mpNbDU7yyGnhRMILsYhH3VRAijrPcBU8%2FCj1Y9NY6cnGVW0CjTLaz7E3epvaT%2FLtTV72Rs%2B0WVVmd0dz%2FMGTI5F0OsIviaqDlbbO5X6xT3PeXbXHRtf%2Fz%2Bfdka%2BeKPr8KF7IF4vBsT9MFPuPJMBTBMq9hQxXelQ%2Bbewnf18ap4Ib%2BmSMrtDU5zqlD8QANa5MBGh%2FOwOvSDfcV2d66mfEWsbGWmIz6nsyZDWQSmqmxDneYyvjHPmRXHZxeueyRGLZzvRioKnGto9nIPkibAJA16adcOZRQr1iAP3bUyBR7T4RgAWTKxhkCYFwshq%2B7iV9r0whk50cmRcTg4fy5x4OmmNkHndIA2%2BYuMbmE9dwGYB4KFTsvnDE6Ah47r%2FfE3AYI%2BoXADpkdlENcZ8OZEEf8FFGZNxMs6ZLpG3SUFLL7Q2kcFU%2FA%2FJsw%2BvWDa%2F7emewLaoeibaF1B9qUNnuqWK3%2BUfXYVL1v%2FomD15xxeDkPnXTOKSVcCbDGtOu0YQNpGAP7U1HU58UrqGu8xIbHtkQ3LVhb7Dx46ET3Ffcm1q0YcOizNmf3bC3VjWfAcpSv3MyTlgJ23FHQgmgvk%2Bgk8pL0mcCDOn08MDAQlf%2B%2FSlTZ1z12fnqntOhbOTL9%2FZdevbAPN%2Byby1f%2FuUtC%2Fixm8ZBo59LTXEW060hGrTDplNprWd58fwB%2Fb%2FE27BdS%2Fs7U%2BrGVCeQ46nzaw9QccnmZerGZZs3Yw9aVHt%2BKh6HN4ti6lxIhT%2FwahnZtWwzlY9QHQ2c79C%2BdxzvVDKy8GqKWQERO9YAKbpsDUTLdWV5dE8PVPjvj9pqw7ah%2FPFVtkit7aj6G5xY9mfJrCz1j1e0BcnPol4UjtrCdbahIVtd2HaURujnFJR8CuOuUUfhrGhgKKgjCYNSvCc1WKlEp8wHUaAYynFNyzZn%2B2MnYv36dbMDBTonl%2FT%2Fma5IKAyEGz%2B4eRnVtaX6tss2o34u8mWorFtuFgm4A6qK%2Fyp%2FgLEBVat5WnPDdKA574ubuFJ%2FIUfZ%2FY2Nt6mN%2BZNNTSTaeI56gKwkXerTe9DDHUw8%2FH35FY3nNN7GGuBKWhrV9ep%2B0k1WjNWVaHkW1yA%2BQHWNu8rtBw2a5YXuE40rs7%2FGA%2Bj09V3hA98yRnFPOGr8ltGlsFdD%2F7tRce3LH6Trcneuiy7K7J3khKu%2B3qUaXPWaX7T6%2FKfj9BX2eZq2XAcZT79u1ClJzUtHUqfqSMWBcZS43Ena0cUGLgpkKxB1QM%2B0Fxz10wgg6r5rltnFpH05pepUq3Y2HfYqeKRntmUFNz%2BXmcOs1H31U6cC6RTVLfCg7RNBF1UF2%2FwBgu0fFQtPEU1sSg3VcNsR7dWq3af87tUFn1l3ltXpaJxpNvtcZkH2WmMst3JqRpxUH%2BWC0E1qOGtP66s1MYv%2BVLu8%2FXFXvV%2FZbunYYBeVN64ls0ur6NzpV9xzlmQwB5qC4Tq70WC0tk8dWJXeHvkD0h9zJOM0vD86%2F1NJMaIAolctvlByferCsqOKDKceOfUu1PsmoFCamV5mCrMUOCi6V6FJosMF22AcrKJgQDVhfYh6tepp%2FlYgvnCEAbJQ1L0rOpajEmRcasMiPfxhgGoVo4rwreQpV6fUJHH2e8fa1s2c13Apl1b89a58ozdoap2sjgLN9uISl7P1DrulyeIkt0zr6JjWocoPOZsaXPb6jtqBblsgsaRre2xHi4nELm0MhG1%2Bx1SXwLpFi53b%2BaHRYo%2FIrbZtuWAKu5cSEXfybnnmUCaXGTpQr0xK2O2WWY76f%2BnAjNVf7nCZHU5XqIkTnpt6VtvsFlPXg1031g%2FVRdpkkyVpD7jnmax88QwDvg%2F66NnMRdRXTcGTmQc3cuINwN5IQqi0yzb%2BYFVHuVqI5s4ADfg5oE4ybDLd28mFSFmYvRoomsWXEdLU2Wl3GJy93ZNb%2Fd5gqmNaqJZSO1l6PVRy0nZIj%2F45EetjLguh1rLqR%2BSK0hO6NrsqcNX8zoUdjQYDJ7tb4os6%2Bi%2BY0qpY2AWlnLRDWdGFTfGY1gV0zNAtJ7pdo24se0D88AwLY%2FgZmE9iuP4V5v7CSR%2FRThaHLh%2BUeBkXwU6BC7lGOevK65udTv%2BtS%2FPfW7qj3ljTcj3b9OkbV85t8xsMj7Ddj7DGpthZKwKPvso%2Fc%2F1K9aLE12fMWLV1y1D9ua8lyJdWXr%2FbG%2BnoCFutf%2FmLILe39ITUV4igr3876fpX5g2zeB52sWnIL4fXHlgeUzOx5QfIvJQyrKQE9wHUqVq%2BPEaOrz0wVvNbJZVSfsuMzxN4l9PkedFzw9V5Dj%2BnzpgoT4ZxCxJfC5RWLc74YVHxKlExCYt0JAOMatREhHBSCAtSfod6x6Ls8HCWECLwXZ9nd5Dz1T24JUdWs6fU3%2B%2BfcnT49Qe%2BkBs%2BwdsMZgPXMp3U5S958snPP%2FEE7bvkOPCuTUDTUQ%2FUzirLhML9yPahoe1D5Fj5jWsaoveyP00PehdUAHk%2FseDVWsvDWXXXsyn%2F4wfpXc2V3%2FQxli3jl%2F5hj%2F83avSCfpTNxOEKLmTjxOEKuxgNlsQn0xgct724mhynupNW1Ph6o3RYS3%2F%2B2TJrzLlkFz%2Bip3qCHKf6eqW02QJLjBYuuj4sobhCWqa%2FYHGEHpcnumuWSOhxeaL7sOakNR6vvmo%2BYcfFA8UFXEPZf9UjyudIOyNwx%2Fi90DdsujS%2FFX2UAwvWSVK4NxaMhAGw3oowp%2Fuc8CTi7D2rBgZWwb%2F60faR7SPsEbjkXy4G0XaqhXPwe2cePjxjxuHD6ssQuR1fq6PF0E%2Bo2t1nePTn8TUmxz%2FA3crMoCc7egESuoTHYc7mYdg6etORoOhR7BBGD%2BqJopELrl4S6cJNRtEAsLP%2FOdvnJq0Wo0GolY2Et9VFB2Kf%2B4bZvVyxfOMz3WdFfSIryj6DwWghre7aQbdiDrkTL3A3vNDuDpk93HqXwam%2BbWmUJZfNn5ozKV5Pmmq8PF%2FjVY%2B2Tlk2M2RzSXKjmbQ4RZcQavEYrN%2F9rlXwtIQqzxQNMzPPfHYLvuPoO9TbT8bpGw5CQPGd%2BSyX%2FCyf0Vxjd2R9NmsunnXYa8xGHzn%2BsSfM5J0y0DZEXWWxkXjcR75KBLNLHi7XvX2G8VOrf4Ykg0AMdBESIpo7MgAfyakA6rkqpI6UjNs0px7cMV%2BD5BF49Tez1VGnYmq0WIijp985m4Sn2gJR9b07riPPFo97OYbUZbxJCpot7H%2FlpZBicglCPN7WOfJkcHqc3ElWqvvz%2F1E6bIQrG%2Btz6WkM1SM9FBTR7FSs8KyBBytSmNEoquJNFN5EQyTiCrnKDx1h58yxCepPHU5nxGoxEQeeOZi2m80DxNxncVhr6BmEfUarxejw%2BWSiHhWk19bSY7aKR5MsteblJpfTLtjimBouXsm3d3djjYM%2BwEW0El9dM%2FueVRWIsXwe43R7SgbVZqrnqoJ1X%2FkuF7pcgf8duv4q6vayV5U9zMV91GxO59UUjW8rHV6u799WzKMT7umRCXbYUKM%2BfoaCcwgaoqZUtmodV3p%2BX7akb4dnU9B9La38RPFUG2SCC90tVA4XwEFhyOpZZrUCsgWYHsczLFBBVGNtstoN1bw0Z%2BO4fYIbvZVt4EUcJEKOhHeincWqONw%2Bq6w5Go%2BWGOSR7LhKV%2BKBqbBPpfUvOf9QqkpDyVhBeyyZQGMsdA5FBUqvFMtUyGq9vjnsAJU4UcrxldP1CCaofyDkSAifoP5QwWx%2BSyUGxp75BzGAvtG7uQ38LehlyEQMeh0TeE6Bm7tYdXqdkt0uOb3kfYlNwmOdDyacOq%2FqlFo1v%2BPTmTi3E%2FglC9W11b34A22zmLzvb231Q0L2Bgg60OTW4YdstO%2BYOJnO38TtpH7zy9ymokWyA79qlVSn38HtpFlImFnhu3b4boNWXklOXV0Iwo7lQ1hrZyPFcwtjwFP7iEKSHSSJw509kh8kj6pr%2BH1jR7km9vcvqN9657vffefkv%2BfKxge1X%2B7RdjYUPIESN7gTvRkB%2FRMYtEkaVkdHApmdBPpnKmz0n1xSWFOyVIuLrinZwpoCRe6kyiVZoHX088F%2BUX4%2BWKS4iBTP0IWxGtZgOdMaV4KTayqHQF%2FVihBwTbgDXTCmKoOBJeNhwJMzEVjtjIFLuU38fPR7hqNG1JS7g%2FqRCuy3vmQ3W9Vu8qbVbP%2BSzazGRJH83MzP90Ck2m31mMjP8TiLn5uwD2Ugr2PFvPQjB5BnSJvQxGQZZEB%2BLopqzGzDbMmbkAPkZVJjeO5FzOSBKCgJze2ZS4Gemc9twrwY6u9H61iUQTcRvtdT9RW3tRxAWwFs2tcuJRnI6xjmBdWjbgFNRHMHiF1uHYBfUR%2Fut5Ug2jXAaT96%2B9RH%2FFToRwIzGbKmVJ1AZQnoabSB1yyIg7ByAridHApPMjyw0OiV6RjSbCuzwLAvFizBliWJua1tsuAgvNPbmljYbpt8lkWam7b3XZiOiKJskMOtmfScnsbPW208knwjuXrXK4Q1iKIgNyYXXDVT9C2Ye%2F78GQ5BEEXfFdde2RwauOysdJNL5AzCy84ard%2FnGAVN8alecnFdgu5Gbd5DJTL%2BhHZK0vApVy3OfU8XTSJg1TlssivsPYUlIqvn66PzrVTymCc4wgF6SDNR0pDf%2B9Gp%2BVnsUH5WtpHYsuhOaey8zdwLN47V8MTbm78g687%2BP3cx6tcAeNpjYGRgYGBk8s0%2FzBIfz2%2FzlUGeZQNQhOFCWfF0GP0%2F8P8c1jusIkAuBwMTSBQAYwQM6HjaY2BkYGAV%2Bd8KJgP%2FXWG9wwAUQQGLAYqPBl942n1TvUoDQRCe1VM8kWARjNrZGIurBAsRBIuA2vkAFsJiKTYW4guIjT5ARMgTxCLoA1hcb5OgDyGHrY7f7M65e8fpLF%2B%2B2W%2FnZ2eTmGfaIJi5I0qGDlZZcD51QzTTJirZPAI9JIwVA%2BwT8L5nOdMaV0AuMJ%2BicRHq8of6LSD18fzq8ds7xjpwBnQiSI9V5QVl6NwPvgM15NXn%2FAtWZyj3W0HjEXitOc%2FdIdbetPdFTZ%2BP6t%2BX7xU0%2Fk6GJtOe1%2FB3arN0%2Fpmz1J4UZc%2BD6ExwjD7vioeGd5HvhvU%2BR%2BDZcGZ6YBPNfAi0G97iBPwFXqph2cW8%2BD7kjMfwtinHb6kLb6Wygk3cZytSEoptGrlScdHtLPeri1JKueACMZfU1ViJG1Sq5E43dIt7SZZFl1zuRhb%2FGOs44xFVDbrJzB5tYs35OmaXTrEmkv0DajnMWQB42mNgYNCCwk0MLxheMPrhgUuY2JiUmOqY2pjWMD1hdmPOY%2B5hPsLCwWLEksSyiOUOawzrLrYiti%2FsCuxJ7Kc45DiSOPZxmnG2cG7jvMelweXDNYXrEbcBdxf3KR4OngheLd443g18fHwZfFv4NfiX8T8TEBIIEZggsEpQS7BMcJsQl5CFUI3QAWEp4RLhCyJaIldEbURXiJ4RYxEzE0sQ2yD2TzxIfJkEk4SeRJbENIkNEg8k%2FklqSGZITpE8InlL8p2UmVSG1A6pb9Jx0ltkjGSmyDySlZF1kc2RnSK7R%2FaZnJ5cmdwB%2BST5SwpuCvsUjRTLFHcoOShNU9qhzKespGyhXKV8SPmBCpOKgUqcyjSVR6omqgmqe9RE1OrUnqkHqO9R%2F6FholGgsUZzgeYZLTUtL60WbS7tKh0OnQydXTpvdGV0O3S%2F6Gnopekt0ruhz6fvpl%2Bnv0n%2Fh4GdQYvBJUMhwwTDdYYvjFSM4oxmGd0zVjK2M84w3mYiYZJgssLkkqmO6TzTF2Z2ZjVmd8ylzP3MJ5lfsRCwcLJoszhhyWXpZdlhecZKxirHapbVPesF1ndsJGwCbBbZ%2FLA1sn1jZ2XXY3fFXsM%2Bz36V%2FS8HD4cGh2OOTI51ThJOK5zeOUs4OzmXOS9wPuUi4JLgss7lm2uU6zY3NrcSty1u39zN3Mvct7l%2F8xDzMPLw88jyaPM44ynkaeEZ59niucqLyUvPKwgAn3OqOQAAAQAAARcApwARAAAAAAACAAAAAQABAAAAQAAuAAAAAHjarZK9TgJBEMf%2Fd6CRaAyRhMLqCgsbL4ciglTGRPEjSiSKlnLycXJ86CEniU%2FhM9jYWPgIFkYfwd6nsDD%2Bd1mBIIUx3mZnfzs3MzszuwDCeIYG8UUwQxmAFgxxPeeuyxrmcaNYxzTuFAewi0fFQSTxqXgM11pC8TgS2oPiCUS1d8Uh8ofiSczpYcVT5LjiCPlY8Qui%2BncOr7D02y6%2FBTCrP%2Fm%2Bb5bdTrPi2I26Z9qNGtbRQBMdXMJBGRW0YOCecxEWYoiTCvxrYBunqHPdoX2bLOyrMKlZg8thDETw5K7Itci1TXlGy0124QRZZLDFU%2FexhxztMozlosTpMH6ZPge0L%2BOKGnFKjJ4WRwppHPL0PP3SI2P9jLQwFOu3GRhDfkeyDo%2F%2FG7IHgzllZQxLdquvrdCyBVvat3seJlYo06gxapUxhU2JWnFygR03sSxnEkvcpf5Y5eibGq315TDp7fKWm8zbUVl71Aqq%2FZtNnlkWmLnQtno9ycvXYbA6W2pF3aKfCayyC0Ja7Fr%2FPW70%2FHO4YM0OKxFvzf0C1MyPjwAAeNpt1VWUU2cYRuHsgxenQt1d8%2F3JOUnqAyR1d%2FcCLQVKO22pu7tQd3d3d3d3d3cXmGzumrWy3pWLs%2FNdPDMpZaWu1783l1Lpf14MnfzO6FbqVupfGkD30iR60JNe9KYP09CXfvRnAAMZxGCGMG3pW6ZjemZgKDMyEzMzC7MyG7MzB3MyF3MzD%2FMyH%2FOzAAuyEAuzCIuyGIuzBGWCRIUqOQU16jRYkqVYmmVYluVYng6GMZwRNGmxAiuyEiuzCquyGquzBmuyFmuzDuuyHuuzARuyERuzCZuyGZuzBVuyFVuzDduyHdszklGMZgd2ZAw7MZZxjGdnJrALu9LJbuzOHkxkT%2FZib%2FZhX%2FZjfw7gQA7iYA7hUA7jcI7gSI7iaI7hWI7jeE7gRE7iZE5hEqdyGqdzBmdyFmdzDudyHudzARdyERdzCZdyGZdzBVdyFVdzDddyHddzAzdyEzdzC7dyG7dzB3dyF3dzD%2FdyH%2FfzAA%2FyEA%2FzCI%2FyGI%2FzBE%2FyFE%2FzDM%2FyHM%2FzAi%2FyEi%2FzCq%2FyGq%2FzBm%2FyFm%2FzDu%2FyHu%2FzAR%2FyER%2FzCZ%2FyGZ%2FzBV%2FyFV%2FzDd%2FyHd%2FzAz%2FyEz%2FzC7%2FyG7%2FzB3%2FyF3%2FzD%2F9mpYwsy7pl3bMeWc%2BsV9Y765NNk%2FXN%2BmX9swHZwGxQNjgb0nPkmInjR0V7Uq%2FOsaPL5Y7ylE3l8tQNN7kVt%2BrmbuHW3LrbcDvam1rtzVvdm50TxrU%2FDBvRtZUY1rV5a3jXFn550Wo%2FXDNWK3dFmh7X9LimxzU9qulRTY9qelTTo5rlKLt2wk7YiaprL%2ByFvbAX9pK9ZC%2FZS%2FaSvWQv2Uv2kr1kr2KvYq9ir2KvYq9ir2KvYq9ir2Kvaq9qr2qvaq9qr2qvaq9qr2qvai%2B3l9vL7eX2cnu5vdxebi%2B3l9sr7BV2CjuFncJOYaewU9gp7NTs1LyrZq9mr2avZq9mr2avZq9mr26vbq9ur26vbq9ur26vbq9ur26vYa9hr2GvYa9hr2GvYa%2FR7oXuQ%2Feh%2B2j%2FUU7e3C3cqc%2FV3fYdof%2FQf%2Bg%2F9B%2F6D%2F2H%2FkP%2Fof%2FQf%2Bg%2F9B%2F6D%2F2H%2FkP%2Fof%2FQf%2Bg%2F9B%2F6D%2F2H%2FkP%2Fof%2FQf%2Bg%2F9B%2F6D%2F2H%2FkP%2Fof%2FQf%2Bg%2F9B%2F6D92H7kP3ofvQfeg%2BdB%2B6D92H7kP3ofvQfRT29B%2F6D%2F2H%2FkP%2Fof%2FQf%2Bg%2F9B%2F6D%2F2H%2FkP%2Fof%2FQf%2Bg%2F9B%2F6D%2F2H%2FkP%2Fof%2FQf%2Bg%2F9B%2F6D%2F2H%2FkP%2Fof%2FQf%2Bg%2F9B%2F6j6nuG3Ya7U5q%2F0hN3nCTW3Grbu4Wrs%2FrP%2Bk%2F6T%2FpP%2Bk%2F6T%2FpP%2Bk%2B6T7pPek86TzpPOk86TzpOuk66TrpOuk66TrpOlWmPu%2F36zrpOuk66TrpOuk66TrpOvl%2FPek76TvpO%2Bk76TvpO%2Bk76TvpO%2Bk76TvpO7V9t%2BqtVs%2FOaOURU6bo6PgPt6rZbwAAAAABVFDDFwAA%29%20format%28%27woff%27%29%2Curl%28data%3Aapplication%2Fx%2Dfont%2Dtruetype%3Bbase64%2CAAEAAAAPAIAAAwBwRkZUTW0ql9wAAAD8AAAAHEdERUYBRAAEAAABGAAAACBPUy8yZ7lriQAAATgAAABgY21hcNqt44EAAAGYAAAGcmN2dCAAKAL4AAAIDAAAAARnYXNw%2F%2F8AAwAACBAAAAAIZ2x5Zn1dwm8AAAgYAACUpGhlYWQFTS%2FYAACcvAAAADZoaGVhCkQEEQAAnPQAAAAkaG10eNLHIGAAAJ0YAAADdGxvY2Fv%2B5XOAACgjAAAAjBtYXhwAWoA2AAAorwAAAAgbmFtZbMsoJsAAKLcAAADonBvc3S6o%2BU1AACmgAAACtF3ZWJmwxhUUAAAsVQAAAAGAAAAAQAAAADMPaLPAAAAANB2gXUAAAAA0HZzlwABAAAADgAAABgAAAAAAAIAAQABARYAAQAEAAAAAgAAAAMEiwGQAAUABAMMAtAAAABaAwwC0AAAAaQAMgK4AAAAAAUAAAAAAAAAAAAAAAIAAAAAAAAAAAAAAFVLV04AQAAg%2F%2F8DwP8QAAAFFAB7AAAAAQAAAAAAAAAAAAAAIAABAAAABQAAAAMAAAAsAAAACgAAAdwAAQAAAAAEaAADAAEAAAAsAAMACgAAAdwABAGwAAAAaABAAAUAKAAgACsAoAClIAogLyBfIKwgvSISIxsl%2FCYBJvonCScP4APgCeAZ4CngOeBJ4FngYOBp4HngieCX4QnhGeEp4TnhRuFJ4VnhaeF54YnhleGZ4gbiCeIW4hniIeIn4jniSeJZ4mD4%2F%2F%2F%2FAAAAIAAqAKAApSAAIC8gXyCsIL0iEiMbJfwmASb6JwknD%2BAB4AXgEOAg4DDgQOBQ4GDgYuBw4IDgkOEB4RDhIOEw4UDhSOFQ4WDhcOGA4ZDhl%2BIA4gniEOIY4iHiI%2BIw4kDiUOJg%2BP%2F%2F%2F%2F%2Fj%2F9r%2FZv9i4Ajf5N%2B132nfWd4F3P3aHdoZ2SHZE9kOIB0gHCAWIBAgCiAEH%2F4f%2BB%2F3H%2FEf6x%2FlH3wfdh9wH2ofZB9jH10fVx9RH0sfRR9EHt4e3B7WHtUezh7NHsUevx65HrMIFQABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADAAAAAACjAAAAAAAAAA1AAAAIAAAACAAAAADAAAAKgAAACsAAAAEAAAAoAAAAKAAAAAGAAAApQAAAKUAAAAHAAAgAAAAIAoAAAAIAAAgLwAAIC8AAAATAAAgXwAAIF8AAAAUAAAgrAAAIKwAAAAVAAAgvQAAIL0AAAAWAAAiEgAAIhIAAAAXAAAjGwAAIxsAAAAYAAAl%2FAAAJfwAAAAZAAAmAQAAJgEAAAAaAAAm%2BgAAJvoAAAAbAAAnCQAAJwkAAAAcAAAnDwAAJw8AAAAdAADgAQAA4AMAAAAeAADgBQAA4AkAAAAhAADgEAAA4BkAAAAmAADgIAAA4CkAAAAwAADgMAAA4DkAAAA6AADgQAAA4EkAAABEAADgUAAA4FkAAABOAADgYAAA4GAAAABYAADgYgAA4GkAAABZAADgcAAA4HkAAABhAADggAAA4IkAAABrAADgkAAA4JcAAAB1AADhAQAA4QkAAAB9AADhEAAA4RkAAACGAADhIAAA4SkAAACQAADhMAAA4TkAAACaAADhQAAA4UYAAACkAADhSAAA4UkAAACrAADhUAAA4VkAAACtAADhYAAA4WkAAAC3AADhcAAA4XkAAADBAADhgAAA4YkAAADLAADhkAAA4ZUAAADVAADhlwAA4ZkAAADbAADiAAAA4gYAAADeAADiCQAA4gkAAADlAADiEAAA4hYAAADmAADiGAAA4hkAAADtAADiIQAA4iEAAADvAADiIwAA4icAAADwAADiMAAA4jkAAAD1AADiQAAA4kkAAAD%2FAADiUAAA4lkAAAEJAADiYAAA4mAAAAETAAD4%2FwAA%2BP8AAAEUAAH1EQAB9REAAAEVAAH2qgAB9qoAAAEWAAYCCgAAAAABAAABAAAAAAAAAAAAAAAAAAAAAQACAAAAAAAAAAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAwAAAAAAAAAAAAAAAAAAAAAAAAAEAAUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAVAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKAL4AAAAAf%2F%2FAAIAAgAoAAABaAMgAAMABwAusQEALzyyBwQA7TKxBgXcPLIDAgDtMgCxAwAvPLIFBADtMrIHBgH8PLIBAgDtMjMRIRElMxEjKAFA%2Fujw8AMg%2FOAoAtAAAQBkAGQETARMAFsAAAEyFh8BHgEdATc%2BAR8BFgYPATMyFhcWFRQGDwEOASsBFx4BDwEGJi8BFRQGBwYjIiYvAS4BPQEHDgEvASY2PwEjIiYnJjU0Nj8BPgE7AScuAT8BNhYfATU0Njc2AlgPJgsLCg%2BeBxYIagcCB57gChECBgMCAQIRCuCeBwIHaggWB54PCikiDyYLCwoPngcWCGoHAgee4AoRAgYDAgECEQrgngcCB2oIFgeeDwopBEwDAgECEQrgngcCB2oIFgeeDwopIg8mCwsKD54HFghqBwIHnuAKEQIGAwIBAhEK4J4HAgdqCBYHng8KKSIPJgsLCg%2BeBxYIagcCB57gChECBgAAAAABAAAAAARMBEwAIwAAATMyFhURITIWHQEUBiMhERQGKwEiJjURISImPQE0NjMhETQ2AcLIFR0BXhUdHRX%2Boh0VyBUd%2FqIVHR0VAV4dBEwdFf6iHRXIFR3%2BohUdHRUBXh0VyBUdAV4VHQAAAAABAHAAAARABEwARQAAATMyFgcBBgchMhYPAQ4BKwEVITIWDwEOASsBFRQGKwEiJj0BISImPwE%2BATsBNSEiJj8BPgE7ASYnASY2OwEyHwEWMj8BNgM5%2BgoFCP6UBgUBDAoGBngGGAp9ARMKBgZ4BhgKfQ8LlAsP%2Fu0KBgZ4BhgKff7tCgYGeAYYCnYFBv6UCAUK%2BhkSpAgUCKQSBEwKCP6UBgwMCKAIDGQMCKAIDK4LDw8LrgwIoAgMZAwIoAgMDAYBbAgKEqQICKQSAAABAGQABQSMBK4AOwAAATIXFhcjNC4DIyIOAwchByEGFSEHIR4EMzI%2BAzUzBgcGIyInLgEnIzczNjcjNzM%2BATc2AujycDwGtSM0QDkXEys4MjAPAXtk%2FtQGAZZk%2FtQJMDlCNBUWOUA0I64eYmunznYkQgzZZHABBdpkhhQ%2BH3UErr1oaS1LMCEPCx4uTzJkMjJkSnRCKw8PIjBKK6trdZ4wqndkLzVkV4UljQAAAgB7AAAETASwAD4ARwAAASEyHgUVHAEVFA4FKwEHITIWDwEOASsBFRQGKwEiJj0BISImPwE%2BATsBNSEiJj8BPgE7ARE0NhcRMzI2NTQmIwGsAV5DakIwFgwBAQwWMEJqQ7ICASAKBgZ4BhgKigsKlQoP%2FvUKBgZ4BhgKdf71CgYGeAYYCnUPtstALS1ABLAaJD8yTyokCwsLJCpQMkAlGmQMCKAIDK8LDg8KrwwIoAgMZAwIoAgMAdsKD8j%2B1EJWVEAAAAEAyAGQBEwCvAAPAAATITIWHQEUBiMhIiY9ATQ2%2BgMgFR0dFfzgFR0dArwdFcgVHR0VyBUdAAAAAgDIAAAD6ASwACUAQQAAARUUBisBFRQGBx4BHQEzMhYdASE1NDY7ATU0NjcuAT0BIyImPQEXFRQWFx4BFAYHDgEdASE1NCYnLgE0Njc%2BAT0BA%2BgdFTJjUVFjMhUd%2FOAdFTJjUVFjMhUdyEE3HCAgHDdBAZBBNxwgIBw3QQSwlhUdZFuVIyOVW5YdFZaWFR2WW5UjI5VbZB0VlshkPGMYDDI8MgwYYzyWljxjGAwyPDIMGGM8ZAAAAAEAAAAAAAAAAAAAAAAxAAAB%2F%2FIBLATCBEEAFgAAATIWFzYzMhYVFAYjISImNTQ2NyY1NDYB9261LCwueKqqeP0ST3FVQgLYBEF3YQ6teHmtclBFaw4MGZnXAAAAAgAAAGQEsASvABoAHgAAAB4BDwEBMzIWHQEhNTQ2OwEBJyY%2BARYfATc2AyEnAwL2IAkKiAHTHhQe%2B1AeFB4B1IcKCSAkCm9wCXoBebbDBLMTIxC7%2FRYlFSoqFSUC6rcQJBQJEJSWEPwecAIWAAAAAAQAAABkBLAETAALABcAIwA3AAATITIWBwEGIicBJjYXARYUBwEGJjURNDYJATYWFREUBicBJjQHARYGIyEiJjcBNjIfARYyPwE2MhkEfgoFCP3MCBQI%2FcwIBQMBCAgI%2FvgICgoDjAEICAoKCP74CFwBbAgFCvuCCgUIAWwIFAikCBQIpAgUBEwKCP3JCAgCNwgK2v74CBQI%2FvgIBQoCJgoF%2FvABCAgFCv3aCgUIAQgIFID%2BlAgKCggBbAgIpAgIpAgAAAAD%2F%2FD%2F8AS6BLoACQANABAAAAAyHwEWFA8BJzcTAScJAQUTA%2BAmDpkNDWPWXyL9mdYCZv4f%2FrNuBLoNmQ4mDlzWYP50%2FZrWAmb8anABTwAAAAEAAAAABLAEsAAPAAABETMyFh0BITU0NjsBEQEhArz6FR384B0V%2Bv4MBLACiv3aHRUyMhUdAiYCJgAAAAEADgAIBEwEnAAfAAABJTYWFREUBgcGLgE2NzYXEQURFAYHBi4BNjc2FxE0NgFwAoUnMFNGT4gkV09IQv2oWEFPiCRXT0hCHQP5ow8eIvzBN1EXGSltchkYEAIJm%2F2iKmAVGilucRoYEQJ%2FJioAAAACAAn%2F%2BAS7BKcAHQApAAAAMh4CFQcXFAcBFgYPAQYiJwEGIycHIi4CND4BBCIOARQeATI%2BATQmAZDItoNOAQFOARMXARY7GikT%2Fu13jgUCZLaDTk6DAXKwlFZWlLCUVlYEp06DtmQCBY15%2Fu4aJRg6FBQBEk0BAU6Dtsi2g1tWlLCUVlaUsJQAAQBkAFgErwREABkAAAE%2BAh4CFRQOAwcuBDU0PgIeAQKJMHt4dVg2Q3mEqD4%2Bp4V4Qzhadnh5A7VESAUtU3ZAOXmAf7JVVbJ%2FgHk5QHZTLQVIAAAAAf%2FTAF4EewSUABgAAAETNjIXEyEyFgcFExYGJyUFBiY3EyUmNjMBl4MHFQeBAaUVBhH%2BqoIHDxH%2Bqf6qEQ8Hgv6lEQYUAyABYRMT%2Fp8RDPn%2BbxQLDPb3DAsUAZD7DBEAAv%2FTAF4EewSUABgAIgAAARM2MhcTITIWBwUTFgYnJQUGJjcTJSY2MwUjFwc3Fyc3IycBl4MHFQeBAaUVBhH%2BqoIHDxH%2Bqf6qEQ8Hgv6lEQYUAfPwxUrBw0rA6k4DIAFhExP%2BnxEM%2Bf5vFAsM9vcMCxQBkPsMEWSO4ouM5YzTAAABAAAAAASwBLAAJgAAATIWHQEUBiMVFBYXBR4BHQEUBiMhIiY9ATQ2NyU%2BAT0BIiY9ATQ2Alh8sD4mDAkBZgkMDwr7ggoPDAkBZgkMJj6wBLCwfPouaEsKFwbmBRcKXQoPDwpdChcF5gYXCktoLvp8sAAAAA0AAAAABLAETAAPABMAIwAnACsALwAzADcARwBLAE8AUwBXAAATITIWFREUBiMhIiY1ETQ2FxUzNSkBIgYVERQWMyEyNjURNCYzFTM1BRUzNSEVMzUFFTM1IRUzNQchIgYVERQWMyEyNjURNCYFFTM1IRUzNQUVMzUhFTM1GQR%2BCg8PCvuCCg8PVWQCo%2F3aCg8PCgImCg8Pc2T8GGQDIGT8GGQDIGTh%2FdoKDw8KAiYKDw%2F872QDIGT8GGQDIGQETA8K%2B%2BYKDw8KBBoKD2RkZA8K%2FqIKDw8KAV4KD2RkyGRkZGTIZGRkZGQPCv6iCg8PCgFeCg9kZGRkZMhkZGRkAAAEAAAAAARMBEwADwAfAC8APwAAEyEyFhURFAYjISImNRE0NikBMhYVERQGIyEiJjURNDYBITIWFREUBiMhIiY1ETQ2KQEyFhURFAYjISImNRE0NjIBkBUdHRX%2BcBUdHQJtAZAVHR0V%2FnAVHR39vQGQFR0dFf5wFR0dAm0BkBUdHRX%2BcBUdHQRMHRX%2BcBUdHRUBkBUdHRX%2BcBUdHRUBkBUd%2FagdFf5wFR0dFQGQFR0dFf5wFR0dFQGQFR0AAAkAAAAABEwETAAPAB8ALwA%2FAE8AXwBvAH8AjwAAEzMyFh0BFAYrASImPQE0NiEzMhYdARQGKwEiJj0BNDYhMzIWHQEUBisBIiY9ATQ2ATMyFh0BFAYrASImPQE0NiEzMhYdARQGKwEiJj0BNDYhMzIWHQEUBisBIiY9ATQ2ATMyFh0BFAYrASImPQE0NiEzMhYdARQGKwEiJj0BNDYhMzIWHQEUBisBIiY9ATQ2MsgVHR0VyBUdHQGlyBUdHRXIFR0dAaXIFR0dFcgVHR389cgVHR0VyBUdHQGlyBUdHRXIFR0dAaXIFR0dFcgVHR389cgVHR0VyBUdHQGlyBUdHRXIFR0dAaXIFR0dFcgVHR0ETB0VyBUdHRXIFR0dFcgVHR0VyBUdHRXIFR0dFcgVHf5wHRXIFR0dFcgVHR0VyBUdHRXIFR0dFcgVHR0VyBUd%2FnAdFcgVHR0VyBUdHRXIFR0dFcgVHR0VyBUdHRXIFR0ABgAAAAAEsARMAA8AHwAvAD8ATwBfAAATMzIWHQEUBisBIiY9ATQ2KQEyFh0BFAYjISImPQE0NgEzMhYdARQGKwEiJj0BNDYpATIWHQEUBiMhIiY9ATQ2ATMyFh0BFAYrASImPQE0NikBMhYdARQGIyEiJj0BNDYyyBUdHRXIFR0dAaUCvBUdHRX9RBUdHf6FyBUdHRXIFR0dAaUCvBUdHRX9RBUdHf6FyBUdHRXIFR0dAaUCvBUdHRX9RBUdHQRMHRXIFR0dFcgVHR0VyBUdHRXIFR3%2BcB0VyBUdHRXIFR0dFcgVHR0VyBUd%2FnAdFcgVHR0VyBUdHRXIFR0dFcgVHQAAAAABACYALAToBCAAFwAACQE2Mh8BFhQHAQYiJwEmND8BNjIfARYyAdECOwgUB7EICPzxBxUH%2FoAICLEHFAirBxYB3QI7CAixBxQI%2FPAICAGACBQHsQgIqwcAAQBuAG4EQgRCACMAAAEXFhQHCQEWFA8BBiInCQEGIi8BJjQ3CQEmND8BNjIXCQE2MgOIsggI%2FvUBCwgIsggVB%2F70%2FvQHFQiyCAgBC%2F71CAiyCBUHAQwBDAcVBDuzCBUH%2FvT%2B9AcVCLIICAEL%2FvUICLIIFQcBDAEMBxUIsggI%2FvUBDAcAAwAX%2F%2BsExQSZABkAJQBJAAAAMh4CFRQHARYUDwEGIicBBiMiLgI0PgEEIg4BFB4BMj4BNCYFMzIWHQEzMhYdARQGKwEVFAYrASImPQEjIiY9ATQ2OwE1NDYBmcSzgk1OASwICG0HFQj%2B1HeOYrSBTU2BAW%2BzmFhYmLOZWFj%2BvJYKD0sKDw8KSw8KlgoPSwoPDwpLDwSZTYKzYo15%2FtUIFQhsCAgBK01NgbTEs4JNWJmzmFhYmLOZIw8KSw8KlgoPSwoPDwpLDwqWCg9LCg8AAAMAF%2F%2FrBMUEmQAZACUANQAAADIeAhUUBwEWFA8BBiInAQYjIi4CND4BBCIOARQeATI%2BATQmBSEyFh0BFAYjISImPQE0NgGZxLOCTU4BLAgIbQcVCP7Ud45itIFNTYEBb7OYWFiYs5lYWP5YAV4KDw8K%2FqIKDw8EmU2Cs2KNef7VCBUIbAgIAStNTYG0xLOCTViZs5hYWJizmYcPCpYKDw8KlgoPAAAAAAIAFwAXBJkEsAAPAC0AAAEzMhYVERQGKwEiJjURNDYFNRYSFRQOAiIuAjU0EjcVDgEVFB4BMj4BNTQmAiZkFR0dFWQVHR0BD6fSW5vW6tabW9KnZ3xyxejFcnwEsB0V%2FnAVHR0VAZAVHeGmPv7ZuHXWm1tbm9Z1uAEnPqY3yHh0xXJyxXR4yAAEAGQAAASwBLAADwAfAC8APwAAATMyFhURFAYrASImNRE0NgEzMhYVERQGKwEiJjURNDYBMzIWFREUBisBIiY1ETQ2BTMyFh0BFAYrASImPQE0NgQBlgoPDwqWCg8P%2Ft6WCg8PCpYKDw%2F%2B3pYKDw8KlgoPD%2F7elgoPDwqWCg8PBLAPCvuCCg8PCgR%2BCg%2F%2BcA8K%2FRIKDw8KAu4KD%2F7UDwr%2BPgoPDwoBwgoPyA8K%2BgoPDwr6Cg8AAAAAAgAaABsElgSWAEcATwAAATIfAhYfATcWFwcXFh8CFhUUDwIGDwEXBgcnBwYPAgYjIi8CJi8BByYnNycmLwImNTQ%2FAjY%2FASc2Nxc3Nj8CNhIiBhQWMjY0AlghKSYFMS0Fhj0rUAMZDgGYBQWYAQ8YA1AwOIYFLDIFJisfISkmBTEtBYY8LFADGQ0ClwYGlwINGQNQLzqFBS0xBSYreLJ%2BfrJ%2BBJYFmAEOGQJQMDmGBSwxBiYrHiIoJgYxLAWGPSxRAxkOApcFBZcCDhkDUTA5hgUtMAYmKiAhKCYGMC0Fhj0sUAIZDgGYBf6ZfrF%2BfrEABwBkAAAEsAUUABMAFwAhACUAKQAtADEAAAEhMhYdASEyFh0BITU0NjMhNTQ2FxUhNQERFAYjISImNREXETMRMxEzETMRMxEzETMRAfQBLCk7ARMKD%2Fu0DwoBEzspASwBLDsp%2FUQpO2RkZGRkZGRkBRQ7KWQPCktLCg9kKTtkZGT%2B1PzgKTs7KQMgZP1EArz9RAK8%2FUQCvP1EArwAAQAMAAAFCATRAB8AABMBNjIXARYGKwERFAYrASImNREhERQGKwEiJjURIyImEgJsCBUHAmAIBQqvDwr6Cg%2F%2B1A8K%2BgoPrwoFAmoCYAcH%2FaAICv3BCg8PCgF3%2FokKDw8KAj8KAAIAZAAAA%2BgEsAARABcAAAERFBYzIREUBiMhIiY1ETQ2MwEjIiY9AQJYOykBLB0V%2FOAVHR0VA1L6FR0EsP5wKTv9dhUdHRUETBUd%2FnAdFfoAAwAXABcEmQSZAA8AGwAwAAAAMh4CFA4CIi4CND4BBCIOARQeATI%2BATQmBTMyFhURMzIWHQEUBisBIiY1ETQ2AePq1ptbW5vW6tabW1ubAb%2FoxXJyxejFcnL%2BfDIKD68KDw8K%2BgoPDwSZW5vW6tabW1ub1urWmztyxejFcnLF6MUNDwr%2B7Q8KMgoPDwoBXgoPAAAAAAL%2FnAAABRQEsAALAA8AACkBAyMDIQEzAzMDMwEDMwMFFP3mKfIp%2FeYBr9EVohTQ%2Fp4b4BsBkP5wBLD%2B1AEs%2FnD%2B1AEsAAAAAAIAZAAABLAEsAAVAC8AAAEzMhYVETMyFgcBBiInASY2OwERNDYBMzIWFREUBiMhIiY1ETQ2OwEyFh0BITU0NgImyBUdvxQLDf65DSYN%2FrkNCxS%2FHQJUMgoPDwr75goPDwoyCg8DhA8EsB0V%2Fj4XEP5wEBABkBAXAcIVHfzgDwr%2BogoPDwoBXgoPDwqvrwoPAAMAFwAXBJkEmQAPABsAMQAAADIeAhQOAiIuAjQ%2BAQQiDgEUHgEyPgE0JgUzMhYVETMyFgcDBiInAyY2OwERNDYB4%2BrWm1tbm9bq1ptbW5sBv%2BjFcnLF6MVycv58lgoPiRUKDd8NJg3fDQoViQ8EmVub1urWm1tbm9bq1ps7csXoxXJyxejFDQ8K%2Fu0XEP7tEBABExAXARMKDwAAAAMAFwAXBJkEmQAPABsAMQAAADIeAhQOAiIuAjQ%2BAQQiDgEUHgEyPgE0JiUTFgYrAREUBisBIiY1ESMiJjcTNjIB4%2BrWm1tbm9bq1ptbW5sBv%2BjFcnLF6MVycv7n3w0KFYkPCpYKD4kVCg3fDSYEmVub1urWm1tbm9bq1ps7csXoxXJyxejFAf7tEBf%2B7QoPDwoBExcQARMQAAAAAAIAAAAABLAEsAAZADkAABMhMhYXExYVERQGBwYjISImJyY1EzQ3Ez4BBSEiBgcDBhY7ATIWHwEeATsBMjY%2FAT4BOwEyNicDLgHhAu4KEwO6BwgFDBn7tAweAgYBB7kDEwKX%2FdQKEgJXAgwKlgoTAiYCEwr6ChMCJgITCpYKDAJXAhIEsA4K%2FXQYGf5XDB4CBggEDRkBqRkYAowKDsgOC%2F4%2BCw4OCpgKDg4KmAoODgsBwgsOAAMAFwAXBJkEmQAPABsAJwAAADIeAhQOAiIuAjQ%2BAQQiDgEUHgEyPgE0JgUXFhQPAQYmNRE0NgHj6tabW1ub1urWm1tbmwG%2F6MVycsXoxXJy%2Fov9ERH9EBgYBJlbm9bq1ptbW5vW6tabO3LF6MVycsXoxV2%2BDCQMvgwLFQGQFQsAAQAXABcEmQSwACgAAAE3NhYVERQGIyEiJj8BJiMiDgEUHgEyPgE1MxQOAiIuAjQ%2BAjMyA7OHBwsPCv6WCwQHhW2BdMVycsXoxXKWW5vW6tabW1ub1nXABCSHBwQL%2FpYKDwsHhUxyxejFcnLFdHXWm1tbm9bq1ptbAAAAAAIAFwABBJkEsAAaADUAAAE3NhYVERQGIyEiJj8BJiMiDgEVIzQ%2BAjMyEzMUDgIjIicHBiY1ETQ2MyEyFg8BFjMyPgEDs4cHCw8L%2FpcLBAeGboF0xXKWW5vWdcDrllub1nXAnIYHCw8LAWgKBQiFboJ0xXIEJIcHBAv%2BlwsPCweGS3LFdHXWm1v9v3XWm1t2hggFCgFoCw8LB4VMcsUAAAAKAGQAAASwBLAADwAfAC8APwBPAF8AbwB%2FAI8AnwAAEyEyFhURFAYjISImNRE0NgUhIgYVERQWMyEyNjURNCYFMzIWHQEUBisBIiY9ATQ2MyEyFh0BFAYjISImPQE0NgczMhYdARQGKwEiJj0BNDYzITIWHQEUBiMhIiY9ATQ2BzMyFh0BFAYrASImPQE0NjMhMhYdARQGIyEiJj0BNDYHMzIWHQEUBisBIiY9ATQ2MyEyFh0BFAYjISImPQE0Nn0EGgoPDwr75goPDwPA%2FK4KDw8KA1IKDw%2F9CDIKDw8KMgoPD9IBwgoPDwr%2BPgoPD74yCg8PCjIKDw%2FSAcIKDw8K%2Fj4KDw%2B%2BMgoPDwoyCg8P0gHCCg8PCv4%2BCg8PvjIKDw8KMgoPD9IBwgoPDwr%2BPgoPDwSwDwr7ggoPDwoEfgoPyA8K%2FK4KDw8KA1IKD2QPCjIKDw8KMgoPDwoyCg8PCjIKD8gPCjIKDw8KMgoPDwoyCg8PCjIKD8gPCjIKDw8KMgoPDwoyCg8PCjIKD8gPCjIKDw8KMgoPDwoyCg8PCjIKDwAAAAACAAAAAARMBLAAGQAjAAABNTQmIyEiBh0BIyIGFREUFjMhMjY1ETQmIyE1NDY7ATIWHQEDhHVT%2FtRSdmQpOzspA4QpOzsp%2FageFMgUHgMgyFN1dlLIOyn9qCk7OykCWCk7lhUdHRWWAAIAZAAABEwETAAJADcAABMzMhYVESMRNDYFMhcWFREUBw4DIyIuAScuAiMiBwYjIicmNRE%2BATc2HgMXHgIzMjc2fTIKD2QPA8AEBRADIUNAMRwaPyonKSxHHlVLBwgGBQ4WeDsXKC4TOQQpLUUdZ1AHBEwPCvvNBDMKDzACBhH%2BWwYGO1AkDQ0ODg8PDzkFAwcPAbY3VwMCAwsGFAEODg5XCAAAAwAAAAAEsASXACEAMQBBAAAAMh4CFREUBisBIiY1ETQuASAOARURFAYrASImNRE0PgEDMzIWFREUBisBIiY1ETQ2ITMyFhURFAYrASImNRE0NgHk6N6jYw8KMgoPjeT%2B%2BuSNDwoyCg9joyqgCAwMCKAIDAwCYKAIDAwIoAgMDASXY6PedP7UCg8PCgEsf9FyctF%2F%2FtQKDw8KASx03qP9wAwI%2FjQIDAwIAcwIDAwI%2FjQIDAwIAcwIDAAAAAACAAAA0wRHA90AFQA5AAABJTYWFREUBiclJisBIiY1ETQ2OwEyBTc2Mh8BFhQPARcWFA8BBiIvAQcGIi8BJjQ%2FAScmND8BNjIXAUEBAgkMDAn%2B%2FhUZ%2BgoPDwr6GQJYeAcUByIHB3h4BwciBxQHeHgHFAciBwd3dwcHIgcUBwMurAYHCv0SCgcGrA4PCgFeCg%2BEeAcHIgcUB3h4BxQHIgcHd3cHByIHFAd4eAcUByIICAAAAAACAAAA0wNyA90AFQAvAAABJTYWFREUBiclJisBIiY1ETQ2OwEyJTMWFxYVFAcGDwEiLwEuATc2NTQnJjY%2FATYBQQECCQwMCf7%2BFRn6Cg8PCvoZAdIECgZgWgYLAwkHHQcDBkhOBgMIHQcDLqwGBwr9EgoHBqwODwoBXgoPZAEJgaGafwkBAQYXBxMIZ36EaggUBxYFAAAAAAMAAADEBGID7AAbADEASwAAATMWFxYVFAYHBgcjIi8BLgE3NjU0JicmNj8BNgUlNhYVERQGJyUmKwEiJjURNDY7ATIlMxYXFhUUBwYPASIvAS4BNzY1NCcmNj8BNgPHAwsGh0RABwoDCQcqCAIGbzs3BgIJKgf9ggECCQwMCf7%2BFRn6Cg8PCvoZAdIECgZgWgYLAwkHHQcDBkhOBgMIHQcD7AEJs9lpy1QJAQYiBhQIlrJarEcJFAYhBb6sBgcK%2FRIKBwasDg8KAV4KD2QBCYGhmn8JAQEGFwcTCGd%2BhGoIFQYWBQAAAAANAAAAAASwBLAACQAVABkAHQAhACUALQA7AD8AQwBHAEsATwAAATMVIxUhFSMRIQEjFTMVIREjESM1IQURIREhESERBSM1MwUjNTMBMxEhETM1MwEzFSMVIzUjNTM1IzUhBREhEQcjNTMFIzUzASM1MwUhNSEB9GRk%2FnBkAfQCvMjI%2FtTIZAJY%2B7QBLAGQASz84GRkArxkZP1EyP4MyGQB9MhkyGRkyAEs%2FUQBLGRkZAOEZGT%2BDGRkAfT%2B1AEsA4RkZGQCWP4MZMgBLAEsyGT%2B1AEs%2FtQBLMhkZGT%2BDP4MAfRk%2FtRkZGRkyGTI%2FtQBLMhkZGT%2B1GRkZAAAAAAJAAAAAASwBLAAAwAHAAsADwATABcAGwAfACMAADcjETMTIxEzASMRMxMjETMBIxEzASE1IRcjNTMXIzUzBSM1M2RkZMhkZAGQyMjIZGQBLMjI%2FOD%2B1AEsyGRkyGRkASzIyMgD6PwYA%2Bj8GAPo%2FBgD6PwYA%2Bj7UGRkW1tbW1sAAAIAAAAKBKYEsAANABUAAAkBFhQHAQYiJwETNDYzBCYiBhQWMjYB9AKqCAj%2BMAgUCP1WAQ8KAUM7Uzs7UzsEsP1WCBQI%2FjAICAKqAdsKD807O1Q7OwAAAAADAAAACgXSBLAADQAZACEAAAkBFhQHAQYiJwETNDYzIQEWFAcBBiIvAQkBBCYiBhQWMjYB9AKqCAj%2BMAgUCP1WAQ8KAwYCqggI%2FjAIFAg4Aaj9RP7TO1M7O1M7BLD9VggUCP4wCAgCqgHbCg%2F9VggUCP4wCAg4AaoCvM07O1Q7OwAAAAABAGQAAASwBLAAJgAAASEyFREUDwEGJjURNCYjISIPAQYWMyEyFhURFAYjISImNRE0PwE2ASwDOUsSQAgKDwr9RBkSQAgFCgK8Cg8PCvyuCg8SixIEsEv8fBkSQAgFCgO2Cg8SQAgKDwr8SgoPDwoDzxkSixIAAAABAMj%2F%2FwRMBLAACgAAEyEyFhURCQERNDb6AyAVHf4%2B%2Fj4dBLAdFfuCAbz%2BQwR%2FFR0AAAAAAwAAAAAEsASwABUARQBVAAABISIGBwMGHwEeATMhMjY%2FATYnAy4BASMiBg8BDgEjISImLwEuASsBIgYVERQWOwEyNj0BNDYzITIWHQEUFjsBMjY1ETQmASEiBg8BBhYzITI2LwEuAQM2%2FkQLEAFOBw45BhcKAcIKFwY%2BDgdTARABVpYKFgROBBYK%2FdoKFgROBBYKlgoPDwqWCg8PCgLuCg8PCpYKDw%2F%2Bsf4MChMCJgILCgJYCgsCJgITBLAPCv7TGBVsCQwMCWwVGAEtCg%2F%2BcA0JnAkNDQmcCQ0PCv12Cg8PCpYKDw8KlgoPDwoCigoP%2FagOCpgKDg4KmAoOAAAAAAQAAABkBLAETAAdACEAKQAxAAABMzIeAh8BMzIWFREUBiMhIiY1ETQ2OwE%2BBAEVMzUEIgYUFjI2NCQyFhQGIiY0AfTIOF00JAcGlik7Oyn8GCk7OymWAgknM10ByGT%2Bz76Hh76H%2Fu9WPDxWPARMKTs7FRQ7Kf2oKTs7KQJYKTsIG0U1K%2F7UZGRGh76Hh74IPFY8PFYAAAAAAgA1AAAEsASvACAAIwAACQEWFx4BHwEVITUyNi8BIQYHBh4CMxUhNTY3PgE%2FAQEDIQMCqQGBFCgSJQkK%2Fl81LBFS%2Fnk6IgsJKjIe%2FpM4HAwaBwcBj6wBVKIEr%2FwaMioTFQECQkJXLd6RWSIuHAxCQhgcDCUNDQPu%2FVoByQAAAAADAGQAAAPwBLAAJwAyADsAAAEeBhUUDgMjITU%2BATURNC4EJzUFMh4CFRQOAgclMzI2NTQuAisBETMyNjU0JisBAvEFEzUwOyodN1htbDD%2BDCk7AQYLFyEaAdc5dWM%2BHy0tEP6Pi05pESpTPnbYUFJ9Xp8CgQEHGB0zOlIuQ3VONxpZBzMoAzsYFBwLEAkHRwEpSXNDM1s6KwkxYUopOzQb%2FK5lUFqBAAABAMgAAANvBLAAGQAAARcOAQcDBhYXFSE1NjcTNjQuBCcmJzUDbQJTQgeECSxK%2Fgy6Dq0DAw8MHxUXDQYEsDkTNSj8uTEoBmFhEFIDQBEaExAJCwYHAwI5AAAAAAL%2FtQAABRQEsAAlAC8AAAEjNC4FKwERFBYfARUhNTI%2BAzURIyIOBRUjESEFIxEzByczESM3BRQyCAsZEyYYGcgyGRn%2BcAQOIhoWyBkYJhMZCwgyA%2Bj7m0tLfX1LS30DhBUgFQ4IAwH8rhYZAQJkZAEFCRUOA1IBAwgOFSAVASzI%2FOCnpwMgpwACACH%2FtQSPBLAAJQAvAAABIzQuBSsBERQWHwEVITUyPgM1ESMiDgUVIxEhEwc1IRUnNxUhNQRMMggLGRMmGBnIMhkZ%2FnAEDiIaFsgZGCYTGQsIMgPoQ6f84KenAyADhBUgFQ4IAwH9dhYZAQJkZAEFCRUOAooBAwgOFSAVASz7gn1LS319S0sABAAAAAAEsARMAA8AHwAvAD8AABMhMhYdARQGIyEiJj0BNDYTITIWHQEUBiMhIiY9ATQ2EyEyFh0BFAYjISImPQE0NhMhMhYdARQGIyEiJj0BNDYyAlgVHR0V%2FagVHR0VA%2BgVHR0V%2FBgVHR0VAyAVHR0V%2FOAVHR0VBEwVHR0V%2B7QVHR0ETB0VZBUdHRVkFR3%2B1B0VZBUdHRVkFR3%2B1B0VZBUdHRVkFR3%2B1B0VZBUdHRVkFR0ABAAAAAAEsARMAA8AHwAvAD8AABMhMhYdARQGIyEiJj0BNDYDITIWHQEUBiMhIiY9ATQ2EyEyFh0BFAYjISImPQE0NgMhMhYdARQGIyEiJj0BNDb6ArwVHR0V%2FUQVHR2zBEwVHR0V%2B7QVHR3dArwVHR0V%2FUQVHR2zBEwVHR0V%2B7QVHR0ETB0VZBUdHRVkFR3%2B1B0VZBUdHRVkFR3%2B1B0VZBUdHRVkFR3%2B1B0VZBUdHRVkFR0ABAAAAAAEsARMAA8AHwAvAD8AAAE1NDYzITIWHQEUBiMhIiYBNTQ2MyEyFh0BFAYjISImEzU0NjMhMhYdARQGIyEiJgE1NDYzITIWHQEUBiMhIiYB9B0VAlgVHR0V%2FagVHf5wHRUD6BUdHRX8GBUdyB0VAyAVHR0V%2FOAVHf7UHRUETBUdHRX7tBUdA7ZkFR0dFWQVHR3%2B6WQVHR0VZBUdHf7pZBUdHRVkFR0d%2FulkFR0dFWQVHR0AAAQAAAAABLAETAAPAB8ALwA%2FAAATITIWHQEUBiMhIiY9ATQ2EyEyFh0BFAYjISImPQE0NhMhMhYdARQGIyEiJj0BNDYTITIWHQEUBiMhIiY9ATQ2MgRMFR0dFfu0FR0dFQRMFR0dFfu0FR0dFQRMFR0dFfu0FR0dFQRMFR0dFfu0FR0dBEwdFWQVHR0VZBUd%2FtQdFWQVHR0VZBUd%2FtQdFWQVHR0VZBUd%2FtQdFWQVHR0VZBUdAAgAAAAABLAETAAPAB8ALwA%2FAE8AXwBvAH8AABMzMhYdARQGKwEiJj0BNDYpATIWHQEUBiMhIiY9ATQ2ATMyFh0BFAYrASImPQE0NikBMhYdARQGIyEiJj0BNDYBMzIWHQEUBisBIiY9ATQ2KQEyFh0BFAYjISImPQE0NgEzMhYdARQGKwEiJj0BNDYpATIWHQEUBiMhIiY9ATQ2MmQVHR0VZBUdHQFBAyAVHR0V%2FOAVHR3%2B6WQVHR0VZBUdHQFBAyAVHR0V%2FOAVHR3%2B6WQVHR0VZBUdHQFBAyAVHR0V%2FOAVHR3%2B6WQVHR0VZBUdHQFBAyAVHR0V%2FOAVHR0ETB0VZBUdHRVkFR0dFWQVHR0VZBUd%2FtQdFWQVHR0VZBUdHRVkFR0dFWQVHf7UHRVkFR0dFWQVHR0VZBUdHRVkFR3%2B1B0VZBUdHRVkFR0dFWQVHR0VZBUdAAAG%2F5wAAASwBEwAAwATACMAKgA6AEoAACEjETsCMhYdARQGKwEiJj0BNDYTITIWHQEUBiMhIiY9ATQ2BQc1IzUzNQUhMhYdARQGIyEiJj0BNDYTITIWHQEUBiMhIiY9ATQ2AZBkZJZkFR0dFWQVHR0VAfQVHR0V%2FgwVHR3%2B%2BqfIyAHCASwVHR0V%2FtQVHR0VAlgVHR0V%2FagVHR0ETB0VZBUdHRVkFR3%2B1B0VZBUdHRVkFR36fUtkS68dFWQVHR0VZBUd%2FtQdFWQVHR0VZBUdAAAABgAAAAAFFARMAA8AEwAjACoAOgBKAAATMzIWHQEUBisBIiY9ATQ2ASMRMwEhMhYdARQGIyEiJj0BNDYFMxUjFSc3BSEyFh0BFAYjISImPQE0NhMhMhYdARQGIyEiJj0BNDYyZBUdHRVkFR0dA2dkZPyuAfQVHR0V%2FgwVHR0EL8jIp6f75gEsFR0dFf7UFR0dFQJYFR0dFf2oFR0dBEwdFWQVHR0VZBUd%2B7QETP7UHRVkFR0dFWQVHchkS319rx0VZBUdHRVkFR3%2B1B0VZBUdHRVkFR0AAAAAAgAAAMgEsAPoAA8AEgAAEyEyFhURFAYjISImNRE0NgkCSwLuHywsH%2F0SHywsBIT%2B1AEsA%2BgsH%2F12HywsHwKKHyz9RAEsASwAAwAAAAAEsARMAA8AFwAfAAATITIWFREUBiMhIiY1ETQ2FxE3BScBExEEMhYUBiImNCwEWBIaGhL7qBIaGkr3ASpKASXs%2FNJwTk5wTgRMGhL8DBIaGhID9BIaZP0ftoOcAT7%2B4AH0dE5vT09vAAAAAAIA2wAFBDYEkQAWAB4AAAEyHgEVFAcOAQ8BLgQnJjU0PgIWIgYUFjI2NAKIdcZzRkWyNjYJIV5YbSk8RHOft7eCgreCBJF4ynVzj23pPz4IIWZomEiEdVijeUjDgriBgbgAAAACABcAFwSZBJkADwAXAAAAMh4CFA4CIi4CND4BAREiDgEUHgEB4%2BrWm1tbm9bq1ptbW5sBS3TFcnLFBJlbm9bq1ptbW5vW6tab%2FG8DVnLF6MVyAAACAHUAAwPfBQ8AGgA1AAABHgYVFA4DBy4DNTQ%2BBQMOAhceBBcWNj8BNiYnLgInJjc2IyYCKhVJT1dOPiUzVnB9P1SbfEokP0xXUEm8FykoAwEbITEcExUWAgYCCQkFEikMGiACCAgFD0iPdXdzdYdFR4BeRiYEBTpjl1lFh3ZzeHaQ%2Ff4hS4I6JUEnIw4IBwwQIgoYBwQQQSlZtgsBAAAAAwAAAAAEywRsAAwAKgAvAAABNz4CHgEXHgEPAiUhMhcHISIGFREUFjMhMjY9ATcRFAYjISImNRE0NgkBBzcBA%2BhsAgYUFR0OFgoFBmz9BQGQMje7%2FpApOzspAfQpO8i7o%2F5wpbm5Azj%2BlqE3AWMD9XMBAgIEDw4WKgsKc8gNuzsp%2FgwpOzsptsj%2BtKW5uaUBkKW5%2Ftf%2BljKqAWMAAgAAAAAEkwRMABsANgAAASEGByMiBhURFBYzITI2NTcVFAYjISImNRE0NgUBFhQHAQYmJzUmDgMHPgY3NT4BAV4BaaQ0wyk7OykB9Ck7yLml%2FnClubkCfwFTCAj%2BrAcLARo5ZFRYGgouOUlARioTAQsETJI2Oyn%2BDCk7OymZZ6W5uaUBkKW5G%2F7TBxUH%2Fs4GBAnLAQINFjAhO2JBNB0UBwHSCgUAAAAAAgAAAAAEnQRMAB0ANQAAASEyFwchIgYVERQWMyEyNj0BNxUUBiMhIiY1ETQ2CQE2Mh8BFhQHAQYiLwEmND8BNjIfARYyAV4BXjxDsv6jKTs7KQH0KTvIuaX%2BcKW5uQHKAYsHFQdlBwf97QcVB%2FgHB2UHFQdvCBQETBexOyn%2BDCk7OylFyNulubmlAZCluf4zAYsHB2UHFQf97AcH%2BAcVB2UHB28HAAAAAQAKAAoEpgSmADsAAAkBNjIXARYGKwEVMzU0NhcBFhQHAQYmPQEjFTMyFgcBBiInASY2OwE1IxUUBicBJjQ3ATYWHQEzNSMiJgE%2BAQgIFAgBBAcFCqrICggBCAgI%2FvgICsiqCgUH%2FvwIFAj%2B%2BAgFCq%2FICgj%2B%2BAgIAQgICsivCgUDlgEICAj%2B%2BAgKyK0KBAf%2B%2FAcVB%2F73BwQKrcgKCP74CAgBCAgKyK0KBAcBCQcVBwEEBwQKrcgKAAEAyAAAA4QETAAZAAATMzIWFREBNhYVERQGJwERFAYrASImNRE0NvpkFR0B0A8VFQ%2F%2BMB0VZBUdHQRMHRX%2BSgHFDggV%2FBgVCA4Bxf5KFR0dFQPoFR0AAAABAAAAAASwBEwAIwAAEzMyFhURATYWFREBNhYVERQGJwERFAYnAREUBisBIiY1ETQ2MmQVHQHQDxUB0A8VFQ%2F%2BMBUP%2FjAdFWQVHR0ETB0V%2FkoBxQ4IFf5KAcUOCBX8GBUIDgHF%2FkoVCA4Bxf5KFR0dFQPoFR0AAAABAJ0AGQSwBDMAFQAAAREUBicBERQGJwEmNDcBNhYVEQE2FgSwFQ%2F%2BMBUP%2FhQPDwHsDxUB0A8VBBr8GBUIDgHF%2FkoVCA4B4A4qDgHgDggV%2FkoBxQ4IAAAAAQDIABYEMwQ2AAsAABMBFhQHAQYmNRE0NvMDLhIS%2FNISGRkEMv4OCx4L%2Fg4LDhUD6BUOAAIAyABkA4QD6AAPAB8AABMzMhYVERQGKwEiJjURNDYhMzIWFREUBisBIiY1ETQ2%2BsgVHR0VyBUdHQGlyBUdHRXIFR0dA%2BgdFfzgFR0dFQMgFR0dFfzgFR0dFQMgFR0AAAEAyABkBEwD6AAPAAABERQGIyEiJjURNDYzITIWBEwdFfzgFR0dFQMgFR0DtvzgFR0dFQMgFR0dAAAAAAEAAAAZBBMEMwAVAAABETQ2FwEWFAcBBiY1EQEGJjURNDYXAfQVDwHsDw%2F%2BFA8V%2FjAPFRUPAmQBthUIDv4gDioO%2FiAOCBUBtv47DggVA%2BgVCA4AAAH%2F%2FgACBLMETwAjAAABNzIWFRMUBiMHIiY1AwEGJjUDAQYmNQM0NhcBAzQ2FwEDNDYEGGQUHgUdFWQVHQL%2BMQ4VAv4yDxUFFQ8B0gIVDwHSAh0ETgEdFfwYFR0BHRUBtf46DwkVAbX%2BOQ4JFAPoFQkP%2Fj4BthQJDv49AbYVHQAAAQEsAAAD6ARMABkAAAEzMhYVERQGKwEiJjURAQYmNRE0NhcBETQ2A1JkFR0dFWQVHf4wDxUVDwHQHQRMHRX8GBUdHRUBtv47DggVA%2BgVCA7%2BOwG2FR0AAAIAZADIBLAESAALABsAAAkBFgYjISImNwE2MgEhMhYdARQGIyEiJj0BNDYCrgH1DwkW%2B%2B4WCQ8B9Q8q%2FfcD6BUdHRX8GBUdHQQ5%2FeQPFhYPAhwP%2FUgdFWQVHR0VZBUdAAEAiP%2F8A3UESgAFAAAJAgcJAQN1%2FqABYMX92AIoA4T%2Bn%2F6fxgIoAiYAAAAAAQE7%2F%2FwEKARKAAUAAAkBJwkBNwQo%2FdnGAWH%2Bn8YCI%2F3ZxgFhAWHGAAIAFwAXBJkEmQAPADMAAAAyHgIUDgIiLgI0PgEFIyIGHQEjIgYdARQWOwEVFBY7ATI2PQEzMjY9ATQmKwE1NCYB4%2BrWm1tbm9bq1ptbW5sBfWQVHZYVHR0Vlh0VZBUdlhUdHRWWHQSZW5vW6tabW1ub1urWm7odFZYdFWQVHZYVHR0Vlh0VZBUdlhUdAAAAAAIAFwAXBJkEmQAPAB8AAAAyHgIUDgIiLgI0PgEBISIGHQEUFjMhMjY9ATQmAePq1ptbW5vW6tabW1ubAkX%2BDBUdHRUB9BUdHQSZW5vW6tabW1ub1urWm%2F5%2BHRVkFR0dFWQVHQACABcAFwSZBJkADwAzAAAAMh4CFA4CIi4CND4BBCIPAScmIg8BBhQfAQcGFB8BFjI%2FARcWMj8BNjQvATc2NC8BAePq1ptbW5vW6tabW1ubAeUZCXh4CRkJjQkJeHgJCY0JGQl4eAkZCY0JCXh4CQmNBJlbm9bq1ptbW5vW6tabrQl4eAkJjQkZCXh4CRkJjQkJeHgJCY0JGQl4eAkZCY0AAgAXABcEmQSZAA8AJAAAADIeAhQOAiIuAjQ%2BAQEnJiIPAQYUHwEWMjcBNjQvASYiBwHj6tabW1ub1urWm1tbmwEVVAcVCIsHB%2FIHFQcBdwcHiwcVBwSZW5vW6tabW1ub1urWm%2F4xVQcHiwgUCPEICAF3BxUIiwcHAAAAAAMAFwAXBJkEmQAPADsASwAAADIeAhQOAiIuAjQ%2BAQUiDgMVFDsBFjc%2BATMyFhUUBgciDgUHBhY7ATI%2BAzU0LgMTIyIGHQEUFjsBMjY9ATQmAePq1ptbW5vW6tabW1ubAT8dPEIyIRSDHgUGHR8UFw4TARkOGhITDAIBDQ6tBx4oIxgiM0Q8OpYKDw8KlgoPDwSZW5vW6tabW1ub1urWm5ELHi9PMhkFEBQQFRIXFgcIBw4UHCoZCBEQKDhcNi9IKhsJ%2FeMPCpYKDw8KlgoPAAADABcAFwSZBJkADwAfAD4AAAAyHgIUDgIiLgI0PgEFIyIGHQEUFjsBMjY9ATQmAyMiBh0BFBY7ARUjIgYdARQWMyEyNj0BNCYrARE0JgHj6tabW1ub1urWm1tbmwGWlgoPDwqWCg8PCvoKDw8KS0sKDw8KAV4KDw8KSw8EmVub1urWm1tbm9bq1ptWDwqWCg8PCpYKD%2F7UDwoyCg%2FIDwoyCg8PCjIKDwETCg8AAgAAAAAEsASwAC8AXwAAATMyFh0BHgEXMzIWHQEUBisBDgEHFRQGKwEiJj0BLgEnIyImPQE0NjsBPgE3NTQ2ExUUBisBIiY9AQ4BBzMyFh0BFAYrAR4BFzU0NjsBMhYdAT4BNyMiJj0BNDY7AS4BAg2WCg9nlxvCCg8PCsIbl2cPCpYKD2eXG8IKDw8KwhuXZw%2B5DwqWCg9EZheoCg8PCqgXZkQPCpYKD0RmF6gKDw8KqBdmBLAPCsIbl2cPCpYKD2eXG8IKDw8KwhuXZw8KlgoPZ5cbwgoP%2Fs2oCg8PCqgXZkQPCpYKD0RmF6gKDw8KqBdmRA8KlgoPRGYAAwAXABcEmQSZAA8AGwA%2FAAAAMh4CFA4CIi4CND4BBCIOARQeATI%2BATQmBxcWFA8BFxYUDwEGIi8BBwYiLwEmND8BJyY0PwE2Mh8BNzYyAePq1ptbW5vW6tabW1ubAb%2FoxXJyxejFcnKaQAcHfHwHB0AHFQd8fAcVB0AHB3x8BwdABxUHfHwHFQSZW5vW6tabW1ub1urWmztyxejFcnLF6MVaQAcVB3x8BxUHQAcHfHwHB0AHFQd8fAcVB0AHB3x8BwAAAAMAFwAXBJkEmQAPABsAMAAAADIeAhQOAiIuAjQ%2BAQQiDgEUHgEyPgE0JgcXFhQHAQYiLwEmND8BNjIfATc2MgHj6tabW1ub1urWm1tbmwG%2F6MVycsXoxXJyg2oHB%2F7ACBQIyggIagcVB0%2FFBxUEmVub1urWm1tbm9bq1ps7csXoxXJyxejFfWoHFQf%2BvwcHywcVB2oICE%2FFBwAAAAMAFwAXBJkEmQAPABgAIQAAADIeAhQOAiIuAjQ%2BAQUiDgEVFBcBJhcBFjMyPgE1NAHj6tabW1ub1urWm1tbmwFLdMVyQQJLafX9uGhzdMVyBJlbm9bq1ptbW5vW6tabO3LFdHhpAktB0P24PnLFdHMAAAAAAQAXAFMEsAP5ABUAABMBNhYVESEyFh0BFAYjIREUBicBJjQnAgoQFwImFR0dFf3aFxD99hACRgGrDQoV%2Ft0dFcgVHf7dFQoNAasNJgAAAAABAAAAUwSZA%2FkAFQAACQEWFAcBBiY1ESEiJj0BNDYzIRE0NgJ%2FAgoQEP32EBf92hUdHRUCJhcD8f5VDSYN%2FlUNChUBIx0VyBUdASMVCgAAAAEAtwAABF0EmQAVAAAJARYGIyERFAYrASImNREhIiY3ATYyAqoBqw0KFf7dHRXIFR3%2B3RUKDQGrDSYEif32EBf92hUdHRUCJhcQAgoQAAAAAQC3ABcEXQSwABUAAAEzMhYVESEyFgcBBiInASY2MyERNDYCJsgVHQEjFQoN%2FlUNJg3%2BVQ0KFQEjHQSwHRX92hcQ%2FfYQEAIKEBcCJhUdAAABAAAAtwSZBF0AFwAACQEWFAcBBiY1EQ4DBz4ENxE0NgJ%2FAgoQEP32EBdesKWBJAUsW4fHfhcEVf5VDSYN%2FlUNChUBIwIkRHVNabGdcUYHAQYVCgACAAAAAASwBLAAFQArAAABITIWFREUBi8BBwYiLwEmND8BJyY2ASEiJjURNDYfATc2Mh8BFhQPARcWBgNSASwVHRUOXvkIFAhqBwf5Xg4I%2FiH%2B1BUdFQ5e%2BQgUCGoHB%2FleDggEsB0V%2FtQVCA5e%2BQcHaggUCPleDhX7UB0VASwVCA5e%2BQcHaggUCPleDhUAAAACAEkASQRnBGcAFQArAAABFxYUDwEXFgYjISImNRE0Nh8BNzYyASEyFhURFAYvAQcGIi8BJjQ%2FAScmNgP2agcH%2BV4OCBX%2B1BUdFQ5e%2BQgU%2FQwBLBUdFQ5e%2BQgUCGoHB%2FleDggEYGoIFAj5Xg4VHRUBLBUIDl75B%2F3xHRX%2B1BUIDl75BwdqCBQI%2BV4OFQAAAAADABcAFwSZBJkADwAfAC8AAAAyHgIUDgIiLgI0PgEFIyIGFxMeATsBMjY3EzYmAyMiBh0BFBY7ATI2PQE0JgHj6tabW1ub1urWm1tbmwGz0BQYBDoEIxQ2FCMEOgQYMZYKDw8KlgoPDwSZW5vW6tabW1ub1urWm7odFP7SFB0dFAEuFB3%2BDA8KlgoPDwqWCg8AAAAABQAAAAAEsASwAEkAVQBhAGgAbwAAATIWHwEWHwEWFxY3Nj8BNjc2MzIWHwEWHwIeATsBMhYdARQGKwEiBh0BIREjESE1NCYrASImPQE0NjsBMjY1ND8BNjc%2BBAUHBhY7ATI2LwEuAQUnJgYPAQYWOwEyNhMhIiY1ESkBERQGIyERAQQJFAUFFhbEFQ8dCAsmxBYXERUXMA0NDgQZCAEPCj0KDw8KMgoP%2FnDI%2FnAPCjIKDw8KPQsOCRkFDgIGFRYfAp2mBwQK2woKAzMDEP41sQgQAzMDCgrnCwMe%2FokKDwGQAlgPCv6JBLAEAgIKDXYNCxUJDRZ2DQoHIREQFRh7LAkLDwoyCg8PCq8BLP7UrwoPDwoyCg8GBQQwgBkUAwgWEQ55ogcKDgqVCgSqnQcECo8KDgr8cg8KAXf%2BiQoPAZAAAAAAAgAAAAwErwSmACsASQAAATYWFQYCDgQuAScmByYOAQ8BBiY1NDc%2BATc%2BAScuAT4BNz4GFyYGBw4BDwEOBAcOARY2Nz4CNz4DNz4BBI0IGgItQmxhi2KORDg9EQQRMxuZGhYqCFUYEyADCQIQOjEnUmFch3vAJQgdHyaiPT44XHRZUhcYDhItIRmKcVtGYWtbKRYEBKYDEwiy%2Ft3IlVgxEQgLCwwBAQIbG5kYEyJAJghKFRE8Hzdff4U%2FM0o1JSMbL0QJGCYvcSEhHjZST2c1ODwEJygeW0AxJUBff1UyFAABAF0AHgRyBM8ATwAAAQ4BHgQXLgc%2BATceAwYHDgQHBicmNzY3PgQuAScWDgMmJy4BJyY%2BBDcGHgM3PgEuAicmPgMCjScfCic4R0IgBBsKGAoQAwEJEg5gikggBhANPkpTPhZINx8SBgsNJysiCRZOQQoVNU1bYC9QZwICBAUWITsoCAYdJzIYHw8YIiYHDyJJYlkEz0OAZVxEOSQMBzgXOB42IzElKRIqg5Gnl0o3Z0c6IAYWCwYNAwQFIDhHXGF1OWiqb0sdBxUknF0XNTQ8PEUiNWNROBYJDS5AQVUhVZloUSkAAAAAA%2F%2FcAGoE1ARGABsAPwBRAAAAMh4FFA4FIi4FND4EBSYGFxYVFAYiJjU0NzYmBwYHDgEXHgQyPgM3NiYnJgUHDgEXFhcWNj8BNiYnJicuAQIGpJ17bk85HBw6T257naKde25POhwcOU9uewIPDwYIGbD4sBcIBw5GWg0ECxYyWl%2BDiINfWjIWCwQMWv3%2FIw8JCSU4EC0OIw4DDywtCyIERi1JXGJcSSpJXGJcSS0tSVxiXEkqSVxiXEncDwYTOT58sLB8OzcTBg9FcxAxEiRGXkQxMEVeRSQSMRF1HiQPLxJEMA0EDyIPJQ8sSRIEAAAABP%2FcAAAE1ASwABQAJwA7AEwAACEjNy4ENTQ%2BBTMyFzczEzceARUUDgMHNz4BNzYmJyYlBgcOARceBBc3LgE1NDc2JhcHDgEXFhcWNj8CJyYnLgECUJQfW6l2WSwcOU9ue51SPUEglCYvbIknUGqYUi5NdiYLBAw2%2FVFGWg0ECxIqSExoNSlrjxcIB3wjDwkJJTgQLQ4MFgMsLQsieBRhdHpiGxVJXGJcSS0Pef5StVXWNBpacm5jGq0xiD8SMRFGckVzEDESHjxRQTkNmhKnbjs3EwZwJA8vEkQwDQQPC1YELEkSBAAAAAP%2FngAABRIEqwALABgAKAAAJwE2FhcBFgYjISImJSE1NDY7ATIWHQEhAQczMhYPAQ4BKwEiJi8BJjZaAoIUOBQCghUbJfryJRsBCgFZDwqWCg8BWf5DaNAUGAQ6BCMUNhQjBDoEGGQEKh8FIfvgIEdEhEsKDw8KSwLT3x0U%2FBQdHRT8FB0AAAABAGQAFQSwBLAAKAAAADIWFREBHgEdARQGJyURFh0BFAYvAQcGJj0BNDcRBQYmPQE0NjcBETQCTHxYAWsPFhgR%2FplkGhPNzRMaZP6ZERgWDwFrBLBYPv6t%2FrsOMRQpFA0M%2Bf75XRRAFRAJgIAJEBVAFF0BB%2FkMDRQpFDEOAUUBUz4AAAARAAAAAARMBLAAHQAnACsALwAzADcAOwA%2FAEMARwBLAE8AUwBXAFsAXwBjAAABMzIWHQEzMhYdASE1NDY7ATU0NjsBMhYdASE1NDYBERQGIyEiJjURFxUzNTMVMzUzFTM1MxUzNTMVMzUFFTM1MxUzNTMVMzUzFTM1MxUzNQUVMzUzFTM1MxUzNTMVMzUzFTM1A1JkFR0yFR37tB0VMh0VZBUdAfQdAQ8dFfwYFR1kZGRkZGRkZGRk%2FHxkZGRkZGRkZGT8fGRkZGRkZGRkZASwHRUyHRWWlhUdMhUdHRUyMhUd%2FnD9EhUdHRUC7shkZGRkZGRkZGRkyGRkZGRkZGRkZGTIZGRkZGRkZGRkZAAAAAMAAAAZBXcElwAZACUANwAAARcWFA8BBiY9ASMBISImPQE0NjsBATM1NDYBBycjIiY9ATQ2MyEBFxYUDwEGJj0BIyc3FzM1NDYEb%2FkPD%2FkOFZ%2F9qP7dFR0dFdECWPEV%2FamNetEVHR0VASMDGvkPD%2FkOFfG1jXqfFQSN5g4qDuYOCBWW%2FagdFWQVHQJYlhUI%2FpiNeh0VZBUd%2Fk3mDioO5g4IFZa1jXqWFQgAAAABAAAAAASwBEwAEgAAEyEyFhURFAYjIQERIyImNRE0NmQD6Ck7Oyn9rP7QZCk7OwRMOyn9qCk7%2FtQBLDspAlgpOwAAAAMAZAAABEwEsAAJABMAPwAAEzMyFh0BITU0NiEzMhYdASE1NDYBERQOBSIuBTURIRUUFRwBHgYyPgYmNTQ9AZbIFR3%2B1B0C0cgVHf7UHQEPBhgoTGacwJxmTCgYBgEsAwcNFB8nNkI2Jx8TDwUFAQSwHRX6%2BhUdHRX6%2BhUd%2FnD%2B1ClJalZcPigoPlxWakkpASz6CRIVKyclIRsWEAgJEBccISUnKhURCPoAAAAB%2F%2F8A1ARMA8IABQAAAQcJAScBBEzG%2Fp%2F%2Bn8UCJwGbxwFh%2Fp%2FHAicAAQAAAO4ETQPcAAUAAAkCNwkBBE392v3ZxgFhAWEDFf3ZAifH%2Fp8BYQAAAAAC%2F1EAZAVfA%2BgAFAApAAABITIWFREzMhYPAQYiLwEmNjsBESElFxYGKwERIRchIiY1ESMiJj8BNjIBlALqFR2WFQgO5g4qDuYOCBWW%2FoP%2BHOYOCBWWAYHX%2FRIVHZYVCA7mDioD6B0V%2FdkVDvkPD%2FkOFQGRuPkOFf5wyB0VAiYVDvkPAAABAAYAAASeBLAAMAAAEzMyFh8BITIWBwMOASMhFyEyFhQGKwEVFAYiJj0BIRUUBiImPQEjIiYvAQMjIiY0NjheERwEJgOAGB4FZAUsIf2HMAIXFR0dFTIdKh3%2B1B0qHR8SHQYFyTYUHh4EsBYQoiUY%2FiUVK8gdKh0yFR0dFTIyFR0dFTIUCQoDwR0qHQAAAAACAAAAAASwBEwACwAPAAABFSE1MzQ2MyEyFhUFIREhBLD7UMg7KQEsKTv9RASw%2B1AD6GRkKTs7Kcj84AACAAAAAAXcBEwADAAQAAATAxEzNDYzITIWFSEVBQEhAcjIyDspASwqOgH0ASz%2B1PtQASwDIP5wAlgpOzspyGT9RAK8AAEBRQAAA2sErwAbAAABFxYGKwERMzIWDwEGIi8BJjY7AREjIiY%2FATYyAnvmDggVlpYVCA7mDioO5g4IFZaWFQgO5g4qBKD5DhX9pxUO%2BQ8P%2BQ4VAlkVDvkPAAAAAQABAUQErwNrABsAAAEXFhQPAQYmPQEhFRQGLwEmND8BNhYdASE1NDYDqPkODvkPFf2oFQ%2F5Dg75DxUCWBUDYOUPKQ%2FlDwkUl5cUCQ%2FlDykP5Q8JFZWVFQkAAAAEAAAAAASwBLAACQAZAB0AIQAAAQMuASMhIgYHAwUhIgYdARQWMyEyNj0BNCYFNTMVMzUzFQSRrAUkFP1gFCQFrAQt%2FBgpOzspA%2BgpOzv%2Bq2RkZAGQAtwXLSgV%2FR1kOylkKTs7KWQpO8hkZGRkAAAAA%2F%2BcAGQEsARMAAsAIwAxAAAAMhYVERQGIiY1ETQDJSMTFgYjIisBIiYnAj0BNDU0PgE7ASUBFSIuAz0BND4CNwRpKh0dKh1k%2FV0mLwMRFQUCVBQdBDcCCwzIAqP8GAQOIhoWFR0dCwRMHRX8rhUdHRUDUhX8mcj%2B7BAIHBUBUQ76AgQQDw36%2FtT6AQsTKRwyGigUDAEAAAACAEoAAARmBLAALAA1AAABMzIWDwEeARcTFzMyFhQGBw4EIyIuBC8BLgE0NjsBNxM%2BATcnJjYDFjMyNw4BIiYCKV4UEgYSU3oPP3YRExwaEggeZGqfTzl0XFU%2BLwwLEhocExF2Pw96UxIGEyQyNDUxDDdGOASwFRMlE39N%2FrmtHSkoBwQLHBYSCg4REg4FBAgoKR2tAUdNfhQgExr7vgYGMT09AAEAFAAUBJwEnAAXAAABNwcXBxcHFycHJwcnBzcnNyc3Jxc3FzcDIOBO6rS06k7gLZubLeBO6rS06k7gLZubA7JO4C2bmy3gTuq0tOpO4C2bmy3gTuq0tAADAAAAZASwBLAAIQAtAD0AAAEzMhYdAQchMhYdARQHAw4BKwEiJi8BIyImNRE0PwI%2BARcPAREzFzMTNSE3NQEzMhYVERQGKwEiJjURNDYCijIoPBwBSCg8He4QLBf6B0YfHz0tNxSRYA0xG2SWZIjW%2Bv4%2BMv12ZBUdHRVkFR0dBLBRLJZ9USxkLR3%2BqBghMhkZJCcBkCQbxMYcKGTU1f6JZAF3feGv%2FtQdFf4MFR0dFQH0FR0AAAAAAwAAAAAEsARMACAAMAA8AAABMzIWFxMWHQEUBiMhFh0BFAYrASImLwImNRE0NjsBNgUzMhYVERQGKwEiJjURNDYhByMRHwEzNSchNQMCWPoXLBDuHTwo%2FrgcPCgyGzENYJEUNy09fP3pZBUdHRVkFR0dAl%2BIZJZkMjIBwvoETCEY%2FqgdLWQsUXYHlixRKBzGxBskAZAnJGRkHRX%2BDBUdHRUB9BUdZP6J1dSv4X0BdwADAAAAZAUOBE8AGwA3AEcAAAElNh8BHgEPASEyFhQGKwEDDgEjISImNRE0NjcXERchEz4BOwEyNiYjISoDLgQnJj8BJwUzMhYVERQGKwEiJjURNDYBZAFrHxZuDQEMVAEuVGxuVGqDBhsP%2FqoHphwOOmQBJYMGGw%2FLFRMSFv44AgoCCQMHAwUDAQwRklb9T2QVHR0VZBUdHQNp5hAWcA0mD3lMkE7%2BrRUoog0CDRElCkj%2BCVkBUxUoMjIBAgIDBQIZFrdT5B0V%2FgwVHR0VAfQVHQAAAAP%2FnABkBLAETwAdADYARgAAAQUeBBURFAYjISImJwMjIiY0NjMhJyY2PwE2BxcWBw4FKgIjIRUzMhYXEyE3ESUFMzIWFREUBisBIiY1ETQ2AdsBbgIIFBANrAf%2Bqg8bBoNqVW1sVAEuVQsBDW4WSpIRDAIDBQMHAwkDCgH%2BJd0PHAaCASZq%2FqoCUGQVHR0VZBUdHQRP5gEFEBEXC%2F3zDaIoFQFTTpBMeQ8mDXAWrrcWGQIFAwICAWQoFf6tWQH37OQdFf4MFR0dFQH0FR0AAAADAGEAAARMBQ4AGwA3AEcAAAAyFh0BBR4BFREUBiMhIiYvAQMmPwE%2BAR8BETQXNTQmBhURHAMOBAcGLwEHEyE3ESUuAQMhMhYdARQGIyEiJj0BNDYB3pBOAVMVKKIN%2FfMRJQoJ5hAWcA0mD3nGMjIBAgIDBQIZFrdT7AH3Wf6tFSiWAfQVHR0V%2FgwVHR0FDm5UaoMGGw%2F%2BqgemHA4OAWsfFm4NAQxUAS5U1ssVExIW%2FjgCCgIJAwcDBQMBDBGSVv6tZAElgwYb%2FQsdFWQVHR0VZBUdAAP%2F%2FQAGA%2BgFFAAPAC0ASQAAASEyNj0BNCYjISIGHQEUFgEVFAYiJjURBwYmLwEmNxM%2BBDMhMhYVERQGBwEDFzc2Fx4FHAIVERQWNj0BNDY3JREnAV4B9BUdHRX%2BDBUdHQEPTpBMeQ8mDXAWEOYBBRARFwsCDQ2iKBX9iexTtxYZAgUDAgIBMjIoFQFTWQRMHRVkFR0dFWQVHfzmalRubFQBLlQMAQ1uFh8BawIIEw8Mpgf%2Bqg8bBgHP%2Fq1WkhEMAQMFAwcDCQIKAv44FhITFcsPGwaDASVkAAIAFgAWBJoEmgAPACUAAAAyHgIUDgIiLgI0PgEBJSYGHQEhIgYdARQWMyEVFBY3JTY0AeLs1ptbW5vW7NabW1ubAob%2B7RAX%2Fu0KDw8KARMXEAETEASaW5vW7NabW1ub1uzWm%2F453w0KFYkPCpYKD4kVCg3fDSYAAAIAFgAWBJoEmgAPACUAAAAyHgIUDgIiLgI0PgENAQYUFwUWNj0BITI2PQE0JiMhNTQmAeLs1ptbW5vW7NabW1ubASX%2B7RAQARMQFwETCg8PCv7tFwSaW5vW7NabW1ub1uzWm%2BjfDSYN3w0KFYkPCpYKD4kVCgAAAAIAFgAWBJoEmgAPACUAAAAyHgIUDgIiLgI0PgEBAyYiBwMGFjsBERQWOwEyNjURMzI2AeLs1ptbW5vW7NabW1ubAkvfDSYN3w0KFYkPCpYKD4kVCgSaW5vW7NabW1ub1uzWm%2F5AARMQEP7tEBf%2B7QoPDwoBExcAAAIAFgAWBJoEmgAPACUAAAAyHgIUDgIiLgI0PgEFIyIGFREjIgYXExYyNxM2JisBETQmAeLs1ptbW5vW7NabW1ubAZeWCg%2BJFQoN3w0mDd8NChWJDwSaW5vW7NabW1ub1uzWm7sPCv7tFxD%2B7RAQARMQFwETCg8AAAMAGAAYBJgEmAAPAJYApgAAADIeAhQOAiIuAjQ%2BASUOAwcGJgcOAQcGFgcOAQcGFgcUFgcyHgEXHgIXHgI3Fg4BFx4CFxQGFBcWNz4CNy4BJy4BJyIOAgcGJyY2NS4BJzYuAQYHBicmNzY3HgIXHgMfAT4CJyY%2BATc%2BAzcmNzIWMjY3LgMnND4CJiceAT8BNi4CJwYHFB4BFS4CJz4BNxYyPgEB5OjVm1xcm9Xo1ZtcXJsBZA8rHDoKDz0PFD8DAxMBAzEFCRwGIgEMFhkHECIvCxU%2FOR0HFBkDDRQjEwcFaHUeISQDDTAMD0UREi4oLBAzDwQBBikEAQMLGhIXExMLBhAGKBsGBxYVEwYFAgsFAwMNFwQGCQcYFgYQCCARFwkKKiFBCwQCAQMDHzcLDAUdLDgNEiEQEgg%2FKhADGgMKEgoRBJhcm9Xo1ZtcXJvV6NWbEQwRBwkCAwYFBycPCxcHInIWInYcCUcYChQECA4QBAkuHgQPJioRFRscBAcSCgwCch0kPiAIAQcHEAsBAgsLIxcBMQENCQIPHxkCFBkdHB4QBgEBBwoMGBENBAMMJSAQEhYXDQ4qFBkKEhIDCQsXJxQiBgEOCQwHAQ0DBAUcJAwSCwRnETIoAwEJCwsLJQcKDBEAAAAAAQAAAAIErwSFABYAAAE2FwUXNxYGBw4BJwEGIi8BJjQ3ASY2AvSkjv79kfsGUE08hjv9rA8rD28PDwJYIk8EhVxliuh%2BWYcrIgsW%2FawQEG4PKxACV2XJAAYAAABgBLAErAAPABMAIwAnADcAOwAAEyEyFh0BFAYjISImPQE0NgUjFTMFITIWHQEUBiMhIiY9ATQ2BSEVIQUhMhYdARQGIyEiJj0BNDYFIRUhZAPoKTs7KfwYKTs7BBHIyPwYA%2BgpOzsp%2FBgpOzsEEf4MAfT8GAPoKTs7KfwYKTs7BBH%2B1AEsBKw7KWQpOzspZCk7ZGTIOylkKTs7KWQpO2RkyDspZCk7OylkKTtkZAAAAAIAZAAABEwEsAALABEAABMhMhYUBiMhIiY0NgERBxEBIZYDhBUdHRX8fBUdHQI7yP6iA4QEsB0qHR0qHf1E%2FtTIAfQB9AAAAAMAAABkBLAEsAAXABsAJQAAATMyFh0BITIWFREhNSMVIRE0NjMhNTQ2FxUzNQEVFAYjISImPQEB9MgpOwEsKTv%2BDMj%2BDDspASw7KcgB9Dsp%2FBgpOwSwOylkOyn%2BcGRkAZApO2QpO2RkZP1EyCk7OynIAAAABAAAAAAEsASwABUAKwBBAFcAABMhMhYPARcWFA8BBiIvAQcGJjURNDYpATIWFREUBi8BBwYiLwEmND8BJyY2ARcWFA8BFxYGIyEiJjURNDYfATc2MgU3NhYVERQGIyEiJj8BJyY0PwE2MhcyASwVCA5exwcHaggUCMdeDhUdAzUBLBUdFQ5exwgUCGoHB8deDgj%2BL2oHB8deDggV%2FtQVHRUOXscIFALLXg4VHRX%2B1BUIDl7HBwdqCBQIBLAVDl7HCBQIagcHx14OCBUBLBUdHRX%2B1BUIDl7HBwdqCBQIx14OFf0maggUCMdeDhUdFQEsFQgOXscHzl4OCBX%2B1BUdFQ5exwgUCGoHBwAAAAYAAAAABKgEqAAPABsAIwA7AEMASwAAADIeAhQOAiIuAjQ%2BAQQiDgEUHgEyPgE0JiQyFhQGIiY0JDIWFAYjIicHFhUUBiImNTQ2PwImNTQEMhYUBiImNCQyFhQGIiY0Advy3Z9fX5%2Fd8t2gXl6gAcbgv29vv%2BC%2Fb2%2F%2BLS0gIC0gAUwtICAWDg83ETNIMykfegEJ%2FoctICAtIAIdLSAgLSAEqF%2Bf3fLdoF5eoN3y3Z9Xb7%2Fgv29vv%2BC%2FBiAtISEtICAtIQqRFxwkMzMkIDEFfgEODhekIC0gIC0gIC0gIC0AAf%2FYAFoEuQS8AFsAACUBNjc2JicmIyIOAwcABw4EFx4BMzI3ATYnLgEjIgcGBwEOASY0NwA3PgEzMhceARcWBgcOBgcGIyImJyY2NwE2NzYzMhceARcWBgcBDgEnLgECIgHVWwgHdl8WGSJBMD8hIP6IDx4eLRMNBQlZN0ozAiQkEAcdEhoYDRr%2Bqw8pHA4BRyIjQS4ODyw9DQ4YIwwod26La1YOOEBGdiIwGkQB%2F0coW2tQSE5nDxE4Qv4eDyoQEAOtAdZbZWKbEQQUGjIhH%2F6JDxsdNSg3HT5CMwIkJCcQFBcMGv6uDwEcKQ4BTSIjIQEINykvYyMLKnhuiWZMBxtAOU6%2BRAH%2FSBg3ISSGV121Qv4kDwIPDyYAAAACAGQAWASvBEQAGQBEAAABPgIeAhUUDgMHLgQ1ND4CHgEFIg4DIi4DIyIGFRQeAhcWFx4EMj4DNzY3PgQ1NCYCiTB7eHVYNkN5hKg%2BPqeFeEM4WnZ4eQEjIT8yLSohJyktPyJDbxtBMjMPBw86KzEhDSIzKUAMBAgrKT8dF2oDtURIBS1TdkA5eYB%2FslVVsn%2BAeTlAdlMtBUgtJjY1JiY1NiZvTRc4SjQxDwcOPCouGBgwKEALBAkpKkQqMhNPbQACADn%2F8gR3BL4AFwAuAAAAMh8BFhUUBg8BJi8BNycBFwcvASY0NwEDNxYfARYUBwEGIi8BJjQ%2FARYfAQcXAQKru0KNQjgiHR8uEl%2F3%2FnvUaRONQkIBGxJpCgmNQkL%2B5UK6Qo1CQjcdLhJf9wGFBL5CjUJeKmsiHTUuEl%2F4%2FnvUahKNQrpCARv%2BRmkICY1CukL%2B5UJCjUK7Qjc3LxFf%2BAGFAAAAAAMAyAAAA%2BgEsAARABUAHQAAADIeAhURFAYjISImNRE0PgEHESERACIGFBYyNjQCBqqaZDo7Kf2oKTs8Zj4CWP7%2FVj09Vj0EsB4uMhX8Ryk7OykDuRUzLar9RAK8%2FRY9Vj09VgABAAAAAASwBLAAFgAACQEWFAYiLwEBEScBBRMBJyEBJyY0NjIDhgEbDx0qDiT%2B6dT%2BzP7oywEz0gEsAQsjDx0qBKH%2B5g8qHQ8j%2FvX%2B1NL%2BzcsBGAE01AEXJA4qHQAAAAADAScAEQQJBOAAMgBAAEsAAAEVHgQXIy4DJxEXHgQVFAYHFSM1JicuASczHgEXEScuBDU0PgI3NRkBDgMVFB4DFxYXET4ENC4CArwmRVI8LAKfBA0dMydAIjxQNyiym2SWVygZA4sFV0obLkJOMCAyVWg6HSoqFQ4TJhkZCWgWKTEiGBkzNwTgTgUTLD9pQiQuLBsH%2Fs0NBxMtPGQ%2Bi6oMTU8QVyhrVk1iEAFPCA4ZLzlYNkZwSCoGTf4SARIEDh02Jh0rGRQIBgPQ%2FsoCCRYgNEM0JRkAAAABAGQAZgOUBK0ASgAAATIeARUjNC4CIyIGBwYVFB4BFxYXMxUjFgYHBgc%2BATM2FjMyNxcOAyMiLgEHDgEPASc%2BBTc%2BAScjNTMmJy4CPgE3NgIxVJlemSc8OxolVBQpGxoYBgPxxQgVFS02ImIWIIwiUzUyHzY4HCAXanQmJ1YYFzcEGAcTDBEJMAwk3aYXFQcKAg4tJGEErVCLTig%2FIhIdFSw5GkowKgkFZDKCHj4yCg8BIh6TExcIASIfBAMaDAuRAxAFDQsRCjePR2QvORQrREFMIVgAAAACABn%2F%2FwSXBLAADwAfAAABMzIWDwEGIi8BJjY7AREzBRcWBisBESMRIyImPwE2MgGQlhUIDuYOKg7mDggVlsgCF%2BYOCBWWyJYVCA7mDioBLBYO%2Bg8P%2Bg4WA4QQ%2BQ4V%2FHwDhBUO%2BQ8AAAQAGf%2F%2FA%2BgEsAAHABcAGwAlAAABIzUjFSMRIQEzMhYPAQYiLwEmNjsBETMFFTM1EwczFSE1NyM1IQPoZGRkASz9qJYVCA7mDioO5g4IFZbIAZFkY8jI%2FtTIyAEsArxkZAH0%2FHwWDvoPD%2FoOFgOEZMjI%2FRL6ZJb6ZAAAAAAEABn%2F%2FwPoBLAADwAZACEAJQAAATMyFg8BBiIvASY2OwERMwUHMxUhNTcjNSERIzUjFSMRIQcVMzUBkJYVCA7mDioO5g4IFZbIAljIyP7UyMgBLGRkZAEsx2QBLBYO%2Bg8P%2Bg4WA4SW%2BmSW%2BmT7UGRkAfRkyMgAAAAEABn%2F%2FwRMBLAADwAVABsAHwAAATMyFg8BBiIvASY2OwERMwEjESM1MxMjNSMRIQcVMzUBkJYVCA7mDioO5g4IFZbIAlhkZMhkZMgBLMdkASwWDvoPD%2FoOFgOE%2FgwBkGT7UGQBkGTIyAAAAAAEABn%2F%2FwRMBLAADwAVABkAHwAAATMyFg8BBiIvASY2OwERMwEjNSMRIQcVMzUDIxEjNTMBkJYVCA7mDioO5g4IFZbIArxkyAEsx2QBZGTIASwWDvoPD%2FoOFgOE%2FgxkAZBkyMj7tAGQZAAAAAAFABn%2F%2FwSwBLAADwATABcAGwAfAAABMzIWDwEGIi8BJjY7AREzBSM1MxMhNSETITUhEyE1IQGQlhUIDuYOKg7mDggVlsgB9MjIZP7UASxk%2FnABkGT%2BDAH0ASwWDvoPD%2FoOFgOEyMj%2BDMj%2BDMj%2BDMgABQAZ%2F%2F8EsASwAA8AEwAXABsAHwAAATMyFg8BBiIvASY2OwERMwUhNSEDITUhAyE1IQMjNTMBkJYVCA7mDioO5g4IFZbIAyD%2BDAH0ZP5wAZBk%2FtQBLGTIyAEsFg76Dw%2F6DhYDhMjI%2FgzI%2FgzI%2FgzIAAIAAAAABEwETAAPAB8AAAEhMhYVERQGIyEiJjURNDYFISIGFREUFjMhMjY1ETQmAV4BkKK8u6P%2BcKW5uQJn%2FgwpOzspAfQpOzsETLuj%2FnClubmlAZClucg7Kf4MKTs7KQH0KTsAAAAAAwAAAAAETARMAA8AHwArAAABITIWFREUBiMhIiY1ETQ2BSEiBhURFBYzITI2NRE0JgUXFhQPAQYmNRE0NgFeAZClubml%2FnCju7wCZP4MKTs7KQH0KTs7%2Fm%2F9ERH9EBgYBEy5pf5wpbm5pQGQo7vIOyn%2BDCk7OykB9Ck7gr4MJAy%2BDAsVAZAVCwAAAAADAAAAAARMBEwADwAfACsAAAEhMhYVERQGIyEiJjURNDYFISIGFREUFjMhMjY1ETQmBSEyFg8BBiIvASY2AV4BkKO7uaX%2BcKW5uQJn%2FgwpOzspAfQpOzv%2BFQGQFQsMvgwkDL4MCwRMvKL%2BcKW5uaUBkKO7yDsp%2FgwpOzspAfQpO8gYEP0REf0QGAAAAAMAAAAABEwETAAPAB8AKwAAASEyFhURFAYjISImNRE0NgUhIgYVERQWMyEyNjURNCYFFxYGIyEiJj8BNjIBXgGQpbm5pf5wo7u5Amf%2BDCk7OykB9Ck7O%2F77vgwLFf5wFQsMvgwkBEy5pf5wo7u8ogGQpbnIOyn%2BDCk7OykB9Ck7z%2F0QGBgQ%2FREAAAAAAgAAAAAFFARMAB8ANQAAASEyFhURFAYjISImPQE0NjMhMjY1ETQmIyEiJj0BNDYHARYUBwEGJj0BIyImPQE0NjsBNTQ2AiYBkKW5uaX%2BcBUdHRUBwik7Oyn%2BPhUdHb8BRBAQ%2FrwQFvoVHR0V%2BhYETLml%2FnCluR0VZBUdOykB9Ck7HRVkFR3p%2FuQOJg7%2B5A4KFZYdFcgVHZYVCgAAAQDZAAID1wSeACMAAAEXFgcGAgclMhYHIggBBwYrAScmNz4BPwEhIicmNzYANjc2MwMZCQgDA5gCASwYEQ4B%2Fvf%2B8wQMDgkJCQUCUCcn%2FtIXCAoQSwENuwUJEASeCQoRC%2F5TBwEjEv7K%2FsUFDwgLFQnlbm4TFRRWAS%2FTBhAAAAACAAAAAAT%2BBEwAHwA1AAABITIWHQEUBiMhIgYVERQWMyEyFh0BFAYjISImNRE0NgUBFhQHAQYmPQEjIiY9ATQ2OwE1NDYBXgGQFR0dFf4%2BKTs7KQHCFR0dFf5wpbm5AvEBRBAQ%2FrwQFvoVHR0V%2BhYETB0VZBUdOyn%2BDCk7HRVkFR25pQGQpbnp%2FuQOJg7%2B5A4KFZYdFcgVHZYVCgACAAAAAASwBLAAFQAxAAABITIWFREUBi8BAQYiLwEmNDcBJyY2ASMiBhURFBYzITI2PQE3ERQGIyEiJjURNDYzIQLuAZAVHRUObf7IDykPjQ8PAThtDgj%2B75wpOzspAfQpO8i7o%2F5wpbm5pQEsBLAdFf5wFQgObf7IDw%2BNDykPAThtDhX%2B1Dsp%2FgwpOzsplMj%2B1qW5uaUBkKW5AAADAA4ADgSiBKIADwAbACMAAAAyHgIUDgIiLgI0PgEEIg4BFB4BMj4BNCYEMhYUBiImNAHh7tmdXV2d2e7ZnV1dnQHD5sJxccLmwnFx%2FnugcnKgcgSiXZ3Z7tmdXV2d2e7ZnUdxwubCcXHC5sJzcqBycqAAAAMAAAAABEwEsAAVAB8AIwAAATMyFhURMzIWBwEGIicBJjY7ARE0NgEhMhYdASE1NDYFFTM1AcLIFR31FAoO%2FoEOJw3%2BhQ0JFfod%2FoUD6BUd%2B7QdA2dkBLAdFf6iFg%2F%2BVg8PAaoPFgFeFR38fB0V%2BvoVHWQyMgAAAAMAAAAABEwErAAVAB8AIwAACQEWBisBFRQGKwEiJj0BIyImNwE%2BAQEhMhYdASE1NDYFFTM1AkcBeg4KFfQiFsgUGPoUCw4Bfw4n%2FfkD6BUd%2B7QdA2dkBJ7%2BTQ8g%2BhQeHRX6IQ8BrxAC%2FH8dFfr6FR1kMjIAAwAAAAAETARLABQAHgAiAAAJATYyHwEWFAcBBiInASY0PwE2MhcDITIWHQEhNTQ2BRUzNQGMAXEHFQeLBwf98wcVB%2F7cBweLCBUH1APoFR37tB0DZ2QC0wFxBweLCBUH%2FfMICAEjCBQIiwcH%2FdIdFfr6FR1kMjIABAAAAAAETASbAAkAGQAjACcAABM3NjIfAQcnJjQFNzYWFQMOASMFIiY%2FASc3ASEyFh0BITU0NgUVMzWHjg4qDk3UTQ4CFtIOFQIBHRX9qxUIDtCa1P49A%2BgVHfu0HQNnZAP%2Fjg4OTdRMDyqa0g4IFf2pFB4BFQ7Qm9T9Oh0V%2BvoVHWQyMgAAAAQAAAAABEwEsAAPABkAIwAnAAABBR4BFRMUBi8BByc3JyY2EwcGIi8BJjQ%2FAQEhMhYdASE1NDYFFTM1AV4CVxQeARUO0JvUm9IOCMNMDyoOjg4OTf76A%2BgVHfu0HQNnZASwAgEdFf2rFQgO0JrUmtIOFf1QTQ4Ojg4qDk3%2BWB0V%2BvoVHWQyMgACAAT%2F7ASwBK8ABQAIAAAlCQERIQkBFQEEsP4d%2Fsb%2BcQSs%2FTMCq2cBFP5xAacDHPz55gO5AAAAAAIAAABkBEwEsAAVABkAAAERFAYrAREhESMiJjURNDY7AREhETMHIzUzBEwdFZb9RJYVHR0V%2BgH0ZMhkZAPo%2FK4VHQGQ%2FnAdFQPoFB7%2B1AEsyMgAAAMAAABFBN0EsAAWABoALwAAAQcBJyYiDwEhESMiJjURNDY7AREhETMHIzUzARcWFAcBBiIvASY0PwE2Mh8BATYyBEwC%2FtVfCRkJlf7IlhUdHRX6AfRkyGRkAbBqBwf%2BXAgUCMoICGoHFQdPASkHFQPolf7VXwkJk%2F5wHRUD6BQe%2FtQBLMjI%2Fc5qBxUH%2FlsHB8sHFQdqCAhPASkHAAMAAAANBQcEsAAWABoAPgAAAREHJy4BBwEhESMiJjURNDY7AREhETMHIzUzARcWFA8BFxYUDwEGIi8BBwYiLwEmND8BJyY0PwE2Mh8BNzYyBExnhg8lEP72%2FreWFR0dFfoB9GTIZGQB9kYPD4ODDw9GDykPg4MPKQ9GDw%2BDgw8PRg8pD4ODDykD6P7zZ4YPAw7%2B9v5wHRUD6BQe%2FtQBLMjI%2FYxGDykPg4MPKQ9GDw%2BDgw8PRg8pD4ODDykPRg8Pg4MPAAADAAAAFQSXBLAAFQAZAC8AAAERISIGHQEhESMiJjURNDY7AREhETMHIzUzEzMyFh0BMzIWDwEGIi8BJjY7ATU0NgRM%2FqIVHf4MlhUdHRX6AfRkyGRklmQVHZYVCA7mDioO5g4IFZYdA%2Bj%2B1B0Vlv5wHRUD6BQe%2FtQBLMjI%2FagdFfoVDuYODuYOFfoVHQAAAAADAAAAAASXBLAAFQAZAC8AAAERJyYiBwEhESMiJjURNDY7AREhETMHIzUzExcWBisBFRQGKwEiJj0BIyImPwE2MgRMpQ4qDv75%2Fm6WFR0dFfoB9GTIZGTr5g4IFZYdFWQVHZYVCA7mDioD6P5wpQ8P%2Fvf%2BcB0VA%2BgUHv7UASzIyP2F5Q8V%2BhQeHhT6FQ%2FlDwADAAAAyASwBEwACQATABcAABMhMhYdASE1NDYBERQGIyEiJjURExUhNTIETBUd%2B1AdBJMdFfu0FR1kAZAETB0VlpYVHf7U%2FdoVHR0VAib%2B1MjIAAAGAAMAfQStBJcADwAZAB0ALQAxADsAAAEXFhQPAQYmPQEhNSE1NDYBIyImPQE0NjsBFyM1MwE3NhYdASEVIRUUBi8BJjQFIzU7AjIWHQEUBisBA6f4Dg74DhX%2BcAGQFf0vMhUdHRUyyGRk%2FoL3DhUBkP5wFQ73DwOBZGRkMxQdHRQzBI3mDioO5g4IFZbIlhUI%2FoUdFWQVHcjI%2FcvmDggVlsiWFQgO5g4qecgdFWQVHQAAAAACAGQAAASwBLAAFgBRAAABJTYWFREUBisBIiY1ES4ENRE0NiUyFh8BERQOAg8BERQGKwEiJjURLgQ1ETQ%2BAzMyFh8BETMRPAE%2BAjMyFh8BETMRND4DA14BFBklHRXIFR0EDiIaFiX%2B4RYZAgEVHR0LCh0VyBUdBA4iGhYBBwoTDRQZAgNkBQkVDxcZAQFkAQUJFQQxdBIUH%2FuuFR0dFQGNAQgbHzUeAWcfRJEZDA3%2BPhw%2FMSkLC%2F5BFR0dFQG%2FBA8uLkAcAcICBxENCxkMDf6iAV4CBxENCxkMDf6iAV4CBxENCwABAGQAAASwBEwAMwAAARUiDgMVERQWHwEVITUyNjURIREUFjMVITUyPgM1ETQmLwE1IRUiBhURIRE0JiM1BLAEDiIaFjIZGf5wSxn%2BDBlL%2FnAEDiIaFjIZGQGQSxkB9BlLBEw4AQUKFA78iBYZAQI4OA0lAYr%2BdiUNODgBBQoUDgN4FhkBAjg4DSX%2BdgGKJQ04AAAABgAAAAAETARMAAwAHAAgACQAKAA0AAABITIWHQEjBTUnITchBSEyFhURFAYjISImNRE0NhcVITUBBTUlBRUhNQUVFAYjIQchJyE3MwKjAXcVHWn%2B2cj%2BcGQBd%2F4lASwpOzsp%2FtQpOzspASwCvP5wAZD8GAEsArwdFf6JZP6JZAGQyGkD6B0VlmJiyGTIOyn%2BDCk7OykB9Ck7ZMjI%2FveFo4XGyMhm%2BBUdZGTIAAEAEAAQBJ8EnwAmAAATNzYWHwEWBg8BHgEXNz4BHwEeAQ8BBiIuBicuBTcRohEuDosOBhF3ZvyNdxEzE8ATBxGjAw0uMUxPZWZ4O0p3RjITCwED76IRBhPCFDERdo78ZXYRBA6IDi8RogEECBUgNUNjO0qZfHNVQBAAAAACAAAAAASwBEwAIwBBAAAAMh4EHwEVFAYvAS4BPQEmIAcVFAYPAQYmPQE%2BBRIyHgIfARUBHgEdARQGIyEiJj0BNDY3ATU0PgIB%2FLimdWQ%2FLAkJHRTKFB2N%2FsKNHRTKFB0DDTE7ZnTKcFImFgEBAW0OFR0V%2B7QVHRUOAW0CFiYETBUhKCgiCgrIFRgDIgMiFZIYGJIVIgMiAxgVyAQNJyQrIP7kExwcCgoy%2FtEPMhTUFR0dFdQUMg8BLzIEDSEZAAADAAAAAASwBLAADQAdACcAAAEHIScRMxUzNTMVMzUzASEyFhQGKwEXITcjIiY0NgMhMhYdASE1NDYETMj9qMjIyMjIyPyuArwVHR0VDIn8SokMFR0dswRMFR37UB0CvMjIAfTIyMjI%2FOAdKh1kZB0qHf7UHRUyMhUdAAAAAwBkAAAEsARMAAkAEwAdAAABIyIGFREhETQmASMiBhURIRE0JgEhETQ2OwEyFhUCvGQpOwEsOwFnZCk7ASw7%2FRv%2B1DspZCk7BEw7KfwYA%2BgpO%2F7UOyn9RAK8KTv84AGQKTs7KQAAAAAF%2F5wAAASwBEwADwATAB8AJQApAAATITIWFREUBiMhIiY1ETQ2FxEhEQUjFTMRITUzNSMRIQURByMRMwcRMxHIArx8sLB8%2FUR8sLAYA4T%2BDMjI%2FtTIyAEsAZBkyMhkZARMsHz%2BDHywsHwB9HywyP1EArzIZP7UZGQBLGT%2B1GQB9GT%2B1AEsAAAABf%2BcAAAEsARMAA8AEwAfACUAKQAAEyEyFhURFAYjISImNRE0NhcRIREBIzUjFSMRMxUzNTMFEQcjETMHETMRyAK8fLCwfP1EfLCwGAOE%2FgxkZGRkZGQBkGTIyGRkBEywfP4MfLCwfAH0fLDI%2FUQCvP2oyMgB9MjIZP7UZAH0ZP7UASwABP%2BcAAAEsARMAA8AEwAbACMAABMhMhYVERQGIyEiJjURNDYXESERBSMRMxUhESEFIxEzFSERIcgCvHywsHz9RHywsBgDhP4MyMj%2B1AEsAZDIyP7UASwETLB8%2Fgx8sLB8AfR8sMj9RAK8yP7UZAH0ZP7UZAH0AAAABP%2BcAAAEsARMAA8AEwAWABkAABMhMhYVERQGIyEiJjURNDYXESERAS0BDQERyAK8fLCwfP1EfLCwGAOE%2Fgz%2B1AEsAZD%2B1ARMsHz%2BDHywsHwB9HywyP1EArz%2BDJaWlpYBLAAAAAX%2FnAAABLAETAAPABMAFwAgACkAABMhMhYVERQGIyEiJjURNDYXESERAyERIQcjIgYVFBY7AQERMzI2NTQmI8gCvHywsHz9RHywsBgDhGT9RAK8ZIImOTYpgv4Mgik2OSYETLB8%2Fgx8sLB8AfR8sMj9RAK8%2FagB9GRWQUFUASz%2B1FRBQVYAAAAF%2F5wAAASwBEwADwATAB8AJQApAAATITIWFREUBiMhIiY1ETQ2FxEhEQUjFTMRITUzNSMRIQEjESM1MwMjNTPIArx8sLB8%2FUR8sLAYA4T%2BDMjI%2FtTIyAEsAZBkZMjIZGQETLB8%2Fgx8sLB8AfR8sMj9RAK8yGT%2B1GRkASz%2BDAGQZP4MZAAG%2F5wAAASwBEwADwATABkAHwAjACcAABMhMhYVERQGIyEiJjURNDYXESERBTMRIREzASMRIzUzBRUzNQEjNTPIArx8sLB8%2FUR8sLAYA4T9RMj%2B1GQCWGRkyP2oZAEsZGQETLB8%2Fgx8sLB8AfR8sMj9RAK8yP5wAfT%2BDAGQZMjIyP7UZAAF%2F5wAAASwBEwADwATABwAIgAmAAATITIWFREUBiMhIiY1ETQ2FxEhEQEHIzU3NSM1IQEjESM1MwMjNTPIArx8sLB8%2FUR8sLAYA4T%2BDMdkx8gBLAGQZGTIx2RkBEywfP4MfLCwfAH0fLDI%2FUQCvP5wyDLIlmT%2BDAGQZP4MZAAAAAMACQAJBKcEpwAPABsAJQAAADIeAhQOAiIuAjQ%2BAQQiDgEUHgEyPgE0JgchFSEVISc1NyEB4PDbnl5entvw255eXp4BxeTCcXHC5MJxcWz%2B1AEs%2FtRkZAEsBKdentvw255eXp7b8NueTHHC5MJxccLkwtDIZGTIZAAAAAAEAAkACQSnBKcADwAbACcAKwAAADIeAhQOAiIuAjQ%2BAQQiDgEUHgEyPgE0JgcVBxcVIycjFSMRIQcVMzUB4PDbnl5entvw255eXp4BxeTCcXHC5MJxcWwyZGRklmQBLMjIBKdentvw255eXp7b8NueTHHC5MJxccLkwtBkMmQyZGQBkGRkZAAAAv%2Fy%2F50EwgRBACAANgAAATIWFzYzMhYUBisBNTQmIyEiBh0BIyImNTQ2NyY1ND4BEzMyFhURMzIWDwEGIi8BJjY7ARE0NgH3brUsLC54qqp4gB0V%2FtQVHd5QcFZBAmKqepYKD4kVCg3fDSYN3w0KFYkPBEF3YQ6t8a36FR0dFfpzT0VrDhMSZKpi%2FbMPCv7tFxD0EBD0EBcBEwoPAAAAAAL%2F8v%2BcBMMEQQAcADMAAAEyFhc2MzIWFxQGBwEmIgcBIyImNTQ2NyY1ND4BExcWBisBERQGKwEiJjURIyImNzY3NjIB9m62LCsueaoBeFr%2Bhg0lDf6DCU9xVkECYqnm3w0KFYkPCpYKD4kVCg3HGBMZBEF3YQ%2BteGOkHAFoEBD%2Bk3NPRWsOExNkqWP9kuQQF%2F7tCg8PCgETFxDMGBMAAAABAGQAAARMBG0AGAAAJTUhATMBMwkBMwEzASEVIyIGHQEhNTQmIwK8AZD%2B8qr%2B8qr%2B1P7Uqv7yqv7yAZAyFR0BkB0VZGQBLAEsAU3%2Bs%2F7U%2FtRkHRUyMhUdAAAAAAEAeQAABDcEmwAvAAABMhYXHgEVFAYHFhUUBiMiJxUyFh0BITU0NjM1BiMiJjU0Ny4BNTQ2MzIXNCY1NDYCWF6TGll7OzIJaUo3LRUd%2FtQdFS03SmkELzlpSgUSAqMEm3FZBoNaPWcfHRpKaR77HRUyMhUd%2Bx5pShIUFVg1SmkCAhAFdKMAAAAGACcAFASJBJwAEQAqAEIASgBiAHsAAAEWEgIHDgEiJicmAhI3PgEyFgUiBw4BBwYWHwEWMzI3Njc2Nz4BLwEmJyYXIgcOAQcGFh8BFjMyNz4BNz4BLwEmJyYWJiIGFBYyNjciBw4BBw4BHwEWFxYzMjc%2BATc2Ji8BJhciBwYHBgcOAR8BFhcWMzI3PgE3NiYvASYD8m9PT29T2dzZU29PT29T2dzZ%2Fj0EBHmxIgQNDCQDBBcGG0dGYAsNAwkDCwccBAVQdRgEDA0iBAQWBhJROQwMAwkDCwf5Y4xjY4xjVhYGElE6CwwDCQMLBwgEBVB1GAQNDCIEjRcGG0dGYAsNAwkDCwcIBAR5sSIEDQwkAwPyb%2F7V%2FtVvU1dXU28BKwErb1NXVxwBIrF5DBYDCQEWYEZHGwMVDCMNBgSRAhh1UA0WAwkBFTpREgMVCyMMBwT6Y2OMY2MVFTpREQQVCyMMBwQCGHVQDRYDCQEkFmBGRxsDFQwjDQYEASKxeQwWAwkBAAAABQBkAAAD6ASwAAwADwAWABwAIgAAASERIzUhFSERNDYzIQEjNQMzByczNTMDISImNREFFRQGKwECvAEstP6s%2FoQPCgI%2FASzIZKLU1KJktP51Cg8DhA8KwwMg%2FoTIyALzCg%2F%2B1Mj84NTUyP4MDwoBi8jDCg8AAAAABQBkAAAD6ASwAAkADAATABoAIQAAASERCQERNDYzIQEjNRMjFSM1IzcDISImPQEpARUUBisBNQK8ASz%2Bov3aDwoCPwEsyD6iZKLUqv6dCg8BfAIIDwqbAyD9%2BAFe%2FdoERwoP%2FtTI%2FHzIyNT%2BZA8KNzcKD1AAAAAAAwAAAAAEsAP0AAgAGQAfAAABIxUzFyERIzcFMzIeAhUhFSEDETM0PgIBMwMhASEEiqJkZP7UotT9EsgbGiEOASz9qMhkDiEaAnPw8PzgASwB9AMgyGQBLNTUBBErJGT%2BogHCJCsRBP5w%2FnAB9AAAAAMAAAAABEwETAAZADIAOQAAATMyFh0BMzIWHQEUBiMhIiY9ATQ2OwE1NDYFNTIWFREUBiMhIic3ARE0NjMVFBYzITI2AQc1IzUzNQKKZBUdMhUdHRX%2B1BUdHRUyHQFzKTs7Kf2oARP2%2Fro7KVg%2BASw%2BWP201MjIBEwdFTIdFWQVHR0VZBUdMhUd%2BpY7KfzgKTsE9gFGAUQpO5Y%2BWFj95tSiZKIAAwBkAAAEvARMABkANgA9AAABMzIWHQEzMhYdARQGIyEiJj0BNDY7ATU0NgU1MhYVESMRMxQOAiMhIiY1ETQ2MxUUFjMhMjYBBzUjNTM1AcJkFR0yFR0dFf7UFR0dFTIdAXMpO8jIDiEaG%2F2oKTs7KVg%2BASw%2BWAGc1MjIBEwdFTIdFWQVHR0VZBUdMhUd%2BpY7Kf4M%2FtQkKxEEOykDICk7lj5YWP3m1KJkogAAAAP%2FogAABRYE1AALABsAHwAACQEWBiMhIiY3ATYyEyMiBhcTHgE7ATI2NxM2JgMVMzUCkgJ9FyAs%2BwQsIBcCfRZARNAUGAQ6BCMUNhQjBDoEGODIBK37sCY3NyYEUCf%2BTB0U%2FtIUHR0UAS4UHf4MZGQAAAAACQAAAAAETARMAA8AHwAvAD8ATwBfAG8AfwCPAAABMzIWHQEUBisBIiY9ATQ2EzMyFh0BFAYrASImPQE0NiEzMhYdARQGKwEiJj0BNDYBMzIWHQEUBisBIiY9ATQ2ITMyFh0BFAYrASImPQE0NiEzMhYdARQGKwEiJj0BNDYBMzIWHQEUBisBIiY9ATQ2ITMyFh0BFAYrASImPQE0NiEzMhYdARQGKwEiJj0BNDYBqfoKDw8K%2BgoPDwr6Cg8PCvoKDw8BmvoKDw8K%2BgoPD%2Fzq%2BgoPDwr6Cg8PAZr6Cg8PCvoKDw8BmvoKDw8K%2BgoPD%2Fzq%2BgoPDwr6Cg8PAZr6Cg8PCvoKDw8BmvoKDw8K%2BgoPDwRMDwqWCg8PCpYKD%2F7UDwqWCg8PCpYKDw8KlgoPDwqWCg%2F%2B1A8KlgoPDwqWCg8PCpYKDw8KlgoPDwqWCg8PCpYKD%2F7UDwqWCg8PCpYKDw8KlgoPDwqWCg8PCpYKDw8KlgoPAAAAAwAAAAAEsAUUABkAKQAzAAABMxUjFSEyFg8BBgchJi8BJjYzITUjNTM1MwEhMhYUBisBFyE3IyImNDYDITIWHQEhNTQ2ArxkZAFePjEcQiko%2FPwoKUIcMT4BXmRkyP4%2BArwVHR0VDIn8SooNFR0dswRMFR37UB0EsMhkTzeEUzMzU4Q3T2TIZPx8HSodZGQdKh3%2B1B0VMjIVHQAABAAAAAAEsAUUAAUAGQArADUAAAAyFhUjNAchFhUUByEyFg8BIScmNjMhJjU0AyEyFhQGKwEVBSElNSMiJjQ2AyEyFh0BITU0NgIwUDnCPAE6EgMBSCkHIq%2F9WrIiCikBSAOvArwVHR0VlgET%2FEoBE5YVHR2zBEwVHftQHQUUOykpjSUmCBEhFpGRFiERCCb%2BlR0qHcjIyMgdKh39qB0VMjIVHQAEAAAAAASwBJ0ABwAUACQALgAAADIWFAYiJjQTMzIWFRQXITY1NDYzASEyFhQGKwEXITcjIiY0NgMhMhYdASE1NDYCDZZqapZqty4iKyf%2BvCcrI%2F7NArwVHR0VDYr8SokMFR0dswRMFR37UB0EnWqWamqW%2Fus5Okxra0w6Of5yHSodZGQdKh3%2B1B0VMjIVHQAEAAAAAASwBRQADwAcACwANgAAATIeARUUBiImNTQ3FzcnNhMzMhYVFBchNjU0NjMBITIWFAYrARchNyMiJjQ2AyEyFh0BITU0NgJYL1szb5xvIpBvoyIfLiIrJ%2F68Jysj%2Fs0CvBUdHRUNivxKiQwVHR2zBEwVHftQHQUUa4s2Tm9vTj5Rj2%2BjGv4KOTpMa2tMOjn%2Bch0qHWRkHSod%2FtQdFTIyFR0AAAADAAAAAASwBRIAEgAiACwAAAEFFSEUHgMXIS4BNTQ%2BAjcBITIWFAYrARchNyMiJjQ2AyEyFh0BITU0NgJYASz%2B1CU%2FP00T%2Fe48PUJtj0r%2BogK8FR0dFQ2K%2FEqJDBUdHbMETBUd%2B1AdBLChizlmUT9IGVO9VFShdksE%2FH4dKh1kZB0qHf7UHRUyMhUdAAIAyAAAA%2BgFFAAPACkAAAAyFh0BHgEdASE1NDY3NTQDITIWFyMVMxUjFTMVIxUzFAYjISImNRE0NgIvUjsuNv5wNi5kAZA2XBqsyMjIyMh1U%2F5wU3V1BRQ7KU4aXDYyMjZcGk4p%2Fkc2LmRkZGRkU3V1UwGQU3UAAAMAZP%2F%2FBEwETAAPAC8AMwAAEyEyFhURFAYjISImNRE0NgMhMhYdARQGIyEXFhQGIi8BIQcGIiY0PwEhIiY9ATQ2BQchJ5YDhBUdHRX8fBUdHQQDtgoPDwr%2B5eANGiUNWP30Vw0mGg3g%2Ft8KDw8BqmQBRGQETB0V%2FgwVHR0VAfQVHf1EDwoyCg%2FgDSUbDVhYDRslDeAPCjIKD2RkZAAAAAAEAAAAAASwBEwAGQAjAC0ANwAAEyEyFh0BIzQmKwEiBhUjNCYrASIGFSM1NDYDITIWFREhETQ2ExUUBisBIiY9ASEVFAYrASImPQHIAyBTdWQ7KfopO2Q7KfopO2R1EQPoKTv7UDvxHRVkFR0D6B0VZBUdBEx1U8gpOzspKTs7KchTdf4MOyn%2B1AEsKTv%2BDDIVHR0VMjIVHR0VMgADAAEAAASpBKwADQARABsAAAkBFhQPASEBJjQ3ATYyCQMDITIWHQEhNTQ2AeACqh8fg%2F4f%2FfsgIAEnH1n%2BrAFWAS%2F%2Bq6IDIBUd%2FHwdBI39VR9ZH4MCBh9ZHwEoH%2F5u%2FqoBMAFV%2FBsdFTIyFR0AAAAAAgCPAAAEIQSwABcALwAAAQMuASMhIgYHAwYWMyEVFBYyNj0BMzI2AyE1NDY7ATU0NjsBETMRMzIWHQEzMhYVBCG9CCcV%2FnAVJwi9CBMVAnEdKh19FROo%2Fa0dFTIdFTDILxUdMhUdAocB%2BhMcHBP%2BBhMclhUdHRWWHP2MMhUdMhUdASz%2B1B0VMh0VAAAEAAAAAASwBLAADQAQAB8AIgAAASERFAYjIREBNTQ2MyEBIzUBIREUBiMhIiY1ETQ2MyEBIzUDhAEsDwr%2Bif7UDwoBdwEsyP2oASwPCv12Cg8PCgF3ASzIAyD9wQoPAk8BLFQKD%2F7UyP4M%2FcEKDw8KA7YKD%2F7UyAAC%2F5wAZAUUBEcARgBWAAABMzIeAhcWFxY2NzYnJjc%2BARYXFgcOASsBDgEPAQ4BKwEiJj8BBisBIicHDgErASImPwEmLwEuAT0BNDY7ATY3JyY2OwE2BSMiBh0BFBY7ATI2PQE0JgHkw0uOakkMEhEfQwoKGRMKBQ8XDCkCA1Y9Pgc4HCcDIhVkFRgDDDEqwxgpCwMiFWQVGAMaVCyfExwdFXwLLW8QBxXLdAFF%2BgoPDwr6Cg8PBEdBa4pJDgYKISAiJRsQCAYIDCw9P1c3fCbqFB0dFEYOCEAUHR0UnUplNQcmFTIVHVdPXw4TZV8PCjIKDw8KMgoPAAb%2FnP%2FmBRQEfgAJACQANAA8AFIAYgAAASU2Fh8BFgYPASUzMhYfASEyFh0BFAYHBQYmJyYjISImPQE0NhcjIgYdARQ7ATI2NTQmJyYEIgYUFjI2NAE3PgEeARceAT8BFxYGDwEGJi8BJjYlBwYfAR4BPwE2Jy4BJy4BAoEBpxMuDiAOAxCL%2FCtqQ0geZgM3FR0cE%2F0fFyIJKjr%2B1D5YWLlQExIqhhALIAsSAYBALS1ALf4PmBIgHhMQHC0aPzANITNQL3wpgigJASlmHyElDR0RPRMFAhQHCxADhPcICxAmDyoNeMgiNtQdFTIVJgeEBBQPQ1g%2ByD5YrBwVODMQEAtEERzJLUAtLUD%2B24ITChESEyMgAwWzPUkrRSgJL5cvfRxYGyYrDwkLNRAhFEgJDAQAAAAAAwBkAAAEOQSwAFEAYABvAAABMzIWHQEeARcWDgIPATIeBRUUDgUjFRQGKwEiJj0BIxUUBisBIiY9ASMiJj0BNDY7AREjIiY9ATQ2OwE1NDY7ATIWHQEzNTQ2AxUhMj4CNTc0LgMjARUhMj4CNTc0LgMjAnGWCg9PaAEBIC4uEBEGEjQwOiodFyI2LUAjGg8KlgoPZA8KlgoPrwoPDwpLSwoPDwqvDwqWCg9kD9cBBxwpEwsBAQsTKRz%2B%2BQFrHCkTCwEBCxMpHASwDwptIW1KLk0tHwYGAw8UKDJOLTtdPCoVCwJLCg8PCktLCg8PCksPCpYKDwJYDwqWCg9LCg8PCktLCg%2F%2B1MgVHR0LCgQOIhoW%2FnDIFR0dCwoEDiIaFgAAAwAEAAIEsASuABcAKQAsAAATITIWFREUBg8BDgEjISImJy4CNRE0NgQiDgQPARchNy4FAyMT1AMMVnokEhIdgVL9xFKCHAgYKHoCIIx9VkcrHQYGnAIwnAIIIClJVSGdwwSuelb%2BYDO3QkJXd3ZYHFrFMwGgVnqZFyYtLSUMDPPzBQ8sKDEj%2FsIBBQACAMgAAAOEBRQADwAZAAABMzIWFREUBiMhIiY1ETQ2ARUUBisBIiY9AQHblmesVCn%2BPilUrAFINhWWFTYFFKxn%2FgwpVFQpAfRnrPwY4RU2NhXhAAACAMgAAAOEBRQADwAZAAABMxQWMxEUBiMhIiY1ETQ2ARUUBisBIiY9AQHbYLOWVCn%2BPilUrAFINhWWFTYFFJaz%2FkIpVFQpAfRnrPwY4RU2NhXhAAACAAAAFAUOBBoAFAAaAAAJASUHFRcVJwc1NzU0Jj4CPwEnCQEFJTUFJQUO%2FYL%2Bhk5klpZkAQEBBQQvkwKCAVz%2Bov6iAV4BXgL%2F%2FuWqPOCWx5SVyJb6BA0GCgYDKEEBG%2F1ipqaTpaUAAAMAZAH0BLADIAAHAA8AFwAAEjIWFAYiJjQkMhYUBiImNCQyFhQGIiY0vHxYWHxYAeh8WFh8WAHofFhYfFgDIFh8WFh8WFh8WFh8WFh8WFh8AAAAAAMBkAAAArwETAAHAA8AFwAAADIWFAYiJjQSMhYUBiImNBIyFhQGIiY0Aeh8WFh8WFh8WFh8WFh8WFh8WARMWHxYWHz%2ByFh8WFh8%2FshYfFhYfAAAAAMAZABkBEwETAAPAB8ALwAAEyEyFh0BFAYjISImPQE0NhMhMhYdARQGIyEiJj0BNDYTITIWHQEUBiMhIiY9ATQ2fQO2Cg8PCvxKCg8PCgO2Cg8PCvxKCg8PCgO2Cg8PCvxKCg8PBEwPCpYKDw8KlgoP%2FnAPCpYKDw8KlgoP%2FnAPCpYKDw8KlgoPAAAABAAAAAAEsASwAA8AHwAvADMAAAEhMhYVERQGIyEiJjURNDYFISIGFREUFjMhMjY1ETQmBSEyFhURFAYjISImNRE0NhcVITUBXgH0ory7o%2F4Mpbm5Asv9qCk7OykCWCk7O%2F2xAfQVHR0V%2FgwVHR1HAZAEsLuj%2FgylubmlAfSlucg7Kf2oKTs7KQJYKTtkHRX%2B1BUdHRUBLBUdZMjIAAAAAAEAZABkBLAETAA7AAATITIWFAYrARUzMhYUBisBFTMyFhQGKwEVMzIWFAYjISImNDY7ATUjIiY0NjsBNSMiJjQ2OwE1IyImNDaWA%2BgVHR0VMjIVHR0VMjIVHR0VMjIVHR0V%2FBgVHR0VMjIVHR0VMjIVHR0VMjIVHR0ETB0qHcgdKh3IHSodyB0qHR0qHcgdKh3IHSodyB0qHQAAAAYBLAAFA%2BgEowAHAA0AEwAZAB8AKgAAAR4BBgcuATYBMhYVIiYlFAYjNDYBMhYVIiYlFAYjNDYDFRQGIiY9ARYzMgKKVz8%2FV1c%2FP%2F75fLB8sAK8sHyw%2FcB8sHywArywfLCwHSodKAMRBKNDsrJCQrKy%2FsCwfLB8fLB8sP7UsHywfHywfLD%2B05AVHR0VjgQAAAH%2FtQDIBJQDgQBCAAABNzYXAR4BBw4BKwEyFRQOBCsBIhE0NyYiBxYVECsBIi4DNTQzIyImJyY2NwE2HwEeAQ4BLwEHIScHBi4BNgLpRRkUASoLCAYFGg8IAQQNGyc%2FKZK4ChRUFQu4jjBJJxkHAgcPGQYGCAsBKhQaTBQVCiMUM7YDe7YsFCMKFgNuEwYS%2FtkLHw8OEw0dNkY4MhwBIBgXBAQYF%2F7gKjxTQyMNEw4PHwoBKBIHEwUjKBYGDMHBDAUWKCMAAAAAAgAAAAAEsASwACUAQwAAASM0LgUrAREUFh8BFSE1Mj4DNREjIg4FFSMRIQEjNC4DKwERFBYXMxUjNTI1ESMiDgMVIzUhBLAyCAsZEyYYGcgyGRn%2BcAQOIhoWyBkYJhMZCwgyA%2Bj9RBkIChgQEWQZDQzIMmQREBgKCBkB9AOEFSAVDggDAfyuFhkBAmRkAQUJFQ4DUgEDCA4VIBUBLP0SDxMKBQH%2BVwsNATIyGQGpAQUKEw%2BWAAAAAAMAAAAABEwErgAdACAAMAAAATUiJy4BLwEBIwEGBw4BDwEVITUiJj8BIRcWBiMVARsBARUUBiMhIiY9ATQ2MyEyFgPoGR4OFgUE%2Ft9F%2FtQSFQkfCwsBETE7EkUBJT0NISf%2B7IZ5AbEdFfwYFR0dFQPoFR0BLDIgDiIKCwLr%2FQ4jFQkTBQUyMisusKYiQTIBhwFW%2Fqr942QVHR0VZBUdHQADAAAAAASwBLAADwBHAEoAABMhMhYVERQGIyEiJjURNDYFIyIHAQYHBgcGHQEUFjMhMjY9ATQmIyInJj8BIRcWBwYjIgYdARQWMyEyNj0BNCYnIicmJyMBJhMjEzIETBUdHRX7tBUdHQJGRg0F%2FtUREhImDAsJAREIDAwINxAKCj8BCjkLEQwYCAwMCAE5CAwLCBEZGQ8B%2FuAFDsVnBLAdFfu0FR0dFQRMFR1SDP0PIBMSEAUNMggMDAgyCAwXDhmjmR8YEQwIMggMDAgyBwwBGRskAuwM%2FgUBCAAABAAAAAAEsASwAAMAEwAjACcAAAEhNSEFITIWFREUBiMhIiY1ETQ2KQEyFhURFAYjISImNRE0NhcRIREEsPtQBLD7ggGQFR0dFf5wFR0dAm0BkBUdHRX%2BcBUdHUcBLARMZMgdFfx8FR0dFQOEFR0dFf5wFR0dFQGQFR1k%2FtQBLAAEAAAAAASwBLAADwAfACMAJwAAEyEyFhURFAYjISImNRE0NgEhMhYVERQGIyEiJjURNDYXESEREyE1ITIBkBUdHRX%2BcBUdHQJtAZAVHR0V%2FnAVHR1HASzI%2B1AEsASwHRX8fBUdHRUDhBUd%2FgwdFf5wFR0dFQGQFR1k%2FtQBLP2oZAAAAAACAAAAZASwA%2BgAJwArAAATITIWFREzNTQ2MyEyFh0BMxUjFRQGIyEiJj0BIxEUBiMhIiY1ETQ2AREhETIBkBUdZB0VAZAVHWRkHRX%2BcBUdZB0V%2FnAVHR0CnwEsA%2BgdFf6ilhUdHRWWZJYVHR0Vlv6iFR0dFQMgFR3%2B1P7UASwAAAQAAAAABLAEsAADABMAFwAnAAAzIxEzFyEyFhURFAYjISImNRE0NhcRIREBITIWFREUBiMhIiY1ETQ2ZGRklgGQFR0dFf5wFR0dRwEs%2FqIDhBUdHRX8fBUdHQSwZB0V%2FnAVHR0VAZAVHWT%2B1AEs%2FgwdFf5wFR0dFQGQFR0AAAAAAgBkAAAETASwACcAKwAAATMyFhURFAYrARUhMhYVERQGIyEiJjURNDYzITUjIiY1ETQ2OwE1MwcRIRECWJYVHR0VlgHCFR0dFfx8FR0dFQFelhUdHRWWZMgBLARMHRX%2BcBUdZB0V%2FnAVHR0VAZAVHWQdFQGQFR1kyP7UASwAAAAEAAAAAASwBLAAAwATABcAJwAAISMRMwUhMhYVERQGIyEiJjURNDYXESERASEyFhURFAYjISImNRE0NgSwZGT9dgGQFR0dFf5wFR0dRwEs%2FK4DhBUdHRX8fBUdHQSwZB0V%2FnAVHR0VAZAVHWT%2B1AEs%2FgwdFf5wFR0dFQGQFR0AAAEBLAAwA28EgAAPAAAJAQYjIiY1ETQ2MzIXARYUA2H%2BEhcSDhAQDhIXAe4OAjX%2BEhcbGQPoGRsX%2FhIOKgAAAAABAUEAMgOEBH4ACwAACQE2FhURFAYnASY0AU8B7h0qKh3%2BEg4CewHuHREp%2FBgpER0B7g4qAAAAAAEAMgFBBH4DhAALAAATITIWBwEGIicBJjZkA%2BgpER3%2BEg4qDv4SHREDhCod%2FhIODgHuHSoAAAAAAQAyASwEfgNvAAsAAAkBFgYjISImNwE2MgJ7Ae4dESn8GCkRHQHuDioDYf4SHSoqHQHuDgAAAAACAAgAAASwBCgABgAKAAABFQE1LQE1ASE1IQK8%2FUwBnf5jBKj84AMgAuW2%2Fr3dwcHd%2B9jIAAAAAAIAAABkBLAEsAALADEAAAEjFTMVIREzNSM1IQEzND4FOwERFAYPARUhNSIuAzURMzIeBRUzESEEsMjI%2FtTIyAEs%2B1AyCAsZEyYYGWQyGRkBkAQOIhoWZBkYJhMZCwgy%2FOADhGRkASxkZP4MFSAVDggDAf3aFhkBAmRkAQUJFQ4CJgEDCA4VIBUBLAAAAgAAAAAETAPoACUAMQAAASM0LgUrAREUFh8BFSE1Mj4DNREjIg4FFSMRIQEjFTMVIREzNSM1IQMgMggLGRMmGBlkMhkZ%2FnAEDiIaFmQZGCYTGQsIMgMgASzIyP7UyMgBLAK8FSAVDggDAf3aFhkCAWRkAQUJFQ4CJgEDCA4VIBUBLPzgZGQBLGRkAAABAMgAZgNyBEoAEgAAATMyFgcJARYGKwEiJwEmNDcBNgK9oBAKDP4wAdAMChCgDQr%2BKQcHAdcKBEoWDP4w%2FjAMFgkB1wgUCAHXCQAAAQE%2BAGYD6ARKABIAAAEzMhcBFhQHAQYrASImNwkBJjYBU6ANCgHXBwf%2BKQoNoBAKDAHQ%2FjAMCgRKCf4pCBQI%2FikJFgwB0AHQDBYAAAEAZgDIBEoDcgASAAAAFh0BFAcBBiInASY9ATQ2FwkBBDQWCf4pCBQI%2FikJFgwB0AHQA3cKEKANCv4pBwcB1woNoBAKDP4wAdAAAAABAGYBPgRKA%2BgAEgAACQEWHQEUBicJAQYmPQE0NwE2MgJqAdcJFgz%2BMP4wDBYJAdcIFAPh%2FikKDaAQCgwB0P4wDAoQoA0KAdcHAAAAAgDZ%2F%2FkEPQSwAAUAOgAAARQGIzQ2BTMyFh8BNjc%2BAh4EBgcOBgcGIiYjIgYiJy4DLwEuAT4EHgEXJyY2A%2BiwfLD%2BVmQVJgdPBQsiKFAzRyorDwURAQQSFyozTSwNOkkLDkc3EDlfNyYHBw8GDyUqPjdGMR%2BTDA0EsHywfLDIHBPCAQIGBwcFDx81S21DBxlLR1xKQhEFBQcHGWt0bCQjP2hJNyATBwMGBcASGAAAAAACAMgAFQOEBLAAFgAaAAATITIWFREUBisBEQcGJjURIyImNRE0NhcVITX6AlgVHR0Vlv8TGpYVHR2rASwEsB0V%2FnAVHf4MsgkQFQKKHRUBkBUdZGRkAAAAAgDIABkETASwAA4AEgAAEyEyFhURBRElIREjETQ2ARU3NfoC7ic9%2FUQCWP1EZB8BDWQEsFEs%2FFt1A7Z9%2FBgEARc0%2FV1kFGQAAQAAAAECTW%2FDBF9fDzz1AB8EsAAAAADQdnOXAAAAANB2c5f%2FUf%2BcBdwFFAAAAAgAAgAAAAAAAAABAAAFFP%2BFAAAFFP9R%2FtQF3AABAAAAAAAAAAAAAAAAAAAAowG4ACgAAAAAAZAAAASwAAAEsABkBLAAAASwAAAEsABwAooAAAUUAAACigAABRQAAAGxAAABRQAAANgAAADYAAAAogAAAQQAAABIAAABBAAAAUUAAASwAGQEsAB7BLAAyASwAMgB9AAABLD%2F8gSwAAAEsAAABLD%2F8ASwAAAEsAAOBLAACQSwAGQEsP%2FTBLD%2F0wSwAAAEsAAABLAAAASwAAAEsAAABLAAJgSwAG4EsAAXBLAAFwSwABcEsABkBLAAGgSwAGQEsAAMBLAAZASwABcEsP%2BcBLAAZASwABcEsAAXBLAAAASwABcEsAAXBLAAFwSwAGQEsAAABLAAZASwAAAEsAAABLAAAASwAAAEsAAABLAAAASwAAAEsAAABLAAZASwAMgEsAAABLAAAASwADUEsABkBLAAyASw%2F7UEsAAhBLAAAASwAAAEsAAABLAAAASwAAAEsP%2BcBLAAAASwAAAEsAAABLAA2wSwABcEsAB1BLAAAASwAAAEsAAABLAACgSwAMgEsAAABLAAnQSwAMgEsADIBLAAyASwAAAEsP%2F%2BBLABLASwAGQEsACIBLABOwSwABcEsAAXBLAAFwSwABcEsAAXBLAAFwSwAAAEsAAXBLAAFwSwABcEsAAXBLAAAASwALcEsAC3BLAAAASwAAAEsABJBLAAFwSwAAAEsAAABLAAXQSw%2F9wEsP%2FcBLD%2FnwSwAGQEsAAABLAAAASwAAAEsABkBLD%2F%2FwSwAAAEsP9RBLAABgSwAAAEsAAABLABRQSwAAEEsAAABLD%2FnASwAEoEsAAUBLAAAASwAAAEsAAABLD%2FnASwAGEEsP%2F9BLAAFgSwABYEsAAWBLAAFgSwABgEsAAABMQAAASwAGQAAAAAAAD%2F2ABkADkAyAAAAScAZAAZABkAGQAZABkAGQAZAAAAAAAAAAAAAADZAAAAAAAOAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAMAZABkAAAAEAAAAAAAZP%2Bc%2F5z%2FnP%2Bc%2F5z%2FnP%2Bc%2F5wACQAJ%2F%2FL%2F8gBkAHkAJwBkAGQAAAAAAGT%2FogAAAAAAAAAAAAAAAADIAGQAAAABAI8AAP%2Bc%2F5wAZAAEAMgAyAAAAGQBkABkAAAAZAEs%2F7UAAAAAAAAAAAAAAAAAAABkAAABLAFBADIAMgAIAAAAAADIAT4AZgBmANkAyADIAAAAKgAqACoAKgCyAOgA6AFOAU4BTgFOAU4BTgFOAU4BTgFOAU4BTgFOAU4BpAIGAiICfgKGAqwC5ANGA24DjAPEBAgEMgRiBKIE3AVcBboGcgb0ByAHYgfKCB4IYgi%2BCTYJhAm2Cd4KKApMCpQK4gswC4oLygwIDFgNKg1eDbAODg5oDrQPKA%2BmD%2BYQEhBUEJAQqhEqEXYRthIKEjgSfBLAExoTdBPQFCoU1BU8FagVzBYEFjYWYBawFv4XUhemGAIYLhhqGJYYsBjgGP4ZKBloGZQZxBnaGe4aNhpoGrga9hteG7QcMhyUHOIdHB1EHWwdlB28HeYeLh52HsAfYh%2FSIEYgviEyIXYhuCJAIpYiuCMOIyIjOCN6I8Ij4CQCJDAkXiSWJOIlNCVgJbwmFCZ%2BJuYnUCe8J%2FgoNChwKKwpoCnMKiYqSiqEKworeiwILGgsuizsLRwtiC30LiguZi6iLtgvDi9GL34vsi%2F4MD4whDDSMRIxYDGuMegyJDJeMpoy3jMiMz4zaDO2NBg0YDSoNNI1LDWeNeg2PjZ8Ntw3GjdON5I31DgQOEI4hjjIOQo5SjmIOcw6HDpsOpo63jugO9w8GDxQPKI8%2BD0yPew%2BOj6MPtQ%2FKD9uP6o%2F%2BkBIQIBAxkECQX5CGEKoQu5DGENCQ3ZDoEPKRBBEYESuRPZFWkW2RgZGdEa0RvZHNkd2R7ZH9kgWSDJITkhqSIZIzEkSSThJXkmESapKAkouSlIAAQAAARcApwARAAAAAAACAAAAAQABAAAAQAAuAAAAAAAAABAAxgABAAAAAAATABIAAAADAAEECQAAAGoAEgADAAEECQABACgAfAADAAEECQACAA4ApAADAAEECQADAEwAsgADAAEECQAEADgA%2FgADAAEECQAFAHgBNgADAAEECQAGADYBrgADAAEECQAIABYB5AADAAEECQAJABYB%2BgADAAEECQALACQCEAADAAEECQAMACQCNAADAAEECQATACQCWAADAAEECQDIABYCfAADAAEECQDJADACkgADAAEECdkDABoCwnd3dy5nbHlwaGljb25zLmNvbQBDAG8AcAB5AHIAaQBnAGgAdAAgAKkAIAAyADAAMQA0ACAAYgB5ACAASgBhAG4AIABLAG8AdgBhAHIAaQBrAC4AIABBAGwAbAAgAHIAaQBnAGgAdABzACAAcgBlAHMAZQByAHYAZQBkAC4ARwBMAFkAUABIAEkAQwBPAE4AUwAgAEgAYQBsAGYAbABpAG4AZwBzAFIAZQBnAHUAbABhAHIAMQAuADAAMAA5ADsAVQBLAFcATgA7AEcATABZAFAASABJAEMATwBOAFMASABhAGwAZgBsAGkAbgBnAHMALQBSAGUAZwB1AGwAYQByAEcATABZAFAASABJAEMATwBOAFMAIABIAGEAbABmAGwAaQBuAGcAcwAgAFIAZQBnAHUAbABhAHIAVgBlAHIAcwBpAG8AbgAgADEALgAwADAAOQA7AFAAUwAgADAAMAAxAC4AMAAwADkAOwBoAG8AdABjAG8AbgB2ACAAMQAuADAALgA3ADAAOwBtAGEAawBlAG8AdABmAC4AbABpAGIAMgAuADUALgA1ADgAMwAyADkARwBMAFkAUABIAEkAQwBPAE4AUwBIAGEAbABmAGwAaQBuAGcAcwAtAFIAZQBnAHUAbABhAHIASgBhAG4AIABLAG8AdgBhAHIAaQBrAEoAYQBuACAASwBvAHYAYQByAGkAawB3AHcAdwAuAGcAbAB5AHAAaABpAGMAbwBuAHMALgBjAG8AbQB3AHcAdwAuAGcAbAB5AHAAaABpAGMAbwBuAHMALgBjAG8AbQB3AHcAdwAuAGcAbAB5AHAAaABpAGMAbwBuAHMALgBjAG8AbQBXAGUAYgBmAG8AbgB0ACAAMQAuADAAVwBlAGQAIABPAGMAdAAgADIAOQAgADAANgA6ADMANgA6ADAANwAgADIAMAAxADQARgBvAG4AdAAgAFMAcQB1AGkAcgByAGUAbAAAAAIAAAAAAAD%2FtQAyAAAAAAAAAAAAAAAAAAAAAAAAAAABFwAAAQIBAwADAA0ADgEEAJYBBQEGAQcBCAEJAQoBCwEMAQ0BDgEPARABEQESARMA7wEUARUBFgEXARgBGQEaARsBHAEdAR4BHwEgASEBIgEjASQBJQEmAScBKAEpASoBKwEsAS0BLgEvATABMQEyATMBNAE1ATYBNwE4ATkBOgE7ATwBPQE%2BAT8BQAFBAUIBQwFEAUUBRgFHAUgBSQFKAUsBTAFNAU4BTwFQAVEBUgFTAVQBVQFWAVcBWAFZAVoBWwFcAV0BXgFfAWABYQFiAWMBZAFlAWYBZwFoAWkBagFrAWwBbQFuAW8BcAFxAXIBcwF0AXUBdgF3AXgBeQF6AXsBfAF9AX4BfwGAAYEBggGDAYQBhQGGAYcBiAGJAYoBiwGMAY0BjgGPAZABkQGSAZMBlAGVAZYBlwGYAZkBmgGbAZwBnQGeAZ8BoAGhAaIBowGkAaUBpgGnAagBqQGqAasBrAGtAa4BrwGwAbEBsgGzAbQBtQG2AbcBuAG5AboBuwG8Ab0BvgG%2FAcABwQHCAcMBxAHFAcYBxwHIAckBygHLAcwBzQHOAc8B0AHRAdIB0wHUAdUB1gHXAdgB2QHaAdsB3AHdAd4B3wHgAeEB4gHjAeQB5QHmAecB6AHpAeoB6wHsAe0B7gHvAfAB8QHyAfMB9AH1AfYB9wH4AfkB%2BgH7AfwB%2FQH%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%3D%29%20format%28%27truetype%27%29%2Curl%28data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPD94bWwgdmVyc2lvbj0iMS4wIiBzdGFuZGFsb25lPSJubyI%2FPgo8IURPQ1RZUEUgc3ZnIFBVQkxJQyAiLS8vVzNDLy9EVEQgU1ZHIDEuMS8vRU4iICJodHRwOi8vd3d3LnczLm9yZy9HcmFwaGljcy9TVkcvMS4xL0RURC9zdmcxMS5kdGQiID4KPHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPgo8bWV0YWRhdGE%2BPC9tZXRhZGF0YT4KPGRlZnM%2BCjxmb250IGlkPSJnbHlwaGljb25zX2hhbGZsaW5nc3JlZ3VsYXIiIGhvcml6LWFkdi14PSIxMjAwIiA%2BCjxmb250LWZhY2UgdW5pdHMtcGVyLWVtPSIxMjAwIiBhc2NlbnQ9Ijk2MCIgZGVzY2VudD0iLTI0MCIgLz4KPG1pc3NpbmctZ2x5cGggaG9yaXotYWR2LXg9IjUwMCIgLz4KPGdseXBoIGhvcml6LWFkdi14PSIwIiAvPgo8Z2x5cGggaG9yaXotYWR2LXg9IjQwMCIgLz4KPGdseXBoIHVuaWNvZGU9IiAiIC8%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%2BCjxnbHlwaCB1bmljb2RlPSImI3gyMDAzOyIgaG9yaXotYWR2LXg9IjEzMDAiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3gyMDA0OyIgaG9yaXotYWR2LXg9IjQzMyIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeDIwMDU7IiBob3Jpei1hZHYteD0iMzI1IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4MjAwNjsiIGhvcml6LWFkdi14PSIyMTYiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3gyMDA3OyIgaG9yaXotYWR2LXg9IjIxNiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeDIwMDg7IiBob3Jpei1hZHYteD0iMTYyIiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4MjAwOTsiIGhvcml6LWFkdi14PSIyNjAiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3gyMDBhOyIgaG9yaXotYWR2LXg9IjcyIiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4MjAyZjsiIGhvcml6LWFkdi14PSIyNjAiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3gyMDVmOyIgaG9yaXotYWR2LXg9IjMyNSIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeDIwYWM7IiBkPSJNNzQ0IDExOThxMjQyIDAgMzU0IC0xODlxNjAgLTEwNCA2NiAtMjA5aC0xODFxMCA0NSAtMTcuNSA4Mi41dC00My41IDYxLjV0LTU4IDQwLjV0LTYwLjUgMjR0LTUxLjUgNy41cS0xOSAwIC00MC41IC01LjV0LTQ5LjUgLTIwLjV0LTUzIC0zOHQtNDkgLTYyLjV0LTM5IC04OS41aDM3OWwtMTAwIC0xMDBoLTMwMHEtNiAtNTAgLTYgLTEwMGg0MDZsLTEwMCAtMTAwaC0zMDBxOSAtNzQgMzMgLTEzMnQ1Mi41IC05MXQ2MS41IC01NC41dDU5IC0yOSB0NDcgLTcuNXEyMiAwIDUwLjUgNy41dDYwLjUgMjQuNXQ1OCA0MXQ0My41IDYxdDE3LjUgODBoMTc0cS0zMCAtMTcxIC0xMjggLTI3OHEtMTA3IC0xMTcgLTI3NCAtMTE3cS0yMDYgMCAtMzI0IDE1OHEtMzYgNDggLTY5IDEzM3QtNDUgMjA0aC0yMTdsMTAwIDEwMGgxMTJxMSA0NyA2IDEwMGgtMjE4bDEwMCAxMDBoMTM0cTIwIDg3IDUxIDE1My41dDYyIDEwMy41cTExNyAxNDEgMjk3IDE0MXoiIC8%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%2BCjxnbHlwaCB1bmljb2RlPSImI3gyNmZhOyIgZD0iTTc3NCAxMTkzLjVxMTYgLTkuNSAyMC41IC0yN3QtNS41IC0zMy41bC0xMzYgLTE4N2w0NjcgLTc0NmgzMHEyMCAwIDM1IC0xOC41dDE1IC0zOS41di00MmgtMTIwMHY0MnEwIDIxIDE1IDM5LjV0MzUgMTguNWgzMGw0NjggNzQ2bC0xMzUgMTgzcS0xMCAxNiAtNS41IDM0dDIwLjUgMjh0MzQgNS41dDI4IC0yMC41bDExMSAtMTQ4bDExMiAxNTBxOSAxNiAyNyAyMC41dDM0IC01ek02MDAgMjAwaDM3N2wtMTgyIDExMmwtMTk1IDUzNHYtNjQ2eiAiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3gyNzA5OyIgZD0iTTI1IDExMDBoMTE1MHExMCAwIDEyLjUgLTV0LTUuNSAtMTNsLTU2NCAtNTY3cS04IC04IC0xOCAtOHQtMTggOGwtNTY0IDU2N3EtOCA4IC01LjUgMTN0MTIuNSA1ek0xOCA4ODJsMjY0IC0yNjRxOCAtOCA4IC0xOHQtOCAtMThsLTI2NCAtMjY0cS04IC04IC0xMyAtNS41dC01IDEyLjV2NTUwcTAgMTAgNSAxMi41dDEzIC01LjV6TTkxOCA2MThsMjY0IDI2NHE4IDggMTMgNS41dDUgLTEyLjV2LTU1MHEwIC0xMCAtNSAtMTIuNXQtMTMgNS41IGwtMjY0IDI2NHEtOCA4IC04IDE4dDggMTh6TTgxOCA0ODJsMzY0IC0zNjRxOCAtOCA1LjUgLTEzdC0xMi41IC01aC0xMTUwcS0xMCAwIC0xMi41IDV0NS41IDEzbDM2NCAzNjRxOCA4IDE4IDh0MTggLThsMTY0IC0xNjRxOCAtOCAxOCAtOHQxOCA4bDE2NCAxNjRxOCA4IDE4IDh0MTggLTh6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4MjcwZjsiIGQ9Ik0xMDExIDEyMTBxMTkgMCAzMyAtMTNsMTUzIC0xNTNxMTMgLTE0IDEzIC0zM3QtMTMgLTMzbC05OSAtOTJsLTIxNCAyMTRsOTUgOTZxMTMgMTQgMzIgMTR6TTEwMTMgODAwbC02MTUgLTYxNGwtMjE0IDIxNGw2MTQgNjE0ek0zMTcgOTZsLTMzMyAtMTEybDExMCAzMzV6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTAwMTsiIGQ9Ik03MDAgNjUwdi01NTBoMjUwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di01MGgtODAwdjUwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNWgyNTB2NTUwbC01MDAgNTUwaDEyMDB6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTAwMjsiIGQ9Ik0zNjggMTAxN2w2NDUgMTYzcTM5IDE1IDYzIDB0MjQgLTQ5di04MzFxMCAtNTUgLTQxLjUgLTk1LjV0LTExMS41IC02My41cS03OSAtMjUgLTE0NyAtNC41dC04NiA3NXQyNS41IDExMS41dDEyMi41IDgycTcyIDI0IDEzOCA4djUyMWwtNjAwIC0xNTV2LTYwNnEwIC00MiAtNDQgLTkwdC0xMDkgLTY5cS03OSAtMjYgLTE0NyAtNS41dC04NiA3NS41dDI1LjUgMTExLjV0MTIyLjUgODIuNXE3MiAyNCAxMzggN3Y2MzlxMCAzOCAxNC41IDU5IHQ1My41IDM0eiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUwMDM7IiBkPSJNNTAwIDExOTFxMTAwIDAgMTkxIC0zOXQxNTYuNSAtMTA0LjV0MTA0LjUgLTE1Ni41dDM5IC0xOTFsLTEgLTJsMSAtNXEwIC0xNDEgLTc4IC0yNjJsMjc1IC0yNzRxMjMgLTI2IDIyLjUgLTQ0LjV0LTIyLjUgLTQyLjVsLTU5IC01OHEtMjYgLTIwIC00Ni41IC0yMHQtMzkuNSAyMGwtMjc1IDI3NHEtMTE5IC03NyAtMjYxIC03N2wtNSAxbC0yIC0xcS0xMDAgMCAtMTkxIDM5dC0xNTYuNSAxMDQuNXQtMTA0LjUgMTU2LjV0LTM5IDE5MSB0MzkgMTkxdDEwNC41IDE1Ni41dDE1Ni41IDEwNC41dDE5MSAzOXpNNTAwIDEwMjJxLTg4IDAgLTE2MiAtNDN0LTExNyAtMTE3dC00MyAtMTYydDQzIC0xNjJ0MTE3IC0xMTd0MTYyIC00M3QxNjIgNDN0MTE3IDExN3Q0MyAxNjJ0LTQzIDE2MnQtMTE3IDExN3QtMTYyIDQzeiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUwMDU7IiBkPSJNNjQ5IDk0OXE0OCA2OCAxMDkuNSAxMDR0MTIxLjUgMzguNXQxMTguNSAtMjB0MTAyLjUgLTY0dDcxIC0xMDAuNXQyNyAtMTIzcTAgLTU3IC0zMy41IC0xMTcuNXQtOTQgLTEyNC41dC0xMjYuNSAtMTI3LjV0LTE1MCAtMTUyLjV0LTE0NiAtMTc0cS02MiA4NSAtMTQ1LjUgMTc0dC0xNTAgMTUyLjV0LTEyNi41IDEyNy41dC05My41IDEyNC41dC0zMy41IDExNy41cTAgNjQgMjggMTIzdDczIDEwMC41dDEwNCA2NHQxMTkgMjAgdDEyMC41IC0zOC41dDEwNC41IC0xMDR6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTAwNjsiIGQ9Ik00MDcgODAwbDEzMSAzNTNxNyAxOSAxNy41IDE5dDE3LjUgLTE5bDEyOSAtMzUzaDQyMXEyMSAwIDI0IC04LjV0LTE0IC0yMC41bC0zNDIgLTI0OWwxMzAgLTQwMXE3IC0yMCAtMC41IC0yNS41dC0yNC41IDYuNWwtMzQzIDI0NmwtMzQyIC0yNDdxLTE3IC0xMiAtMjQuNSAtNi41dC0wLjUgMjUuNWwxMzAgNDAwbC0zNDcgMjUxcS0xNyAxMiAtMTQgMjAuNXQyMyA4LjVoNDI5eiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUwMDc7IiBkPSJNNDA3IDgwMGwxMzEgMzUzcTcgMTkgMTcuNSAxOXQxNy41IC0xOWwxMjkgLTM1M2g0MjFxMjEgMCAyNCAtOC41dC0xNCAtMjAuNWwtMzQyIC0yNDlsMTMwIC00MDFxNyAtMjAgLTAuNSAtMjUuNXQtMjQuNSA2LjVsLTM0MyAyNDZsLTM0MiAtMjQ3cS0xNyAtMTIgLTI0LjUgLTYuNXQtMC41IDI1LjVsMTMwIDQwMGwtMzQ3IDI1MXEtMTcgMTIgLTE0IDIwLjV0MjMgOC41aDQyOXpNNDc3IDcwMGgtMjQwbDE5NyAtMTQybC03NCAtMjI2IGwxOTMgMTM5bDE5NSAtMTQwbC03NCAyMjlsMTkyIDE0MGgtMjM0bC03OCAyMTF6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTAwODsiIGQ9Ik02MDAgMTIwMHExMjQgMCAyMTIgLTg4dDg4IC0yMTJ2LTI1MHEwIC00NiAtMzEgLTk4dC02OSAtNTJ2LTc1cTAgLTEwIDYgLTIxLjV0MTUgLTE3LjVsMzU4IC0yMzBxOSAtNSAxNSAtMTYuNXQ2IC0yMS41di05M3EwIC0xMCAtNy41IC0xNy41dC0xNy41IC03LjVoLTExNTBxLTEwIDAgLTE3LjUgNy41dC03LjUgMTcuNXY5M3EwIDEwIDYgMjEuNXQxNSAxNi41bDM1OCAyMzBxOSA2IDE1IDE3LjV0NiAyMS41djc1cS0zOCAwIC02OSA1MiB0LTMxIDk4djI1MHEwIDEyNCA4OCAyMTJ0MjEyIDg4eiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUwMDk7IiBkPSJNMjUgMTEwMGgxMTUwcTEwIDAgMTcuNSAtNy41dDcuNSAtMTcuNXYtMTA1MHEwIC0xMCAtNy41IC0xNy41dC0xNy41IC03LjVoLTExNTBxLTEwIDAgLTE3LjUgNy41dC03LjUgMTcuNXYxMDUwcTAgMTAgNy41IDE3LjV0MTcuNSA3LjV6TTEwMCAxMDAwdi0xMDBoMTAwdjEwMGgtMTAwek04NzUgMTAwMGgtNTUwcS0xMCAwIC0xNy41IC03LjV0LTcuNSAtMTcuNXYtMzUwcTAgLTEwIDcuNSAtMTcuNXQxNy41IC03LjVoNTUwIHExMCAwIDE3LjUgNy41dDcuNSAxNy41djM1MHEwIDEwIC03LjUgMTcuNXQtMTcuNSA3LjV6TTEwMDAgMTAwMHYtMTAwaDEwMHYxMDBoLTEwMHpNMTAwIDgwMHYtMTAwaDEwMHYxMDBoLTEwMHpNMTAwMCA4MDB2LTEwMGgxMDB2MTAwaC0xMDB6TTEwMCA2MDB2LTEwMGgxMDB2MTAwaC0xMDB6TTEwMDAgNjAwdi0xMDBoMTAwdjEwMGgtMTAwek04NzUgNTAwaC01NTBxLTEwIDAgLTE3LjUgLTcuNXQtNy41IC0xNy41di0zNTBxMCAtMTAgNy41IC0xNy41IHQxNy41IC03LjVoNTUwcTEwIDAgMTcuNSA3LjV0Ny41IDE3LjV2MzUwcTAgMTAgLTcuNSAxNy41dC0xNy41IDcuNXpNMTAwIDQwMHYtMTAwaDEwMHYxMDBoLTEwMHpNMTAwMCA0MDB2LTEwMGgxMDB2MTAwaC0xMDB6TTEwMCAyMDB2LTEwMGgxMDB2MTAwaC0xMDB6TTEwMDAgMjAwdi0xMDBoMTAwdjEwMGgtMTAweiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUwMTA7IiBkPSJNNTAgMTEwMGg0MDBxMjEgMCAzNS41IC0xNC41dDE0LjUgLTM1LjV2LTQwMHEwIC0yMSAtMTQuNSAtMzUuNXQtMzUuNSAtMTQuNWgtNDAwcS0yMSAwIC0zNS41IDE0LjV0LTE0LjUgMzUuNXY0MDBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41ek02NTAgMTEwMGg0MDBxMjEgMCAzNS41IC0xNC41dDE0LjUgLTM1LjV2LTQwMHEwIC0yMSAtMTQuNSAtMzUuNXQtMzUuNSAtMTQuNWgtNDAwcS0yMSAwIC0zNS41IDE0LjV0LTE0LjUgMzUuNXY0MDAgcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNXpNNTAgNTAwaDQwMHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtNDAwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC00MDBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djQwMHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjV6TTY1MCA1MDBoNDAwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di00MDBxMCAtMjEgLTE0LjUgLTM1LjV0LTM1LjUgLTE0LjVoLTQwMCBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djQwMHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjV6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTAxMTsiIGQ9Ik01MCAxMTAwaDIwMHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtMjAwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC0yMDBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djIwMHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjV6TTQ1MCAxMTAwaDIwMHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtMjAwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC0yMDBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djIwMCBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41ek04NTAgMTEwMGgyMDBxMjEgMCAzNS41IC0xNC41dDE0LjUgLTM1LjV2LTIwMHEwIC0yMSAtMTQuNSAtMzUuNXQtMzUuNSAtMTQuNWgtMjAwcS0yMSAwIC0zNS41IDE0LjV0LTE0LjUgMzUuNXYyMDBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41ek01MCA3MDBoMjAwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di0yMDBxMCAtMjEgLTE0LjUgLTM1LjV0LTM1LjUgLTE0LjVoLTIwMCBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djIwMHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjV6TTQ1MCA3MDBoMjAwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di0yMDBxMCAtMjEgLTE0LjUgLTM1LjV0LTM1LjUgLTE0LjVoLTIwMHEtMjEgMCAtMzUuNSAxNC41dC0xNC41IDM1LjV2MjAwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNXpNODUwIDcwMGgyMDBxMjEgMCAzNS41IC0xNC41dDE0LjUgLTM1LjV2LTIwMCBxMCAtMjEgLTE0LjUgLTM1LjV0LTM1LjUgLTE0LjVoLTIwMHEtMjEgMCAtMzUuNSAxNC41dC0xNC41IDM1LjV2MjAwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNXpNNTAgMzAwaDIwMHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtMjAwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC0yMDBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djIwMHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjV6TTQ1MCAzMDBoMjAwIHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtMjAwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC0yMDBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djIwMHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjV6TTg1MCAzMDBoMjAwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di0yMDBxMCAtMjEgLTE0LjUgLTM1LjV0LTM1LjUgLTE0LjVoLTIwMHEtMjEgMCAtMzUuNSAxNC41dC0xNC41IDM1LjV2MjAwcTAgMjEgMTQuNSAzNS41IHQzNS41IDE0LjV6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTAxMjsiIGQ9Ik01MCAxMTAwaDIwMHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtMjAwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC0yMDBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djIwMHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjV6TTQ1MCAxMTAwaDcwMHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtMjAwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC03MDBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djIwMCBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41ek01MCA3MDBoMjAwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di0yMDBxMCAtMjEgLTE0LjUgLTM1LjV0LTM1LjUgLTE0LjVoLTIwMHEtMjEgMCAtMzUuNSAxNC41dC0xNC41IDM1LjV2MjAwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNXpNNDUwIDcwMGg3MDBxMjEgMCAzNS41IC0xNC41dDE0LjUgLTM1LjV2LTIwMHEwIC0yMSAtMTQuNSAtMzUuNXQtMzUuNSAtMTQuNWgtNzAwIHEtMjEgMCAtMzUuNSAxNC41dC0xNC41IDM1LjV2MjAwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNXpNNTAgMzAwaDIwMHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtMjAwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC0yMDBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djIwMHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjV6TTQ1MCAzMDBoNzAwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di0yMDAgcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC03MDBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djIwMHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjV6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTAxMzsiIGQ9Ik00NjUgNDc3bDU3MSA1NzFxOCA4IDE4IDh0MTcgLThsMTc3IC0xNzdxOCAtNyA4IC0xN3QtOCAtMThsLTc4MyAtNzg0cS03IC04IC0xNy41IC04dC0xNy41IDhsLTM4NCAzODRxLTggOCAtOCAxOHQ4IDE3bDE3NyAxNzdxNyA4IDE3IDh0MTggLThsMTcxIC0xNzFxNyAtNyAxOCAtN3QxOCA3eiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUwMTQ7IiBkPSJNOTA0IDEwODNsMTc4IC0xNzlxOCAtOCA4IC0xOC41dC04IC0xNy41bC0yNjcgLTI2OGwyNjcgLTI2OHE4IC03IDggLTE3LjV0LTggLTE4LjVsLTE3OCAtMTc4cS04IC04IC0xOC41IC04dC0xNy41IDhsLTI2OCAyNjdsLTI2OCAtMjY3cS03IC04IC0xNy41IC04dC0xOC41IDhsLTE3OCAxNzhxLTggOCAtOCAxOC41dDggMTcuNWwyNjcgMjY4bC0yNjcgMjY4cS04IDcgLTggMTcuNXQ4IDE4LjVsMTc4IDE3OHE4IDggMTguNSA4dDE3LjUgLTggbDI2OCAtMjY3bDI2OCAyNjhxNyA3IDE3LjUgN3QxOC41IC03eiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUwMTU7IiBkPSJNNTA3IDExNzdxOTggMCAxODcuNSAtMzguNXQxNTQuNSAtMTAzLjV0MTAzLjUgLTE1NC41dDM4LjUgLTE4Ny41cTAgLTE0MSAtNzggLTI2MmwzMDAgLTI5OXE4IC04IDggLTE4LjV0LTggLTE4LjVsLTEwOSAtMTA4cS03IC04IC0xNy41IC04dC0xOC41IDhsLTMwMCAyOTlxLTExOSAtNzcgLTI2MSAtNzdxLTk4IDAgLTE4OCAzOC41dC0xNTQuNSAxMDN0LTEwMyAxNTQuNXQtMzguNSAxODh0MzguNSAxODcuNXQxMDMgMTU0LjUgdDE1NC41IDEwMy41dDE4OCAzOC41ek01MDYuNSAxMDIzcS04OS41IDAgLTE2NS41IC00NHQtMTIwIC0xMjAuNXQtNDQgLTE2NnQ0NCAtMTY1LjV0MTIwIC0xMjB0MTY1LjUgLTQ0dDE2NiA0NHQxMjAuNSAxMjB0NDQgMTY1LjV0LTQ0IDE2NnQtMTIwLjUgMTIwLjV0LTE2NiA0NHpNNDI1IDkwMGgxNTBxMTAgMCAxNy41IC03LjV0Ny41IC0xNy41di03NWg3NXExMCAwIDE3LjUgLTcuNXQ3LjUgLTE3LjV2LTE1MHEwIC0xMCAtNy41IC0xNy41IHQtMTcuNSAtNy41aC03NXYtNzVxMCAtMTAgLTcuNSAtMTcuNXQtMTcuNSAtNy41aC0xNTBxLTEwIDAgLTE3LjUgNy41dC03LjUgMTcuNXY3NWgtNzVxLTEwIDAgLTE3LjUgNy41dC03LjUgMTcuNXYxNTBxMCAxMCA3LjUgMTcuNXQxNy41IDcuNWg3NXY3NXEwIDEwIDcuNSAxNy41dDE3LjUgNy41eiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUwMTY7IiBkPSJNNTA3IDExNzdxOTggMCAxODcuNSAtMzguNXQxNTQuNSAtMTAzLjV0MTAzLjUgLTE1NC41dDM4LjUgLTE4Ny41cTAgLTE0MSAtNzggLTI2MmwzMDAgLTI5OXE4IC04IDggLTE4LjV0LTggLTE4LjVsLTEwOSAtMTA4cS03IC04IC0xNy41IC04dC0xOC41IDhsLTMwMCAyOTlxLTExOSAtNzcgLTI2MSAtNzdxLTk4IDAgLTE4OCAzOC41dC0xNTQuNSAxMDN0LTEwMyAxNTQuNXQtMzguNSAxODh0MzguNSAxODcuNXQxMDMgMTU0LjUgdDE1NC41IDEwMy41dDE4OCAzOC41ek01MDYuNSAxMDIzcS04OS41IDAgLTE2NS41IC00NHQtMTIwIC0xMjAuNXQtNDQgLTE2NnQ0NCAtMTY1LjV0MTIwIC0xMjB0MTY1LjUgLTQ0dDE2NiA0NHQxMjAuNSAxMjB0NDQgMTY1LjV0LTQ0IDE2NnQtMTIwLjUgMTIwLjV0LTE2NiA0NHpNMzI1IDgwMGgzNTBxMTAgMCAxNy41IC03LjV0Ny41IC0xNy41di0xNTBxMCAtMTAgLTcuNSAtMTcuNXQtMTcuNSAtNy41aC0zNTBxLTEwIDAgLTE3LjUgNy41IHQtNy41IDE3LjV2MTUwcTAgMTAgNy41IDE3LjV0MTcuNSA3LjV6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTAxNzsiIGQ9Ik01NTAgMTIwMGgxMDBxMjEgMCAzNS41IC0xNC41dDE0LjUgLTM1LjV2LTQwMHEwIC0yMSAtMTQuNSAtMzUuNXQtMzUuNSAtMTQuNWgtMTAwcS0yMSAwIC0zNS41IDE0LjV0LTE0LjUgMzUuNXY0MDBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41ek04MDAgOTc1djE2NnExNjcgLTYyIDI3MiAtMjA5LjV0MTA1IC0zMzEuNXEwIC0xMTcgLTQ1LjUgLTIyNHQtMTIzIC0xODQuNXQtMTg0LjUgLTEyM3QtMjI0IC00NS41dC0yMjQgNDUuNSB0LTE4NC41IDEyM3QtMTIzIDE4NC41dC00NS41IDIyNHEwIDE4NCAxMDUgMzMxLjV0MjcyIDIwOS41di0xNjZxLTEwMyAtNTUgLTE2NSAtMTU1dC02MiAtMjIwcTAgLTExNiA1NyAtMjE0LjV0MTU1LjUgLTE1NS41dDIxNC41IC01N3QyMTQuNSA1N3QxNTUuNSAxNTUuNXQ1NyAyMTQuNXEwIDEyMCAtNjIgMjIwdC0xNjUgMTU1eiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUwMTg7IiBkPSJNMTAyNSAxMjAwaDE1MHExMCAwIDE3LjUgLTcuNXQ3LjUgLTE3LjV2LTExNTBxMCAtMTAgLTcuNSAtMTcuNXQtMTcuNSAtNy41aC0xNTBxLTEwIDAgLTE3LjUgNy41dC03LjUgMTcuNXYxMTUwcTAgMTAgNy41IDE3LjV0MTcuNSA3LjV6TTcyNSA4MDBoMTUwcTEwIDAgMTcuNSAtNy41dDcuNSAtMTcuNXYtNzUwcTAgLTEwIC03LjUgLTE3LjV0LTE3LjUgLTcuNWgtMTUwcS0xMCAwIC0xNy41IDcuNXQtNy41IDE3LjV2NzUwIHEwIDEwIDcuNSAxNy41dDE3LjUgNy41ek00MjUgNTAwaDE1MHExMCAwIDE3LjUgLTcuNXQ3LjUgLTE3LjV2LTQ1MHEwIC0xMCAtNy41IC0xNy41dC0xNy41IC03LjVoLTE1MHEtMTAgMCAtMTcuNSA3LjV0LTcuNSAxNy41djQ1MHEwIDEwIDcuNSAxNy41dDE3LjUgNy41ek0xMjUgMzAwaDE1MHExMCAwIDE3LjUgLTcuNXQ3LjUgLTE3LjV2LTI1MHEwIC0xMCAtNy41IC0xNy41dC0xNy41IC03LjVoLTE1MHEtMTAgMCAtMTcuNSA3LjV0LTcuNSAxNy41IHYyNTBxMCAxMCA3LjUgMTcuNXQxNy41IDcuNXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDE5OyIgZD0iTTYwMCAxMTc0cTMzIDAgNzQgLTVsMzggLTE1Mmw1IC0xcTQ5IC0xNCA5NCAtMzlsNSAtMmwxMzQgODBxNjEgLTQ4IDEwNCAtMTA1bC04MCAtMTM0bDMgLTVxMjUgLTQ0IDM5IC05M2wxIC02bDE1MiAtMzhxNSAtNDMgNSAtNzNxMCAtMzQgLTUgLTc0bC0xNTIgLTM4bC0xIC02cS0xNSAtNDkgLTM5IC05M2wtMyAtNWw4MCAtMTM0cS00OCAtNjEgLTEwNCAtMTA1bC0xMzQgODFsLTUgLTNxLTQ0IC0yNSAtOTQgLTM5bC01IC0ybC0zOCAtMTUxIHEtNDMgLTUgLTc0IC01cS0zMyAwIC03NCA1bC0zOCAxNTFsLTUgMnEtNDkgMTQgLTk0IDM5bC01IDNsLTEzNCAtODFxLTYwIDQ4IC0xMDQgMTA1bDgwIDEzNGwtMyA1cS0yNSA0NSAtMzggOTNsLTIgNmwtMTUxIDM4cS02IDQyIC02IDc0cTAgMzMgNiA3M2wxNTEgMzhsMiA2cTEzIDQ4IDM4IDkzbDMgNWwtODAgMTM0cTQ3IDYxIDEwNSAxMDVsMTMzIC04MGw1IDJxNDUgMjUgOTQgMzlsNSAxbDM4IDE1MnE0MyA1IDc0IDV6TTYwMCA4MTUgcS04OSAwIC0xNTIgLTYzdC02MyAtMTUxLjV0NjMgLTE1MS41dDE1MiAtNjN0MTUyIDYzdDYzIDE1MS41dC02MyAxNTEuNXQtMTUyIDYzeiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUwMjA7IiBkPSJNNTAwIDEzMDBoMzAwcTQxIDAgNzAuNSAtMjkuNXQyOS41IC03MC41di0xMDBoMjc1cTEwIDAgMTcuNSAtNy41dDcuNSAtMTcuNXYtNzVoLTExMDB2NzVxMCAxMCA3LjUgMTcuNXQxNy41IDcuNWgyNzV2MTAwcTAgNDEgMjkuNSA3MC41dDcwLjUgMjkuNXpNNTAwIDEyMDB2LTEwMGgzMDB2MTAwaC0zMDB6TTExMDAgOTAwdi04MDBxMCAtNDEgLTI5LjUgLTcwLjV0LTcwLjUgLTI5LjVoLTcwMHEtNDEgMCAtNzAuNSAyOS41dC0yOS41IDcwLjUgdjgwMGg5MDB6TTMwMCA4MDB2LTcwMGgxMDB2NzAwaC0xMDB6TTUwMCA4MDB2LTcwMGgxMDB2NzAwaC0xMDB6TTcwMCA4MDB2LTcwMGgxMDB2NzAwaC0xMDB6TTkwMCA4MDB2LTcwMGgxMDB2NzAwaC0xMDB6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTAyMTsiIGQ9Ik0xOCA2MThsNjIwIDYwOHE4IDcgMTguNSA3dDE3LjUgLTdsNjA4IC02MDhxOCAtOCA1LjUgLTEzdC0xMi41IC01aC0xNzV2LTU3NXEwIC0xMCAtNy41IC0xNy41dC0xNy41IC03LjVoLTI1MHEtMTAgMCAtMTcuNSA3LjV0LTcuNSAxNy41djM3NWgtMzAwdi0zNzVxMCAtMTAgLTcuNSAtMTcuNXQtMTcuNSAtNy41aC0yNTBxLTEwIDAgLTE3LjUgNy41dC03LjUgMTcuNXY1NzVoLTE3NXEtMTAgMCAtMTIuNSA1dDUuNSAxM3oiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDIyOyIgZD0iTTYwMCAxMjAwdi00MDBxMCAtNDEgMjkuNSAtNzAuNXQ3MC41IC0yOS41aDMwMHYtNjUwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC04MDBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djExMDBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41aDQ1MHpNMTAwMCA4MDBoLTI1MHEtMjEgMCAtMzUuNSAxNC41dC0xNC41IDM1LjV2MjUweiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUwMjM7IiBkPSJNNjAwIDExNzdxMTE3IDAgMjI0IC00NS41dDE4NC41IC0xMjN0MTIzIC0xODQuNXQ0NS41IC0yMjR0LTQ1LjUgLTIyNHQtMTIzIC0xODQuNXQtMTg0LjUgLTEyM3QtMjI0IC00NS41dC0yMjQgNDUuNXQtMTg0LjUgMTIzdC0xMjMgMTg0LjV0LTQ1LjUgMjI0dDQ1LjUgMjI0dDEyMyAxODQuNXQxODQuNSAxMjN0MjI0IDQ1LjV6TTYwMCAxMDI3cS0xMTYgMCAtMjE0LjUgLTU3dC0xNTUuNSAtMTU1LjV0LTU3IC0yMTQuNXQ1NyAtMjE0LjUgdDE1NS41IC0xNTUuNXQyMTQuNSAtNTd0MjE0LjUgNTd0MTU1LjUgMTU1LjV0NTcgMjE0LjV0LTU3IDIxNC41dC0xNTUuNSAxNTUuNXQtMjE0LjUgNTd6TTUyNSA5MDBoNTBxMTAgMCAxNy41IC03LjV0Ny41IC0xNy41di0yNzVoMTc1cTEwIDAgMTcuNSAtNy41dDcuNSAtMTcuNXYtNTBxMCAtMTAgLTcuNSAtMTcuNXQtMTcuNSAtNy41aC0yNTBxLTEwIDAgLTE3LjUgNy41dC03LjUgMTcuNXYzNTBxMCAxMCA3LjUgMTcuNXQxNy41IDcuNXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDI0OyIgZD0iTTEzMDAgMGgtNTM4bC00MSA0MDBoLTI0MmwtNDEgLTQwMGgtNTM4bDQzMSAxMjAwaDIwOWwtMjEgLTMwMGgxNjJsLTIwIDMwMGgyMDh6TTUxNSA4MDBsLTI3IC0zMDBoMjI0bC0yNyAzMDBoLTE3MHoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDI1OyIgZD0iTTU1MCAxMjAwaDIwMHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtNDUwaDE5MXEyMCAwIDI1LjUgLTExLjV0LTcuNSAtMjcuNWwtMzI3IC00MDBxLTEzIC0xNiAtMzIgLTE2dC0zMiAxNmwtMzI3IDQwMHEtMTMgMTYgLTcuNSAyNy41dDI1LjUgMTEuNWgxOTF2NDUwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNXpNMTEyNSA0MDBoNTBxMTAgMCAxNy41IC03LjV0Ny41IC0xNy41di0zNTBxMCAtMTAgLTcuNSAtMTcuNXQtMTcuNSAtNy41IGgtMTA1MHEtMTAgMCAtMTcuNSA3LjV0LTcuNSAxNy41djM1MHEwIDEwIDcuNSAxNy41dDE3LjUgNy41aDUwcTEwIDAgMTcuNSAtNy41dDcuNSAtMTcuNXYtMTc1aDkwMHYxNzVxMCAxMCA3LjUgMTcuNXQxNy41IDcuNXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDI2OyIgZD0iTTYwMCAxMTc3cTExNyAwIDIyNCAtNDUuNXQxODQuNSAtMTIzdDEyMyAtMTg0LjV0NDUuNSAtMjI0dC00NS41IC0yMjR0LTEyMyAtMTg0LjV0LTE4NC41IC0xMjN0LTIyNCAtNDUuNXQtMjI0IDQ1LjV0LTE4NC41IDEyM3QtMTIzIDE4NC41dC00NS41IDIyNHQ0NS41IDIyNHQxMjMgMTg0LjV0MTg0LjUgMTIzdDIyNCA0NS41ek02MDAgMTAyN3EtMTE2IDAgLTIxNC41IC01N3QtMTU1LjUgLTE1NS41dC01NyAtMjE0LjV0NTcgLTIxNC41IHQxNTUuNSAtMTU1LjV0MjE0LjUgLTU3dDIxNC41IDU3dDE1NS41IDE1NS41dDU3IDIxNC41dC01NyAyMTQuNXQtMTU1LjUgMTU1LjV0LTIxNC41IDU3ek01MjUgOTAwaDE1MHExMCAwIDE3LjUgLTcuNXQ3LjUgLTE3LjV2LTI3NWgxMzdxMjEgMCAyNiAtMTEuNXQtOCAtMjcuNWwtMjIzIC0yNzVxLTEzIC0xNiAtMzIgLTE2dC0zMiAxNmwtMjIzIDI3NXEtMTMgMTYgLTggMjcuNXQyNiAxMS41aDEzN3YyNzVxMCAxMCA3LjUgMTcuNXQxNy41IDcuNXogIiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTAyNzsiIGQ9Ik02MDAgMTE3N3ExMTcgMCAyMjQgLTQ1LjV0MTg0LjUgLTEyM3QxMjMgLTE4NC41dDQ1LjUgLTIyNHQtNDUuNSAtMjI0dC0xMjMgLTE4NC41dC0xODQuNSAtMTIzdC0yMjQgLTQ1LjV0LTIyNCA0NS41dC0xODQuNSAxMjN0LTEyMyAxODQuNXQtNDUuNSAyMjR0NDUuNSAyMjR0MTIzIDE4NC41dDE4NC41IDEyM3QyMjQgNDUuNXpNNjAwIDEwMjdxLTExNiAwIC0yMTQuNSAtNTd0LTE1NS41IC0xNTUuNXQtNTcgLTIxNC41dDU3IC0yMTQuNSB0MTU1LjUgLTE1NS41dDIxNC41IC01N3QyMTQuNSA1N3QxNTUuNSAxNTUuNXQ1NyAyMTQuNXQtNTcgMjE0LjV0LTE1NS41IDE1NS41dC0yMTQuNSA1N3pNNjMyIDkxNGwyMjMgLTI3NXExMyAtMTYgOCAtMjcuNXQtMjYgLTExLjVoLTEzN3YtMjc1cTAgLTEwIC03LjUgLTE3LjV0LTE3LjUgLTcuNWgtMTUwcS0xMCAwIC0xNy41IDcuNXQtNy41IDE3LjV2Mjc1aC0xMzdxLTIxIDAgLTI2IDExLjV0OCAyNy41bDIyMyAyNzVxMTMgMTYgMzIgMTYgdDMyIC0xNnoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDI4OyIgZD0iTTIyNSAxMjAwaDc1MHExMCAwIDE5LjUgLTd0MTIuNSAtMTdsMTg2IC02NTJxNyAtMjQgNyAtNDl2LTQyNXEwIC0xMiAtNCAtMjd0LTkgLTE3cS0xMiAtNiAtMzcgLTZoLTExMDBxLTEyIDAgLTI3IDR0LTE3IDhxLTYgMTMgLTYgMzhsMSA0MjVxMCAyNSA3IDQ5bDE4NSA2NTJxMyAxMCAxMi41IDE3dDE5LjUgN3pNODc4IDEwMDBoLTU1NnEtMTAgMCAtMTkgLTd0LTExIC0xOGwtODcgLTQ1MHEtMiAtMTEgNCAtMTh0MTYgLTdoMTUwIHExMCAwIDE5LjUgLTd0MTEuNSAtMTdsMzggLTE1MnEyIC0xMCAxMS41IC0xN3QxOS41IC03aDI1MHExMCAwIDE5LjUgN3QxMS41IDE3bDM4IDE1MnEyIDEwIDExLjUgMTd0MTkuNSA3aDE1MHExMCAwIDE2IDd0NCAxOGwtODcgNDUwcS0yIDExIC0xMSAxOHQtMTkgN3oiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDI5OyIgZD0iTTYwMCAxMTc3cTExNyAwIDIyNCAtNDUuNXQxODQuNSAtMTIzdDEyMyAtMTg0LjV0NDUuNSAtMjI0dC00NS41IC0yMjR0LTEyMyAtMTg0LjV0LTE4NC41IC0xMjN0LTIyNCAtNDUuNXQtMjI0IDQ1LjV0LTE4NC41IDEyM3QtMTIzIDE4NC41dC00NS41IDIyNHQ0NS41IDIyNHQxMjMgMTg0LjV0MTg0LjUgMTIzdDIyNCA0NS41ek02MDAgMTAyN3EtMTE2IDAgLTIxNC41IC01N3QtMTU1LjUgLTE1NS41dC01NyAtMjE0LjV0NTcgLTIxNC41IHQxNTUuNSAtMTU1LjV0MjE0LjUgLTU3dDIxNC41IDU3dDE1NS41IDE1NS41dDU3IDIxNC41dC01NyAyMTQuNXQtMTU1LjUgMTU1LjV0LTIxNC41IDU3ek01NDAgODIwbDI1MyAtMTkwcTE3IC0xMiAxNyAtMzB0LTE3IC0zMGwtMjUzIC0xOTBxLTE2IC0xMiAtMjggLTYuNXQtMTIgMjYuNXY0MDBxMCAyMSAxMiAyNi41dDI4IC02LjV6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTAzMDsiIGQ9Ik05NDcgMTA2MGwxMzUgMTM1cTcgNyAxMi41IDV0NS41IC0xM3YtMzYycTAgLTEwIC03LjUgLTE3LjV0LTE3LjUgLTcuNWgtMzYycS0xMSAwIC0xMyA1LjV0NSAxMi41bDEzMyAxMzNxLTEwOSA3NiAtMjM4IDc2cS0xMTYgMCAtMjE0LjUgLTU3dC0xNTUuNSAtMTU1LjV0LTU3IC0yMTQuNXQ1NyAtMjE0LjV0MTU1LjUgLTE1NS41dDIxNC41IC01N3QyMTQuNSA1N3QxNTUuNSAxNTUuNXQ1NyAyMTQuNWgxNTBxMCAtMTE3IC00NS41IC0yMjQgdC0xMjMgLTE4NC41dC0xODQuNSAtMTIzdC0yMjQgLTQ1LjV0LTIyNCA0NS41dC0xODQuNSAxMjN0LTEyMyAxODQuNXQtNDUuNSAyMjR0NDUuNSAyMjR0MTIzIDE4NC41dDE4NC41IDEyM3QyMjQgNDUuNXExOTIgMCAzNDcgLTExN3oiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDMxOyIgZD0iTTk0NyAxMDYwbDEzNSAxMzVxNyA3IDEyLjUgNXQ1LjUgLTEzdi0zNjFxMCAtMTEgLTcuNSAtMTguNXQtMTguNSAtNy41aC0zNjFxLTExIDAgLTEzIDUuNXQ1IDEyLjVsMTM0IDEzNHEtMTEwIDc1IC0yMzkgNzVxLTExNiAwIC0yMTQuNSAtNTd0LTE1NS41IC0xNTUuNXQtNTcgLTIxNC41aC0xNTBxMCAxMTcgNDUuNSAyMjR0MTIzIDE4NC41dDE4NC41IDEyM3QyMjQgNDUuNXExOTIgMCAzNDcgLTExN3pNMTAyNyA2MDBoMTUwIHEwIC0xMTcgLTQ1LjUgLTIyNHQtMTIzIC0xODQuNXQtMTg0LjUgLTEyM3QtMjI0IC00NS41cS0xOTIgMCAtMzQ4IDExOGwtMTM0IC0xMzRxLTcgLTggLTEyLjUgLTUuNXQtNS41IDEyLjV2MzYwcTAgMTEgNy41IDE4LjV0MTguNSA3LjVoMzYwcTEwIDAgMTIuNSAtNS41dC01LjUgLTEyLjVsLTEzMyAtMTMzcTExMCAtNzYgMjQwIC03NnExMTYgMCAyMTQuNSA1N3QxNTUuNSAxNTUuNXQ1NyAyMTQuNXoiIC8%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%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%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDM5OyIgZD0iTTUwMCA5MDBoMTAwdi0xMDBoLTEwMHYtMTAwaC00MDB2LTEwMGgtMTAwdjYwMGg1MDB2LTMwMHpNMTIwMCA3MDBoLTIwMHYtMTAwaDIwMHYtMjAwaC0zMDB2MzAwaC0yMDB2MzAwaC0xMDB2MjAwaDYwMHYtNTAwek0xMDAgMTEwMHYtMzAwaDMwMHYzMDBoLTMwMHpNODAwIDExMDB2LTMwMGgzMDB2MzAwaC0zMDB6TTMwMCA5MDBoLTEwMHYxMDBoMTAwdi0xMDB6TTEwMDAgOTAwaC0xMDB2MTAwaDEwMHYtMTAwek0zMDAgNTAwaDIwMHYtNTAwIGgtNTAwdjUwMGgyMDB2MTAwaDEwMHYtMTAwek04MDAgMzAwaDIwMHYtMTAwaC0xMDB2LTEwMGgtMjAwdjEwMGgtMTAwdjEwMGgxMDB2MjAwaC0yMDB2MTAwaDMwMHYtMzAwek0xMDAgNDAwdi0zMDBoMzAwdjMwMGgtMzAwek0zMDAgMjAwaC0xMDB2MTAwaDEwMHYtMTAwek0xMjAwIDIwMGgtMTAwdjEwMGgxMDB2LTEwMHpNNzAwIDBoLTEwMHYxMDBoMTAwdi0xMDB6TTEyMDAgMGgtMzAwdjEwMGgzMDB2LTEwMHoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDQwOyIgZD0iTTEwMCAyMDBoLTEwMHYxMDAwaDEwMHYtMTAwMHpNMzAwIDIwMGgtMTAwdjEwMDBoMTAwdi0xMDAwek03MDAgMjAwaC0yMDB2MTAwMGgyMDB2LTEwMDB6TTkwMCAyMDBoLTEwMHYxMDAwaDEwMHYtMTAwMHpNMTIwMCAyMDBoLTIwMHYxMDAwaDIwMHYtMTAwMHpNNDAwIDBoLTMwMHYxMDBoMzAwdi0xMDB6TTYwMCAwaC0xMDB2OTFoMTAwdi05MXpNODAwIDBoLTEwMHY5MWgxMDB2LTkxek0xMTAwIDBoLTIwMHY5MWgyMDB2LTkxeiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUwNDE7IiBkPSJNNTAwIDEyMDBsNjgyIC02ODJxOCAtOCA4IC0xOHQtOCAtMThsLTQ2NCAtNDY0cS04IC04IC0xOCAtOHQtMTggOGwtNjgyIDY4MmwxIDQ3NXEwIDEwIDcuNSAxNy41dDE3LjUgNy41aDQ3NHpNMzE5LjUgMTAyNC41cS0yOS41IDI5LjUgLTcxIDI5LjV0LTcxIC0yOS41dC0yOS41IC03MS41dDI5LjUgLTcxLjV0NzEgLTI5LjV0NzEgMjkuNXQyOS41IDcxLjV0LTI5LjUgNzEuNXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDQyOyIgZD0iTTUwMCAxMjAwbDY4MiAtNjgycTggLTggOCAtMTh0LTggLTE4bC00NjQgLTQ2NHEtOCAtOCAtMTggLTh0LTE4IDhsLTY4MiA2ODJsMSA0NzVxMCAxMCA3LjUgMTcuNXQxNy41IDcuNWg0NzR6TTgwMCAxMjAwbDY4MiAtNjgycTggLTggOCAtMTh0LTggLTE4bC00NjQgLTQ2NHEtOCAtOCAtMTggLTh0LTE4IDhsLTU2IDU2bDQyNCA0MjZsLTcwMCA3MDBoMTUwek0zMTkuNSAxMDI0LjVxLTI5LjUgMjkuNSAtNzEgMjkuNXQtNzEgLTI5LjUgdC0yOS41IC03MS41dDI5LjUgLTcxLjV0NzEgLTI5LjV0NzEgMjkuNXQyOS41IDcxLjV0LTI5LjUgNzEuNXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDQzOyIgZD0iTTMwMCAxMjAwaDgyNXE3NSAwIDc1IC03NXYtOTAwcTAgLTI1IC0xOCAtNDNsLTY0IC02NHEtOCAtOCAtMTMgLTUuNXQtNSAxMi41djk1MHEwIDEwIC03LjUgMTcuNXQtMTcuNSA3LjVoLTcwMHEtMjUgMCAtNDMgLTE4bC02NCAtNjRxLTggLTggLTUuNSAtMTN0MTIuNSAtNWg3MDBxMTAgMCAxNy41IC03LjV0Ny41IC0xNy41di05NTBxMCAtMTAgLTcuNSAtMTcuNXQtMTcuNSAtNy41aC04NTBxLTEwIDAgLTE3LjUgNy41dC03LjUgMTcuNXY5NzUgcTAgMjUgMTggNDNsMTM5IDEzOXExOCAxOCA0MyAxOHoiIC8%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%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDQ4OyIgZD0iTTc1MyA2NDFxNSAtMSAxNC41IC00LjV0MzYgLTE1LjV0NTAuNSAtMjYuNXQ1My41IC00MHQ1MC41IC01NC41dDM1LjUgLTcwdDE0LjUgLTg3cTAgLTY3IC0yNy41IC0xMjUuNXQtNzEuNSAtOTcuNXQtOTguNSAtNjYuNXQtMTA4LjUgLTQwLjV0LTEwMiAtMTNoLTUwMHY4OXE0MSA3IDcwLjUgMzIuNXQyOS41IDY1LjV2ODI3cTAgMjQgLTAuNSAzNHQtMy41IDI0dC04LjUgMTkuNXQtMTcgMTMuNXQtMjggMTIuNXQtNDIuNSAxMS41djcxIGw0NzEgLTFxNTcgMCAxMTUuNSAtMjAuNXQxMDggLTU3dDgwLjUgLTk0dDMxIC0xMjQuNXEwIC01MSAtMTUuNSAtOTYuNXQtMzggLTc0LjV0LTQ1IC01MC41dC0zOC41IC0zMC41ek00MDAgNzAwaDEzOXE3OCAwIDEzMC41IDQ4LjV0NTIuNSAxMjIuNXEwIDQxIC04LjUgNzAuNXQtMjkuNSA1NS41dC02Mi41IDM5LjV0LTEwMy41IDEzLjVoLTExOHYtMzUwek00MDAgMjAwaDIxNnE4MCAwIDEyMSA1MC41dDQxIDEzMC41cTAgOTAgLTYyLjUgMTU0LjUgdC0xNTYuNSA2NC41aC0xNTl2LTQwMHoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDQ5OyIgZD0iTTg3NyAxMjAwbDIgLTU3cS04MyAtMTkgLTExNiAtNDUuNXQtNDAgLTY2LjVsLTEzMiAtODM5cS05IC00OSAxMyAtNjl0OTYgLTI2di05N2gtNTAwdjk3cTE4NiAxNiAyMDAgOThsMTczIDgzMnEzIDE3IDMgMzB0LTEuNSAyMi41dC05IDE3LjV0LTEzLjUgMTIuNXQtMjEuNSAxMHQtMjYgOC41dC0zMy41IDEwcS0xMyAzIC0xOSA1djU3aDQyNXoiIC8%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%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDU0OyIgZD0iTTUwMCA5NTB2MTAwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNWg2MDBxMjEgMCAzNS41IC0xNC41dDE0LjUgLTM1LjV2LTEwMHEwIC0yMSAtMTQuNSAtMzUuNXQtMzUuNSAtMTQuNWgtNjAwcS0yMSAwIC0zNS41IDE0LjV0LTE0LjUgMzUuNXpNMTAwIDY1MHYxMDBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41aDEwMDBxMjEgMCAzNS41IC0xNC41dDE0LjUgLTM1LjV2LTEwMHEwIC0yMSAtMTQuNSAtMzUuNXQtMzUuNSAtMTQuNWgtMTAwMCBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41ek0zMDAgMzUwdjEwMHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjVoODAwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di0xMDBxMCAtMjEgLTE0LjUgLTM1LjV0LTM1LjUgLTE0LjVoLTgwMHEtMjEgMCAtMzUuNSAxNC41dC0xNC41IDM1LjV6TTAgNTB2MTAwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNWgxMTAwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di0xMDAgcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC0xMTAwcS0yMSAwIC0zNS41IDE0LjV0LTE0LjUgMzUuNXoiIC8%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%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDY2OyIgZD0iTTM1MCAxMTAwaDM2MXEtMTY0IC0xNDYgLTIxNiAtMjAwaC0xOTVxLTQxIDAgLTcwLjUgLTI5LjV0LTI5LjUgLTcwLjV2LTUwMHEwIC00MSAyOS41IC03MC41dDcwLjUgLTI5LjVoNTAwcTQxIDAgNzAuNSAyOS41dDI5LjUgNzAuNWwyMDAgMTUzdi0xMDNxMCAtMTY1IC05Mi41IC0yNTcuNXQtMjU3LjUgLTkyLjVoLTQwMHEtMTY1IDAgLTI1Ny41IDkyLjV0LTkyLjUgMjU3LjV2NDAwcTAgMTY1IDkyLjUgMjU3LjV0MjU3LjUgOTIuNXogTTgyNCAxMDczbDMzOSAtMzAxcTggLTcgOCAtMTcuNXQtOCAtMTcuNWwtMzQwIC0zMDZxLTcgLTYgLTEyLjUgLTR0LTYuNSAxMXYyMDNxLTI2IDEgLTU0LjUgMHQtNzguNSAtNy41dC05MiAtMTcuNXQtODYgLTM1dC03MCAtNTdxMTAgNTkgMzMgMTA4dDUxLjUgODEuNXQ2NSA1OC41dDY4LjUgNDAuNXQ2NyAyNC41dDU2IDEzLjV0NDAgNC41djIxMHExIDEwIDYuNSAxMi41dDEzLjUgLTQuNXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDY3OyIgZD0iTTM1MCAxMTAwaDM1MHE2MCAwIDEyNyAtMjNsLTE3OCAtMTc3aC0zNDlxLTQxIDAgLTcwLjUgLTI5LjV0LTI5LjUgLTcwLjV2LTUwMHEwIC00MSAyOS41IC03MC41dDcwLjUgLTI5LjVoNTAwcTQxIDAgNzAuNSAyOS41dDI5LjUgNzAuNXY2OWwyMDAgMjAwdi0yMTlxMCAtMTY1IC05Mi41IC0yNTcuNXQtMjU3LjUgLTkyLjVoLTQwMHEtMTY1IDAgLTI1Ny41IDkyLjV0LTkyLjUgMjU3LjV2NDAwcTAgMTY1IDkyLjUgMjU3LjV0MjU3LjUgOTIuNXogTTY0MyA2MzlsMzk1IDM5NXE3IDcgMTcuNSA3dDE3LjUgLTdsMTAxIC0xMDFxNyAtNyA3IC0xNy41dC03IC0xNy41bC01MzEgLTUzMnEtNyAtNyAtMTcuNSAtN3QtMTcuNSA3bC0yNDggMjQ4cS03IDcgLTcgMTcuNXQ3IDE3LjVsMTAxIDEwMXE3IDcgMTcuNSA3dDE3LjUgLTdsMTExIC0xMTFxOCAtNyAxOCAtN3QxOCA3eiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUwNjg7IiBkPSJNMzE4IDkxOGwyNjQgMjY0cTggOCAxOCA4dDE4IC04bDI2MCAtMjY0cTcgLTggNC41IC0xM3QtMTIuNSAtNWgtMTcwdi0yMDBoMjAwdjE3M3EwIDEwIDUgMTJ0MTMgLTVsMjY0IC0yNjBxOCAtNyA4IC0xNy41dC04IC0xNy41bC0yNjQgLTI2NXEtOCAtNyAtMTMgLTV0LTUgMTJ2MTczaC0yMDB2LTIwMGgxNzBxMTAgMCAxMi41IC01dC00LjUgLTEzbC0yNjAgLTI2NHEtOCAtOCAtMTggLTh0LTE4IDhsLTI2NCAyNjRxLTggOCAtNS41IDEzIHQxMi41IDVoMTc1djIwMGgtMjAwdi0xNzNxMCAtMTAgLTUgLTEydC0xMyA1bC0yNjQgMjY1cS04IDcgLTggMTcuNXQ4IDE3LjVsMjY0IDI2MHE4IDcgMTMgNXQ1IC0xMnYtMTczaDIwMHYyMDBoLTE3NXEtMTAgMCAtMTIuNSA1dDUuNSAxM3oiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDY5OyIgZD0iTTI1MCAxMTAwaDEwMHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtNDM4bDQ2NCA0NTNxMTUgMTQgMjUuNSAxMHQxMC41IC0yNXYtMTAwMHEwIC0yMSAtMTAuNSAtMjV0LTI1LjUgMTBsLTQ2NCA0NTN2LTQzOHEwIC0yMSAtMTQuNSAtMzUuNXQtMzUuNSAtMTQuNWgtMTAwcS0yMSAwIC0zNS41IDE0LjV0LTE0LjUgMzUuNXYxMDAwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDcwOyIgZD0iTTUwIDExMDBoMTAwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di00MzhsNDY0IDQ1M3ExNSAxNCAyNS41IDEwdDEwLjUgLTI1di00MzhsNDY0IDQ1M3ExNSAxNCAyNS41IDEwdDEwLjUgLTI1di0xMDAwcTAgLTIxIC0xMC41IC0yNXQtMjUuNSAxMGwtNDY0IDQ1M3YtNDM4cTAgLTIxIC0xMC41IC0yNXQtMjUuNSAxMGwtNDY0IDQ1M3YtNDM4cTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC0xMDBxLTIxIDAgLTM1LjUgMTQuNSB0LTE0LjUgMzUuNXYxMDAwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDcxOyIgZD0iTTEyMDAgMTA1MHYtMTAwMHEwIC0yMSAtMTAuNSAtMjV0LTI1LjUgMTBsLTQ2NCA0NTN2LTQzOHEwIC0yMSAtMTAuNSAtMjV0LTI1LjUgMTBsLTQ5MiA0ODBxLTE1IDE0IC0xNSAzNXQxNSAzNWw0OTIgNDgwcTE1IDE0IDI1LjUgMTB0MTAuNSAtMjV2LTQzOGw0NjQgNDUzcTE1IDE0IDI1LjUgMTB0MTAuNSAtMjV6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTA3MjsiIGQ9Ik0yNDMgMTA3NGw4MTQgLTQ5OHExOCAtMTEgMTggLTI2dC0xOCAtMjZsLTgxNCAtNDk4cS0xOCAtMTEgLTMwLjUgLTR0LTEyLjUgMjh2MTAwMHEwIDIxIDEyLjUgMjh0MzAuNSAtNHoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDczOyIgZD0iTTI1MCAxMDAwaDIwMHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtODAwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC0yMDBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djgwMHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjV6TTY1MCAxMDAwaDIwMHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtODAwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC0yMDBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djgwMCBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41eiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUwNzQ7IiBkPSJNMTEwMCA5NTB2LTgwMHEwIC0yMSAtMTQuNSAtMzUuNXQtMzUuNSAtMTQuNWgtODAwcS0yMSAwIC0zNS41IDE0LjV0LTE0LjUgMzUuNXY4MDBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41aDgwMHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDc1OyIgZD0iTTUwMCA2MTJ2NDM4cTAgMjEgMTAuNSAyNXQyNS41IC0xMGw0OTIgLTQ4MHExNSAtMTQgMTUgLTM1dC0xNSAtMzVsLTQ5MiAtNDgwcS0xNSAtMTQgLTI1LjUgLTEwdC0xMC41IDI1djQzOGwtNDY0IC00NTNxLTE1IC0xNCAtMjUuNSAtMTB0LTEwLjUgMjV2MTAwMHEwIDIxIDEwLjUgMjV0MjUuNSAtMTB6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTA3NjsiIGQ9Ik0xMDQ4IDExMDJsMTAwIDFxMjAgMCAzNSAtMTQuNXQxNSAtMzUuNWw1IC0xMDAwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41bC0xMDAgLTFxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41bC0yIDQzN2wtNDYzIC00NTRxLTE0IC0xNSAtMjQuNSAtMTAuNXQtMTAuNSAyNS41bC0yIDQzN2wtNDYyIC00NTVxLTE1IC0xNCAtMjUuNSAtOS41dC0xMC41IDI0LjVsLTUgMTAwMHEwIDIxIDEwLjUgMjUuNXQyNS41IC0xMC41bDQ2NiAtNDUwIGwtMiA0MzhxMCAyMCAxMC41IDI0LjV0MjUuNSAtOS41bDQ2NiAtNDUxbC0yIDQzOHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjV6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTA3NzsiIGQ9Ik04NTAgMTEwMGgxMDBxMjEgMCAzNS41IC0xNC41dDE0LjUgLTM1LjV2LTEwMDBxMCAtMjEgLTE0LjUgLTM1LjV0LTM1LjUgLTE0LjVoLTEwMHEtMjEgMCAtMzUuNSAxNC41dC0xNC41IDM1LjV2NDM4bC00NjQgLTQ1M3EtMTUgLTE0IC0yNS41IC0xMHQtMTAuNSAyNXYxMDAwcTAgMjEgMTAuNSAyNXQyNS41IC0xMGw0NjQgLTQ1M3Y0MzhxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41eiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUwNzg7IiBkPSJNNjg2IDEwODFsNTAxIC01NDBxMTUgLTE1IDEwLjUgLTI2dC0yNi41IC0xMWgtMTA0MnEtMjIgMCAtMjYuNSAxMXQxMC41IDI2bDUwMSA1NDBxMTUgMTUgMzYgMTV0MzYgLTE1ek0xNTAgNDAwaDEwMDBxMjEgMCAzNS41IC0xNC41dDE0LjUgLTM1LjV2LTEwMHEwIC0yMSAtMTQuNSAtMzUuNXQtMzUuNSAtMTQuNWgtMTAwMHEtMjEgMCAtMzUuNSAxNC41dC0xNC41IDM1LjV2MTAwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDc5OyIgZD0iTTg4NSA5MDBsLTM1MiAtMzUzbDM1MiAtMzUzbC0xOTcgLTE5OGwtNTUyIDU1Mmw1NTIgNTUweiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUwODA7IiBkPSJNMTA2NCA1NDdsLTU1MSAtNTUxbC0xOTggMTk4bDM1MyAzNTNsLTM1MyAzNTNsMTk4IDE5OHoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDgxOyIgZD0iTTYwMCAxMTc3cTExNyAwIDIyNCAtNDUuNXQxODQuNSAtMTIzdDEyMyAtMTg0LjV0NDUuNSAtMjI0dC00NS41IC0yMjR0LTEyMyAtMTg0LjV0LTE4NC41IC0xMjN0LTIyNCAtNDUuNXQtMjI0IDQ1LjV0LTE4NC41IDEyM3QtMTIzIDE4NC41dC00NS41IDIyNHQ0NS41IDIyNHQxMjMgMTg0LjV0MTg0LjUgMTIzdDIyNCA0NS41ek02NTAgOTAwaC0xMDBxLTIxIDAgLTM1LjUgLTE0LjV0LTE0LjUgLTM1LjV2LTE1MGgtMTUwIHEtMjEgMCAtMzUuNSAtMTQuNXQtMTQuNSAtMzUuNXYtMTAwcTAgLTIxIDE0LjUgLTM1LjV0MzUuNSAtMTQuNWgxNTB2LTE1MHEwIC0yMSAxNC41IC0zNS41dDM1LjUgLTE0LjVoMTAwcTIxIDAgMzUuNSAxNC41dDE0LjUgMzUuNXYxNTBoMTUwcTIxIDAgMzUuNSAxNC41dDE0LjUgMzUuNXYxMDBxMCAyMSAtMTQuNSAzNS41dC0zNS41IDE0LjVoLTE1MHYxNTBxMCAyMSAtMTQuNSAzNS41dC0zNS41IDE0LjV6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTA4MjsiIGQ9Ik02MDAgMTE3N3ExMTcgMCAyMjQgLTQ1LjV0MTg0LjUgLTEyM3QxMjMgLTE4NC41dDQ1LjUgLTIyNHQtNDUuNSAtMjI0dC0xMjMgLTE4NC41dC0xODQuNSAtMTIzdC0yMjQgLTQ1LjV0LTIyNCA0NS41dC0xODQuNSAxMjN0LTEyMyAxODQuNXQtNDUuNSAyMjR0NDUuNSAyMjR0MTIzIDE4NC41dDE4NC41IDEyM3QyMjQgNDUuNXpNODUwIDcwMGgtNTAwcS0yMSAwIC0zNS41IC0xNC41dC0xNC41IC0zNS41di0xMDBxMCAtMjEgMTQuNSAtMzUuNSB0MzUuNSAtMTQuNWg1MDBxMjEgMCAzNS41IDE0LjV0MTQuNSAzNS41djEwMHEwIDIxIC0xNC41IDM1LjV0LTM1LjUgMTQuNXoiIC8%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%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDg2OyIgZD0iTTYwMCAxMTc3cTExNyAwIDIyNCAtNDUuNXQxODQuNSAtMTIzdDEyMyAtMTg0LjV0NDUuNSAtMjI0dC00NS41IC0yMjR0LTEyMyAtMTg0LjV0LTE4NC41IC0xMjN0LTIyNCAtNDUuNXQtMjI0IDQ1LjV0LTE4NC41IDEyM3QtMTIzIDE4NC41dC00NS41IDIyNHQ0NS41IDIyNHQxMjMgMTg0LjV0MTg0LjUgMTIzdDIyNCA0NS41ek02NzUgMTAwMGgtMTUwcS0xMCAwIC0xNy41IC03LjV0LTcuNSAtMTcuNXYtMTUwcTAgLTEwIDcuNSAtMTcuNSB0MTcuNSAtNy41aDE1MHExMCAwIDE3LjUgNy41dDcuNSAxNy41djE1MHEwIDEwIC03LjUgMTcuNXQtMTcuNSA3LjV6TTY3NSA3MDBoLTI1MHEtMTAgMCAtMTcuNSAtNy41dC03LjUgLTE3LjV2LTUwcTAgLTEwIDcuNSAtMTcuNXQxNy41IC03LjVoNzV2LTIwMGgtNzVxLTEwIDAgLTE3LjUgLTcuNXQtNy41IC0xNy41di01MHEwIC0xMCA3LjUgLTE3LjV0MTcuNSAtNy41aDM1MHExMCAwIDE3LjUgNy41dDcuNSAxNy41djUwcTAgMTAgLTcuNSAxNy41IHQtMTcuNSA3LjVoLTc1djI3NXEwIDEwIC03LjUgMTcuNXQtMTcuNSA3LjV6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTA4NzsiIGQ9Ik01MjUgMTIwMGgxNTBxMTAgMCAxNy41IC03LjV0Ny41IC0xNy41di0xOTRxMTAzIC0yNyAxNzguNSAtMTAyLjV0MTAyLjUgLTE3OC41aDE5NHExMCAwIDE3LjUgLTcuNXQ3LjUgLTE3LjV2LTE1MHEwIC0xMCAtNy41IC0xNy41dC0xNy41IC03LjVoLTE5NHEtMjcgLTEwMyAtMTAyLjUgLTE3OC41dC0xNzguNSAtMTAyLjV2LTE5NHEwIC0xMCAtNy41IC0xNy41dC0xNy41IC03LjVoLTE1MHEtMTAgMCAtMTcuNSA3LjV0LTcuNSAxNy41djE5NCBxLTEwMyAyNyAtMTc4LjUgMTAyLjV0LTEwMi41IDE3OC41aC0xOTRxLTEwIDAgLTE3LjUgNy41dC03LjUgMTcuNXYxNTBxMCAxMCA3LjUgMTcuNXQxNy41IDcuNWgxOTRxMjcgMTAzIDEwMi41IDE3OC41dDE3OC41IDEwMi41djE5NHEwIDEwIDcuNSAxNy41dDE3LjUgNy41ek03MDAgODkzdi0xNjhxMCAtMTAgLTcuNSAtMTcuNXQtMTcuNSAtNy41aC0xNTBxLTEwIDAgLTE3LjUgNy41dC03LjUgMTcuNXYxNjhxLTY4IC0yMyAtMTE5IC03NCB0LTc0IC0xMTloMTY4cTEwIDAgMTcuNSAtNy41dDcuNSAtMTcuNXYtMTUwcTAgLTEwIC03LjUgLTE3LjV0LTE3LjUgLTcuNWgtMTY4cTIzIC02OCA3NCAtMTE5dDExOSAtNzR2MTY4cTAgMTAgNy41IDE3LjV0MTcuNSA3LjVoMTUwcTEwIDAgMTcuNSAtNy41dDcuNSAtMTcuNXYtMTY4cTY4IDIzIDExOSA3NHQ3NCAxMTloLTE2OHEtMTAgMCAtMTcuNSA3LjV0LTcuNSAxNy41djE1MHEwIDEwIDcuNSAxNy41dDE3LjUgNy41aDE2OCBxLTIzIDY4IC03NCAxMTl0LTExOSA3NHoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDg4OyIgZD0iTTYwMCAxMTc3cTExNyAwIDIyNCAtNDUuNXQxODQuNSAtMTIzdDEyMyAtMTg0LjV0NDUuNSAtMjI0dC00NS41IC0yMjR0LTEyMyAtMTg0LjV0LTE4NC41IC0xMjN0LTIyNCAtNDUuNXQtMjI0IDQ1LjV0LTE4NC41IDEyM3QtMTIzIDE4NC41dC00NS41IDIyNHQ0NS41IDIyNHQxMjMgMTg0LjV0MTg0LjUgMTIzdDIyNCA0NS41ek02MDAgMTAyN3EtMTE2IDAgLTIxNC41IC01N3QtMTU1LjUgLTE1NS41dC01NyAtMjE0LjV0NTcgLTIxNC41IHQxNTUuNSAtMTU1LjV0MjE0LjUgLTU3dDIxNC41IDU3dDE1NS41IDE1NS41dDU3IDIxNC41dC01NyAyMTQuNXQtMTU1LjUgMTU1LjV0LTIxNC41IDU3ek03NTkgODIzbDY0IC02NHE3IC03IDcgLTE3LjV0LTcgLTE3LjVsLTEyNCAtMTI0bDEyNCAtMTI0cTcgLTcgNyAtMTcuNXQtNyAtMTcuNWwtNjQgLTY0cS03IC03IC0xNy41IC03dC0xNy41IDdsLTEyNCAxMjRsLTEyNCAtMTI0cS03IC03IC0xNy41IC03dC0xNy41IDdsLTY0IDY0IHEtNyA3IC03IDE3LjV0NyAxNy41bDEyNCAxMjRsLTEyNCAxMjRxLTcgNyAtNyAxNy41dDcgMTcuNWw2NCA2NHE3IDcgMTcuNSA3dDE3LjUgLTdsMTI0IC0xMjRsMTI0IDEyNHE3IDcgMTcuNSA3dDE3LjUgLTd6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTA4OTsiIGQ9Ik02MDAgMTE3N3ExMTcgMCAyMjQgLTQ1LjV0MTg0LjUgLTEyM3QxMjMgLTE4NC41dDQ1LjUgLTIyNHQtNDUuNSAtMjI0dC0xMjMgLTE4NC41dC0xODQuNSAtMTIzdC0yMjQgLTQ1LjV0LTIyNCA0NS41dC0xODQuNSAxMjN0LTEyMyAxODQuNXQtNDUuNSAyMjR0NDUuNSAyMjR0MTIzIDE4NC41dDE4NC41IDEyM3QyMjQgNDUuNXpNNjAwIDEwMjdxLTExNiAwIC0yMTQuNSAtNTd0LTE1NS41IC0xNTUuNXQtNTcgLTIxNC41dDU3IC0yMTQuNSB0MTU1LjUgLTE1NS41dDIxNC41IC01N3QyMTQuNSA1N3QxNTUuNSAxNTUuNXQ1NyAyMTQuNXQtNTcgMjE0LjV0LTE1NS41IDE1NS41dC0yMTQuNSA1N3pNNzgyIDc4OGwxMDYgLTEwNnE3IC03IDcgLTE3LjV0LTcgLTE3LjVsLTMyMCAtMzIxcS04IC03IC0xOCAtN3QtMTggN2wtMjAyIDIwM3EtOCA3IC04IDE3LjV0OCAxNy41bDEwNiAxMDZxNyA4IDE3LjUgOHQxNy41IC04bDc5IC03OWwxOTcgMTk3cTcgNyAxNy41IDd0MTcuNSAtN3oiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDkwOyIgZD0iTTYwMCAxMTc3cTExNyAwIDIyNCAtNDUuNXQxODQuNSAtMTIzdDEyMyAtMTg0LjV0NDUuNSAtMjI0dC00NS41IC0yMjR0LTEyMyAtMTg0LjV0LTE4NC41IC0xMjN0LTIyNCAtNDUuNXQtMjI0IDQ1LjV0LTE4NC41IDEyM3QtMTIzIDE4NC41dC00NS41IDIyNHQ0NS41IDIyNHQxMjMgMTg0LjV0MTg0LjUgMTIzdDIyNCA0NS41ek02MDAgMTAyN3EtMTE2IDAgLTIxNC41IC01N3QtMTU1LjUgLTE1NS41dC01NyAtMjE0LjVxMCAtMTIwIDY1IC0yMjUgbDU4NyA1ODdxLTEwNSA2NSAtMjI1IDY1ek05NjUgODE5bC01ODQgLTU4NHExMDQgLTYyIDIxOSAtNjJxMTE2IDAgMjE0LjUgNTd0MTU1LjUgMTU1LjV0NTcgMjE0LjVxMCAxMTUgLTYyIDIxOXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDkxOyIgZD0iTTM5IDU4Mmw1MjIgNDI3cTE2IDEzIDI3LjUgOHQxMS41IC0yNnYtMjkxaDU1MHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtMjAwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC01NTB2LTI5MXEwIC0yMSAtMTEuNSAtMjZ0LTI3LjUgOGwtNTIyIDQyN3EtMTYgMTMgLTE2IDMydDE2IDMyeiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUwOTI7IiBkPSJNNjM5IDEwMDlsNTIyIC00MjdxMTYgLTEzIDE2IC0zMnQtMTYgLTMybC01MjIgLTQyN3EtMTYgLTEzIC0yNy41IC04dC0xMS41IDI2djI5MWgtNTUwcS0yMSAwIC0zNS41IDE0LjV0LTE0LjUgMzUuNXYyMDBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41aDU1MHYyOTFxMCAyMSAxMS41IDI2dDI3LjUgLTh6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTA5MzsiIGQ9Ik02ODIgMTE2MWw0MjcgLTUyMnExMyAtMTYgOCAtMjcuNXQtMjYgLTExLjVoLTI5MXYtNTUwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC0yMDBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djU1MGgtMjkxcS0yMSAwIC0yNiAxMS41dDggMjcuNWw0MjcgNTIycTEzIDE2IDMyIDE2dDMyIC0xNnoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDk0OyIgZD0iTTU1MCAxMjAwaDIwMHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtNTUwaDI5MXEyMSAwIDI2IC0xMS41dC04IC0yNy41bC00MjcgLTUyMnEtMTMgLTE2IC0zMiAtMTZ0LTMyIDE2bC00MjcgNTIycS0xMyAxNiAtOCAyNy41dDI2IDExLjVoMjkxdjU1MHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjV6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTA5NTsiIGQ9Ik02MzkgMTEwOWw1MjIgLTQyN3ExNiAtMTMgMTYgLTMydC0xNiAtMzJsLTUyMiAtNDI3cS0xNiAtMTMgLTI3LjUgLTh0LTExLjUgMjZ2MjkxcS05NCAtMiAtMTgyIC0yMHQtMTcwLjUgLTUydC0xNDcgLTkyLjV0LTEwMC41IC0xMzUuNXE1IDEwNSAyNyAxOTMuNXQ2Ny41IDE2N3QxMTMgMTM1dDE2NyA5MS41dDIyNS41IDQydjI2MnEwIDIxIDExLjUgMjZ0MjcuNSAtOHoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDk2OyIgZD0iTTg1MCAxMjAwaDMwMHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtMzAwcTAgLTIxIC0xMC41IC0yNXQtMjQuNSAxMGwtOTQgOTRsLTI0OSAtMjQ5cS04IC03IC0xOCAtN3QtMTggN2wtMTA2IDEwNnEtNyA4IC03IDE4dDcgMThsMjQ5IDI0OWwtOTQgOTRxLTE0IDE0IC0xMCAyNC41dDI1IDEwLjV6TTM1MCAwaC0zMDBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djMwMHEwIDIxIDEwLjUgMjV0MjQuNSAtMTBsOTQgLTk0bDI0OSAyNDkgcTggNyAxOCA3dDE4IC03bDEwNiAtMTA2cTcgLTggNyAtMTh0LTcgLTE4bC0yNDkgLTI0OWw5NCAtOTRxMTQgLTE0IDEwIC0yNC41dC0yNSAtMTAuNXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMDk3OyIgZD0iTTEwMTQgMTEyMGwxMDYgLTEwNnE3IC04IDcgLTE4dC03IC0xOGwtMjQ5IC0yNDlsOTQgLTk0cTE0IC0xNCAxMCAtMjQuNXQtMjUgLTEwLjVoLTMwMHEtMjEgMCAtMzUuNSAxNC41dC0xNC41IDM1LjV2MzAwcTAgMjEgMTAuNSAyNXQyNC41IC0xMGw5NCAtOTRsMjQ5IDI0OXE4IDcgMTggN3QxOCAtN3pNMjUwIDYwMGgzMDBxMjEgMCAzNS41IC0xNC41dDE0LjUgLTM1LjV2LTMwMHEwIC0yMSAtMTAuNSAtMjV0LTI0LjUgMTBsLTk0IDk0IGwtMjQ5IC0yNDlxLTggLTcgLTE4IC03dC0xOCA3bC0xMDYgMTA2cS03IDggLTcgMTh0NyAxOGwyNDkgMjQ5bC05NCA5NHEtMTQgMTQgLTEwIDI0LjV0MjUgMTAuNXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMTAxOyIgZD0iTTYwMCAxMTc3cTExNyAwIDIyNCAtNDUuNXQxODQuNSAtMTIzdDEyMyAtMTg0LjV0NDUuNSAtMjI0dC00NS41IC0yMjR0LTEyMyAtMTg0LjV0LTE4NC41IC0xMjN0LTIyNCAtNDUuNXQtMjI0IDQ1LjV0LTE4NC41IDEyM3QtMTIzIDE4NC41dC00NS41IDIyNHQ0NS41IDIyNHQxMjMgMTg0LjV0MTg0LjUgMTIzdDIyNCA0NS41ek03MDQgOTAwaC0yMDhxLTIwIDAgLTMyIC0xNC41dC04IC0zNC41bDU4IC0zMDJxNCAtMjAgMjEuNSAtMzQuNSB0MzcuNSAtMTQuNWg1NHEyMCAwIDM3LjUgMTQuNXQyMS41IDM0LjVsNTggMzAycTQgMjAgLTggMzQuNXQtMzIgMTQuNXpNNjc1IDQwMGgtMTUwcS0xMCAwIC0xNy41IC03LjV0LTcuNSAtMTcuNXYtMTUwcTAgLTEwIDcuNSAtMTcuNXQxNy41IC03LjVoMTUwcTEwIDAgMTcuNSA3LjV0Ny41IDE3LjV2MTUwcTAgMTAgLTcuNSAxNy41dC0xNy41IDcuNXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMTAyOyIgZD0iTTI2MCAxMjAwcTkgMCAxOSAtMnQxNSAtNGw1IC0ycTIyIC0xMCA0NCAtMjNsMTk2IC0xMThxMjEgLTEzIDM2IC0yNHEyOSAtMjEgMzcgLTEycTExIDEzIDQ5IDM1bDE5NiAxMThxMjIgMTMgNDUgMjNxMTcgNyAzOCA3cTIzIDAgNDcgLTE2LjV0MzcgLTMzLjVsMTMgLTE2cTE0IC0yMSAxOCAtNDVsMjUgLTEyM2w4IC00NHExIC05IDguNSAtMTQuNXQxNy41IC01LjVoNjFxMTAgMCAxNy41IC03LjV0Ny41IC0xNy41di01MCBxMCAtMTAgLTcuNSAtMTcuNXQtMTcuNSAtNy41aC01MHEtMTAgMCAtMTcuNSAtNy41dC03LjUgLTE3LjV2LTE3NWgtNDAwdjMwMGgtMjAwdi0zMDBoLTQwMHYxNzVxMCAxMCAtNy41IDE3LjV0LTE3LjUgNy41aC01MHEtMTAgMCAtMTcuNSA3LjV0LTcuNSAxNy41djUwcTAgMTAgNy41IDE3LjV0MTcuNSA3LjVoNjFxMTEgMCAxOCAzdDcgOHEwIDQgOSA1MmwyNSAxMjhxNSAyNSAxOSA0NXEyIDMgNSA3dDEzLjUgMTV0MjEuNSAxOS41dDI2LjUgMTUuNSB0MjkuNSA3ek05MTUgMTA3OWwtMTY2IC0xNjJxLTcgLTcgLTUgLTEydDEyIC01aDIxOXExMCAwIDE1IDd0MiAxN2wtNTEgMTQ5cS0zIDEwIC0xMSAxMnQtMTUgLTZ6TTQ2MyA5MTdsLTE3NyAxNTdxLTggNyAtMTYgNXQtMTEgLTEybC01MSAtMTQzcS0zIC0xMCAyIC0xN3QxNSAtN2gyMzFxMTEgMCAxMi41IDV0LTUuNSAxMnpNNTAwIDBoLTM3NXEtMTAgMCAtMTcuNSA3LjV0LTcuNSAxNy41djM3NWg0MDB2LTQwMHpNMTEwMCA0MDB2LTM3NSBxMCAtMTAgLTcuNSAtMTcuNXQtMTcuNSAtNy41aC0zNzV2NDAwaDQwMHoiIC8%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%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMTA3OyIgZD0iTS05MCAxMDBsNjQyIDEwNjZxMjAgMzEgNDggMjguNXQ0OCAtMzUuNWw2NDIgLTEwNTZxMjEgLTMyIDcuNSAtNjcuNXQtNTAuNSAtMzUuNWgtMTI5NHEtMzcgMCAtNTAuNSAzNHQ3LjUgNjZ6TTE1NSAyMDBoMzQ1djc1cTAgMTAgNy41IDE3LjV0MTcuNSA3LjVoMTUwcTEwIDAgMTcuNSAtNy41dDcuNSAtMTcuNXYtNzVoMzQ1bC00NDUgNzIzek00OTYgNzAwaDIwOHEyMCAwIDMyIC0xNC41dDggLTM0LjVsLTU4IC0yNTIgcS00IC0yMCAtMjEuNSAtMzQuNXQtMzcuNSAtMTQuNWgtNTRxLTIwIDAgLTM3LjUgMTQuNXQtMjEuNSAzNC41bC01OCAyNTJxLTQgMjAgOCAzNC41dDMyIDE0LjV6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTEwODsiIGQ9Ik02NTAgMTIwMHE2MiAwIDEwNiAtNDR0NDQgLTEwNnYtMzM5bDM2MyAtMzI1cTE1IC0xNCAyNiAtMzguNXQxMSAtNDQuNXYtNDFxMCAtMjAgLTEyIC0yNi41dC0yOSA1LjVsLTM1OSAyNDl2LTI2M3ExMDAgLTkzIDEwMCAtMTEzdi02NHEwIC0yMSAtMTMgLTI5dC0zMiAxbC0yMDUgMTI4bC0yMDUgLTEyOHEtMTkgLTkgLTMyIC0xdC0xMyAyOXY2NHEwIDIwIDEwMCAxMTN2MjYzbC0zNTkgLTI0OXEtMTcgLTEyIC0yOSAtNS41dC0xMiAyNi41djQxIHEwIDIwIDExIDQ0LjV0MjYgMzguNWwzNjMgMzI1djMzOXEwIDYyIDQ0IDEwNnQxMDYgNDR6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTEwOTsiIGQ9Ik04NTAgMTIwMGgxMDBxMjEgMCAzNS41IC0xNC41dDE0LjUgLTM1LjV2LTUwaDUwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di0xNTBoLTExMDB2MTUwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNWg1MHY1MHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjVoMTAwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di01MGg1MDB2NTBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41ek0xMTAwIDgwMHYtNzUwcTAgLTIxIC0xNC41IC0zNS41IHQtMzUuNSAtMTQuNWgtMTAwMHEtMjEgMCAtMzUuNSAxNC41dC0xNC41IDM1LjV2NzUwaDExMDB6TTEwMCA2MDB2LTEwMGgxMDB2MTAwaC0xMDB6TTMwMCA2MDB2LTEwMGgxMDB2MTAwaC0xMDB6TTUwMCA2MDB2LTEwMGgxMDB2MTAwaC0xMDB6TTcwMCA2MDB2LTEwMGgxMDB2MTAwaC0xMDB6TTkwMCA2MDB2LTEwMGgxMDB2MTAwaC0xMDB6TTEwMCA0MDB2LTEwMGgxMDB2MTAwaC0xMDB6TTMwMCA0MDB2LTEwMGgxMDB2MTAwaC0xMDB6TTUwMCA0MDAgdi0xMDBoMTAwdjEwMGgtMTAwek03MDAgNDAwdi0xMDBoMTAwdjEwMGgtMTAwek05MDAgNDAwdi0xMDBoMTAwdjEwMGgtMTAwek0xMDAgMjAwdi0xMDBoMTAwdjEwMGgtMTAwek0zMDAgMjAwdi0xMDBoMTAwdjEwMGgtMTAwek01MDAgMjAwdi0xMDBoMTAwdjEwMGgtMTAwek03MDAgMjAwdi0xMDBoMTAwdjEwMGgtMTAwek05MDAgMjAwdi0xMDBoMTAwdjEwMGgtMTAweiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUxMTA7IiBkPSJNMTEzNSAxMTY1bDI0OSAtMjMwcTE1IC0xNCAxNSAtMzV0LTE1IC0zNWwtMjQ5IC0yMzBxLTE0IC0xNCAtMjQuNSAtMTB0LTEwLjUgMjV2MTUwaC0xNTlsLTYwMCAtNjAwaC0yOTFxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djEwMHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjVoMjA5bDYwMCA2MDBoMjQxdjE1MHEwIDIxIDEwLjUgMjV0MjQuNSAtMTB6TTUyMiA4MTlsLTE0MSAtMTQxbC0xMjIgMTIyaC0yMDlxLTIxIDAgLTM1LjUgMTQuNSB0LTE0LjUgMzUuNXYxMDBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41aDI5MXpNMTEzNSA1NjVsMjQ5IC0yMzBxMTUgLTE0IDE1IC0zNXQtMTUgLTM1bC0yNDkgLTIzMHEtMTQgLTE0IC0yNC41IC0xMHQtMTAuNSAyNXYxNTBoLTI0MWwtMTgxIDE4MWwxNDEgMTQxbDEyMiAtMTIyaDE1OXYxNTBxMCAyMSAxMC41IDI1dDI0LjUgLTEweiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUxMTE7IiBkPSJNMTAwIDExMDBoMTAwMHE0MSAwIDcwLjUgLTI5LjV0MjkuNSAtNzAuNXYtNjAwcTAgLTQxIC0yOS41IC03MC41dC03MC41IC0yOS41aC01OTZsLTMwNCAtMzAwdjMwMGgtMTAwcS00MSAwIC03MC41IDI5LjV0LTI5LjUgNzAuNXY2MDBxMCA0MSAyOS41IDcwLjV0NzAuNSAyOS41eiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUxMTI7IiBkPSJNMTUwIDEyMDBoMjAwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di0yNTBoLTMwMHYyNTBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41ek04NTAgMTIwMGgyMDBxMjEgMCAzNS41IC0xNC41dDE0LjUgLTM1LjV2LTI1MGgtMzAwdjI1MHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjV6TTExMDAgODAwdi0zMDBxMCAtNDEgLTMgLTc3LjV0LTE1IC04OS41dC0zMiAtOTZ0LTU4IC04OXQtODkgLTc3dC0xMjkgLTUxdC0xNzQgLTIwdC0xNzQgMjAgdC0xMjkgNTF0LTg5IDc3dC01OCA4OXQtMzIgOTZ0LTE1IDg5LjV0LTMgNzcuNXYzMDBoMzAwdi0yNTB2LTI3di00Mi41dDEuNSAtNDF0NSAtMzh0MTAgLTM1dDE2LjUgLTMwdDI1LjUgLTI0LjV0MzUgLTE5dDQ2LjUgLTEydDYwIC00dDYwIDQuNXQ0Ni41IDEyLjV0MzUgMTkuNXQyNSAyNS41dDE3IDMwLjV0MTAgMzV0NSAzOHQyIDQwLjV0LTAuNSA0MnYyNXYyNTBoMzAweiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUxMTM7IiBkPSJNMTEwMCA0MTFsLTE5OCAtMTk5bC0zNTMgMzUzbC0zNTMgLTM1M2wtMTk3IDE5OWw1NTEgNTUxeiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUxMTQ7IiBkPSJNMTEwMSA3ODlsLTU1MCAtNTUxbC01NTEgNTUxbDE5OCAxOTlsMzUzIC0zNTNsMzUzIDM1M3oiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMTE1OyIgZD0iTTQwNCAxMDAwaDc0NnEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtNTUxaDE1MHEyMSAwIDI1IC0xMC41dC0xMCAtMjQuNWwtMjMwIC0yNDlxLTE0IC0xNSAtMzUgLTE1dC0zNSAxNWwtMjMwIDI0OXEtMTQgMTQgLTEwIDI0LjV0MjUgMTAuNWgxNTB2NDAxaC0zODF6TTEzNSA5ODRsMjMwIC0yNDlxMTQgLTE0IDEwIC0yNC41dC0yNSAtMTAuNWgtMTUwdi00MDBoMzg1bDIxNSAtMjAwaC03NTBxLTIxIDAgLTM1LjUgMTQuNSB0LTE0LjUgMzUuNXY1NTBoLTE1MHEtMjEgMCAtMjUgMTAuNXQxMCAyNC41bDIzMCAyNDlxMTQgMTUgMzUgMTV0MzUgLTE1eiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUxMTY7IiBkPSJNNTYgMTIwMGg5NHExNyAwIDMxIC0xMXQxOCAtMjdsMzggLTE2Mmg4OTZxMjQgMCAzOSAtMTguNXQxMCAtNDIuNWwtMTAwIC00NzVxLTUgLTIxIC0yNyAtNDIuNXQtNTUgLTIxLjVoLTYzM2w0OCAtMjAwaDUzNXEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXQtMTQuNSAtMzUuNXQtMzUuNSAtMTQuNWgtNTB2LTUwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41dC0zNS41IDE0LjV0LTE0LjUgMzUuNXY1MGgtMzAwdi01MCBxMCAtMjEgLTE0LjUgLTM1LjV0LTM1LjUgLTE0LjV0LTM1LjUgMTQuNXQtMTQuNSAzNS41djUwaC0zMXEtMTggMCAtMzIuNSAxMHQtMjAuNSAxOWwtNSAxMGwtMjAxIDk2MWgtNTRxLTIwIDAgLTM1IDE0LjV0LTE1IDM1LjV0MTUgMzUuNXQzNSAxNC41eiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUxMTc7IiBkPSJNMTIwMCAxMDAwdi0xMDBoLTEyMDB2MTAwaDIwMHEwIDQxIDI5LjUgNzAuNXQ3MC41IDI5LjVoMzAwcTQxIDAgNzAuNSAtMjkuNXQyOS41IC03MC41aDUwMHpNMCA4MDBoMTIwMHYtODAwaC0xMjAwdjgwMHoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMTE4OyIgZD0iTTIwMCA4MDBsLTIwMCAtNDAwdjYwMGgyMDBxMCA0MSAyOS41IDcwLjV0NzAuNSAyOS41aDMwMHE0MiAwIDcxIC0yOS41dDI5IC03MC41aDUwMHYtMjAwaC0xMDAwek0xNTAwIDcwMGwtMzAwIC03MDBoLTEyMDBsMzAwIDcwMGgxMjAweiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUxMTk7IiBkPSJNNjM1IDExODRsMjMwIC0yNDlxMTQgLTE0IDEwIC0yNC41dC0yNSAtMTAuNWgtMTUwdi02MDFoMTUwcTIxIDAgMjUgLTEwLjV0LTEwIC0yNC41bC0yMzAgLTI0OXEtMTQgLTE1IC0zNSAtMTV0LTM1IDE1bC0yMzAgMjQ5cS0xNCAxNCAtMTAgMjQuNXQyNSAxMC41aDE1MHY2MDFoLTE1MHEtMjEgMCAtMjUgMTAuNXQxMCAyNC41bDIzMCAyNDlxMTQgMTUgMzUgMTV0MzUgLTE1eiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUxMjA7IiBkPSJNOTM2IDg2NGwyNDkgLTIyOXExNCAtMTUgMTQgLTM1LjV0LTE0IC0zNS41bC0yNDkgLTIyOXEtMTUgLTE1IC0yNS41IC0xMC41dC0xMC41IDI0LjV2MTUxaC02MDB2LTE1MXEwIC0yMCAtMTAuNSAtMjQuNXQtMjUuNSAxMC41bC0yNDkgMjI5cS0xNCAxNSAtMTQgMzUuNXQxNCAzNS41bDI0OSAyMjlxMTUgMTUgMjUuNSAxMC41dDEwLjUgLTI1LjV2LTE0OWg2MDB2MTQ5cTAgMjEgMTAuNSAyNS41dDI1LjUgLTEwLjV6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTEyMTsiIGQ9Ik0xMTY5IDQwMGwtMTcyIDczMnEtNSAyMyAtMjMgNDUuNXQtMzggMjIuNWgtNjcycS0yMCAwIC0zOCAtMjB0LTIzIC00MWwtMTcyIC03MzloMTEzOHpNMTEwMCAzMDBoLTEwMDBxLTQxIDAgLTcwLjUgLTI5LjV0LTI5LjUgLTcwLjV2LTEwMHEwIC00MSAyOS41IC03MC41dDcwLjUgLTI5LjVoMTAwMHE0MSAwIDcwLjUgMjkuNXQyOS41IDcwLjV2MTAwcTAgNDEgLTI5LjUgNzAuNXQtNzAuNSAyOS41ek04MDAgMTAwdjEwMGgxMDB2LTEwMGgtMTAwIHpNMTAwMCAxMDB2MTAwaDEwMHYtMTAwaC0xMDB6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTEyMjsiIGQ9Ik0xMTUwIDExMDBxMjEgMCAzNS41IC0xNC41dDE0LjUgLTM1LjV2LTg1MHEwIC0yMSAtMTQuNSAtMzUuNXQtMzUuNSAtMTQuNXQtMzUuNSAxNC41dC0xNC41IDM1LjV2ODUwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNXpNMTAwMCAyMDBsLTY3NSAyMDBoLTM4bDQ3IC0yNzZxMyAtMTYgLTUuNSAtMjB0LTI5LjUgLTRoLTdoLTg0cS0yMCAwIC0zNC41IDE0dC0xOC41IDM1cS01NSAzMzcgLTU1IDM1MXYyNTB2NnEwIDE2IDEgMjMuNXQ2LjUgMTQgdDE3LjUgNi41aDIwMGw2NzUgMjUwdi04NTB6TTAgNzUwdi0yNTBxLTQgMCAtMTEgMC41dC0yNCA2dC0zMCAxNXQtMjQgMzB0LTExIDQ4LjV2NTBxMCAyNiAxMC41IDQ2dDI1IDMwdDI5IDE2dDI1LjUgN3oiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMTIzOyIgZD0iTTU1MyAxMjAwaDk0cTIwIDAgMjkgLTEwLjV0MyAtMjkuNWwtMTggLTM3cTgzIC0xOSAxNDQgLTgyLjV0NzYgLTE0MC41bDYzIC0zMjdsMTE4IC0xNzNoMTdxMTkgMCAzMyAtMTQuNXQxNCAtMzV0LTEzIC00MC41dC0zMSAtMjdxLTggLTQgLTIzIC05LjV0LTY1IC0xOS41dC0xMDMgLTI1dC0xMzIuNSAtMjB0LTE1OC41IC05cS01NyAwIC0xMTUgNXQtMTA0IDEydC04OC41IDE1LjV0LTczLjUgMTcuNXQtNTQuNSAxNnQtMzUuNSAxMmwtMTEgNCBxLTE4IDggLTMxIDI4dC0xMyA0MC41dDE0IDM1dDMzIDE0LjVoMTdsMTE4IDE3M2w2MyAzMjdxMTUgNzcgNzYgMTQwdDE0NCA4M2wtMTggMzJxLTYgMTkgMy41IDMydDI4LjUgMTN6TTQ5OCAxMTBxNTAgLTYgMTAyIC02cTUzIDAgMTAyIDZxLTEyIC00OSAtMzkuNSAtNzkuNXQtNjIuNSAtMzAuNXQtNjMgMzAuNXQtMzkgNzkuNXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMTI0OyIgZD0iTTgwMCA5NDZsMjI0IDc4bC03OCAtMjI0bDIzNCAtNDVsLTE4MCAtMTU1bDE4MCAtMTU1bC0yMzQgLTQ1bDc4IC0yMjRsLTIyNCA3OGwtNDUgLTIzNGwtMTU1IDE4MGwtMTU1IC0xODBsLTQ1IDIzNGwtMjI0IC03OGw3OCAyMjRsLTIzNCA0NWwxODAgMTU1bC0xODAgMTU1bDIzNCA0NWwtNzggMjI0bDIyNCAtNzhsNDUgMjM0bDE1NSAtMTgwbDE1NSAxODB6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTEyNTsiIGQ9Ik02NTAgMTIwMGg1MHE0MCAwIDcwIC00MC41dDMwIC04NC41di0xNTBsLTI4IC0xMjVoMzI4cTQwIDAgNzAgLTQwLjV0MzAgLTg0LjV2LTEwMHEwIC00NSAtMjkgLTc0bC0yMzggLTM0NHEtMTYgLTI0IC0zOCAtNDAuNXQtNDUgLTE2LjVoLTI1MHEtNyAwIC00MiAyNXQtNjYgNTBsLTMxIDI1aC02MXEtNDUgMCAtNzIuNSAxOHQtMjcuNSA1N3Y0MDBxMCAzNiAyMCA2M2wxNDUgMTk2bDk2IDE5OHExMyAyOCAzNy41IDQ4dDUxLjUgMjB6IE02NTAgMTEwMGwtMTAwIC0yMTJsLTE1MCAtMjEzdi0zNzVoMTAwbDEzNiAtMTAwaDIxNGwyNTAgMzc1djEyNWgtNDUwbDUwIDIyNXYxNzVoLTUwek01MCA4MDBoMTAwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di01MDBxMCAtMjEgLTE0LjUgLTM1LjV0LTM1LjUgLTE0LjVoLTEwMHEtMjEgMCAtMzUuNSAxNC41dC0xNC41IDM1LjV2NTAwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNXoiIC8%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%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMTMyOyIgZD0iTTYwMCAxMTc4cTExOCAwIDIyNSAtNDUuNXQxODQuNSAtMTIzdDEyMyAtMTg0LjV0NDUuNSAtMjI1dC00NS41IC0yMjV0LTEyMyAtMTg0LjV0LTE4NC41IC0xMjN0LTIyNSAtNDUuNXQtMjI1IDQ1LjV0LTE4NC41IDEyM3QtMTIzIDE4NC41dC00NS41IDIyNXQ0NS41IDIyNXQxMjMgMTg0LjV0MTg0LjUgMTIzdDIyNSA0NS41ek01NjEgODU1bC0yNzUgLTIyM3EtMTYgLTEzIC0xNiAtMzJ0MTYgLTMybDI3NSAtMjIzcTE2IC0xMyAyNy41IC04IHQxMS41IDI2djEzN2gyNzVxMTAgMCAxNy41IDcuNXQ3LjUgMTcuNXYxNTBxMCAxMCAtNy41IDE3LjV0LTE3LjUgNy41aC0yNzV2MTM3cTAgMjEgLTExLjUgMjZ0LTI3LjUgLTh6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTEzMzsiIGQ9Ik02MDAgMTE3OHExMTggMCAyMjUgLTQ1LjV0MTg0LjUgLTEyM3QxMjMgLTE4NC41dDQ1LjUgLTIyNXQtNDUuNSAtMjI1dC0xMjMgLTE4NC41dC0xODQuNSAtMTIzdC0yMjUgLTQ1LjV0LTIyNSA0NS41dC0xODQuNSAxMjN0LTEyMyAxODQuNXQtNDUuNSAyMjV0NDUuNSAyMjV0MTIzIDE4NC41dDE4NC41IDEyM3QyMjUgNDUuNXpNODU1IDYzOWwtMjIzIDI3NXEtMTMgMTYgLTMyIDE2dC0zMiAtMTZsLTIyMyAtMjc1cS0xMyAtMTYgLTggLTI3LjUgdDI2IC0xMS41aDEzN3YtMjc1cTAgLTEwIDcuNSAtMTcuNXQxNy41IC03LjVoMTUwcTEwIDAgMTcuNSA3LjV0Ny41IDE3LjV2Mjc1aDEzN3EyMSAwIDI2IDExLjV0LTggMjcuNXoiIC8%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%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMTM2OyIgZD0iTTc1NiAxMTU3cTE2NCA5MiAzMDYgLTlsLTI1OSAtMTM4bDE0NSAtMjMybDI1MSAxMjZxNiAtODkgLTM0IC0xNTYuNXQtMTE3IC0xMTAuNXEtNjAgLTM0IC0xMjcgLTM5LjV0LTEyNiAxNi41bC01OTYgLTU5NnEtMTUgLTE2IC0zNi41IC0xNnQtMzYuNSAxNmwtMTExIDExMHEtMTUgMTUgLTE1IDM2LjV0MTUgMzcuNWw2MDAgNTk5cS0zNCAxMDEgNS41IDIwMS41dDEzNS41IDE1NC41eiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUxMzc7IiBob3Jpei1hZHYteD0iMTIyMCIgZD0iTTEwMCAxMTk2aDEwMDBxNDEgMCA3MC41IC0yOS41dDI5LjUgLTcwLjV2LTEwMHEwIC00MSAtMjkuNSAtNzAuNXQtNzAuNSAtMjkuNWgtMTAwMHEtNDEgMCAtNzAuNSAyOS41dC0yOS41IDcwLjV2MTAwcTAgNDEgMjkuNSA3MC41dDcwLjUgMjkuNXpNMTEwMCAxMDk2aC0yMDB2LTEwMGgyMDB2MTAwek0xMDAgNzk2aDEwMDBxNDEgMCA3MC41IC0yOS41dDI5LjUgLTcwLjV2LTEwMHEwIC00MSAtMjkuNSAtNzAuNXQtNzAuNSAtMjkuNWgtMTAwMCBxLTQxIDAgLTcwLjUgMjkuNXQtMjkuNSA3MC41djEwMHEwIDQxIDI5LjUgNzAuNXQ3MC41IDI5LjV6TTExMDAgNjk2aC01MDB2LTEwMGg1MDB2MTAwek0xMDAgMzk2aDEwMDBxNDEgMCA3MC41IC0yOS41dDI5LjUgLTcwLjV2LTEwMHEwIC00MSAtMjkuNSAtNzAuNXQtNzAuNSAtMjkuNWgtMTAwMHEtNDEgMCAtNzAuNSAyOS41dC0yOS41IDcwLjV2MTAwcTAgNDEgMjkuNSA3MC41dDcwLjUgMjkuNXpNMTEwMCAyOTZoLTMwMHYtMTAwaDMwMHYxMDB6ICIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUxMzg7IiBkPSJNMTUwIDEyMDBoOTAwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41dC0xNC41IC0zNS41dC0zNS41IC0xNC41aC05MDBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41dDE0LjUgMzUuNXQzNS41IDE0LjV6TTcwMCA1MDB2LTMwMGwtMjAwIC0yMDB2NTAwbC0zNTAgNTAwaDkwMHoiIC8%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%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMTQzOyIgZD0iTTY0OSA5NDlxNDggNjggMTA5LjUgMTA0dDEyMS41IDM4LjV0MTE4LjUgLTIwdDEwMi41IC02NHQ3MSAtMTAwLjV0MjcgLTEyM3EwIC01NyAtMzMuNSAtMTE3LjV0LTk0IC0xMjQuNXQtMTI2LjUgLTEyNy41dC0xNTAgLTE1Mi41dC0xNDYgLTE3NHEtNjIgODUgLTE0NS41IDE3NHQtMTUwIDE1Mi41dC0xMjYuNSAxMjcuNXQtOTMuNSAxMjQuNXQtMzMuNSAxMTcuNXEwIDY0IDI4IDEyM3Q3MyAxMDAuNXQxMDQgNjR0MTE5IDIwIHQxMjAuNSAtMzguNXQxMDQuNSAtMTA0ek04OTYgOTcycS0zMyAwIC02NC41IC0xOXQtNTYuNSAtNDZ0LTQ3LjUgLTUzLjV0LTQzLjUgLTQ1LjV0LTM3LjUgLTE5dC0zNiAxOXQtNDAgNDUuNXQtNDMgNTMuNXQtNTQgNDZ0LTY1LjUgMTlxLTY3IDAgLTEyMi41IC01NS41dC01NS41IC0xMzIuNXEwIC0yMyAxMy41IC01MXQ0NiAtNjV0NTcuNSAtNjN0NzYgLTc1bDIyIC0yMnExNSAtMTQgNDQgLTQ0dDUwLjUgLTUxdDQ2IC00NHQ0MSAtMzV0MjMgLTEyIHQyMy41IDEydDQyLjUgMzZ0NDYgNDR0NTIuNSA1MnQ0NCA0M3E0IDQgMTIgMTNxNDMgNDEgNjMuNSA2MnQ1MiA1NXQ0NiA1NXQyNiA0NnQxMS41IDQ0cTAgNzkgLTUzIDEzMy41dC0xMjAgNTQuNXoiIC8%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%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMTUxOyIgZD0iTTEwMDAgNzAwaC0xMDB2MTAwaC0xMDB2LTEwMGgtMTAwdjUwMGgzMDB2LTUwMHpNNDAwIDMwMGgxNTBxMjEgMCAyNSAtMTF0LTEwIC0yNWwtMjMwIC0yNTBxLTE0IC0xNSAtMzUgLTE1dC0zNSAxNWwtMjMwIDI1MHEtMTQgMTQgLTEwIDI1dDI1IDExaDE1MHY5MDBoMjAwdi05MDB6TTgwMSAxMTAwdi0yMDBoMTAwdjIwMGgtMTAwek0xMDAwIDM1MGwtMjAwIC0yNTBoMjAwdi0xMDBoLTMwMHYxNTBsMjAwIDI1MGgtMjAwdjEwMGgzMDB2LTE1MHogIiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTE1MjsiIGQ9Ik00MDAgMzAwaDE1MHEyMSAwIDI1IC0xMXQtMTAgLTI1bC0yMzAgLTI1MHEtMTQgLTE1IC0zNSAtMTV0LTM1IDE1bC0yMzAgMjUwcS0xNCAxNCAtMTAgMjV0MjUgMTFoMTUwdjkwMGgyMDB2LTkwMHpNMTAwMCAxMDUwbC0yMDAgLTI1MGgyMDB2LTEwMGgtMzAwdjE1MGwyMDAgMjUwaC0yMDB2MTAwaDMwMHYtMTUwek0xMDAwIDBoLTEwMHYxMDBoLTEwMHYtMTAwaC0xMDB2NTAwaDMwMHYtNTAwek04MDEgNDAwdi0yMDBoMTAwdjIwMGgtMTAweiAiIC8%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%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMTYwOyIgZD0iTTM1MCAxMTAwaDQwMHExNjUgMCAyNTcuNSAtOTIuNXQ5Mi41IC0yNTcuNXYtNDAwcTAgLTE2MyAtOTIuNSAtMjU2LjV0LTI1Ny41IC05My41aC00MDBxLTE2MyAwIC0yNTYuNSA5NHQtOTMuNSAyNTZ2NDAwcTAgMTY1IDkyLjUgMjU3LjV0MjU3LjUgOTIuNXpNODAwIDkwMGgtNTAwcS00MSAwIC03MC41IC0yOS41dC0yOS41IC03MC41di01MDBxMCAtNDEgMjkuNSAtNzAuNXQ3MC41IC0yOS41aDUwMHE0MSAwIDcwLjUgMjkuNXQyOS41IDcwLjUgdjUwMHEwIDQxIC0yOS41IDcwLjV0LTcwLjUgMjkuNXpNNTgwIDY5M2wxOTAgLTI1M3ExMiAtMTYgNi41IC0yOHQtMjYuNSAtMTJoLTQwMHEtMjEgMCAtMjYuNSAxMnQ2LjUgMjhsMTkwIDI1M3ExMiAxNyAzMCAxN3QzMCAtMTd6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTE2MTsiIGQ9Ik01NTAgMTEwMGg0MDBxMTY1IDAgMjU3LjUgLTkyLjV0OTIuNSAtMjU3LjV2LTQwMHEwIC0xNjUgLTkyLjUgLTI1Ny41dC0yNTcuNSAtOTIuNWgtNDAwcS0yMSAwIC0zNS41IDE0LjV0LTE0LjUgMzUuNXYxMDBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41aDQ1MHE0MSAwIDcwLjUgMjkuNXQyOS41IDcwLjV2NTAwcTAgNDEgLTI5LjUgNzAuNXQtNzAuNSAyOS41aC00NTBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djEwMCBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41ek0zMzggODY3bDMyNCAtMjg0cTE2IC0xNCAxNiAtMzN0LTE2IC0zM2wtMzI0IC0yODRxLTE2IC0xNCAtMjcgLTl0LTExIDI2djE1MGgtMjUwcS0yMSAwIC0zNS41IDE0LjV0LTE0LjUgMzUuNXYyMDBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41aDI1MHYxNTBxMCAyMSAxMSAyNnQyNyAtOXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMTYyOyIgZD0iTTc5MyAxMTgybDkgLTlxOCAtMTAgNSAtMjdxLTMgLTExIC03OSAtMjI1LjV0LTc4IC0yMjEuNWwzMDAgMXEyNCAwIDMyLjUgLTE3LjV0LTUuNSAtMzUuNXEtMSAwIC0xMzMuNSAtMTU1dC0yNjcgLTMxMi41dC0xMzguNSAtMTYyLjVxLTEyIC0xNSAtMjYgLTE1aC05bC05IDhxLTkgMTEgLTQgMzJxMiA5IDQyIDEyMy41dDc5IDIyNC41bDM5IDExMGgtMzAycS0yMyAwIC0zMSAxOXEtMTAgMjEgNiA0MXE3NSA4NiAyMDkuNSAyMzcuNSB0MjI4IDI1N3Q5OC41IDExMS41cTkgMTYgMjUgMTZoOXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMTYzOyIgZD0iTTM1MCAxMTAwaDQwMHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtMTAwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC00NTBxLTQxIDAgLTcwLjUgLTI5LjV0LTI5LjUgLTcwLjV2LTUwMHEwIC00MSAyOS41IC03MC41dDcwLjUgLTI5LjVoNDUwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di0xMDBxMCAtMjEgLTE0LjUgLTM1LjV0LTM1LjUgLTE0LjVoLTQwMHEtMTY1IDAgLTI1Ny41IDkyLjV0LTkyLjUgMjU3LjV2NDAwIHEwIDE2NSA5Mi41IDI1Ny41dDI1Ny41IDkyLjV6TTkzOCA4NjdsMzI0IC0yODRxMTYgLTE0IDE2IC0zM3QtMTYgLTMzbC0zMjQgLTI4NHEtMTYgLTE0IC0yNyAtOXQtMTEgMjZ2MTUwaC0yNTBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djIwMHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjVoMjUwdjE1MHEwIDIxIDExIDI2dDI3IC05eiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUxNjQ7IiBkPSJNNzUwIDEyMDBoNDAwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di00MDBxMCAtMjEgLTEwLjUgLTI1dC0yNC41IDEwbC0xMDkgMTA5bC0zMTIgLTMxMnEtMTUgLTE1IC0zNS41IC0xNXQtMzUuNSAxNWwtMTQxIDE0MXEtMTUgMTUgLTE1IDM1LjV0MTUgMzUuNWwzMTIgMzEybC0xMDkgMTA5cS0xNCAxNCAtMTAgMjQuNXQyNSAxMC41ek00NTYgOTAwaC0xNTZxLTQxIDAgLTcwLjUgLTI5LjV0LTI5LjUgLTcwLjV2LTUwMCBxMCAtNDEgMjkuNSAtNzAuNXQ3MC41IC0yOS41aDUwMHE0MSAwIDcwLjUgMjkuNXQyOS41IDcwLjV2MTQ4bDIwMCAyMDB2LTI5OHEwIC0xNjUgLTkzLjUgLTI1Ny41dC0yNTYuNSAtOTIuNWgtNDAwcS0xNjUgMCAtMjU3LjUgOTIuNXQtOTIuNSAyNTcuNXY0MDBxMCAxNjUgOTIuNSAyNTcuNXQyNTcuNSA5Mi41aDMwMHoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMTY1OyIgZD0iTTYwMCAxMTg2cTExOSAwIDIyNy41IC00Ni41dDE4NyAtMTI1dDEyNSAtMTg3dDQ2LjUgLTIyNy41dC00Ni41IC0yMjcuNXQtMTI1IC0xODd0LTE4NyAtMTI1dC0yMjcuNSAtNDYuNXQtMjI3LjUgNDYuNXQtMTg3IDEyNXQtMTI1IDE4N3QtNDYuNSAyMjcuNXQ0Ni41IDIyNy41dDEyNSAxODd0MTg3IDEyNXQyMjcuNSA0Ni41ek02MDAgMTAyMnEtMTE1IDAgLTIxMiAtNTYuNXQtMTUzLjUgLTE1My41dC01Ni41IC0yMTJ0NTYuNSAtMjEyIHQxNTMuNSAtMTUzLjV0MjEyIC01Ni41dDIxMiA1Ni41dDE1My41IDE1My41dDU2LjUgMjEydC01Ni41IDIxMnQtMTUzLjUgMTUzLjV0LTIxMiA1Ni41ek02MDAgNzk0cTgwIDAgMTM3IC01N3Q1NyAtMTM3dC01NyAtMTM3dC0xMzcgLTU3dC0xMzcgNTd0LTU3IDEzN3Q1NyAxMzd0MTM3IDU3eiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUxNjY7IiBkPSJNNDUwIDEyMDBoMjAwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di0zNTBoMjQ1cTIwIDAgMjUgLTExdC05IC0yNmwtMzgzIC00MjZxLTE0IC0xNSAtMzMuNSAtMTV0LTMyLjUgMTVsLTM3OSA0MjZxLTEzIDE1IC04LjUgMjZ0MjUuNSAxMWgyNTB2MzUwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNXpNNTAgMzAwaDEwMDBxMjEgMCAzNS41IC0xNC41dDE0LjUgLTM1LjV2LTI1MGgtMTEwMHYyNTBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41eiBNOTAwIDIwMHYtNTBoMTAwdjUwaC0xMDB6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTE2NzsiIGQ9Ik01ODMgMTE4MmwzNzggLTQzNXExNCAtMTUgOSAtMzF0LTI2IC0xNmgtMjQ0di0yNTBxMCAtMjAgLTE3IC0zNXQtMzkgLTE1aC0yMDBxLTIwIDAgLTMyIDE0LjV0LTEyIDM1LjV2MjUwaC0yNTBxLTIwIDAgLTI1LjUgMTYuNXQ4LjUgMzEuNWwzODMgNDMxcTE0IDE2IDMzLjUgMTd0MzMuNSAtMTR6TTUwIDMwMGgxMDAwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di0yNTBoLTExMDB2MjUwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNXogTTkwMCAyMDB2LTUwaDEwMHY1MGgtMTAweiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUxNjg7IiBkPSJNMzk2IDcyM2wzNjkgMzY5cTcgNyAxNy41IDd0MTcuNSAtN2wxMzkgLTEzOXE3IC04IDcgLTE4LjV0LTcgLTE3LjVsLTUyNSAtNTI1cS03IC04IC0xNy41IC04dC0xNy41IDhsLTI5MiAyOTFxLTcgOCAtNyAxOHQ3IDE4bDEzOSAxMzlxOCA3IDE4LjUgN3QxNy41IC03ek01MCAzMDBoMTAwMHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtMjUwaC0xMTAwdjI1MHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjV6TTkwMCAyMDB2LTUwaDEwMHY1MCBoLTEwMHoiIC8%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%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMTc4OyIgZD0iTTkzNSAxMTY1bDI0OCAtMjMwcTE0IC0xNCAxNCAtMzV0LTE0IC0zNWwtMjQ4IC0yMzBxLTE0IC0xNCAtMjQuNSAtMTB0LTEwLjUgMjV2MTUwaC00MDB2MjAwaDQwMHYxNTBxMCAyMSAxMC41IDI1dDI0LjUgLTEwek0yMDAgODAwaC01MHEtMjEgMCAtMzUuNSAxNC41dC0xNC41IDM1LjV2MTAwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNWg1MHYtMjAwek00MDAgODAwaC0xMDB2MjAwaDEwMHYtMjAwek0xOCA0MzVsMjQ3IDIzMCBxMTQgMTQgMjQuNSAxMHQxMC41IC0yNXYtMTUwaDQwMHYtMjAwaC00MDB2LTE1MHEwIC0yMSAtMTAuNSAtMjV0LTI0LjUgMTBsLTI0NyAyMzBxLTE1IDE0IC0xNSAzNXQxNSAzNXpNOTAwIDMwMGgtMTAwdjIwMGgxMDB2LTIwMHpNMTAwMCA1MDBoNTFxMjAgMCAzNC41IC0xNC41dDE0LjUgLTM1LjV2LTEwMHEwIC0yMSAtMTQuNSAtMzUuNXQtMzQuNSAtMTQuNWgtNTF2MjAweiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUxNzk7IiBkPSJNODYyIDEwNzNsMjc2IDExNnEyNSAxOCA0My41IDh0MTguNSAtNDF2LTExMDZxMCAtMjEgLTE0LjUgLTM1LjV0LTM1LjUgLTE0LjVoLTIwMHEtMjEgMCAtMzUuNSAxNC41dC0xNC41IDM1LjV2Mzk3cS00IDEgLTExIDV0LTI0IDE3LjV0LTMwIDI5dC0yNCA0MnQtMTEgNTYuNXYzNTlxMCAzMSAxOC41IDY1dDQzLjUgNTJ6TTU1MCAxMjAwcTIyIDAgMzQuNSAtMTIuNXQxNC41IC0yNC41bDEgLTEzdi00NTBxMCAtMjggLTEwLjUgLTU5LjUgdC0yNSAtNTZ0LTI5IC00NXQtMjUuNSAtMzEuNWwtMTAgLTExdi00NDdxMCAtMjEgLTE0LjUgLTM1LjV0LTM1LjUgLTE0LjVoLTIwMHEtMjEgMCAtMzUuNSAxNC41dC0xNC41IDM1LjV2NDQ3cS00IDQgLTExIDExLjV0LTI0IDMwLjV0LTMwIDQ2dC0yNCA1NXQtMTEgNjB2NDUwcTAgMiAwLjUgNS41dDQgMTJ0OC41IDE1dDE0LjUgMTJ0MjIuNSA1LjVxMjAgMCAzMi41IC0xMi41dDE0LjUgLTI0LjVsMyAtMTN2LTM1MGgxMDB2MzUwdjUuNXQyLjUgMTIgdDcgMTV0MTUgMTJ0MjUuNSA1LjVxMjMgMCAzNS41IC0xMi41dDEzLjUgLTI0LjVsMSAtMTN2LTM1MGgxMDB2MzUwcTAgMiAwLjUgNS41dDMgMTJ0NyAxNXQxNSAxMnQyNC41IDUuNXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMTgwOyIgZD0iTTEyMDAgMTEwMHYtNTZxLTQgMCAtMTEgLTAuNXQtMjQgLTN0LTMwIC03LjV0LTI0IC0xNXQtMTEgLTI0di04ODhxMCAtMjIgMjUgLTM0LjV0NTAgLTEzLjVsMjUgLTJ2LTU2aC00MDB2NTZxNzUgMCA4Ny41IDYuNXQxMi41IDQzLjV2Mzk0aC01MDB2LTM5NHEwIC0zNyAxMi41IC00My41dDg3LjUgLTYuNXYtNTZoLTQwMHY1NnE0IDAgMTEgMC41dDI0IDN0MzAgNy41dDI0IDE1dDExIDI0djg4OHEwIDIyIC0yNSAzNC41dC01MCAxMy41IGwtMjUgMnY1Nmg0MDB2LTU2cS03NSAwIC04Ny41IC02LjV0LTEyLjUgLTQzLjV2LTM5NGg1MDB2Mzk0cTAgMzcgLTEyLjUgNDMuNXQtODcuNSA2LjV2NTZoNDAweiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUxODE7IiBkPSJNNjc1IDEwMDBoMzc1cTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di0xNTBoLTEwNWwtMjk1IC05OHY5OGwtMjAwIDIwMGgtNDAwbDEwMCAxMDBoMzc1ek0xMDAgOTAwaDMwMHE0MSAwIDcwLjUgLTI5LjV0MjkuNSAtNzAuNXYtNTAwcTAgLTQxIC0yOS41IC03MC41dC03MC41IC0yOS41aC0zMDBxLTQxIDAgLTcwLjUgMjkuNXQtMjkuNSA3MC41djUwMHEwIDQxIDI5LjUgNzAuNXQ3MC41IDI5LjV6TTEwMCA4MDB2LTIwMGgzMDB2MjAwIGgtMzAwek0xMTAwIDUzNWwtNDAwIC0xMzN2MTYzbDQwMCAxMzN2LTE2M3pNMTAwIDUwMHYtMjAwaDMwMHYyMDBoLTMwMHpNMTEwMCAzOTh2LTI0OHEwIC0yMSAtMTQuNSAtMzUuNXQtMzUuNSAtMTQuNWgtMzc1bC0xMDAgLTEwMGgtMzc1bC0xMDAgMTAwaDQwMGwyMDAgMjAwaDEwNXoiIC8%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%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMTg4OyIgZD0iTTIwMCAxMTAwaDcwMHExMjQgMCAyMTIgLTg4dDg4IC0yMTJ2LTUwMHEwIC0xMjQgLTg4IC0yMTJ0LTIxMiAtODhoLTcwMHEtMTI0IDAgLTIxMiA4OHQtODggMjEydjUwMHEwIDEyNCA4OCAyMTJ0MjEyIDg4ek0xMDAgOTAwdi03MDBoOTAwdjcwMGgtOTAwek01MDAgNzAwaC0yMDB2LTMwMGgyMDB2LTEwMGgtMzAwdjUwMGgzMDB2LTEwMHpNOTAwIDcwMGgtMjAwdi0zMDBoMjAwdi0xMDBoLTMwMHY1MDBoMzAwdi0xMDB6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTE4OTsiIGQ9Ik0yMDAgMTEwMGg3MDBxMTI0IDAgMjEyIC04OHQ4OCAtMjEydi01MDBxMCAtMTI0IC04OCAtMjEydC0yMTIgLTg4aC03MDBxLTEyNCAwIC0yMTIgODh0LTg4IDIxMnY1MDBxMCAxMjQgODggMjEydDIxMiA4OHpNMTAwIDkwMHYtNzAwaDkwMHY3MDBoLTkwMHpNNTAwIDQwMGwtMzAwIDE1MGwzMDAgMTUwdi0zMDB6TTkwMCA1NTBsLTMwMCAtMTUwdjMwMHoiIC8%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%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMTk1OyIgZD0iTTYwMCAxMTkxcTEyMCAwIDIyOS41IC00N3QxODguNSAtMTI2dDEyNiAtMTg4LjV0NDcgLTIyOS41dC00NyAtMjI5LjV0LTEyNiAtMTg4LjV0LTE4OC41IC0xMjZ0LTIyOS41IC00N3QtMjI5LjUgNDd0LTE4OC41IDEyNnQtMTI2IDE4OC41dC00NyAyMjkuNXQ0NyAyMjkuNXQxMjYgMTg4LjV0MTg4LjUgMTI2dDIyOS41IDQ3ek02MDAgMTAyMXEtMTE0IDAgLTIxMSAtNTYuNXQtMTUzLjUgLTE1My41dC01Ni41IC0yMTF0NTYuNSAtMjExIHQxNTMuNSAtMTUzLjV0MjExIC01Ni41dDIxMSA1Ni41dDE1My41IDE1My41dDU2LjUgMjExdC01Ni41IDIxMXQtMTUzLjUgMTUzLjV0LTIxMSA1Ni41ek04MDAgNzAwdi0xMDBsLTUwIC01MGwxMDAgLTEwMHYtNTBoLTEwMGwtMTAwIDEwMGgtMTUwdi0xMDBoLTEwMHY0MDBoMzAwek01MDAgNzAwdi0xMDBoMjAwdjEwMGgtMjAweiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUxOTc7IiBkPSJNNTAzIDEwODlxMTEwIDAgMjAwLjUgLTU5LjV0MTM0LjUgLTE1Ni41cTQ0IDE0IDkwIDE0cTEyMCAwIDIwNSAtODYuNXQ4NSAtMjA3dC04NSAtMjA3dC0yMDUgLTg2LjVoLTEyOHYyNTBxMCAyMSAtMTQuNSAzNS41dC0zNS41IDE0LjVoLTMwMHEtMjEgMCAtMzUuNSAtMTQuNXQtMTQuNSAtMzUuNXYtMjUwaC0yMjJxLTgwIDAgLTEzNiA1Ny41dC01NiAxMzYuNXEwIDY5IDQzIDEyMi41dDEwOCA2Ny41cS0yIDE5IC0yIDM3cTAgMTAwIDQ5IDE4NSB0MTM0IDEzNHQxODUgNDl6TTUyNSA1MDBoMTUwcTEwIDAgMTcuNSAtNy41dDcuNSAtMTcuNXYtMjc1aDEzN3EyMSAwIDI2IC0xMS41dC04IC0yNy41bC0yMjMgLTI0NHEtMTMgLTE2IC0zMiAtMTZ0LTMyIDE2bC0yMjMgMjQ0cS0xMyAxNiAtOCAyNy41dDI2IDExLjVoMTM3djI3NXEwIDEwIDcuNSAxNy41dDE3LjUgNy41eiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUxOTg7IiBkPSJNNTAyIDEwODlxMTEwIDAgMjAxIC01OS41dDEzNSAtMTU2LjVxNDMgMTUgODkgMTVxMTIxIDAgMjA2IC04Ni41dDg2IC0yMDYuNXEwIC05OSAtNjAgLTE4MXQtMTUwIC0xMTBsLTM3OCAzNjBxLTEzIDE2IC0zMS41IDE2dC0zMS41IC0xNmwtMzgxIC0zNjVoLTlxLTc5IDAgLTEzNS41IDU3LjV0LTU2LjUgMTM2LjVxMCA2OSA0MyAxMjIuNXQxMDggNjcuNXEtMiAxOSAtMiAzOHEwIDEwMCA0OSAxODQuNXQxMzMuNSAxMzR0MTg0LjUgNDkuNXogTTYzMiA0NjdsMjIzIC0yMjhxMTMgLTE2IDggLTI3LjV0LTI2IC0xMS41aC0xMzd2LTI3NXEwIC0xMCAtNy41IC0xNy41dC0xNy41IC03LjVoLTE1MHEtMTAgMCAtMTcuNSA3LjV0LTcuNSAxNy41djI3NWgtMTM3cS0yMSAwIC0yNiAxMS41dDggMjcuNXExOTkgMjA0IDIyMyAyMjhxMTkgMTkgMzEuNSAxOXQzMi41IC0xOXoiIC8%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%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMjA2OyIgZD0iTTQ1MCAxMTAwaDEwMHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtNTBoNTBxMjEgMCAzNS41IC0xNC41dDE0LjUgLTM1LjV2LTEwMHEwIC0yMSAtMTQuNSAtMzUuNXQtMzUuNSAtMTQuNWgtMzAwcS0yMSAwIC0zNS41IDE0LjV0LTE0LjUgMzUuNXYxMDBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41aDUwdjUwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNXpNODAwIDg1MHYxNTBxNDEgMCA3MC41IC0yOS41dDI5LjUgLTcwLjV2LTUwMCBoLTIwMHYtMzAwaDIwMHEwIC0zNiAtNyAtNTcuNXQtMjMuNSAtMzB0LTI5LjUgLTEwLjV0LTQwIC0yaC02MDBxLTQxIDAgLTcwLjUgMjkuNXQtMjkuNSA3MC41djgwMHEwIDQxIDI5LjUgNzAuNXQ3MC41IDI5LjV2LTE1MHEwIC02MiA0NCAtMTA2dDEwNiAtNDRoMzAwcTYyIDAgMTA2IDQ0dDQ0IDEwNnpNMTIxMiAyNTBsLTIxMiAtMjEydjE2MmgtMjAwdjEwMGgyMDB2MTYyeiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUyMDk7IiBkPSJNNjU4IDExOTdsNjM3IC0xMTA0cTIzIC0zOCA3IC02NS41dC02MCAtMjcuNWgtMTI3NnEtNDQgMCAtNjAgMjcuNXQ3IDY1LjVsNjM3IDExMDRxMjIgMzkgNTQgMzl0NTQgLTM5ek03MDQgODAwaC0yMDhxLTIwIDAgLTMyIC0xNC41dC04IC0zNC41bDU4IC0zMDJxNCAtMjAgMjEuNSAtMzQuNXQzNy41IC0xNC41aDU0cTIwIDAgMzcuNSAxNC41dDIxLjUgMzQuNWw1OCAzMDJxNCAyMCAtOCAzNC41dC0zMiAxNC41ek01MDAgMzAwdi0xMDBoMjAwIHYxMDBoLTIwMHoiIC8%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%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMjE5OyIgZD0iTTIwMCAxMTAwaDgwMHE4MyAwIDE0MS41IC01OC41dDU4LjUgLTE0MS41di0yMDBoLTEwMHEwIDQxIC0yOS41IDcwLjV0LTcwLjUgMjkuNWgtMjUwcS00MSAwIC03MC41IC0yOS41dC0yOS41IC03MC41aC0xMDBxMCA0MSAtMjkuNSA3MC41dC03MC41IDI5LjVoLTI1MHEtNDEgMCAtNzAuNSAtMjkuNXQtMjkuNSAtNzAuNWgtMTAwdjIwMHEwIDgzIDU4LjUgMTQxLjV0MTQxLjUgNTguNXpNMTAwIDYwMGgxMDAwcTQxIDAgNzAuNSAtMjkuNSB0MjkuNSAtNzAuNXYtMzAwaC0xMjAwdjMwMHEwIDQxIDI5LjUgNzAuNXQ3MC41IDI5LjV6TTMwMCAxMDB2LTUwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC0xMDBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djUwaDIwMHpNMTEwMCAxMDB2LTUwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC0xMDBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djUwaDIwMHoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMjIxOyIgZD0iTTQ4MCAxMTY1bDY4MiAtNjgzcTMxIC0zMSAzMSAtNzUuNXQtMzEgLTc1LjVsLTEzMSAtMTMxaC00ODFsLTUxNyA1MThxLTMyIDMxIC0zMiA3NS41dDMyIDc1LjVsMjk1IDI5NnEzMSAzMSA3NS41IDMxdDc2LjUgLTMxek0xMDggNzk0bDM0MiAtMzQybDMwMyAzMDRsLTM0MSAzNDF6TTI1MCAxMDBoODAwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di01MGgtOTAwdjUwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNXoiIC8%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%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%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%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMjQxOyIgZD0iTTEyMDAgOTAwaC01MHEwIDIxIC00IDM3dC05LjUgMjYuNXQtMTggMTcuNXQtMjIgMTF0LTI4LjUgNS41dC0zMSAydC0zNyAwLjVoLTIwMHYtODUwcTAgLTIyIDI1IC0zNC41dDUwIC0xMy41bDI1IC0ydi0xMDBoLTQwMHYxMDBxNCAwIDExIDAuNXQyNCAzdDMwIDd0MjQgMTV0MTEgMjQuNXY4NTBoLTIwMHEtMjUgMCAtMzcgLTAuNXQtMzEgLTJ0LTI4LjUgLTUuNXQtMjIgLTExdC0xOCAtMTcuNXQtOS41IC0yNi41dC00IC0zN2gtNTB2MzAwIGgxMDAwdi0zMDB6TTUwMCA0NTBoLTI1cTAgMTUgLTQgMjQuNXQtOSAxNC41dC0xNyA3LjV0LTIwIDN0LTI1IDAuNWgtMTAwdi00MjVxMCAtMTEgMTIuNSAtMTcuNXQyNS41IC03LjVoMTJ2LTUwaC0yMDB2NTBxNTAgMCA1MCAyNXY0MjVoLTEwMHEtMTcgMCAtMjUgLTAuNXQtMjAgLTN0LTE3IC03LjV0LTkgLTE0LjV0LTQgLTI0LjVoLTI1djE1MGg1MDB2LTE1MHoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMjQyOyIgZD0iTTEwMDAgMzAwdjUwcS0yNSAwIC01NSAzMnEtMTQgMTQgLTI1IDMxdC0xNiAyN2wtNCAxMWwtMjg5IDc0N2gtNjlsLTMwMCAtNzU0cS0xOCAtMzUgLTM5IC01NnEtOSAtOSAtMjQuNSAtMTguNXQtMjYuNSAtMTQuNWwtMTEgLTV2LTUwaDI3M3Y1MHEtNDkgMCAtNzguNSAyMS41dC0xMS41IDY3LjVsNjkgMTc2aDI5M2w2MSAtMTY2cTEzIC0zNCAtMy41IC02Ni41dC01NS41IC0zMi41di01MGgzMTJ6TTQxMiA2OTFsMTM0IDM0MmwxMjEgLTM0MiBoLTI1NXpNMTEwMCAxNTB2LTEwMHEwIC0yMSAtMTQuNSAtMzUuNXQtMzUuNSAtMTQuNWgtMTAwMHEtMjEgMCAtMzUuNSAxNC41dC0xNC41IDM1LjV2MTAwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNWgxMDAwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41eiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUyNDM7IiBkPSJNNTAgMTIwMGgxMTAwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di0xMTAwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC0xMTAwcS0yMSAwIC0zNS41IDE0LjV0LTE0LjUgMzUuNXYxMTAwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNXpNNjExIDExMThoLTcwcS0xMyAwIC0xOCAtMTJsLTI5OSAtNzUzcS0xNyAtMzIgLTM1IC01MXEtMTggLTE4IC01NiAtMzRxLTEyIC01IC0xMiAtMTh2LTUwcTAgLTggNS41IC0xNHQxNC41IC02IGgyNzNxOCAwIDE0IDZ0NiAxNHY1MHEwIDggLTYgMTR0LTE0IDZxLTU1IDAgLTcxIDIzcS0xMCAxNCAwIDM5bDYzIDE2M2gyNjZsNTcgLTE1M3ExMSAtMzEgLTYgLTU1cS0xMiAtMTcgLTM2IC0xN3EtOCAwIC0xNCAtNnQtNiAtMTR2LTUwcTAgLTggNiAtMTR0MTQgLTZoMzEzcTggMCAxNCA2dDYgMTR2NTBxMCA3IC01LjUgMTN0LTEzLjUgN3EtMTcgMCAtNDIgMjVxLTI1IDI3IC00MCA2M2gtMWwtMjg4IDc0OHEtNSAxMiAtMTkgMTJ6TTYzOSA2MTEgaC0xOTdsMTAzIDI2NHoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMjQ0OyIgZD0iTTEyMDAgMTEwMGgtMTIwMHYxMDBoMTIwMHYtMTAwek01MCAxMDAwaDQwMHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtOTAwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC00MDBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djkwMHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjV6TTY1MCAxMDAwaDQwMHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtNDAwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC00MDAgcS0yMSAwIC0zNS41IDE0LjV0LTE0LjUgMzUuNXY0MDBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41ek03MDAgOTAwdi0zMDBoMzAwdjMwMGgtMzAweiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUyNDU7IiBkPSJNNTAgMTIwMGg0MDBxMjEgMCAzNS41IC0xNC41dDE0LjUgLTM1LjV2LTkwMHEwIC0yMSAtMTQuNSAtMzUuNXQtMzUuNSAtMTQuNWgtNDAwcS0yMSAwIC0zNS41IDE0LjV0LTE0LjUgMzUuNXY5MDBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41ek02NTAgNzAwaDQwMHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtNDAwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC00MDBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djQwMCBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41ek03MDAgNjAwdi0zMDBoMzAwdjMwMGgtMzAwek0xMjAwIDBoLTEyMDB2MTAwaDEyMDB2LTEwMHoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMjQ2OyIgZD0iTTUwIDEwMDBoNDAwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di0zNTBoMTAwdjE1MHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjVoNDAwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di0xNTBoMTAwdi0xMDBoLTEwMHYtMTUwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC00MDBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djE1MGgtMTAwdi0zNTBxMCAtMjEgLTE0LjUgLTM1LjV0LTM1LjUgLTE0LjVoLTQwMCBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djgwMHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjV6TTcwMCA3MDB2LTMwMGgzMDB2MzAwaC0zMDB6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTI0NzsiIGQ9Ik0xMDAgMGgtMTAwdjEyMDBoMTAwdi0xMjAwek0yNTAgMTEwMGg0MDBxMjEgMCAzNS41IC0xNC41dDE0LjUgLTM1LjV2LTQwMHEwIC0yMSAtMTQuNSAtMzUuNXQtMzUuNSAtMTQuNWgtNDAwcS0yMSAwIC0zNS41IDE0LjV0LTE0LjUgMzUuNXY0MDBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41ek0zMDAgMTAwMHYtMzAwaDMwMHYzMDBoLTMwMHpNMjUwIDUwMGg5MDBxMjEgMCAzNS41IC0xNC41dDE0LjUgLTM1LjV2LTQwMCBxMCAtMjEgLTE0LjUgLTM1LjV0LTM1LjUgLTE0LjVoLTkwMHEtMjEgMCAtMzUuNSAxNC41dC0xNC41IDM1LjV2NDAwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMjQ4OyIgZD0iTTYwMCAxMTAwaDE1MHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtNDAwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC0xNTB2LTEwMGg0NTBxMjEgMCAzNS41IC0xNC41dDE0LjUgLTM1LjV2LTQwMHEwIC0yMSAtMTQuNSAtMzUuNXQtMzUuNSAtMTQuNWgtOTAwcS0yMSAwIC0zNS41IDE0LjV0LTE0LjUgMzUuNXY0MDBxMCAyMSAxNC41IDM1LjV0MzUuNSAxNC41aDM1MHYxMDBoLTE1MHEtMjEgMCAtMzUuNSAxNC41IHQtMTQuNSAzNS41djQwMHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjVoMTUwdjEwMGgxMDB2LTEwMHpNNDAwIDEwMDB2LTMwMGgzMDB2MzAwaC0zMDB6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTI0OTsiIGQ9Ik0xMjAwIDBoLTEwMHYxMjAwaDEwMHYtMTIwMHpNNTUwIDExMDBoNDAwcTIxIDAgMzUuNSAtMTQuNXQxNC41IC0zNS41di00MDBxMCAtMjEgLTE0LjUgLTM1LjV0LTM1LjUgLTE0LjVoLTQwMHEtMjEgMCAtMzUuNSAxNC41dC0xNC41IDM1LjV2NDAwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNXpNNjAwIDEwMDB2LTMwMGgzMDB2MzAwaC0zMDB6TTUwIDUwMGg5MDBxMjEgMCAzNS41IC0xNC41dDE0LjUgLTM1LjV2LTQwMCBxMCAtMjEgLTE0LjUgLTM1LjV0LTM1LjUgLTE0LjVoLTkwMHEtMjEgMCAtMzUuNSAxNC41dC0xNC41IDM1LjV2NDAwcTAgMjEgMTQuNSAzNS41dDM1LjUgMTQuNXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMjUwOyIgZD0iTTg2NSA1NjVsLTQ5NCAtNDk0cS0yMyAtMjMgLTQxIC0yM3EtMTQgMCAtMjIgMTMuNXQtOCAzOC41djEwMDBxMCAyNSA4IDM4LjV0MjIgMTMuNXExOCAwIDQxIC0yM2w0OTQgLTQ5NHExNCAtMTQgMTQgLTM1dC0xNCAtMzV6IiAvPgo8Z2x5cGggdW5pY29kZT0iJiN4ZTI1MTsiIGQ9Ik0zMzUgNjM1bDQ5NCA0OTRxMjkgMjkgNTAgMjAuNXQyMSAtNDkuNXYtMTAwMHEwIC00MSAtMjEgLTQ5LjV0LTUwIDIwLjVsLTQ5NCA0OTRxLTE0IDE0IC0xNCAzNXQxNCAzNXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMjUyOyIgZD0iTTEwMCA5MDBoMTAwMHE0MSAwIDQ5LjUgLTIxdC0yMC41IC01MGwtNDk0IC00OTRxLTE0IC0xNCAtMzUgLTE0dC0zNSAxNGwtNDk0IDQ5NHEtMjkgMjkgLTIwLjUgNTB0NDkuNSAyMXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMjUzOyIgZD0iTTYzNSA4NjVsNDk0IC00OTRxMjkgLTI5IDIwLjUgLTUwdC00OS41IC0yMWgtMTAwMHEtNDEgMCAtNDkuNSAyMXQyMC41IDUwbDQ5NCA0OTRxMTQgMTQgMzUgMTR0MzUgLTE0eiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUyNTQ7IiBkPSJNNzAwIDc0MXYtMTgybC02OTIgLTMyM3YyMjFsNDEzIDE5M2wtNDEzIDE5M3YyMjF6TTEyMDAgMGgtODAwdjIwMGg4MDB2LTIwMHoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMjU1OyIgZD0iTTEyMDAgOTAwaC0yMDB2LTEwMGgyMDB2LTEwMGgtMzAwdjMwMGgyMDB2MTAwaC0yMDB2MTAwaDMwMHYtMzAwek0wIDcwMGg1MHEwIDIxIDQgMzd0OS41IDI2LjV0MTggMTcuNXQyMiAxMXQyOC41IDUuNXQzMSAydDM3IDAuNWgxMDB2LTU1MHEwIC0yMiAtMjUgLTM0LjV0LTUwIC0xMy41bC0yNSAtMnYtMTAwaDQwMHYxMDBxLTQgMCAtMTEgMC41dC0yNCAzdC0zMCA3dC0yNCAxNXQtMTEgMjQuNXY1NTBoMTAwcTI1IDAgMzcgLTAuNXQzMSAtMiB0MjguNSAtNS41dDIyIC0xMXQxOCAtMTcuNXQ5LjUgLTI2LjV0NCAtMzdoNTB2MzAwaC04MDB2LTMwMHoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMjU2OyIgZD0iTTgwMCA3MDBoLTUwcTAgMjEgLTQgMzd0LTkuNSAyNi41dC0xOCAxNy41dC0yMiAxMXQtMjguNSA1LjV0LTMxIDJ0LTM3IDAuNWgtMTAwdi01NTBxMCAtMjIgMjUgLTM0LjV0NTAgLTE0LjVsMjUgLTF2LTEwMGgtNDAwdjEwMHE0IDAgMTEgMC41dDI0IDN0MzAgN3QyNCAxNXQxMSAyNC41djU1MGgtMTAwcS0yNSAwIC0zNyAtMC41dC0zMSAtMnQtMjguNSAtNS41dC0yMiAtMTF0LTE4IC0xNy41dC05LjUgLTI2LjV0LTQgLTM3aC01MHYzMDAgaDgwMHYtMzAwek0xMTAwIDIwMGgtMjAwdi0xMDBoMjAwdi0xMDBoLTMwMHYzMDBoMjAwdjEwMGgtMjAwdjEwMGgzMDB2LTMwMHoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMjU3OyIgZD0iTTcwMSAxMDk4aDE2MHExNiAwIDIxIC0xMXQtNyAtMjNsLTQ2NCAtNDY0bDQ2NCAtNDY0cTEyIC0xMiA3IC0yM3QtMjEgLTExaC0xNjBxLTEzIDAgLTIzIDlsLTQ3MSA0NzFxLTcgOCAtNyAxOHQ3IDE4bDQ3MSA0NzFxMTAgOSAyMyA5eiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGUyNTg7IiBkPSJNMzM5IDEwOThoMTYwcTEzIDAgMjMgLTlsNDcxIC00NzFxNyAtOCA3IC0xOHQtNyAtMThsLTQ3MSAtNDcxcS0xMCAtOSAtMjMgLTloLTE2MHEtMTYgMCAtMjEgMTF0NyAyM2w0NjQgNDY0bC00NjQgNDY0cS0xMiAxMiAtNyAyM3QyMSAxMXoiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMjU5OyIgZD0iTTEwODcgODgycTExIC01IDExIC0yMXYtMTYwcTAgLTEzIC05IC0yM2wtNDcxIC00NzFxLTggLTcgLTE4IC03dC0xOCA3bC00NzEgNDcxcS05IDEwIC05IDIzdjE2MHEwIDE2IDExIDIxdDIzIC03bDQ2NCAtNDY0bDQ2NCA0NjRxMTIgMTIgMjMgN3oiIC8%2BCjxnbHlwaCB1bmljb2RlPSImI3hlMjYwOyIgZD0iTTYxOCA5OTNsNDcxIC00NzFxOSAtMTAgOSAtMjN2LTE2MHEwIC0xNiAtMTEgLTIxdC0yMyA3bC00NjQgNDY0bC00NjQgLTQ2NHEtMTIgLTEyIC0yMyAtN3QtMTEgMjF2MTYwcTAgMTMgOSAyM2w0NzEgNDcxcTggNyAxOCA3dDE4IC03eiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeGY4ZmY7IiBkPSJNMTAwMCAxMjAwcTAgLTEyNCAtODggLTIxMnQtMjEyIC04OHEwIDEyNCA4OCAyMTJ0MjEyIDg4ek00NTAgMTAwMGgxMDBxMjEgMCA0MCAtMTR0MjYgLTMzbDc5IC0xOTRxNSAxIDE2IDNxMzQgNiA1NCA5LjV0NjAgN3Q2NS41IDF0NjEgLTEwdDU2LjUgLTIzdDQyLjUgLTQydDI5IC02NHQ1IC05MnQtMTkuNSAtMTIxLjVxLTEgLTcgLTMgLTE5LjV0LTExIC01MHQtMjAuNSAtNzN0LTMyLjUgLTgxLjV0LTQ2LjUgLTgzdC02NCAtNzAgdC04Mi41IC01MHEtMTMgLTUgLTQyIC01dC02NS41IDIuNXQtNDcuNSAyLjVxLTE0IDAgLTQ5LjUgLTMuNXQtNjMgLTMuNXQtNDMuNSA3cS01NyAyNSAtMTA0LjUgNzguNXQtNzUgMTExLjV0LTQ2LjUgMTEydC0yNiA5MGwtNyAzNXEtMTUgNjMgLTE4IDExNXQ0LjUgODguNXQyNiA2NHQzOS41IDQzLjV0NTIgMjUuNXQ1OC41IDEzdDYyLjUgMnQ1OS41IC00LjV0NTUuNSAtOGwtMTQ3IDE5MnEtMTIgMTggLTUuNSAzMHQyNy41IDEyeiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeDFmNTExOyIgZD0iTTI1MCAxMjAwaDYwMHEyMSAwIDM1LjUgLTE0LjV0MTQuNSAtMzUuNXYtNDAwcTAgLTIxIC0xNC41IC0zNS41dC0zNS41IC0xNC41aC0xNTB2LTUwMGwtMjU1IC0xNzhxLTE5IC05IC0zMiAtMXQtMTMgMjl2NjUwaC0xNTBxLTIxIDAgLTM1LjUgMTQuNXQtMTQuNSAzNS41djQwMHEwIDIxIDE0LjUgMzUuNXQzNS41IDE0LjV6TTQwMCAxMTAwdi0xMDBoMzAwdjEwMGgtMzAweiIgLz4KPGdseXBoIHVuaWNvZGU9IiYjeDFmNmFhOyIgZD0iTTI1MCAxMjAwaDc1MHEzOSAwIDY5LjUgLTQwLjV0MzAuNSAtODQuNXYtOTMzbC03MDAgLTExN3Y5NTBsNjAwIDEyNWgtNzAwdi0xMDAwaC0xMDB2MTAyNXEwIDIzIDE1LjUgNDl0MzQuNSAyNnpNNTAwIDUyNXYtMTAwbDEwMCAyMHYxMDB6IiAvPgo8L2ZvbnQ%2BCjwvZGVmcz48L3N2Zz4g%29%20format%28%27svg%27%29%7D%2Eglyphicon%7Bposition%3Arelative%3Btop%3A1px%3Bdisplay%3Ainline%2Dblock%3Bfont%2Dfamily%3A%27Glyphicons%20Halflings%27%3Bfont%2Dstyle%3Anormal%3Bfont%2Dweight%3A400%3Bline%2Dheight%3A1%3B%2Dwebkit%2Dfont%2Dsmoothing%3Aantialiased%3B%2Dmoz%2Dosx%2Dfont%2Dsmoothing%3Agrayscale%7D%2Eglyphicon%2Dasterisk%3Abefore%7Bcontent%3A%22%5C2a%22%7D%2Eglyphicon%2Dplus%3Abefore%7Bcontent%3A%22%5C2b%22%7D%2Eglyphicon%2Deur%3Abefore%2C%2Eglyphicon%2Deuro%3Abefore%7Bcontent%3A%22%5C20ac%22%7D%2Eglyphicon%2Dminus%3Abefore%7Bcontent%3A%22%5C2212%22%7D%2Eglyphicon%2Dcloud%3Abefore%7Bcontent%3A%22%5C2601%22%7D%2Eglyphicon%2Denvelope%3Abefore%7Bcontent%3A%22%5C2709%22%7D%2Eglyphicon%2Dpencil%3Abefore%7Bcontent%3A%22%5C270f%22%7D%2Eglyphicon%2Dglass%3Abefore%7Bcontent%3A%22%5Ce001%22%7D%2Eglyphicon%2Dmusic%3Abefore%7Bcontent%3A%22%5Ce002%22%7D%2Eglyphicon%2Dsearch%3Abefore%7Bcontent%3A%22%5Ce003%22%7D%2Eglyphicon%2Dheart%3Abefore%7Bcontent%3A%22%5Ce005%22%7D%2Eglyphicon%2Dstar%3Abefore%7Bcontent%3A%22%5Ce006%22%7D%2Eglyphicon%2Dstar%2Dempty%3Abefore%7Bcontent%3A%22%5Ce007%22%7D%2Eglyphicon%2Duser%3Abefore%7Bcontent%3A%22%5Ce008%22%7D%2Eglyphicon%2Dfilm%3Abefore%7Bcontent%3A%22%5Ce009%22%7D%2Eglyphicon%2Dth%2Dlarge%3Abefore%7Bcontent%3A%22%5Ce010%22%7D%2Eglyphicon%2Dth%3Abefore%7Bcontent%3A%22%5Ce011%22%7D%2Eglyphicon%2Dth%2Dlist%3Abefore%7Bcontent%3A%22%5Ce012%22%7D%2Eglyphicon%2Dok%3Abefore%7Bcontent%3A%22%5Ce013%22%7D%2Eglyphicon%2Dremove%3Abefore%7Bcontent%3A%22%5Ce014%22%7D%2Eglyphicon%2Dzoom%2Din%3Abefore%7Bcontent%3A%22%5Ce015%22%7D%2Eglyphicon%2Dzoom%2Dout%3Abefore%7Bcontent%3A%22%5Ce016%22%7D%2Eglyphicon%2Doff%3Abefore%7Bcontent%3A%22%5Ce017%22%7D%2Eglyphicon%2Dsignal%3Abefore%7Bcontent%3A%22%5Ce018%22%7D%2Eglyphicon%2Dcog%3Abefore%7Bcontent%3A%22%5Ce019%22%7D%2Eglyphicon%2Dtrash%3Abefore%7Bcontent%3A%22%5Ce020%22%7D%2Eglyphicon%2Dhome%3Abefore%7Bcontent%3A%22%5Ce021%22%7D%2Eglyphicon%2Dfile%3Abefore%7Bcontent%3A%22%5Ce022%22%7D%2Eglyphicon%2Dtime%3Abefore%7Bcontent%3A%22%5Ce023%22%7D%2Eglyphicon%2Droad%3Abefore%7Bcontent%3A%22%5Ce024%22%7D%2Eglyphicon%2Ddownload%2Dalt%3Abefore%7Bcontent%3A%22%5Ce025%22%7D%2Eglyphicon%2Ddownload%3Abefore%7Bcontent%3A%22%5Ce026%22%7D%2Eglyphicon%2Dupload%3Abefore%7Bcontent%3A%22%5Ce027%22%7D%2Eglyphicon%2Dinbox%3Abefore%7Bcontent%3A%22%5Ce028%22%7D%2Eglyphicon%2Dplay%2Dcircle%3Abefore%7Bcontent%3A%22%5Ce029%22%7D%2Eglyphicon%2Drepeat%3Abefore%7Bcontent%3A%22%5Ce030%22%7D%2Eglyphicon%2Drefresh%3Abefore%7Bcontent%3A%22%5Ce031%22%7D%2Eglyphicon%2Dlist%2Dalt%3Abefore%7Bcontent%3A%22%5Ce032%22%7D%2Eglyphicon%2Dlock%3Abefore%7Bcontent%3A%22%5Ce033%22%7D%2Eglyphicon%2Dflag%3Abefore%7Bcontent%3A%22%5Ce034%22%7D%2Eglyphicon%2Dheadphones%3Abefore%7Bcontent%3A%22%5Ce035%22%7D%2Eglyphicon%2Dvolume%2Doff%3Abefore%7Bcontent%3A%22%5Ce036%22%7D%2Eglyphicon%2Dvolume%2Ddown%3Abefore%7Bcontent%3A%22%5Ce037%22%7D%2Eglyphicon%2Dvolume%2Dup%3Abefore%7Bcontent%3A%22%5Ce038%22%7D%2Eglyphicon%2Dqrcode%3Abefore%7Bcontent%3A%22%5Ce039%22%7D%2Eglyphicon%2Dbarcode%3Abefore%7Bcontent%3A%22%5Ce040%22%7D%2Eglyphicon%2Dtag%3Abefore%7Bcontent%3A%22%5Ce041%22%7D%2Eglyphicon%2Dtags%3Abefore%7Bcontent%3A%22%5Ce042%22%7D%2Eglyphicon%2Dbook%3Abefore%7Bcontent%3A%22%5Ce043%22%7D%2Eglyphicon%2Dbookmark%3Abefore%7Bcontent%3A%22%5Ce044%22%7D%2Eglyphicon%2Dprint%3Abefore%7Bcontent%3A%22%5Ce045%22%7D%2Eglyphicon%2Dcamera%3Abefore%7Bcontent%3A%22%5Ce046%22%7D%2Eglyphicon%2Dfont%3Abefore%7Bcontent%3A%22%5Ce047%22%7D%2Eglyphicon%2Dbold%3Abefore%7Bcontent%3A%22%5Ce048%22%7D%2Eglyphicon%2Ditalic%3Abefore%7Bcontent%3A%22%5Ce049%22%7D%2Eglyphicon%2Dtext%2Dheight%3Abefore%7Bcontent%3A%22%5Ce050%22%7D%2Eglyphicon%2Dtext%2Dwidth%3Abefore%7Bcontent%3A%22%5Ce051%22%7D%2Eglyphicon%2Dalign%2Dleft%3Abefore%7Bcontent%3A%22%5Ce052%22%7D%2Eglyphicon%2Dalign%2Dcenter%3Abefore%7Bcontent%3A%22%5Ce053%22%7D%2Eglyphicon%2Dalign%2Dright%3Abefore%7Bcontent%3A%22%5Ce054%22%7D%2Eglyphicon%2Dalign%2Djustify%3Abefore%7Bcontent%3A%22%5Ce055%22%7D%2Eglyphicon%2Dlist%3Abefore%7Bcontent%3A%22%5Ce056%22%7D%2Eglyphicon%2Dindent%2Dleft%3Abefore%7Bcontent%3A%22%5Ce057%22%7D%2Eglyphicon%2Dindent%2Dright%3Abefore%7Bcontent%3A%22%5Ce058%22%7D%2Eglyphicon%2Dfacetime%2Dvideo%3Abefore%7Bcontent%3A%22%5Ce059%22%7D%2Eglyphicon%2Dpicture%3Abefore%7Bcontent%3A%22%5Ce060%22%7D%2Eglyphicon%2Dmap%2Dmarker%3Abefore%7Bcontent%3A%22%5Ce062%22%7D%2Eglyphicon%2Dadjust%3Abefore%7Bcontent%3A%22%5Ce063%22%7D%2Eglyphicon%2Dtint%3Abefore%7Bcontent%3A%22%5Ce064%22%7D%2Eglyphicon%2Dedit%3Abefore%7Bcontent%3A%22%5Ce065%22%7D%2Eglyphicon%2Dshare%3Abefore%7Bcontent%3A%22%5Ce066%22%7D%2Eglyphicon%2Dcheck%3Abefore%7Bcontent%3A%22%5Ce067%22%7D%2Eglyphicon%2Dmove%3Abefore%7Bcontent%3A%22%5Ce068%22%7D%2Eglyphicon%2Dstep%2Dbackward%3Abefore%7Bcontent%3A%22%5Ce069%22%7D%2Eglyphicon%2Dfast%2Dbackward%3Abefore%7Bcontent%3A%22%5Ce070%22%7D%2Eglyphicon%2Dbackward%3Abefore%7Bcontent%3A%22%5Ce071%22%7D%2Eglyphicon%2Dplay%3Abefore%7Bcontent%3A%22%5Ce072%22%7D%2Eglyphicon%2Dpause%3Abefore%7Bcontent%3A%22%5Ce073%22%7D%2Eglyphicon%2Dstop%3Abefore%7Bcontent%3A%22%5Ce074%22%7D%2Eglyphicon%2Dforward%3Abefore%7Bcontent%3A%22%5Ce075%22%7D%2Eglyphicon%2Dfast%2Dforward%3Abefore%7Bcontent%3A%22%5Ce076%22%7D%2Eglyphicon%2Dstep%2Dforward%3Abefore%7Bcontent%3A%22%5Ce077%22%7D%2Eglyphicon%2Deject%3Abefore%7Bcontent%3A%22%5Ce078%22%7D%2Eglyphicon%2Dchevron%2Dleft%3Abefore%7Bcontent%3A%22%5Ce079%22%7D%2Eglyphicon%2Dchevron%2Dright%3Abefore%7Bcontent%3A%22%5Ce080%22%7D%2Eglyphicon%2Dplus%2Dsign%3Abefore%7Bcontent%3A%22%5Ce081%22%7D%2Eglyphicon%2Dminus%2Dsign%3Abefore%7Bcontent%3A%22%5Ce082%22%7D%2Eglyphicon%2Dremove%2Dsign%3Abefore%7Bcontent%3A%22%5Ce083%22%7D%2Eglyphicon%2Dok%2Dsign%3Abefore%7Bcontent%3A%22%5Ce084%22%7D%2Eglyphicon%2Dquestion%2Dsign%3Abefore%7Bcontent%3A%22%5Ce085%22%7D%2Eglyphicon%2Dinfo%2Dsign%3Abefore%7Bcontent%3A%22%5Ce086%22%7D%2Eglyphicon%2Dscreenshot%3Abefore%7Bcontent%3A%22%5Ce087%22%7D%2Eglyphicon%2Dremove%2Dcircle%3Abefore%7Bcontent%3A%22%5Ce088%22%7D%2Eglyphicon%2Dok%2Dcircle%3Abefore%7Bcontent%3A%22%5Ce089%22%7D%2Eglyphicon%2Dban%2Dcircle%3Abefore%7Bcontent%3A%22%5Ce090%22%7D%2Eglyphicon%2Darrow%2Dleft%3Abefore%7Bcontent%3A%22%5Ce091%22%7D%2Eglyphicon%2Darrow%2Dright%3Abefore%7Bcontent%3A%22%5Ce092%22%7D%2Eglyphicon%2Darrow%2Dup%3Abefore%7Bcontent%3A%22%5Ce093%22%7D%2Eglyphicon%2Darrow%2Ddown%3Abefore%7Bcontent%3A%22%5Ce094%22%7D%2Eglyphicon%2Dshare%2Dalt%3Abefore%7Bcontent%3A%22%5Ce095%22%7D%2Eglyphicon%2Dresize%2Dfull%3Abefore%7Bcontent%3A%22%5Ce096%22%7D%2Eglyphicon%2Dresize%2Dsmall%3Abefore%7Bcontent%3A%22%5Ce097%22%7D%2Eglyphicon%2Dexclamation%2Dsign%3Abefore%7Bcontent%3A%22%5Ce101%22%7D%2Eglyphicon%2Dgift%3Abefore%7Bcontent%3A%22%5Ce102%22%7D%2Eglyphicon%2Dleaf%3Abefore%7Bcontent%3A%22%5Ce103%22%7D%2Eglyphicon%2Dfire%3Abefore%7Bcontent%3A%22%5Ce104%22%7D%2Eglyphicon%2Deye%2Dopen%3Abefore%7Bcontent%3A%22%5Ce105%22%7D%2Eglyphicon%2Deye%2Dclose%3Abefore%7Bcontent%3A%22%5Ce106%22%7D%2Eglyphicon%2Dwarning%2Dsign%3Abefore%7Bcontent%3A%22%5Ce107%22%7D%2Eglyphicon%2Dplane%3Abefore%7Bcontent%3A%22%5Ce108%22%7D%2Eglyphicon%2Dcalendar%3Abefore%7Bcontent%3A%22%5Ce109%22%7D%2Eglyphicon%2Drandom%3Abefore%7Bcontent%3A%22%5Ce110%22%7D%2Eglyphicon%2Dcomment%3Abefore%7Bcontent%3A%22%5Ce111%22%7D%2Eglyphicon%2Dmagnet%3Abefore%7Bcontent%3A%22%5Ce112%22%7D%2Eglyphicon%2Dchevron%2Dup%3Abefore%7Bcontent%3A%22%5Ce113%22%7D%2Eglyphicon%2Dchevron%2Ddown%3Abefore%7Bcontent%3A%22%5Ce114%22%7D%2Eglyphicon%2Dretweet%3Abefore%7Bcontent%3A%22%5Ce115%22%7D%2Eglyphicon%2Dshopping%2Dcart%3Abefore%7Bcontent%3A%22%5Ce116%22%7D%2Eglyphicon%2Dfolder%2Dclose%3Abefore%7Bcontent%3A%22%5Ce117%22%7D%2Eglyphicon%2Dfolder%2Dopen%3Abefore%7Bcontent%3A%22%5Ce118%22%7D%2Eglyphicon%2Dresize%2Dvertical%3Abefore%7Bcontent%3A%22%5Ce119%22%7D%2Eglyphicon%2Dresize%2Dhorizontal%3Abefore%7Bcontent%3A%22%5Ce120%22%7D%2Eglyphicon%2Dhdd%3Abefore%7Bcontent%3A%22%5Ce121%22%7D%2Eglyphicon%2Dbullhorn%3Abefore%7Bcontent%3A%22%5Ce122%22%7D%2Eglyphicon%2Dbell%3Abefore%7Bcontent%3A%22%5Ce123%22%7D%2Eglyphicon%2Dcertificate%3Abefore%7Bcontent%3A%22%5Ce124%22%7D%2Eglyphicon%2Dthumbs%2Dup%3Abefore%7Bcontent%3A%22%5Ce125%22%7D%2Eglyphicon%2Dthumbs%2Ddown%3Abefore%7Bcontent%3A%22%5Ce126%22%7D%2Eglyphicon%2Dhand%2Dright%3Abefore%7Bcontent%3A%22%5Ce127%22%7D%2Eglyphicon%2Dhand%2Dleft%3Abefore%7Bcontent%3A%22%5Ce128%22%7D%2Eglyphicon%2Dhand%2Dup%3Abefore%7Bcontent%3A%22%5Ce129%22%7D%2Eglyphicon%2Dhand%2Ddown%3Abefore%7Bcontent%3A%22%5Ce130%22%7D%2Eglyphicon%2Dcircle%2Darrow%2Dright%3Abefore%7Bcontent%3A%22%5Ce131%22%7D%2Eglyphicon%2Dcircle%2Darrow%2Dleft%3Abefore%7Bcontent%3A%22%5Ce132%22%7D%2Eglyphicon%2Dcircle%2Darrow%2Dup%3Abefore%7Bcontent%3A%22%5Ce133%22%7D%2Eglyphicon%2Dcircle%2Darrow%2Ddown%3Abefore%7Bcontent%3A%22%5Ce134%22%7D%2Eglyphicon%2Dglobe%3Abefore%7Bcontent%3A%22%5Ce135%22%7D%2Eglyphicon%2Dwrench%3Abefore%7Bcontent%3A%22%5Ce136%22%7D%2Eglyphicon%2Dtasks%3Abefore%7Bcontent%3A%22%5Ce137%22%7D%2Eglyphicon%2Dfilter%3Abefore%7Bcontent%3A%22%5Ce138%22%7D%2Eglyphicon%2Dbriefcase%3Abefore%7Bcontent%3A%22%5Ce139%22%7D%2Eglyphicon%2Dfullscreen%3Abefore%7Bcontent%3A%22%5Ce140%22%7D%2Eglyphicon%2Ddashboard%3Abefore%7Bcontent%3A%22%5Ce141%22%7D%2Eglyphicon%2Dpaperclip%3Abefore%7Bcontent%3A%22%5Ce142%22%7D%2Eglyphicon%2Dheart%2Dempty%3Abefore%7Bcontent%3A%22%5Ce143%22%7D%2Eglyphicon%2Dlink%3Abefore%7Bcontent%3A%22%5Ce144%22%7D%2Eglyphicon%2Dphone%3Abefore%7Bcontent%3A%22%5Ce145%22%7D%2Eglyphicon%2Dpushpin%3Abefore%7Bcontent%3A%22%5Ce146%22%7D%2Eglyphicon%2Dusd%3Abefore%7Bcontent%3A%22%5Ce148%22%7D%2Eglyphicon%2Dgbp%3Abefore%7Bcontent%3A%22%5Ce149%22%7D%2Eglyphicon%2Dsort%3Abefore%7Bcontent%3A%22%5Ce150%22%7D%2Eglyphicon%2Dsort%2Dby%2Dalphabet%3Abefore%7Bcontent%3A%22%5Ce151%22%7D%2Eglyphicon%2Dsort%2Dby%2Dalphabet%2Dalt%3Abefore%7Bcontent%3A%22%5Ce152%22%7D%2Eglyphicon%2Dsort%2Dby%2Dorder%3Abefore%7Bcontent%3A%22%5Ce153%22%7D%2Eglyphicon%2Dsort%2Dby%2Dorder%2Dalt%3Abefore%7Bcontent%3A%22%5Ce154%22%7D%2Eglyphicon%2Dsort%2Dby%2Dattributes%3Abefore%7Bcontent%3A%22%5Ce155%22%7D%2Eglyphicon%2Dsort%2Dby%2Dattributes%2Dalt%3Abefore%7Bcontent%3A%22%5Ce156%22%7D%2Eglyphicon%2Dunchecked%3Abefore%7Bcontent%3A%22%5Ce157%22%7D%2Eglyphicon%2Dexpand%3Abefore%7Bcontent%3A%22%5Ce158%22%7D%2Eglyphicon%2Dcollapse%2Ddown%3Abefore%7Bcontent%3A%22%5Ce159%22%7D%2Eglyphicon%2Dcollapse%2Dup%3Abefore%7Bcontent%3A%22%5Ce160%22%7D%2Eglyphicon%2Dlog%2Din%3Abefore%7Bcontent%3A%22%5Ce161%22%7D%2Eglyphicon%2Dflash%3Abefore%7Bcontent%3A%22%5Ce162%22%7D%2Eglyphicon%2Dlog%2Dout%3Abefore%7Bcontent%3A%22%5Ce163%22%7D%2Eglyphicon%2Dnew%2Dwindow%3Abefore%7Bcontent%3A%22%5Ce164%22%7D%2Eglyphicon%2Drecord%3Abefore%7Bcontent%3A%22%5Ce165%22%7D%2Eglyphicon%2Dsave%3Abefore%7Bcontent%3A%22%5Ce166%22%7D%2Eglyphicon%2Dopen%3Abefore%7Bcontent%3A%22%5Ce167%22%7D%2Eglyphicon%2Dsaved%3Abefore%7Bcontent%3A%22%5Ce168%22%7D%2Eglyphicon%2Dimport%3Abefore%7Bcontent%3A%22%5Ce169%22%7D%2Eglyphicon%2Dexport%3Abefore%7Bcontent%3A%22%5Ce170%22%7D%2Eglyphicon%2Dsend%3Abefore%7Bcontent%3A%22%5Ce171%22%7D%2Eglyphicon%2Dfloppy%2Ddisk%3Abefore%7Bcontent%3A%22%5Ce172%22%7D%2Eglyphicon%2Dfloppy%2Dsaved%3Abefore%7Bcontent%3A%22%5Ce173%22%7D%2Eglyphicon%2Dfloppy%2Dremove%3Abefore%7Bcontent%3A%22%5Ce174%22%7D%2Eglyphicon%2Dfloppy%2Dsave%3Abefore%7Bcontent%3A%22%5Ce175%22%7D%2Eglyphicon%2Dfloppy%2Dopen%3Abefore%7Bcontent%3A%22%5Ce176%22%7D%2Eglyphicon%2Dcredit%2Dcard%3Abefore%7Bcontent%3A%22%5Ce177%22%7D%2Eglyphicon%2Dtransfer%3Abefore%7Bcontent%3A%22%5Ce178%22%7D%2Eglyphicon%2Dcutlery%3Abefore%7Bcontent%3A%22%5Ce179%22%7D%2Eglyphicon%2Dheader%3Abefore%7Bcontent%3A%22%5Ce180%22%7D%2Eglyphicon%2Dcompressed%3Abefore%7Bcontent%3A%22%5Ce181%22%7D%2Eglyphicon%2Dearphone%3Abefore%7Bcontent%3A%22%5Ce182%22%7D%2Eglyphicon%2Dphone%2Dalt%3Abefore%7Bcontent%3A%22%5Ce183%22%7D%2Eglyphicon%2Dtower%3Abefore%7Bcontent%3A%22%5Ce184%22%7D%2Eglyphicon%2Dstats%3Abefore%7Bcontent%3A%22%5Ce185%22%7D%2Eglyphicon%2Dsd%2Dvideo%3Abefore%7Bcontent%3A%22%5Ce186%22%7D%2Eglyphicon%2Dhd%2Dvideo%3Abefore%7Bcontent%3A%22%5Ce187%22%7D%2Eglyphicon%2Dsubtitles%3Abefore%7Bcontent%3A%22%5Ce188%22%7D%2Eglyphicon%2Dsound%2Dstereo%3Abefore%7Bcontent%3A%22%5Ce189%22%7D%2Eglyphicon%2Dsound%2Ddolby%3Abefore%7Bcontent%3A%22%5Ce190%22%7D%2Eglyphicon%2Dsound%2D5%2D1%3Abefore%7Bcontent%3A%22%5Ce191%22%7D%2Eglyphicon%2Dsound%2D6%2D1%3Abefore%7Bcontent%3A%22%5Ce192%22%7D%2Eglyphicon%2Dsound%2D7%2D1%3Abefore%7Bcontent%3A%22%5Ce193%22%7D%2Eglyphicon%2Dcopyright%2Dmark%3Abefore%7Bcontent%3A%22%5Ce194%22%7D%2Eglyphicon%2Dregistration%2Dmark%3Abefore%7Bcontent%3A%22%5Ce195%22%7D%2Eglyphicon%2Dcloud%2Ddownload%3Abefore%7Bcontent%3A%22%5Ce197%22%7D%2Eglyphicon%2Dcloud%2Dupload%3Abefore%7Bcontent%3A%22%5Ce198%22%7D%2Eglyphicon%2Dtree%2Dconifer%3Abefore%7Bcontent%3A%22%5Ce199%22%7D%2Eglyphicon%2Dtree%2Ddeciduous%3Abefore%7Bcontent%3A%22%5Ce200%22%7D%2Eglyphicon%2Dcd%3Abefore%7Bcontent%3A%22%5Ce201%22%7D%2Eglyphicon%2Dsave%2Dfile%3Abefore%7Bcontent%3A%22%5Ce202%22%7D%2Eglyphicon%2Dopen%2Dfile%3Abefore%7Bcontent%3A%22%5Ce203%22%7D%2Eglyphicon%2Dlevel%2Dup%3Abefore%7Bcontent%3A%22%5Ce204%22%7D%2Eglyphicon%2Dcopy%3Abefore%7Bcontent%3A%22%5Ce205%22%7D%2Eglyphicon%2Dpaste%3Abefore%7Bcontent%3A%22%5Ce206%22%7D%2Eglyphicon%2Dalert%3Abefore%7Bcontent%3A%22%5Ce209%22%7D%2Eglyphicon%2Dequalizer%3Abefore%7Bcontent%3A%22%5Ce210%22%7D%2Eglyphicon%2Dking%3Abefore%7Bcontent%3A%22%5Ce211%22%7D%2Eglyphicon%2Dqueen%3Abefore%7Bcontent%3A%22%5Ce212%22%7D%2Eglyphicon%2Dpawn%3Abefore%7Bcontent%3A%22%5Ce213%22%7D%2Eglyphicon%2Dbishop%3Abefore%7Bcontent%3A%22%5Ce214%22%7D%2Eglyphicon%2Dknight%3Abefore%7Bcontent%3A%22%5Ce215%22%7D%2Eglyphicon%2Dbaby%2Dformula%3Abefore%7Bcontent%3A%22%5Ce216%22%7D%2Eglyphicon%2Dtent%3Abefore%7Bcontent%3A%22%5C26fa%22%7D%2Eglyphicon%2Dblackboard%3Abefore%7Bcontent%3A%22%5Ce218%22%7D%2Eglyphicon%2Dbed%3Abefore%7Bcontent%3A%22%5Ce219%22%7D%2Eglyphicon%2Dapple%3Abefore%7Bcontent%3A%22%5Cf8ff%22%7D%2Eglyphicon%2Derase%3Abefore%7Bcontent%3A%22%5Ce221%22%7D%2Eglyphicon%2Dhourglass%3Abefore%7Bcontent%3A%22%5C231b%22%7D%2Eglyphicon%2Dlamp%3Abefore%7Bcontent%3A%22%5Ce223%22%7D%2Eglyphicon%2Dduplicate%3Abefore%7Bcontent%3A%22%5Ce224%22%7D%2Eglyphicon%2Dpiggy%2Dbank%3Abefore%7Bcontent%3A%22%5Ce225%22%7D%2Eglyphicon%2Dscissors%3Abefore%7Bcontent%3A%22%5Ce226%22%7D%2Eglyphicon%2Dbitcoin%3Abefore%7Bcontent%3A%22%5Ce227%22%7D%2Eglyphicon%2Dbtc%3Abefore%7Bcontent%3A%22%5Ce227%22%7D%2Eglyphicon%2Dxbt%3Abefore%7Bcontent%3A%22%5Ce227%22%7D%2Eglyphicon%2Dyen%3Abefore%7Bcontent%3A%22%5C00a5%22%7D%2Eglyphicon%2Djpy%3Abefore%7Bcontent%3A%22%5C00a5%22%7D%2Eglyphicon%2Druble%3Abefore%7Bcontent%3A%22%5C20bd%22%7D%2Eglyphicon%2Drub%3Abefore%7Bcontent%3A%22%5C20bd%22%7D%2Eglyphicon%2Dscale%3Abefore%7Bcontent%3A%22%5Ce230%22%7D%2Eglyphicon%2Dice%2Dlolly%3Abefore%7Bcontent%3A%22%5Ce231%22%7D%2Eglyphicon%2Dice%2Dlolly%2Dtasted%3Abefore%7Bcontent%3A%22%5Ce232%22%7D%2Eglyphicon%2Deducation%3Abefore%7Bcontent%3A%22%5Ce233%22%7D%2Eglyphicon%2Doption%2Dhorizontal%3Abefore%7Bcontent%3A%22%5Ce234%22%7D%2Eglyphicon%2Doption%2Dvertical%3Abefore%7Bcontent%3A%22%5Ce235%22%7D%2Eglyphicon%2Dmenu%2Dhamburger%3Abefore%7Bcontent%3A%22%5Ce236%22%7D%2Eglyphicon%2Dmodal%2Dwindow%3Abefore%7Bcontent%3A%22%5Ce237%22%7D%2Eglyphicon%2Doil%3Abefore%7Bcontent%3A%22%5Ce238%22%7D%2Eglyphicon%2Dgrain%3Abefore%7Bcontent%3A%22%5Ce239%22%7D%2Eglyphicon%2Dsunglasses%3Abefore%7Bcontent%3A%22%5Ce240%22%7D%2Eglyphicon%2Dtext%2Dsize%3Abefore%7Bcontent%3A%22%5Ce241%22%7D%2Eglyphicon%2Dtext%2Dcolor%3Abefore%7Bcontent%3A%22%5Ce242%22%7D%2Eglyphicon%2Dtext%2Dbackground%3Abefore%7Bcontent%3A%22%5Ce243%22%7D%2Eglyphicon%2Dobject%2Dalign%2Dtop%3Abefore%7Bcontent%3A%22%5Ce244%22%7D%2Eglyphicon%2Dobject%2Dalign%2Dbottom%3Abefore%7Bcontent%3A%22%5Ce245%22%7D%2Eglyphicon%2Dobject%2Dalign%2Dhorizontal%3Abefore%7Bcontent%3A%22%5Ce246%22%7D%2Eglyphicon%2Dobject%2Dalign%2Dleft%3Abefore%7Bcontent%3A%22%5Ce247%22%7D%2Eglyphicon%2Dobject%2Dalign%2Dvertical%3Abefore%7Bcontent%3A%22%5Ce248%22%7D%2Eglyphicon%2Dobject%2Dalign%2Dright%3Abefore%7Bcontent%3A%22%5Ce249%22%7D%2Eglyphicon%2Dtriangle%2Dright%3Abefore%7Bcontent%3A%22%5Ce250%22%7D%2Eglyphicon%2Dtriangle%2Dleft%3Abefore%7Bcontent%3A%22%5Ce251%22%7D%2Eglyphicon%2Dtriangle%2Dbottom%3Abefore%7Bcontent%3A%22%5Ce252%22%7D%2Eglyphicon%2Dtriangle%2Dtop%3Abefore%7Bcontent%3A%22%5Ce253%22%7D%2Eglyphicon%2Dconsole%3Abefore%7Bcontent%3A%22%5Ce254%22%7D%2Eglyphicon%2Dsuperscript%3Abefore%7Bcontent%3A%22%5Ce255%22%7D%2Eglyphicon%2Dsubscript%3Abefore%7Bcontent%3A%22%5Ce256%22%7D%2Eglyphicon%2Dmenu%2Dleft%3Abefore%7Bcontent%3A%22%5Ce257%22%7D%2Eglyphicon%2Dmenu%2Dright%3Abefore%7Bcontent%3A%22%5Ce258%22%7D%2Eglyphicon%2Dmenu%2Ddown%3Abefore%7Bcontent%3A%22%5Ce259%22%7D%2Eglyphicon%2Dmenu%2Dup%3Abefore%7Bcontent%3A%22%5Ce260%22%7D%2A%7B%2Dwebkit%2Dbox%2Dsizing%3Aborder%2Dbox%3B%2Dmoz%2Dbox%2Dsizing%3Aborder%2Dbox%3Bbox%2Dsizing%3Aborder%2Dbox%7D%3Aafter%2C%3Abefore%7B%2Dwebkit%2Dbox%2Dsizing%3Aborder%2Dbox%3B%2Dmoz%2Dbox%2Dsizing%3Aborder%2Dbox%3Bbox%2Dsizing%3Aborder%2Dbox%7Dhtml%7Bfont%2Dsize%3A10px%3B%2Dwebkit%2Dtap%2Dhighlight%2Dcolor%3Argba%280%2C0%2C0%2C0%29%7Dbody%7Bfont%2Dfamily%3A%22Helvetica%20Neue%22%2CHelvetica%2CArial%2Csans%2Dserif%3Bfont%2Dsize%3A14px%3Bline%2Dheight%3A1%2E42857143%3Bcolor%3A%23333%3Bbackground%2Dcolor%3A%23fff%7Dbutton%2Cinput%2Cselect%2Ctextarea%7Bfont%2Dfamily%3Ainherit%3Bfont%2Dsize%3Ainherit%3Bline%2Dheight%3Ainherit%7Da%7Bcolor%3A%23337ab7%3Btext%2Ddecoration%3Anone%7Da%3Afocus%2Ca%3Ahover%7Bcolor%3A%2323527c%3Btext%2Ddecoration%3Aunderline%7Da%3Afocus%7Boutline%3Athin%20dotted%3Boutline%3A5px%20auto%20%2Dwebkit%2Dfocus%2Dring%2Dcolor%3Boutline%2Doffset%3A%2D2px%7Dfigure%7Bmargin%3A0%7Dimg%7Bvertical%2Dalign%3Amiddle%7D%2Ecarousel%2Dinner%3E%2Eitem%3Ea%3Eimg%2C%2Ecarousel%2Dinner%3E%2Eitem%3Eimg%2C%2Eimg%2Dresponsive%2C%2Ethumbnail%20a%3Eimg%2C%2Ethumbnail%3Eimg%7Bdisplay%3Ablock%3Bmax%2Dwidth%3A100%25%3Bheight%3Aauto%7D%2Eimg%2Drounded%7Bborder%2Dradius%3A6px%7D%2Eimg%2Dthumbnail%7Bdisplay%3Ainline%2Dblock%3Bmax%2Dwidth%3A100%25%3Bheight%3Aauto%3Bpadding%3A4px%3Bline%2Dheight%3A1%2E42857143%3Bbackground%2Dcolor%3A%23fff%3Bborder%3A1px%20solid%20%23ddd%3Bborder%2Dradius%3A4px%3B%2Dwebkit%2Dtransition%3Aall%20%2E2s%20ease%2Din%2Dout%3B%2Do%2Dtransition%3Aall%20%2E2s%20ease%2Din%2Dout%3Btransition%3Aall%20%2E2s%20ease%2Din%2Dout%7D%2Eimg%2Dcircle%7Bborder%2Dradius%3A50%25%7Dhr%7Bmargin%2Dtop%3A20px%3Bmargin%2Dbottom%3A20px%3Bborder%3A0%3Bborder%2Dtop%3A1px%20solid%20%23eee%7D%2Esr%2Donly%7Bposition%3Aabsolute%3Bwidth%3A1px%3Bheight%3A1px%3Bpadding%3A0%3Bmargin%3A%2D1px%3Boverflow%3Ahidden%3Bclip%3Arect%280%2C0%2C0%2C0%29%3Bborder%3A0%7D%2Esr%2Donly%2Dfocusable%3Aactive%2C%2Esr%2Donly%2Dfocusable%3Afocus%7Bposition%3Astatic%3Bwidth%3Aauto%3Bheight%3Aauto%3Bmargin%3A0%3Boverflow%3Avisible%3Bclip%3Aauto%7D%5Brole%3Dbutton%5D%7Bcursor%3Apointer%7D%2Eh1%2C%2Eh2%2C%2Eh3%2C%2Eh4%2C%2Eh5%2C%2Eh6%2Ch1%2Ch2%2Ch3%2Ch4%2Ch5%2Ch6%7Bfont%2Dfamily%3Ainherit%3Bfont%2Dweight%3A500%3Bline%2Dheight%3A1%2E1%3Bcolor%3Ainherit%7D%2Eh1%20%2Esmall%2C%2Eh1%20small%2C%2Eh2%20%2Esmall%2C%2Eh2%20small%2C%2Eh3%20%2Esmall%2C%2Eh3%20small%2C%2Eh4%20%2Esmall%2C%2Eh4%20small%2C%2Eh5%20%2Esmall%2C%2Eh5%20small%2C%2Eh6%20%2Esmall%2C%2Eh6%20small%2Ch1%20%2Esmall%2Ch1%20small%2Ch2%20%2Esmall%2Ch2%20small%2Ch3%20%2Esmall%2Ch3%20small%2Ch4%20%2Esmall%2Ch4%20small%2Ch5%20%2Esmall%2Ch5%20small%2Ch6%20%2Esmall%2Ch6%20small%7Bfont%2Dweight%3A400%3Bline%2Dheight%3A1%3Bcolor%3A%23777%7D%2Eh1%2C%2Eh2%2C%2Eh3%2Ch1%2Ch2%2Ch3%7Bmargin%2Dtop%3A20px%3Bmargin%2Dbottom%3A10px%7D%2Eh1%20%2Esmall%2C%2Eh1%20small%2C%2Eh2%20%2Esmall%2C%2Eh2%20small%2C%2Eh3%20%2Esmall%2C%2Eh3%20small%2Ch1%20%2Esmall%2Ch1%20small%2Ch2%20%2Esmall%2Ch2%20small%2Ch3%20%2Esmall%2Ch3%20small%7Bfont%2Dsize%3A65%25%7D%2Eh4%2C%2Eh5%2C%2Eh6%2Ch4%2Ch5%2Ch6%7Bmargin%2Dtop%3A10px%3Bmargin%2Dbottom%3A10px%7D%2Eh4%20%2Esmall%2C%2Eh4%20small%2C%2Eh5%20%2Esmall%2C%2Eh5%20small%2C%2Eh6%20%2Esmall%2C%2Eh6%20small%2Ch4%20%2Esmall%2Ch4%20small%2Ch5%20%2Esmall%2Ch5%20small%2Ch6%20%2Esmall%2Ch6%20small%7Bfont%2Dsize%3A75%25%7D%2Eh1%2Ch1%7Bfont%2Dsize%3A36px%7D%2Eh2%2Ch2%7Bfont%2Dsize%3A30px%7D%2Eh3%2Ch3%7Bfont%2Dsize%3A24px%7D%2Eh4%2Ch4%7Bfont%2Dsize%3A18px%7D%2Eh5%2Ch5%7Bfont%2Dsize%3A14px%7D%2Eh6%2Ch6%7Bfont%2Dsize%3A12px%7Dp%7Bmargin%3A0%200%2010px%7D%2Elead%7Bmargin%2Dbottom%3A20px%3Bfont%2Dsize%3A16px%3Bfont%2Dweight%3A300%3Bline%2Dheight%3A1%2E4%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Elead%7Bfont%2Dsize%3A21px%7D%7D%2Esmall%2Csmall%7Bfont%2Dsize%3A85%25%7D%2Emark%2Cmark%7Bpadding%3A%2E2em%3Bbackground%2Dcolor%3A%23fcf8e3%7D%2Etext%2Dleft%7Btext%2Dalign%3Aleft%7D%2Etext%2Dright%7Btext%2Dalign%3Aright%7D%2Etext%2Dcenter%7Btext%2Dalign%3Acenter%7D%2Etext%2Djustify%7Btext%2Dalign%3Ajustify%7D%2Etext%2Dnowrap%7Bwhite%2Dspace%3Anowrap%7D%2Etext%2Dlowercase%7Btext%2Dtransform%3Alowercase%7D%2Etext%2Duppercase%7Btext%2Dtransform%3Auppercase%7D%2Etext%2Dcapitalize%7Btext%2Dtransform%3Acapitalize%7D%2Etext%2Dmuted%7Bcolor%3A%23777%7D%2Etext%2Dprimary%7Bcolor%3A%23337ab7%7Da%2Etext%2Dprimary%3Afocus%2Ca%2Etext%2Dprimary%3Ahover%7Bcolor%3A%23286090%7D%2Etext%2Dsuccess%7Bcolor%3A%233c763d%7Da%2Etext%2Dsuccess%3Afocus%2Ca%2Etext%2Dsuccess%3Ahover%7Bcolor%3A%232b542c%7D%2Etext%2Dinfo%7Bcolor%3A%2331708f%7Da%2Etext%2Dinfo%3Afocus%2Ca%2Etext%2Dinfo%3Ahover%7Bcolor%3A%23245269%7D%2Etext%2Dwarning%7Bcolor%3A%238a6d3b%7Da%2Etext%2Dwarning%3Afocus%2Ca%2Etext%2Dwarning%3Ahover%7Bcolor%3A%2366512c%7D%2Etext%2Ddanger%7Bcolor%3A%23a94442%7Da%2Etext%2Ddanger%3Afocus%2Ca%2Etext%2Ddanger%3Ahover%7Bcolor%3A%23843534%7D%2Ebg%2Dprimary%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23337ab7%7Da%2Ebg%2Dprimary%3Afocus%2Ca%2Ebg%2Dprimary%3Ahover%7Bbackground%2Dcolor%3A%23286090%7D%2Ebg%2Dsuccess%7Bbackground%2Dcolor%3A%23dff0d8%7Da%2Ebg%2Dsuccess%3Afocus%2Ca%2Ebg%2Dsuccess%3Ahover%7Bbackground%2Dcolor%3A%23c1e2b3%7D%2Ebg%2Dinfo%7Bbackground%2Dcolor%3A%23d9edf7%7Da%2Ebg%2Dinfo%3Afocus%2Ca%2Ebg%2Dinfo%3Ahover%7Bbackground%2Dcolor%3A%23afd9ee%7D%2Ebg%2Dwarning%7Bbackground%2Dcolor%3A%23fcf8e3%7Da%2Ebg%2Dwarning%3Afocus%2Ca%2Ebg%2Dwarning%3Ahover%7Bbackground%2Dcolor%3A%23f7ecb5%7D%2Ebg%2Ddanger%7Bbackground%2Dcolor%3A%23f2dede%7Da%2Ebg%2Ddanger%3Afocus%2Ca%2Ebg%2Ddanger%3Ahover%7Bbackground%2Dcolor%3A%23e4b9b9%7D%2Epage%2Dheader%7Bpadding%2Dbottom%3A9px%3Bmargin%3A40px%200%2020px%3Bborder%2Dbottom%3A1px%20solid%20%23eee%7Dol%2Cul%7Bmargin%2Dtop%3A0%3Bmargin%2Dbottom%3A10px%7Dol%20ol%2Col%20ul%2Cul%20ol%2Cul%20ul%7Bmargin%2Dbottom%3A0%7D%2Elist%2Dunstyled%7Bpadding%2Dleft%3A0%3Blist%2Dstyle%3Anone%7D%2Elist%2Dinline%7Bpadding%2Dleft%3A0%3Bmargin%2Dleft%3A%2D5px%3Blist%2Dstyle%3Anone%7D%2Elist%2Dinline%3Eli%7Bdisplay%3Ainline%2Dblock%3Bpadding%2Dright%3A5px%3Bpadding%2Dleft%3A5px%7Ddl%7Bmargin%2Dtop%3A0%3Bmargin%2Dbottom%3A20px%7Ddd%2Cdt%7Bline%2Dheight%3A1%2E42857143%7Ddt%7Bfont%2Dweight%3A700%7Ddd%7Bmargin%2Dleft%3A0%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Edl%2Dhorizontal%20dt%7Bfloat%3Aleft%3Bwidth%3A160px%3Boverflow%3Ahidden%3Bclear%3Aleft%3Btext%2Dalign%3Aright%3Btext%2Doverflow%3Aellipsis%3Bwhite%2Dspace%3Anowrap%7D%2Edl%2Dhorizontal%20dd%7Bmargin%2Dleft%3A180px%7D%7Dabbr%5Bdata%2Doriginal%2Dtitle%5D%2Cabbr%5Btitle%5D%7Bcursor%3Ahelp%3Bborder%2Dbottom%3A1px%20dotted%20%23777%7D%2Einitialism%7Bfont%2Dsize%3A90%25%3Btext%2Dtransform%3Auppercase%7Dblockquote%7Bpadding%3A10px%2020px%3Bmargin%3A0%200%2020px%3Bfont%2Dsize%3A17%2E5px%3Bborder%2Dleft%3A5px%20solid%20%23eee%7Dblockquote%20ol%3Alast%2Dchild%2Cblockquote%20p%3Alast%2Dchild%2Cblockquote%20ul%3Alast%2Dchild%7Bmargin%2Dbottom%3A0%7Dblockquote%20%2Esmall%2Cblockquote%20footer%2Cblockquote%20small%7Bdisplay%3Ablock%3Bfont%2Dsize%3A80%25%3Bline%2Dheight%3A1%2E42857143%3Bcolor%3A%23777%7Dblockquote%20%2Esmall%3Abefore%2Cblockquote%20footer%3Abefore%2Cblockquote%20small%3Abefore%7Bcontent%3A%27%5C2014%20%5C00A0%27%7D%2Eblockquote%2Dreverse%2Cblockquote%2Epull%2Dright%7Bpadding%2Dright%3A15px%3Bpadding%2Dleft%3A0%3Btext%2Dalign%3Aright%3Bborder%2Dright%3A5px%20solid%20%23eee%3Bborder%2Dleft%3A0%7D%2Eblockquote%2Dreverse%20%2Esmall%3Abefore%2C%2Eblockquote%2Dreverse%20footer%3Abefore%2C%2Eblockquote%2Dreverse%20small%3Abefore%2Cblockquote%2Epull%2Dright%20%2Esmall%3Abefore%2Cblockquote%2Epull%2Dright%20footer%3Abefore%2Cblockquote%2Epull%2Dright%20small%3Abefore%7Bcontent%3A%27%27%7D%2Eblockquote%2Dreverse%20%2Esmall%3Aafter%2C%2Eblockquote%2Dreverse%20footer%3Aafter%2C%2Eblockquote%2Dreverse%20small%3Aafter%2Cblockquote%2Epull%2Dright%20%2Esmall%3Aafter%2Cblockquote%2Epull%2Dright%20footer%3Aafter%2Cblockquote%2Epull%2Dright%20small%3Aafter%7Bcontent%3A%27%5C00A0%20%5C2014%27%7Daddress%7Bmargin%2Dbottom%3A20px%3Bfont%2Dstyle%3Anormal%3Bline%2Dheight%3A1%2E42857143%7Dcode%2Ckbd%2Cpre%2Csamp%7Bfont%2Dfamily%3Amonospace%7Dcode%7Bpadding%3A2px%204px%3Bfont%2Dsize%3A90%25%3Bcolor%3A%23c7254e%3Bbackground%2Dcolor%3A%23f9f2f4%3Bborder%2Dradius%3A4px%7Dkbd%7Bpadding%3A2px%204px%3Bfont%2Dsize%3A90%25%3Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23333%3Bborder%2Dradius%3A3px%3B%2Dwebkit%2Dbox%2Dshadow%3Ainset%200%20%2D1px%200%20rgba%280%2C0%2C0%2C%2E25%29%3Bbox%2Dshadow%3Ainset%200%20%2D1px%200%20rgba%280%2C0%2C0%2C%2E25%29%7Dkbd%20kbd%7Bpadding%3A0%3Bfont%2Dsize%3A100%25%3Bfont%2Dweight%3A700%3B%2Dwebkit%2Dbox%2Dshadow%3Anone%3Bbox%2Dshadow%3Anone%7Dpre%7Bdisplay%3Ablock%3Bpadding%3A9%2E5px%3Bmargin%3A0%200%2010px%3Bfont%2Dsize%3A13px%3Bline%2Dheight%3A1%2E42857143%3Bcolor%3A%23333%3Bword%2Dbreak%3Abreak%2Dall%3Bword%2Dwrap%3Abreak%2Dword%3Bbackground%2Dcolor%3A%23f5f5f5%3Bborder%3A1px%20solid%20%23ccc%3Bborder%2Dradius%3A4px%7Dpre%20code%7Bpadding%3A0%3Bfont%2Dsize%3Ainherit%3Bcolor%3Ainherit%3Bwhite%2Dspace%3Apre%2Dwrap%3Bbackground%2Dcolor%3Atransparent%3Bborder%2Dradius%3A0%7D%2Epre%2Dscrollable%7Bmax%2Dheight%3A340px%3Boverflow%2Dy%3Ascroll%7D%2Econtainer%7Bpadding%2Dright%3A15px%3Bpadding%2Dleft%3A15px%3Bmargin%2Dright%3Aauto%3Bmargin%2Dleft%3Aauto%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Econtainer%7Bwidth%3A750px%7D%7D%40media%20%28min%2Dwidth%3A992px%29%7B%2Econtainer%7Bwidth%3A970px%7D%7D%40media%20%28min%2Dwidth%3A1200px%29%7B%2Econtainer%7Bwidth%3A1170px%7D%7D%2Econtainer%2Dfluid%7Bpadding%2Dright%3A15px%3Bpadding%2Dleft%3A15px%3Bmargin%2Dright%3Aauto%3Bmargin%2Dleft%3Aauto%7D%2Erow%7Bmargin%2Dright%3A%2D15px%3Bmargin%2Dleft%3A%2D15px%7D%2Ecol%2Dlg%2D1%2C%2Ecol%2Dlg%2D10%2C%2Ecol%2Dlg%2D11%2C%2Ecol%2Dlg%2D12%2C%2Ecol%2Dlg%2D2%2C%2Ecol%2Dlg%2D3%2C%2Ecol%2Dlg%2D4%2C%2Ecol%2Dlg%2D5%2C%2Ecol%2Dlg%2D6%2C%2Ecol%2Dlg%2D7%2C%2Ecol%2Dlg%2D8%2C%2Ecol%2Dlg%2D9%2C%2Ecol%2Dmd%2D1%2C%2Ecol%2Dmd%2D10%2C%2Ecol%2Dmd%2D11%2C%2Ecol%2Dmd%2D12%2C%2Ecol%2Dmd%2D2%2C%2Ecol%2Dmd%2D3%2C%2Ecol%2Dmd%2D4%2C%2Ecol%2Dmd%2D5%2C%2Ecol%2Dmd%2D6%2C%2Ecol%2Dmd%2D7%2C%2Ecol%2Dmd%2D8%2C%2Ecol%2Dmd%2D9%2C%2Ecol%2Dsm%2D1%2C%2Ecol%2Dsm%2D10%2C%2Ecol%2Dsm%2D11%2C%2Ecol%2Dsm%2D12%2C%2Ecol%2Dsm%2D2%2C%2Ecol%2Dsm%2D3%2C%2Ecol%2Dsm%2D4%2C%2Ecol%2Dsm%2D5%2C%2Ecol%2Dsm%2D6%2C%2Ecol%2Dsm%2D7%2C%2Ecol%2Dsm%2D8%2C%2Ecol%2Dsm%2D9%2C%2Ecol%2Dxs%2D1%2C%2Ecol%2Dxs%2D10%2C%2Ecol%2Dxs%2D11%2C%2Ecol%2Dxs%2D12%2C%2Ecol%2Dxs%2D2%2C%2Ecol%2Dxs%2D3%2C%2Ecol%2Dxs%2D4%2C%2Ecol%2Dxs%2D5%2C%2Ecol%2Dxs%2D6%2C%2Ecol%2Dxs%2D7%2C%2Ecol%2Dxs%2D8%2C%2Ecol%2Dxs%2D9%7Bposition%3Arelative%3Bmin%2Dheight%3A1px%3Bpadding%2Dright%3A15px%3Bpadding%2Dleft%3A15px%7D%2Ecol%2Dxs%2D1%2C%2Ecol%2Dxs%2D10%2C%2Ecol%2Dxs%2D11%2C%2Ecol%2Dxs%2D12%2C%2Ecol%2Dxs%2D2%2C%2Ecol%2Dxs%2D3%2C%2Ecol%2Dxs%2D4%2C%2Ecol%2Dxs%2D5%2C%2Ecol%2Dxs%2D6%2C%2Ecol%2Dxs%2D7%2C%2Ecol%2Dxs%2D8%2C%2Ecol%2Dxs%2D9%7Bfloat%3Aleft%7D%2Ecol%2Dxs%2D12%7Bwidth%3A100%25%7D%2Ecol%2Dxs%2D11%7Bwidth%3A91%2E66666667%25%7D%2Ecol%2Dxs%2D10%7Bwidth%3A83%2E33333333%25%7D%2Ecol%2Dxs%2D9%7Bwidth%3A75%25%7D%2Ecol%2Dxs%2D8%7Bwidth%3A66%2E66666667%25%7D%2Ecol%2Dxs%2D7%7Bwidth%3A58%2E33333333%25%7D%2Ecol%2Dxs%2D6%7Bwidth%3A50%25%7D%2Ecol%2Dxs%2D5%7Bwidth%3A41%2E66666667%25%7D%2Ecol%2Dxs%2D4%7Bwidth%3A33%2E33333333%25%7D%2Ecol%2Dxs%2D3%7Bwidth%3A25%25%7D%2Ecol%2Dxs%2D2%7Bwidth%3A16%2E66666667%25%7D%2Ecol%2Dxs%2D1%7Bwidth%3A8%2E33333333%25%7D%2Ecol%2Dxs%2Dpull%2D12%7Bright%3A100%25%7D%2Ecol%2Dxs%2Dpull%2D11%7Bright%3A91%2E66666667%25%7D%2Ecol%2Dxs%2Dpull%2D10%7Bright%3A83%2E33333333%25%7D%2Ecol%2Dxs%2Dpull%2D9%7Bright%3A75%25%7D%2Ecol%2Dxs%2Dpull%2D8%7Bright%3A66%2E66666667%25%7D%2Ecol%2Dxs%2Dpull%2D7%7Bright%3A58%2E33333333%25%7D%2Ecol%2Dxs%2Dpull%2D6%7Bright%3A50%25%7D%2Ecol%2Dxs%2Dpull%2D5%7Bright%3A41%2E66666667%25%7D%2Ecol%2Dxs%2Dpull%2D4%7Bright%3A33%2E33333333%25%7D%2Ecol%2Dxs%2Dpull%2D3%7Bright%3A25%25%7D%2Ecol%2Dxs%2Dpull%2D2%7Bright%3A16%2E66666667%25%7D%2Ecol%2Dxs%2Dpull%2D1%7Bright%3A8%2E33333333%25%7D%2Ecol%2Dxs%2Dpull%2D0%7Bright%3Aauto%7D%2Ecol%2Dxs%2Dpush%2D12%7Bleft%3A100%25%7D%2Ecol%2Dxs%2Dpush%2D11%7Bleft%3A91%2E66666667%25%7D%2Ecol%2Dxs%2Dpush%2D10%7Bleft%3A83%2E33333333%25%7D%2Ecol%2Dxs%2Dpush%2D9%7Bleft%3A75%25%7D%2Ecol%2Dxs%2Dpush%2D8%7Bleft%3A66%2E66666667%25%7D%2Ecol%2Dxs%2Dpush%2D7%7Bleft%3A58%2E33333333%25%7D%2Ecol%2Dxs%2Dpush%2D6%7Bleft%3A50%25%7D%2Ecol%2Dxs%2Dpush%2D5%7Bleft%3A41%2E66666667%25%7D%2Ecol%2Dxs%2Dpush%2D4%7Bleft%3A33%2E33333333%25%7D%2Ecol%2Dxs%2Dpush%2D3%7Bleft%3A25%25%7D%2Ecol%2Dxs%2Dpush%2D2%7Bleft%3A16%2E66666667%25%7D%2Ecol%2Dxs%2Dpush%2D1%7Bleft%3A8%2E33333333%25%7D%2Ecol%2Dxs%2Dpush%2D0%7Bleft%3Aauto%7D%2Ecol%2Dxs%2Doffset%2D12%7Bmargin%2Dleft%3A100%25%7D%2Ecol%2Dxs%2Doffset%2D11%7Bmargin%2Dleft%3A91%2E66666667%25%7D%2Ecol%2Dxs%2Doffset%2D10%7Bmargin%2Dleft%3A83%2E33333333%25%7D%2Ecol%2Dxs%2Doffset%2D9%7Bmargin%2Dleft%3A75%25%7D%2Ecol%2Dxs%2Doffset%2D8%7Bmargin%2Dleft%3A66%2E66666667%25%7D%2Ecol%2Dxs%2Doffset%2D7%7Bmargin%2Dleft%3A58%2E33333333%25%7D%2Ecol%2Dxs%2Doffset%2D6%7Bmargin%2Dleft%3A50%25%7D%2Ecol%2Dxs%2Doffset%2D5%7Bmargin%2Dleft%3A41%2E66666667%25%7D%2Ecol%2Dxs%2Doffset%2D4%7Bmargin%2Dleft%3A33%2E33333333%25%7D%2Ecol%2Dxs%2Doffset%2D3%7Bmargin%2Dleft%3A25%25%7D%2Ecol%2Dxs%2Doffset%2D2%7Bmargin%2Dleft%3A16%2E66666667%25%7D%2Ecol%2Dxs%2Doffset%2D1%7Bmargin%2Dleft%3A8%2E33333333%25%7D%2Ecol%2Dxs%2Doffset%2D0%7Bmargin%2Dleft%3A0%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Ecol%2Dsm%2D1%2C%2Ecol%2Dsm%2D10%2C%2Ecol%2Dsm%2D11%2C%2Ecol%2Dsm%2D12%2C%2Ecol%2Dsm%2D2%2C%2Ecol%2Dsm%2D3%2C%2Ecol%2Dsm%2D4%2C%2Ecol%2Dsm%2D5%2C%2Ecol%2Dsm%2D6%2C%2Ecol%2Dsm%2D7%2C%2Ecol%2Dsm%2D8%2C%2Ecol%2Dsm%2D9%7Bfloat%3Aleft%7D%2Ecol%2Dsm%2D12%7Bwidth%3A100%25%7D%2Ecol%2Dsm%2D11%7Bwidth%3A91%2E66666667%25%7D%2Ecol%2Dsm%2D10%7Bwidth%3A83%2E33333333%25%7D%2Ecol%2Dsm%2D9%7Bwidth%3A75%25%7D%2Ecol%2Dsm%2D8%7Bwidth%3A66%2E66666667%25%7D%2Ecol%2Dsm%2D7%7Bwidth%3A58%2E33333333%25%7D%2Ecol%2Dsm%2D6%7Bwidth%3A50%25%7D%2Ecol%2Dsm%2D5%7Bwidth%3A41%2E66666667%25%7D%2Ecol%2Dsm%2D4%7Bwidth%3A33%2E33333333%25%7D%2Ecol%2Dsm%2D3%7Bwidth%3A25%25%7D%2Ecol%2Dsm%2D2%7Bwidth%3A16%2E66666667%25%7D%2Ecol%2Dsm%2D1%7Bwidth%3A8%2E33333333%25%7D%2Ecol%2Dsm%2Dpull%2D12%7Bright%3A100%25%7D%2Ecol%2Dsm%2Dpull%2D11%7Bright%3A91%2E66666667%25%7D%2Ecol%2Dsm%2Dpull%2D10%7Bright%3A83%2E33333333%25%7D%2Ecol%2Dsm%2Dpull%2D9%7Bright%3A75%25%7D%2Ecol%2Dsm%2Dpull%2D8%7Bright%3A66%2E66666667%25%7D%2Ecol%2Dsm%2Dpull%2D7%7Bright%3A58%2E33333333%25%7D%2Ecol%2Dsm%2Dpull%2D6%7Bright%3A50%25%7D%2Ecol%2Dsm%2Dpull%2D5%7Bright%3A41%2E66666667%25%7D%2Ecol%2Dsm%2Dpull%2D4%7Bright%3A33%2E33333333%25%7D%2Ecol%2Dsm%2Dpull%2D3%7Bright%3A25%25%7D%2Ecol%2Dsm%2Dpull%2D2%7Bright%3A16%2E66666667%25%7D%2Ecol%2Dsm%2Dpull%2D1%7Bright%3A8%2E33333333%25%7D%2Ecol%2Dsm%2Dpull%2D0%7Bright%3Aauto%7D%2Ecol%2Dsm%2Dpush%2D12%7Bleft%3A100%25%7D%2Ecol%2Dsm%2Dpush%2D11%7Bleft%3A91%2E66666667%25%7D%2Ecol%2Dsm%2Dpush%2D10%7Bleft%3A83%2E33333333%25%7D%2Ecol%2Dsm%2Dpush%2D9%7Bleft%3A75%25%7D%2Ecol%2Dsm%2Dpush%2D8%7Bleft%3A66%2E66666667%25%7D%2Ecol%2Dsm%2Dpush%2D7%7Bleft%3A58%2E33333333%25%7D%2Ecol%2Dsm%2Dpush%2D6%7Bleft%3A50%25%7D%2Ecol%2Dsm%2Dpush%2D5%7Bleft%3A41%2E66666667%25%7D%2Ecol%2Dsm%2Dpush%2D4%7Bleft%3A33%2E33333333%25%7D%2Ecol%2Dsm%2Dpush%2D3%7Bleft%3A25%25%7D%2Ecol%2Dsm%2Dpush%2D2%7Bleft%3A16%2E66666667%25%7D%2Ecol%2Dsm%2Dpush%2D1%7Bleft%3A8%2E33333333%25%7D%2Ecol%2Dsm%2Dpush%2D0%7Bleft%3Aauto%7D%2Ecol%2Dsm%2Doffset%2D12%7Bmargin%2Dleft%3A100%25%7D%2Ecol%2Dsm%2Doffset%2D11%7Bmargin%2Dleft%3A91%2E66666667%25%7D%2Ecol%2Dsm%2Doffset%2D10%7Bmargin%2Dleft%3A83%2E33333333%25%7D%2Ecol%2Dsm%2Doffset%2D9%7Bmargin%2Dleft%3A75%25%7D%2Ecol%2Dsm%2Doffset%2D8%7Bmargin%2Dleft%3A66%2E66666667%25%7D%2Ecol%2Dsm%2Doffset%2D7%7Bmargin%2Dleft%3A58%2E33333333%25%7D%2Ecol%2Dsm%2Doffset%2D6%7Bmargin%2Dleft%3A50%25%7D%2Ecol%2Dsm%2Doffset%2D5%7Bmargin%2Dleft%3A41%2E66666667%25%7D%2Ecol%2Dsm%2Doffset%2D4%7Bmargin%2Dleft%3A33%2E33333333%25%7D%2Ecol%2Dsm%2Doffset%2D3%7Bmargin%2Dleft%3A25%25%7D%2Ecol%2Dsm%2Doffset%2D2%7Bmargin%2Dleft%3A16%2E66666667%25%7D%2Ecol%2Dsm%2Doffset%2D1%7Bmargin%2Dleft%3A8%2E33333333%25%7D%2Ecol%2Dsm%2Doffset%2D0%7Bmargin%2Dleft%3A0%7D%7D%40media%20%28min%2Dwidth%3A992px%29%7B%2Ecol%2Dmd%2D1%2C%2Ecol%2Dmd%2D10%2C%2Ecol%2Dmd%2D11%2C%2Ecol%2Dmd%2D12%2C%2Ecol%2Dmd%2D2%2C%2Ecol%2Dmd%2D3%2C%2Ecol%2Dmd%2D4%2C%2Ecol%2Dmd%2D5%2C%2Ecol%2Dmd%2D6%2C%2Ecol%2Dmd%2D7%2C%2Ecol%2Dmd%2D8%2C%2Ecol%2Dmd%2D9%7Bfloat%3Aleft%7D%2Ecol%2Dmd%2D12%7Bwidth%3A100%25%7D%2Ecol%2Dmd%2D11%7Bwidth%3A91%2E66666667%25%7D%2Ecol%2Dmd%2D10%7Bwidth%3A83%2E33333333%25%7D%2Ecol%2Dmd%2D9%7Bwidth%3A75%25%7D%2Ecol%2Dmd%2D8%7Bwidth%3A66%2E66666667%25%7D%2Ecol%2Dmd%2D7%7Bwidth%3A58%2E33333333%25%7D%2Ecol%2Dmd%2D6%7Bwidth%3A50%25%7D%2Ecol%2Dmd%2D5%7Bwidth%3A41%2E66666667%25%7D%2Ecol%2Dmd%2D4%7Bwidth%3A33%2E33333333%25%7D%2Ecol%2Dmd%2D3%7Bwidth%3A25%25%7D%2Ecol%2Dmd%2D2%7Bwidth%3A16%2E66666667%25%7D%2Ecol%2Dmd%2D1%7Bwidth%3A8%2E33333333%25%7D%2Ecol%2Dmd%2Dpull%2D12%7Bright%3A100%25%7D%2Ecol%2Dmd%2Dpull%2D11%7Bright%3A91%2E66666667%25%7D%2Ecol%2Dmd%2Dpull%2D10%7Bright%3A83%2E33333333%25%7D%2Ecol%2Dmd%2Dpull%2D9%7Bright%3A75%25%7D%2Ecol%2Dmd%2Dpull%2D8%7Bright%3A66%2E66666667%25%7D%2Ecol%2Dmd%2Dpull%2D7%7Bright%3A58%2E33333333%25%7D%2Ecol%2Dmd%2Dpull%2D6%7Bright%3A50%25%7D%2Ecol%2Dmd%2Dpull%2D5%7Bright%3A41%2E66666667%25%7D%2Ecol%2Dmd%2Dpull%2D4%7Bright%3A33%2E33333333%25%7D%2Ecol%2Dmd%2Dpull%2D3%7Bright%3A25%25%7D%2Ecol%2Dmd%2Dpull%2D2%7Bright%3A16%2E66666667%25%7D%2Ecol%2Dmd%2Dpull%2D1%7Bright%3A8%2E33333333%25%7D%2Ecol%2Dmd%2Dpull%2D0%7Bright%3Aauto%7D%2Ecol%2Dmd%2Dpush%2D12%7Bleft%3A100%25%7D%2Ecol%2Dmd%2Dpush%2D11%7Bleft%3A91%2E66666667%25%7D%2Ecol%2Dmd%2Dpush%2D10%7Bleft%3A83%2E33333333%25%7D%2Ecol%2Dmd%2Dpush%2D9%7Bleft%3A75%25%7D%2Ecol%2Dmd%2Dpush%2D8%7Bleft%3A66%2E66666667%25%7D%2Ecol%2Dmd%2Dpush%2D7%7Bleft%3A58%2E33333333%25%7D%2Ecol%2Dmd%2Dpush%2D6%7Bleft%3A50%25%7D%2Ecol%2Dmd%2Dpush%2D5%7Bleft%3A41%2E66666667%25%7D%2Ecol%2Dmd%2Dpush%2D4%7Bleft%3A33%2E33333333%25%7D%2Ecol%2Dmd%2Dpush%2D3%7Bleft%3A25%25%7D%2Ecol%2Dmd%2Dpush%2D2%7Bleft%3A16%2E66666667%25%7D%2Ecol%2Dmd%2Dpush%2D1%7Bleft%3A8%2E33333333%25%7D%2Ecol%2Dmd%2Dpush%2D0%7Bleft%3Aauto%7D%2Ecol%2Dmd%2Doffset%2D12%7Bmargin%2Dleft%3A100%25%7D%2Ecol%2Dmd%2Doffset%2D11%7Bmargin%2Dleft%3A91%2E66666667%25%7D%2Ecol%2Dmd%2Doffset%2D10%7Bmargin%2Dleft%3A83%2E33333333%25%7D%2Ecol%2Dmd%2Doffset%2D9%7Bmargin%2Dleft%3A75%25%7D%2Ecol%2Dmd%2Doffset%2D8%7Bmargin%2Dleft%3A66%2E66666667%25%7D%2Ecol%2Dmd%2Doffset%2D7%7Bmargin%2Dleft%3A58%2E33333333%25%7D%2Ecol%2Dmd%2Doffset%2D6%7Bmargin%2Dleft%3A50%25%7D%2Ecol%2Dmd%2Doffset%2D5%7Bmargin%2Dleft%3A41%2E66666667%25%7D%2Ecol%2Dmd%2Doffset%2D4%7Bmargin%2Dleft%3A33%2E33333333%25%7D%2Ecol%2Dmd%2Doffset%2D3%7Bmargin%2Dleft%3A25%25%7D%2Ecol%2Dmd%2Doffset%2D2%7Bmargin%2Dleft%3A16%2E66666667%25%7D%2Ecol%2Dmd%2Doffset%2D1%7Bmargin%2Dleft%3A8%2E33333333%25%7D%2Ecol%2Dmd%2Doffset%2D0%7Bmargin%2Dleft%3A0%7D%7D%40media%20%28min%2Dwidth%3A1200px%29%7B%2Ecol%2Dlg%2D1%2C%2Ecol%2Dlg%2D10%2C%2Ecol%2Dlg%2D11%2C%2Ecol%2Dlg%2D12%2C%2Ecol%2Dlg%2D2%2C%2Ecol%2Dlg%2D3%2C%2Ecol%2Dlg%2D4%2C%2Ecol%2Dlg%2D5%2C%2Ecol%2Dlg%2D6%2C%2Ecol%2Dlg%2D7%2C%2Ecol%2Dlg%2D8%2C%2Ecol%2Dlg%2D9%7Bfloat%3Aleft%7D%2Ecol%2Dlg%2D12%7Bwidth%3A100%25%7D%2Ecol%2Dlg%2D11%7Bwidth%3A91%2E66666667%25%7D%2Ecol%2Dlg%2D10%7Bwidth%3A83%2E33333333%25%7D%2Ecol%2Dlg%2D9%7Bwidth%3A75%25%7D%2Ecol%2Dlg%2D8%7Bwidth%3A66%2E66666667%25%7D%2Ecol%2Dlg%2D7%7Bwidth%3A58%2E33333333%25%7D%2Ecol%2Dlg%2D6%7Bwidth%3A50%25%7D%2Ecol%2Dlg%2D5%7Bwidth%3A41%2E66666667%25%7D%2Ecol%2Dlg%2D4%7Bwidth%3A33%2E33333333%25%7D%2Ecol%2Dlg%2D3%7Bwidth%3A25%25%7D%2Ecol%2Dlg%2D2%7Bwidth%3A16%2E66666667%25%7D%2Ecol%2Dlg%2D1%7Bwidth%3A8%2E33333333%25%7D%2Ecol%2Dlg%2Dpull%2D12%7Bright%3A100%25%7D%2Ecol%2Dlg%2Dpull%2D11%7Bright%3A91%2E66666667%25%7D%2Ecol%2Dlg%2Dpull%2D10%7Bright%3A83%2E33333333%25%7D%2Ecol%2Dlg%2Dpull%2D9%7Bright%3A75%25%7D%2Ecol%2Dlg%2Dpull%2D8%7Bright%3A66%2E66666667%25%7D%2Ecol%2Dlg%2Dpull%2D7%7Bright%3A58%2E33333333%25%7D%2Ecol%2Dlg%2Dpull%2D6%7Bright%3A50%25%7D%2Ecol%2Dlg%2Dpull%2D5%7Bright%3A41%2E66666667%25%7D%2Ecol%2Dlg%2Dpull%2D4%7Bright%3A33%2E33333333%25%7D%2Ecol%2Dlg%2Dpull%2D3%7Bright%3A25%25%7D%2Ecol%2Dlg%2Dpull%2D2%7Bright%3A16%2E66666667%25%7D%2Ecol%2Dlg%2Dpull%2D1%7Bright%3A8%2E33333333%25%7D%2Ecol%2Dlg%2Dpull%2D0%7Bright%3Aauto%7D%2Ecol%2Dlg%2Dpush%2D12%7Bleft%3A100%25%7D%2Ecol%2Dlg%2Dpush%2D11%7Bleft%3A91%2E66666667%25%7D%2Ecol%2Dlg%2Dpush%2D10%7Bleft%3A83%2E33333333%25%7D%2Ecol%2Dlg%2Dpush%2D9%7Bleft%3A75%25%7D%2Ecol%2Dlg%2Dpush%2D8%7Bleft%3A66%2E66666667%25%7D%2Ecol%2Dlg%2Dpush%2D7%7Bleft%3A58%2E33333333%25%7D%2Ecol%2Dlg%2Dpush%2D6%7Bleft%3A50%25%7D%2Ecol%2Dlg%2Dpush%2D5%7Bleft%3A41%2E66666667%25%7D%2Ecol%2Dlg%2Dpush%2D4%7Bleft%3A33%2E33333333%25%7D%2Ecol%2Dlg%2Dpush%2D3%7Bleft%3A25%25%7D%2Ecol%2Dlg%2Dpush%2D2%7Bleft%3A16%2E66666667%25%7D%2Ecol%2Dlg%2Dpush%2D1%7Bleft%3A8%2E33333333%25%7D%2Ecol%2Dlg%2Dpush%2D0%7Bleft%3Aauto%7D%2Ecol%2Dlg%2Doffset%2D12%7Bmargin%2Dleft%3A100%25%7D%2Ecol%2Dlg%2Doffset%2D11%7Bmargin%2Dleft%3A91%2E66666667%25%7D%2Ecol%2Dlg%2Doffset%2D10%7Bmargin%2Dleft%3A83%2E33333333%25%7D%2Ecol%2Dlg%2Doffset%2D9%7Bmargin%2Dleft%3A75%25%7D%2Ecol%2Dlg%2Doffset%2D8%7Bmargin%2Dleft%3A66%2E66666667%25%7D%2Ecol%2Dlg%2Doffset%2D7%7Bmargin%2Dleft%3A58%2E33333333%25%7D%2Ecol%2Dlg%2Doffset%2D6%7Bmargin%2Dleft%3A50%25%7D%2Ecol%2Dlg%2Doffset%2D5%7Bmargin%2Dleft%3A41%2E66666667%25%7D%2Ecol%2Dlg%2Doffset%2D4%7Bmargin%2Dleft%3A33%2E33333333%25%7D%2Ecol%2Dlg%2Doffset%2D3%7Bmargin%2Dleft%3A25%25%7D%2Ecol%2Dlg%2Doffset%2D2%7Bmargin%2Dleft%3A16%2E66666667%25%7D%2Ecol%2Dlg%2Doffset%2D1%7Bmargin%2Dleft%3A8%2E33333333%25%7D%2Ecol%2Dlg%2Doffset%2D0%7Bmargin%2Dleft%3A0%7D%7Dtable%7Bbackground%2Dcolor%3Atransparent%7Dcaption%7Bpadding%2Dtop%3A8px%3Bpadding%2Dbottom%3A8px%3Bcolor%3A%23777%3Btext%2Dalign%3Aleft%7Dth%7B%7D%2Etable%7Bwidth%3A100%25%3Bmax%2Dwidth%3A100%25%3Bmargin%2Dbottom%3A20px%7D%2Etable%3Etbody%3Etr%3Etd%2C%2Etable%3Etbody%3Etr%3Eth%2C%2Etable%3Etfoot%3Etr%3Etd%2C%2Etable%3Etfoot%3Etr%3Eth%2C%2Etable%3Ethead%3Etr%3Etd%2C%2Etable%3Ethead%3Etr%3Eth%7Bpadding%3A8px%3Bline%2Dheight%3A1%2E42857143%3Bvertical%2Dalign%3Atop%3Bborder%2Dtop%3A1px%20solid%20%23ddd%7D%2Etable%3Ethead%3Etr%3Eth%7Bvertical%2Dalign%3Abottom%3Bborder%2Dbottom%3A2px%20solid%20%23ddd%7D%2Etable%3Ecaption%2Bthead%3Etr%3Afirst%2Dchild%3Etd%2C%2Etable%3Ecaption%2Bthead%3Etr%3Afirst%2Dchild%3Eth%2C%2Etable%3Ecolgroup%2Bthead%3Etr%3Afirst%2Dchild%3Etd%2C%2Etable%3Ecolgroup%2Bthead%3Etr%3Afirst%2Dchild%3Eth%2C%2Etable%3Ethead%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%3Etd%2C%2Etable%3Ethead%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%3Eth%7Bborder%2Dtop%3A0%7D%2Etable%3Etbody%2Btbody%7Bborder%2Dtop%3A2px%20solid%20%23ddd%7D%2Etable%20%2Etable%7Bbackground%2Dcolor%3A%23fff%7D%2Etable%2Dcondensed%3Etbody%3Etr%3Etd%2C%2Etable%2Dcondensed%3Etbody%3Etr%3Eth%2C%2Etable%2Dcondensed%3Etfoot%3Etr%3Etd%2C%2Etable%2Dcondensed%3Etfoot%3Etr%3Eth%2C%2Etable%2Dcondensed%3Ethead%3Etr%3Etd%2C%2Etable%2Dcondensed%3Ethead%3Etr%3Eth%7Bpadding%3A5px%7D%2Etable%2Dbordered%7Bborder%3A1px%20solid%20%23ddd%7D%2Etable%2Dbordered%3Etbody%3Etr%3Etd%2C%2Etable%2Dbordered%3Etbody%3Etr%3Eth%2C%2Etable%2Dbordered%3Etfoot%3Etr%3Etd%2C%2Etable%2Dbordered%3Etfoot%3Etr%3Eth%2C%2Etable%2Dbordered%3Ethead%3Etr%3Etd%2C%2Etable%2Dbordered%3Ethead%3Etr%3Eth%7Bborder%3A1px%20solid%20%23ddd%7D%2Etable%2Dbordered%3Ethead%3Etr%3Etd%2C%2Etable%2Dbordered%3Ethead%3Etr%3Eth%7Bborder%2Dbottom%2Dwidth%3A2px%7D%2Etable%2Dstriped%3Etbody%3Etr%3Anth%2Dof%2Dtype%28odd%29%7Bbackground%2Dcolor%3A%23f9f9f9%7D%2Etable%2Dhover%3Etbody%3Etr%3Ahover%7Bbackground%2Dcolor%3A%23f5f5f5%7Dtable%20col%5Bclass%2A%3Dcol%2D%5D%7Bposition%3Astatic%3Bdisplay%3Atable%2Dcolumn%3Bfloat%3Anone%7Dtable%20td%5Bclass%2A%3Dcol%2D%5D%2Ctable%20th%5Bclass%2A%3Dcol%2D%5D%7Bposition%3Astatic%3Bdisplay%3Atable%2Dcell%3Bfloat%3Anone%7D%2Etable%3Etbody%3Etr%2Eactive%3Etd%2C%2Etable%3Etbody%3Etr%2Eactive%3Eth%2C%2Etable%3Etbody%3Etr%3Etd%2Eactive%2C%2Etable%3Etbody%3Etr%3Eth%2Eactive%2C%2Etable%3Etfoot%3Etr%2Eactive%3Etd%2C%2Etable%3Etfoot%3Etr%2Eactive%3Eth%2C%2Etable%3Etfoot%3Etr%3Etd%2Eactive%2C%2Etable%3Etfoot%3Etr%3Eth%2Eactive%2C%2Etable%3Ethead%3Etr%2Eactive%3Etd%2C%2Etable%3Ethead%3Etr%2Eactive%3Eth%2C%2Etable%3Ethead%3Etr%3Etd%2Eactive%2C%2Etable%3Ethead%3Etr%3Eth%2Eactive%7Bbackground%2Dcolor%3A%23f5f5f5%7D%2Etable%2Dhover%3Etbody%3Etr%2Eactive%3Ahover%3Etd%2C%2Etable%2Dhover%3Etbody%3Etr%2Eactive%3Ahover%3Eth%2C%2Etable%2Dhover%3Etbody%3Etr%3Ahover%3E%2Eactive%2C%2Etable%2Dhover%3Etbody%3Etr%3Etd%2Eactive%3Ahover%2C%2Etable%2Dhover%3Etbody%3Etr%3Eth%2Eactive%3Ahover%7Bbackground%2Dcolor%3A%23e8e8e8%7D%2Etable%3Etbody%3Etr%2Esuccess%3Etd%2C%2Etable%3Etbody%3Etr%2Esuccess%3Eth%2C%2Etable%3Etbody%3Etr%3Etd%2Esuccess%2C%2Etable%3Etbody%3Etr%3Eth%2Esuccess%2C%2Etable%3Etfoot%3Etr%2Esuccess%3Etd%2C%2Etable%3Etfoot%3Etr%2Esuccess%3Eth%2C%2Etable%3Etfoot%3Etr%3Etd%2Esuccess%2C%2Etable%3Etfoot%3Etr%3Eth%2Esuccess%2C%2Etable%3Ethead%3Etr%2Esuccess%3Etd%2C%2Etable%3Ethead%3Etr%2Esuccess%3Eth%2C%2Etable%3Ethead%3Etr%3Etd%2Esuccess%2C%2Etable%3Ethead%3Etr%3Eth%2Esuccess%7Bbackground%2Dcolor%3A%23dff0d8%7D%2Etable%2Dhover%3Etbody%3Etr%2Esuccess%3Ahover%3Etd%2C%2Etable%2Dhover%3Etbody%3Etr%2Esuccess%3Ahover%3Eth%2C%2Etable%2Dhover%3Etbody%3Etr%3Ahover%3E%2Esuccess%2C%2Etable%2Dhover%3Etbody%3Etr%3Etd%2Esuccess%3Ahover%2C%2Etable%2Dhover%3Etbody%3Etr%3Eth%2Esuccess%3Ahover%7Bbackground%2Dcolor%3A%23d0e9c6%7D%2Etable%3Etbody%3Etr%2Einfo%3Etd%2C%2Etable%3Etbody%3Etr%2Einfo%3Eth%2C%2Etable%3Etbody%3Etr%3Etd%2Einfo%2C%2Etable%3Etbody%3Etr%3Eth%2Einfo%2C%2Etable%3Etfoot%3Etr%2Einfo%3Etd%2C%2Etable%3Etfoot%3Etr%2Einfo%3Eth%2C%2Etable%3Etfoot%3Etr%3Etd%2Einfo%2C%2Etable%3Etfoot%3Etr%3Eth%2Einfo%2C%2Etable%3Ethead%3Etr%2Einfo%3Etd%2C%2Etable%3Ethead%3Etr%2Einfo%3Eth%2C%2Etable%3Ethead%3Etr%3Etd%2Einfo%2C%2Etable%3Ethead%3Etr%3Eth%2Einfo%7Bbackground%2Dcolor%3A%23d9edf7%7D%2Etable%2Dhover%3Etbody%3Etr%2Einfo%3Ahover%3Etd%2C%2Etable%2Dhover%3Etbody%3Etr%2Einfo%3Ahover%3Eth%2C%2Etable%2Dhover%3Etbody%3Etr%3Ahover%3E%2Einfo%2C%2Etable%2Dhover%3Etbody%3Etr%3Etd%2Einfo%3Ahover%2C%2Etable%2Dhover%3Etbody%3Etr%3Eth%2Einfo%3Ahover%7Bbackground%2Dcolor%3A%23c4e3f3%7D%2Etable%3Etbody%3Etr%2Ewarning%3Etd%2C%2Etable%3Etbody%3Etr%2Ewarning%3Eth%2C%2Etable%3Etbody%3Etr%3Etd%2Ewarning%2C%2Etable%3Etbody%3Etr%3Eth%2Ewarning%2C%2Etable%3Etfoot%3Etr%2Ewarning%3Etd%2C%2Etable%3Etfoot%3Etr%2Ewarning%3Eth%2C%2Etable%3Etfoot%3Etr%3Etd%2Ewarning%2C%2Etable%3Etfoot%3Etr%3Eth%2Ewarning%2C%2Etable%3Ethead%3Etr%2Ewarning%3Etd%2C%2Etable%3Ethead%3Etr%2Ewarning%3Eth%2C%2Etable%3Ethead%3Etr%3Etd%2Ewarning%2C%2Etable%3Ethead%3Etr%3Eth%2Ewarning%7Bbackground%2Dcolor%3A%23fcf8e3%7D%2Etable%2Dhover%3Etbody%3Etr%2Ewarning%3Ahover%3Etd%2C%2Etable%2Dhover%3Etbody%3Etr%2Ewarning%3Ahover%3Eth%2C%2Etable%2Dhover%3Etbody%3Etr%3Ahover%3E%2Ewarning%2C%2Etable%2Dhover%3Etbody%3Etr%3Etd%2Ewarning%3Ahover%2C%2Etable%2Dhover%3Etbody%3Etr%3Eth%2Ewarning%3Ahover%7Bbackground%2Dcolor%3A%23faf2cc%7D%2Etable%3Etbody%3Etr%2Edanger%3Etd%2C%2Etable%3Etbody%3Etr%2Edanger%3Eth%2C%2Etable%3Etbody%3Etr%3Etd%2Edanger%2C%2Etable%3Etbody%3Etr%3Eth%2Edanger%2C%2Etable%3Etfoot%3Etr%2Edanger%3Etd%2C%2Etable%3Etfoot%3Etr%2Edanger%3Eth%2C%2Etable%3Etfoot%3Etr%3Etd%2Edanger%2C%2Etable%3Etfoot%3Etr%3Eth%2Edanger%2C%2Etable%3Ethead%3Etr%2Edanger%3Etd%2C%2Etable%3Ethead%3Etr%2Edanger%3Eth%2C%2Etable%3Ethead%3Etr%3Etd%2Edanger%2C%2Etable%3Ethead%3Etr%3Eth%2Edanger%7Bbackground%2Dcolor%3A%23f2dede%7D%2Etable%2Dhover%3Etbody%3Etr%2Edanger%3Ahover%3Etd%2C%2Etable%2Dhover%3Etbody%3Etr%2Edanger%3Ahover%3Eth%2C%2Etable%2Dhover%3Etbody%3Etr%3Ahover%3E%2Edanger%2C%2Etable%2Dhover%3Etbody%3Etr%3Etd%2Edanger%3Ahover%2C%2Etable%2Dhover%3Etbody%3Etr%3Eth%2Edanger%3Ahover%7Bbackground%2Dcolor%3A%23ebcccc%7D%2Etable%2Dresponsive%7Bmin%2Dheight%3A%2E01%25%3Boverflow%2Dx%3Aauto%7D%40media%20screen%20and%20%28max%2Dwidth%3A767px%29%7B%2Etable%2Dresponsive%7Bwidth%3A100%25%3Bmargin%2Dbottom%3A15px%3Boverflow%2Dy%3Ahidden%3B%2Dms%2Doverflow%2Dstyle%3A%2Dms%2Dautohiding%2Dscrollbar%3Bborder%3A1px%20solid%20%23ddd%7D%2Etable%2Dresponsive%3E%2Etable%7Bmargin%2Dbottom%3A0%7D%2Etable%2Dresponsive%3E%2Etable%3Etbody%3Etr%3Etd%2C%2Etable%2Dresponsive%3E%2Etable%3Etbody%3Etr%3Eth%2C%2Etable%2Dresponsive%3E%2Etable%3Etfoot%3Etr%3Etd%2C%2Etable%2Dresponsive%3E%2Etable%3Etfoot%3Etr%3Eth%2C%2Etable%2Dresponsive%3E%2Etable%3Ethead%3Etr%3Etd%2C%2Etable%2Dresponsive%3E%2Etable%3Ethead%3Etr%3Eth%7Bwhite%2Dspace%3Anowrap%7D%2Etable%2Dresponsive%3E%2Etable%2Dbordered%7Bborder%3A0%7D%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etbody%3Etr%3Etd%3Afirst%2Dchild%2C%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etbody%3Etr%3Eth%3Afirst%2Dchild%2C%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etfoot%3Etr%3Etd%3Afirst%2Dchild%2C%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etfoot%3Etr%3Eth%3Afirst%2Dchild%2C%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Ethead%3Etr%3Etd%3Afirst%2Dchild%2C%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Ethead%3Etr%3Eth%3Afirst%2Dchild%7Bborder%2Dleft%3A0%7D%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etbody%3Etr%3Etd%3Alast%2Dchild%2C%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etbody%3Etr%3Eth%3Alast%2Dchild%2C%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etfoot%3Etr%3Etd%3Alast%2Dchild%2C%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etfoot%3Etr%3Eth%3Alast%2Dchild%2C%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Ethead%3Etr%3Etd%3Alast%2Dchild%2C%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Ethead%3Etr%3Eth%3Alast%2Dchild%7Bborder%2Dright%3A0%7D%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etbody%3Etr%3Alast%2Dchild%3Etd%2C%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etbody%3Etr%3Alast%2Dchild%3Eth%2C%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etfoot%3Etr%3Alast%2Dchild%3Etd%2C%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etfoot%3Etr%3Alast%2Dchild%3Eth%7Bborder%2Dbottom%3A0%7D%7Dfieldset%7Bmin%2Dwidth%3A0%3Bpadding%3A0%3Bmargin%3A0%3Bborder%3A0%7Dlegend%7Bdisplay%3Ablock%3Bwidth%3A100%25%3Bpadding%3A0%3Bmargin%2Dbottom%3A20px%3Bfont%2Dsize%3A21px%3Bline%2Dheight%3Ainherit%3Bcolor%3A%23333%3Bborder%3A0%3Bborder%2Dbottom%3A1px%20solid%20%23e5e5e5%7Dlabel%7Bdisplay%3Ainline%2Dblock%3Bmax%2Dwidth%3A100%25%3Bmargin%2Dbottom%3A5px%3Bfont%2Dweight%3A700%7Dinput%5Btype%3Dsearch%5D%7B%2Dwebkit%2Dbox%2Dsizing%3Aborder%2Dbox%3B%2Dmoz%2Dbox%2Dsizing%3Aborder%2Dbox%3Bbox%2Dsizing%3Aborder%2Dbox%7Dinput%5Btype%3Dcheckbox%5D%2Cinput%5Btype%3Dradio%5D%7Bmargin%3A4px%200%200%3Bmargin%2Dtop%3A1px%5C9%3Bline%2Dheight%3Anormal%7Dinput%5Btype%3Dfile%5D%7Bdisplay%3Ablock%7Dinput%5Btype%3Drange%5D%7Bdisplay%3Ablock%3Bwidth%3A100%25%7Dselect%5Bmultiple%5D%2Cselect%5Bsize%5D%7Bheight%3Aauto%7Dinput%5Btype%3Dfile%5D%3Afocus%2Cinput%5Btype%3Dcheckbox%5D%3Afocus%2Cinput%5Btype%3Dradio%5D%3Afocus%7Boutline%3Athin%20dotted%3Boutline%3A5px%20auto%20%2Dwebkit%2Dfocus%2Dring%2Dcolor%3Boutline%2Doffset%3A%2D2px%7Doutput%7Bdisplay%3Ablock%3Bpadding%2Dtop%3A7px%3Bfont%2Dsize%3A14px%3Bline%2Dheight%3A1%2E42857143%3Bcolor%3A%23555%7D%2Eform%2Dcontrol%7Bdisplay%3Ablock%3Bwidth%3A100%25%3Bheight%3A34px%3Bpadding%3A6px%2012px%3Bfont%2Dsize%3A14px%3Bline%2Dheight%3A1%2E42857143%3Bcolor%3A%23555%3Bbackground%2Dcolor%3A%23fff%3Bbackground%2Dimage%3Anone%3Bborder%3A1px%20solid%20%23ccc%3Bborder%2Dradius%3A4px%3B%2Dwebkit%2Dbox%2Dshadow%3Ainset%200%201px%201px%20rgba%280%2C0%2C0%2C%2E075%29%3Bbox%2Dshadow%3Ainset%200%201px%201px%20rgba%280%2C0%2C0%2C%2E075%29%3B%2Dwebkit%2Dtransition%3Aborder%2Dcolor%20ease%2Din%2Dout%20%2E15s%2C%2Dwebkit%2Dbox%2Dshadow%20ease%2Din%2Dout%20%2E15s%3B%2Do%2Dtransition%3Aborder%2Dcolor%20ease%2Din%2Dout%20%2E15s%2Cbox%2Dshadow%20ease%2Din%2Dout%20%2E15s%3Btransition%3Aborder%2Dcolor%20ease%2Din%2Dout%20%2E15s%2Cbox%2Dshadow%20ease%2Din%2Dout%20%2E15s%7D%2Eform%2Dcontrol%3Afocus%7Bborder%2Dcolor%3A%2366afe9%3Boutline%3A0%3B%2Dwebkit%2Dbox%2Dshadow%3Ainset%200%201px%201px%20rgba%280%2C0%2C0%2C%2E075%29%2C0%200%208px%20rgba%28102%2C175%2C233%2C%2E6%29%3Bbox%2Dshadow%3Ainset%200%201px%201px%20rgba%280%2C0%2C0%2C%2E075%29%2C0%200%208px%20rgba%28102%2C175%2C233%2C%2E6%29%7D%2Eform%2Dcontrol%3A%3A%2Dmoz%2Dplaceholder%7Bcolor%3A%23999%3Bopacity%3A1%7D%2Eform%2Dcontrol%3A%2Dms%2Dinput%2Dplaceholder%7Bcolor%3A%23999%7D%2Eform%2Dcontrol%3A%3A%2Dwebkit%2Dinput%2Dplaceholder%7Bcolor%3A%23999%7D%2Eform%2Dcontrol%5Bdisabled%5D%2C%2Eform%2Dcontrol%5Breadonly%5D%2Cfieldset%5Bdisabled%5D%20%2Eform%2Dcontrol%7Bbackground%2Dcolor%3A%23eee%3Bopacity%3A1%7D%2Eform%2Dcontrol%5Bdisabled%5D%2Cfieldset%5Bdisabled%5D%20%2Eform%2Dcontrol%7Bcursor%3Anot%2Dallowed%7Dtextarea%2Eform%2Dcontrol%7Bheight%3Aauto%7Dinput%5Btype%3Dsearch%5D%7B%2Dwebkit%2Dappearance%3Anone%7D%40media%20screen%20and%20%28%2Dwebkit%2Dmin%2Ddevice%2Dpixel%2Dratio%3A0%29%7Binput%5Btype%3Ddate%5D%2Eform%2Dcontrol%2Cinput%5Btype%3Dtime%5D%2Eform%2Dcontrol%2Cinput%5Btype%3Ddatetime%2Dlocal%5D%2Eform%2Dcontrol%2Cinput%5Btype%3Dmonth%5D%2Eform%2Dcontrol%7Bline%2Dheight%3A34px%7D%2Einput%2Dgroup%2Dsm%20input%5Btype%3Ddate%5D%2C%2Einput%2Dgroup%2Dsm%20input%5Btype%3Dtime%5D%2C%2Einput%2Dgroup%2Dsm%20input%5Btype%3Ddatetime%2Dlocal%5D%2C%2Einput%2Dgroup%2Dsm%20input%5Btype%3Dmonth%5D%2Cinput%5Btype%3Ddate%5D%2Einput%2Dsm%2Cinput%5Btype%3Dtime%5D%2Einput%2Dsm%2Cinput%5Btype%3Ddatetime%2Dlocal%5D%2Einput%2Dsm%2Cinput%5Btype%3Dmonth%5D%2Einput%2Dsm%7Bline%2Dheight%3A30px%7D%2Einput%2Dgroup%2Dlg%20input%5Btype%3Ddate%5D%2C%2Einput%2Dgroup%2Dlg%20input%5Btype%3Dtime%5D%2C%2Einput%2Dgroup%2Dlg%20input%5Btype%3Ddatetime%2Dlocal%5D%2C%2Einput%2Dgroup%2Dlg%20input%5Btype%3Dmonth%5D%2Cinput%5Btype%3Ddate%5D%2Einput%2Dlg%2Cinput%5Btype%3Dtime%5D%2Einput%2Dlg%2Cinput%5Btype%3Ddatetime%2Dlocal%5D%2Einput%2Dlg%2Cinput%5Btype%3Dmonth%5D%2Einput%2Dlg%7Bline%2Dheight%3A46px%7D%7D%2Eform%2Dgroup%7Bmargin%2Dbottom%3A15px%7D%2Echeckbox%2C%2Eradio%7Bposition%3Arelative%3Bdisplay%3Ablock%3Bmargin%2Dtop%3A10px%3Bmargin%2Dbottom%3A10px%7D%2Echeckbox%20label%2C%2Eradio%20label%7Bmin%2Dheight%3A20px%3Bpadding%2Dleft%3A20px%3Bmargin%2Dbottom%3A0%3Bfont%2Dweight%3A400%3Bcursor%3Apointer%7D%2Echeckbox%20input%5Btype%3Dcheckbox%5D%2C%2Echeckbox%2Dinline%20input%5Btype%3Dcheckbox%5D%2C%2Eradio%20input%5Btype%3Dradio%5D%2C%2Eradio%2Dinline%20input%5Btype%3Dradio%5D%7Bposition%3Aabsolute%3Bmargin%2Dtop%3A4px%5C9%3Bmargin%2Dleft%3A%2D20px%7D%2Echeckbox%2B%2Echeckbox%2C%2Eradio%2B%2Eradio%7Bmargin%2Dtop%3A%2D5px%7D%2Echeckbox%2Dinline%2C%2Eradio%2Dinline%7Bposition%3Arelative%3Bdisplay%3Ainline%2Dblock%3Bpadding%2Dleft%3A20px%3Bmargin%2Dbottom%3A0%3Bfont%2Dweight%3A400%3Bvertical%2Dalign%3Amiddle%3Bcursor%3Apointer%7D%2Echeckbox%2Dinline%2B%2Echeckbox%2Dinline%2C%2Eradio%2Dinline%2B%2Eradio%2Dinline%7Bmargin%2Dtop%3A0%3Bmargin%2Dleft%3A10px%7Dfieldset%5Bdisabled%5D%20input%5Btype%3Dcheckbox%5D%2Cfieldset%5Bdisabled%5D%20input%5Btype%3Dradio%5D%2Cinput%5Btype%3Dcheckbox%5D%2Edisabled%2Cinput%5Btype%3Dcheckbox%5D%5Bdisabled%5D%2Cinput%5Btype%3Dradio%5D%2Edisabled%2Cinput%5Btype%3Dradio%5D%5Bdisabled%5D%7Bcursor%3Anot%2Dallowed%7D%2Echeckbox%2Dinline%2Edisabled%2C%2Eradio%2Dinline%2Edisabled%2Cfieldset%5Bdisabled%5D%20%2Echeckbox%2Dinline%2Cfieldset%5Bdisabled%5D%20%2Eradio%2Dinline%7Bcursor%3Anot%2Dallowed%7D%2Echeckbox%2Edisabled%20label%2C%2Eradio%2Edisabled%20label%2Cfieldset%5Bdisabled%5D%20%2Echeckbox%20label%2Cfieldset%5Bdisabled%5D%20%2Eradio%20label%7Bcursor%3Anot%2Dallowed%7D%2Eform%2Dcontrol%2Dstatic%7Bmin%2Dheight%3A34px%3Bpadding%2Dtop%3A7px%3Bpadding%2Dbottom%3A7px%3Bmargin%2Dbottom%3A0%7D%2Eform%2Dcontrol%2Dstatic%2Einput%2Dlg%2C%2Eform%2Dcontrol%2Dstatic%2Einput%2Dsm%7Bpadding%2Dright%3A0%3Bpadding%2Dleft%3A0%7D%2Einput%2Dsm%7Bheight%3A30px%3Bpadding%3A5px%2010px%3Bfont%2Dsize%3A12px%3Bline%2Dheight%3A1%2E5%3Bborder%2Dradius%3A3px%7Dselect%2Einput%2Dsm%7Bheight%3A30px%3Bline%2Dheight%3A30px%7Dselect%5Bmultiple%5D%2Einput%2Dsm%2Ctextarea%2Einput%2Dsm%7Bheight%3Aauto%7D%2Eform%2Dgroup%2Dsm%20%2Eform%2Dcontrol%7Bheight%3A30px%3Bpadding%3A5px%2010px%3Bfont%2Dsize%3A12px%3Bline%2Dheight%3A1%2E5%3Bborder%2Dradius%3A3px%7D%2Eform%2Dgroup%2Dsm%20select%2Eform%2Dcontrol%7Bheight%3A30px%3Bline%2Dheight%3A30px%7D%2Eform%2Dgroup%2Dsm%20select%5Bmultiple%5D%2Eform%2Dcontrol%2C%2Eform%2Dgroup%2Dsm%20textarea%2Eform%2Dcontrol%7Bheight%3Aauto%7D%2Eform%2Dgroup%2Dsm%20%2Eform%2Dcontrol%2Dstatic%7Bheight%3A30px%3Bmin%2Dheight%3A32px%3Bpadding%3A6px%2010px%3Bfont%2Dsize%3A12px%3Bline%2Dheight%3A1%2E5%7D%2Einput%2Dlg%7Bheight%3A46px%3Bpadding%3A10px%2016px%3Bfont%2Dsize%3A18px%3Bline%2Dheight%3A1%2E3333333%3Bborder%2Dradius%3A6px%7Dselect%2Einput%2Dlg%7Bheight%3A46px%3Bline%2Dheight%3A46px%7Dselect%5Bmultiple%5D%2Einput%2Dlg%2Ctextarea%2Einput%2Dlg%7Bheight%3Aauto%7D%2Eform%2Dgroup%2Dlg%20%2Eform%2Dcontrol%7Bheight%3A46px%3Bpadding%3A10px%2016px%3Bfont%2Dsize%3A18px%3Bline%2Dheight%3A1%2E3333333%3Bborder%2Dradius%3A6px%7D%2Eform%2Dgroup%2Dlg%20select%2Eform%2Dcontrol%7Bheight%3A46px%3Bline%2Dheight%3A46px%7D%2Eform%2Dgroup%2Dlg%20select%5Bmultiple%5D%2Eform%2Dcontrol%2C%2Eform%2Dgroup%2Dlg%20textarea%2Eform%2Dcontrol%7Bheight%3Aauto%7D%2Eform%2Dgroup%2Dlg%20%2Eform%2Dcontrol%2Dstatic%7Bheight%3A46px%3Bmin%2Dheight%3A38px%3Bpadding%3A11px%2016px%3Bfont%2Dsize%3A18px%3Bline%2Dheight%3A1%2E3333333%7D%2Ehas%2Dfeedback%7Bposition%3Arelative%7D%2Ehas%2Dfeedback%20%2Eform%2Dcontrol%7Bpadding%2Dright%3A42%2E5px%7D%2Eform%2Dcontrol%2Dfeedback%7Bposition%3Aabsolute%3Btop%3A0%3Bright%3A0%3Bz%2Dindex%3A2%3Bdisplay%3Ablock%3Bwidth%3A34px%3Bheight%3A34px%3Bline%2Dheight%3A34px%3Btext%2Dalign%3Acenter%3Bpointer%2Devents%3Anone%7D%2Eform%2Dgroup%2Dlg%20%2Eform%2Dcontrol%2B%2Eform%2Dcontrol%2Dfeedback%2C%2Einput%2Dgroup%2Dlg%2B%2Eform%2Dcontrol%2Dfeedback%2C%2Einput%2Dlg%2B%2Eform%2Dcontrol%2Dfeedback%7Bwidth%3A46px%3Bheight%3A46px%3Bline%2Dheight%3A46px%7D%2Eform%2Dgroup%2Dsm%20%2Eform%2Dcontrol%2B%2Eform%2Dcontrol%2Dfeedback%2C%2Einput%2Dgroup%2Dsm%2B%2Eform%2Dcontrol%2Dfeedback%2C%2Einput%2Dsm%2B%2Eform%2Dcontrol%2Dfeedback%7Bwidth%3A30px%3Bheight%3A30px%3Bline%2Dheight%3A30px%7D%2Ehas%2Dsuccess%20%2Echeckbox%2C%2Ehas%2Dsuccess%20%2Echeckbox%2Dinline%2C%2Ehas%2Dsuccess%20%2Econtrol%2Dlabel%2C%2Ehas%2Dsuccess%20%2Ehelp%2Dblock%2C%2Ehas%2Dsuccess%20%2Eradio%2C%2Ehas%2Dsuccess%20%2Eradio%2Dinline%2C%2Ehas%2Dsuccess%2Echeckbox%20label%2C%2Ehas%2Dsuccess%2Echeckbox%2Dinline%20label%2C%2Ehas%2Dsuccess%2Eradio%20label%2C%2Ehas%2Dsuccess%2Eradio%2Dinline%20label%7Bcolor%3A%233c763d%7D%2Ehas%2Dsuccess%20%2Eform%2Dcontrol%7Bborder%2Dcolor%3A%233c763d%3B%2Dwebkit%2Dbox%2Dshadow%3Ainset%200%201px%201px%20rgba%280%2C0%2C0%2C%2E075%29%3Bbox%2Dshadow%3Ainset%200%201px%201px%20rgba%280%2C0%2C0%2C%2E075%29%7D%2Ehas%2Dsuccess%20%2Eform%2Dcontrol%3Afocus%7Bborder%2Dcolor%3A%232b542c%3B%2Dwebkit%2Dbox%2Dshadow%3Ainset%200%201px%201px%20rgba%280%2C0%2C0%2C%2E075%29%2C0%200%206px%20%2367b168%3Bbox%2Dshadow%3Ainset%200%201px%201px%20rgba%280%2C0%2C0%2C%2E075%29%2C0%200%206px%20%2367b168%7D%2Ehas%2Dsuccess%20%2Einput%2Dgroup%2Daddon%7Bcolor%3A%233c763d%3Bbackground%2Dcolor%3A%23dff0d8%3Bborder%2Dcolor%3A%233c763d%7D%2Ehas%2Dsuccess%20%2Eform%2Dcontrol%2Dfeedback%7Bcolor%3A%233c763d%7D%2Ehas%2Dwarning%20%2Echeckbox%2C%2Ehas%2Dwarning%20%2Echeckbox%2Dinline%2C%2Ehas%2Dwarning%20%2Econtrol%2Dlabel%2C%2Ehas%2Dwarning%20%2Ehelp%2Dblock%2C%2Ehas%2Dwarning%20%2Eradio%2C%2Ehas%2Dwarning%20%2Eradio%2Dinline%2C%2Ehas%2Dwarning%2Echeckbox%20label%2C%2Ehas%2Dwarning%2Echeckbox%2Dinline%20label%2C%2Ehas%2Dwarning%2Eradio%20label%2C%2Ehas%2Dwarning%2Eradio%2Dinline%20label%7Bcolor%3A%238a6d3b%7D%2Ehas%2Dwarning%20%2Eform%2Dcontrol%7Bborder%2Dcolor%3A%238a6d3b%3B%2Dwebkit%2Dbox%2Dshadow%3Ainset%200%201px%201px%20rgba%280%2C0%2C0%2C%2E075%29%3Bbox%2Dshadow%3Ainset%200%201px%201px%20rgba%280%2C0%2C0%2C%2E075%29%7D%2Ehas%2Dwarning%20%2Eform%2Dcontrol%3Afocus%7Bborder%2Dcolor%3A%2366512c%3B%2Dwebkit%2Dbox%2Dshadow%3Ainset%200%201px%201px%20rgba%280%2C0%2C0%2C%2E075%29%2C0%200%206px%20%23c0a16b%3Bbox%2Dshadow%3Ainset%200%201px%201px%20rgba%280%2C0%2C0%2C%2E075%29%2C0%200%206px%20%23c0a16b%7D%2Ehas%2Dwarning%20%2Einput%2Dgroup%2Daddon%7Bcolor%3A%238a6d3b%3Bbackground%2Dcolor%3A%23fcf8e3%3Bborder%2Dcolor%3A%238a6d3b%7D%2Ehas%2Dwarning%20%2Eform%2Dcontrol%2Dfeedback%7Bcolor%3A%238a6d3b%7D%2Ehas%2Derror%20%2Echeckbox%2C%2Ehas%2Derror%20%2Echeckbox%2Dinline%2C%2Ehas%2Derror%20%2Econtrol%2Dlabel%2C%2Ehas%2Derror%20%2Ehelp%2Dblock%2C%2Ehas%2Derror%20%2Eradio%2C%2Ehas%2Derror%20%2Eradio%2Dinline%2C%2Ehas%2Derror%2Echeckbox%20label%2C%2Ehas%2Derror%2Echeckbox%2Dinline%20label%2C%2Ehas%2Derror%2Eradio%20label%2C%2Ehas%2Derror%2Eradio%2Dinline%20label%7Bcolor%3A%23a94442%7D%2Ehas%2Derror%20%2Eform%2Dcontrol%7Bborder%2Dcolor%3A%23a94442%3B%2Dwebkit%2Dbox%2Dshadow%3Ainset%200%201px%201px%20rgba%280%2C0%2C0%2C%2E075%29%3Bbox%2Dshadow%3Ainset%200%201px%201px%20rgba%280%2C0%2C0%2C%2E075%29%7D%2Ehas%2Derror%20%2Eform%2Dcontrol%3Afocus%7Bborder%2Dcolor%3A%23843534%3B%2Dwebkit%2Dbox%2Dshadow%3Ainset%200%201px%201px%20rgba%280%2C0%2C0%2C%2E075%29%2C0%200%206px%20%23ce8483%3Bbox%2Dshadow%3Ainset%200%201px%201px%20rgba%280%2C0%2C0%2C%2E075%29%2C0%200%206px%20%23ce8483%7D%2Ehas%2Derror%20%2Einput%2Dgroup%2Daddon%7Bcolor%3A%23a94442%3Bbackground%2Dcolor%3A%23f2dede%3Bborder%2Dcolor%3A%23a94442%7D%2Ehas%2Derror%20%2Eform%2Dcontrol%2Dfeedback%7Bcolor%3A%23a94442%7D%2Ehas%2Dfeedback%20label%7E%2Eform%2Dcontrol%2Dfeedback%7Btop%3A25px%7D%2Ehas%2Dfeedback%20label%2Esr%2Donly%7E%2Eform%2Dcontrol%2Dfeedback%7Btop%3A0%7D%2Ehelp%2Dblock%7Bdisplay%3Ablock%3Bmargin%2Dtop%3A5px%3Bmargin%2Dbottom%3A10px%3Bcolor%3A%23737373%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Eform%2Dinline%20%2Eform%2Dgroup%7Bdisplay%3Ainline%2Dblock%3Bmargin%2Dbottom%3A0%3Bvertical%2Dalign%3Amiddle%7D%2Eform%2Dinline%20%2Eform%2Dcontrol%7Bdisplay%3Ainline%2Dblock%3Bwidth%3Aauto%3Bvertical%2Dalign%3Amiddle%7D%2Eform%2Dinline%20%2Eform%2Dcontrol%2Dstatic%7Bdisplay%3Ainline%2Dblock%7D%2Eform%2Dinline%20%2Einput%2Dgroup%7Bdisplay%3Ainline%2Dtable%3Bvertical%2Dalign%3Amiddle%7D%2Eform%2Dinline%20%2Einput%2Dgroup%20%2Eform%2Dcontrol%2C%2Eform%2Dinline%20%2Einput%2Dgroup%20%2Einput%2Dgroup%2Daddon%2C%2Eform%2Dinline%20%2Einput%2Dgroup%20%2Einput%2Dgroup%2Dbtn%7Bwidth%3Aauto%7D%2Eform%2Dinline%20%2Einput%2Dgroup%3E%2Eform%2Dcontrol%7Bwidth%3A100%25%7D%2Eform%2Dinline%20%2Econtrol%2Dlabel%7Bmargin%2Dbottom%3A0%3Bvertical%2Dalign%3Amiddle%7D%2Eform%2Dinline%20%2Echeckbox%2C%2Eform%2Dinline%20%2Eradio%7Bdisplay%3Ainline%2Dblock%3Bmargin%2Dtop%3A0%3Bmargin%2Dbottom%3A0%3Bvertical%2Dalign%3Amiddle%7D%2Eform%2Dinline%20%2Echeckbox%20label%2C%2Eform%2Dinline%20%2Eradio%20label%7Bpadding%2Dleft%3A0%7D%2Eform%2Dinline%20%2Echeckbox%20input%5Btype%3Dcheckbox%5D%2C%2Eform%2Dinline%20%2Eradio%20input%5Btype%3Dradio%5D%7Bposition%3Arelative%3Bmargin%2Dleft%3A0%7D%2Eform%2Dinline%20%2Ehas%2Dfeedback%20%2Eform%2Dcontrol%2Dfeedback%7Btop%3A0%7D%7D%2Eform%2Dhorizontal%20%2Echeckbox%2C%2Eform%2Dhorizontal%20%2Echeckbox%2Dinline%2C%2Eform%2Dhorizontal%20%2Eradio%2C%2Eform%2Dhorizontal%20%2Eradio%2Dinline%7Bpadding%2Dtop%3A7px%3Bmargin%2Dtop%3A0%3Bmargin%2Dbottom%3A0%7D%2Eform%2Dhorizontal%20%2Echeckbox%2C%2Eform%2Dhorizontal%20%2Eradio%7Bmin%2Dheight%3A27px%7D%2Eform%2Dhorizontal%20%2Eform%2Dgroup%7Bmargin%2Dright%3A%2D15px%3Bmargin%2Dleft%3A%2D15px%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Eform%2Dhorizontal%20%2Econtrol%2Dlabel%7Bpadding%2Dtop%3A7px%3Bmargin%2Dbottom%3A0%3Btext%2Dalign%3Aright%7D%7D%2Eform%2Dhorizontal%20%2Ehas%2Dfeedback%20%2Eform%2Dcontrol%2Dfeedback%7Bright%3A15px%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Eform%2Dhorizontal%20%2Eform%2Dgroup%2Dlg%20%2Econtrol%2Dlabel%7Bpadding%2Dtop%3A14%2E33px%3Bfont%2Dsize%3A18px%7D%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Eform%2Dhorizontal%20%2Eform%2Dgroup%2Dsm%20%2Econtrol%2Dlabel%7Bpadding%2Dtop%3A6px%3Bfont%2Dsize%3A12px%7D%7D%2Ebtn%7Bdisplay%3Ainline%2Dblock%3Bpadding%3A6px%2012px%3Bmargin%2Dbottom%3A0%3Bfont%2Dsize%3A14px%3Bfont%2Dweight%3A400%3Bline%2Dheight%3A1%2E42857143%3Btext%2Dalign%3Acenter%3Bwhite%2Dspace%3Anowrap%3Bvertical%2Dalign%3Amiddle%3B%2Dms%2Dtouch%2Daction%3Amanipulation%3Btouch%2Daction%3Amanipulation%3Bcursor%3Apointer%3B%2Dwebkit%2Duser%2Dselect%3Anone%3B%2Dmoz%2Duser%2Dselect%3Anone%3B%2Dms%2Duser%2Dselect%3Anone%3Buser%2Dselect%3Anone%3Bbackground%2Dimage%3Anone%3Bborder%3A1px%20solid%20transparent%3Bborder%2Dradius%3A4px%7D%2Ebtn%2Eactive%2Efocus%2C%2Ebtn%2Eactive%3Afocus%2C%2Ebtn%2Efocus%2C%2Ebtn%3Aactive%2Efocus%2C%2Ebtn%3Aactive%3Afocus%2C%2Ebtn%3Afocus%7Boutline%3Athin%20dotted%3Boutline%3A5px%20auto%20%2Dwebkit%2Dfocus%2Dring%2Dcolor%3Boutline%2Doffset%3A%2D2px%7D%2Ebtn%2Efocus%2C%2Ebtn%3Afocus%2C%2Ebtn%3Ahover%7Bcolor%3A%23333%3Btext%2Ddecoration%3Anone%7D%2Ebtn%2Eactive%2C%2Ebtn%3Aactive%7Bbackground%2Dimage%3Anone%3Boutline%3A0%3B%2Dwebkit%2Dbox%2Dshadow%3Ainset%200%203px%205px%20rgba%280%2C0%2C0%2C%2E125%29%3Bbox%2Dshadow%3Ainset%200%203px%205px%20rgba%280%2C0%2C0%2C%2E125%29%7D%2Ebtn%2Edisabled%2C%2Ebtn%5Bdisabled%5D%2Cfieldset%5Bdisabled%5D%20%2Ebtn%7Bcursor%3Anot%2Dallowed%3Bfilter%3Aalpha%28opacity%3D65%29%3B%2Dwebkit%2Dbox%2Dshadow%3Anone%3Bbox%2Dshadow%3Anone%3Bopacity%3A%2E65%7Da%2Ebtn%2Edisabled%2Cfieldset%5Bdisabled%5D%20a%2Ebtn%7Bpointer%2Devents%3Anone%7D%2Ebtn%2Ddefault%7Bcolor%3A%23333%3Bbackground%2Dcolor%3A%23fff%3Bborder%2Dcolor%3A%23ccc%7D%2Ebtn%2Ddefault%2Efocus%2C%2Ebtn%2Ddefault%3Afocus%7Bcolor%3A%23333%3Bbackground%2Dcolor%3A%23e6e6e6%3Bborder%2Dcolor%3A%238c8c8c%7D%2Ebtn%2Ddefault%3Ahover%7Bcolor%3A%23333%3Bbackground%2Dcolor%3A%23e6e6e6%3Bborder%2Dcolor%3A%23adadad%7D%2Ebtn%2Ddefault%2Eactive%2C%2Ebtn%2Ddefault%3Aactive%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Ddefault%7Bcolor%3A%23333%3Bbackground%2Dcolor%3A%23e6e6e6%3Bborder%2Dcolor%3A%23adadad%7D%2Ebtn%2Ddefault%2Eactive%2Efocus%2C%2Ebtn%2Ddefault%2Eactive%3Afocus%2C%2Ebtn%2Ddefault%2Eactive%3Ahover%2C%2Ebtn%2Ddefault%3Aactive%2Efocus%2C%2Ebtn%2Ddefault%3Aactive%3Afocus%2C%2Ebtn%2Ddefault%3Aactive%3Ahover%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Ddefault%2Efocus%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Ddefault%3Afocus%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Ddefault%3Ahover%7Bcolor%3A%23333%3Bbackground%2Dcolor%3A%23d4d4d4%3Bborder%2Dcolor%3A%238c8c8c%7D%2Ebtn%2Ddefault%2Eactive%2C%2Ebtn%2Ddefault%3Aactive%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Ddefault%7Bbackground%2Dimage%3Anone%7D%2Ebtn%2Ddefault%2Edisabled%2C%2Ebtn%2Ddefault%2Edisabled%2Eactive%2C%2Ebtn%2Ddefault%2Edisabled%2Efocus%2C%2Ebtn%2Ddefault%2Edisabled%3Aactive%2C%2Ebtn%2Ddefault%2Edisabled%3Afocus%2C%2Ebtn%2Ddefault%2Edisabled%3Ahover%2C%2Ebtn%2Ddefault%5Bdisabled%5D%2C%2Ebtn%2Ddefault%5Bdisabled%5D%2Eactive%2C%2Ebtn%2Ddefault%5Bdisabled%5D%2Efocus%2C%2Ebtn%2Ddefault%5Bdisabled%5D%3Aactive%2C%2Ebtn%2Ddefault%5Bdisabled%5D%3Afocus%2C%2Ebtn%2Ddefault%5Bdisabled%5D%3Ahover%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Ddefault%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Ddefault%2Eactive%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Ddefault%2Efocus%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Ddefault%3Aactive%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Ddefault%3Afocus%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Ddefault%3Ahover%7Bbackground%2Dcolor%3A%23fff%3Bborder%2Dcolor%3A%23ccc%7D%2Ebtn%2Ddefault%20%2Ebadge%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23333%7D%2Ebtn%2Dprimary%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23337ab7%3Bborder%2Dcolor%3A%232e6da4%7D%2Ebtn%2Dprimary%2Efocus%2C%2Ebtn%2Dprimary%3Afocus%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23286090%3Bborder%2Dcolor%3A%23122b40%7D%2Ebtn%2Dprimary%3Ahover%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23286090%3Bborder%2Dcolor%3A%23204d74%7D%2Ebtn%2Dprimary%2Eactive%2C%2Ebtn%2Dprimary%3Aactive%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Dprimary%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23286090%3Bborder%2Dcolor%3A%23204d74%7D%2Ebtn%2Dprimary%2Eactive%2Efocus%2C%2Ebtn%2Dprimary%2Eactive%3Afocus%2C%2Ebtn%2Dprimary%2Eactive%3Ahover%2C%2Ebtn%2Dprimary%3Aactive%2Efocus%2C%2Ebtn%2Dprimary%3Aactive%3Afocus%2C%2Ebtn%2Dprimary%3Aactive%3Ahover%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Dprimary%2Efocus%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Dprimary%3Afocus%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Dprimary%3Ahover%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23204d74%3Bborder%2Dcolor%3A%23122b40%7D%2Ebtn%2Dprimary%2Eactive%2C%2Ebtn%2Dprimary%3Aactive%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Dprimary%7Bbackground%2Dimage%3Anone%7D%2Ebtn%2Dprimary%2Edisabled%2C%2Ebtn%2Dprimary%2Edisabled%2Eactive%2C%2Ebtn%2Dprimary%2Edisabled%2Efocus%2C%2Ebtn%2Dprimary%2Edisabled%3Aactive%2C%2Ebtn%2Dprimary%2Edisabled%3Afocus%2C%2Ebtn%2Dprimary%2Edisabled%3Ahover%2C%2Ebtn%2Dprimary%5Bdisabled%5D%2C%2Ebtn%2Dprimary%5Bdisabled%5D%2Eactive%2C%2Ebtn%2Dprimary%5Bdisabled%5D%2Efocus%2C%2Ebtn%2Dprimary%5Bdisabled%5D%3Aactive%2C%2Ebtn%2Dprimary%5Bdisabled%5D%3Afocus%2C%2Ebtn%2Dprimary%5Bdisabled%5D%3Ahover%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dprimary%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dprimary%2Eactive%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dprimary%2Efocus%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dprimary%3Aactive%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dprimary%3Afocus%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dprimary%3Ahover%7Bbackground%2Dcolor%3A%23337ab7%3Bborder%2Dcolor%3A%232e6da4%7D%2Ebtn%2Dprimary%20%2Ebadge%7Bcolor%3A%23337ab7%3Bbackground%2Dcolor%3A%23fff%7D%2Ebtn%2Dsuccess%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%235cb85c%3Bborder%2Dcolor%3A%234cae4c%7D%2Ebtn%2Dsuccess%2Efocus%2C%2Ebtn%2Dsuccess%3Afocus%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23449d44%3Bborder%2Dcolor%3A%23255625%7D%2Ebtn%2Dsuccess%3Ahover%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23449d44%3Bborder%2Dcolor%3A%23398439%7D%2Ebtn%2Dsuccess%2Eactive%2C%2Ebtn%2Dsuccess%3Aactive%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Dsuccess%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23449d44%3Bborder%2Dcolor%3A%23398439%7D%2Ebtn%2Dsuccess%2Eactive%2Efocus%2C%2Ebtn%2Dsuccess%2Eactive%3Afocus%2C%2Ebtn%2Dsuccess%2Eactive%3Ahover%2C%2Ebtn%2Dsuccess%3Aactive%2Efocus%2C%2Ebtn%2Dsuccess%3Aactive%3Afocus%2C%2Ebtn%2Dsuccess%3Aactive%3Ahover%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Dsuccess%2Efocus%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Dsuccess%3Afocus%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Dsuccess%3Ahover%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23398439%3Bborder%2Dcolor%3A%23255625%7D%2Ebtn%2Dsuccess%2Eactive%2C%2Ebtn%2Dsuccess%3Aactive%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Dsuccess%7Bbackground%2Dimage%3Anone%7D%2Ebtn%2Dsuccess%2Edisabled%2C%2Ebtn%2Dsuccess%2Edisabled%2Eactive%2C%2Ebtn%2Dsuccess%2Edisabled%2Efocus%2C%2Ebtn%2Dsuccess%2Edisabled%3Aactive%2C%2Ebtn%2Dsuccess%2Edisabled%3Afocus%2C%2Ebtn%2Dsuccess%2Edisabled%3Ahover%2C%2Ebtn%2Dsuccess%5Bdisabled%5D%2C%2Ebtn%2Dsuccess%5Bdisabled%5D%2Eactive%2C%2Ebtn%2Dsuccess%5Bdisabled%5D%2Efocus%2C%2Ebtn%2Dsuccess%5Bdisabled%5D%3Aactive%2C%2Ebtn%2Dsuccess%5Bdisabled%5D%3Afocus%2C%2Ebtn%2Dsuccess%5Bdisabled%5D%3Ahover%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dsuccess%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dsuccess%2Eactive%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dsuccess%2Efocus%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dsuccess%3Aactive%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dsuccess%3Afocus%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dsuccess%3Ahover%7Bbackground%2Dcolor%3A%235cb85c%3Bborder%2Dcolor%3A%234cae4c%7D%2Ebtn%2Dsuccess%20%2Ebadge%7Bcolor%3A%235cb85c%3Bbackground%2Dcolor%3A%23fff%7D%2Ebtn%2Dinfo%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%235bc0de%3Bborder%2Dcolor%3A%2346b8da%7D%2Ebtn%2Dinfo%2Efocus%2C%2Ebtn%2Dinfo%3Afocus%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%2331b0d5%3Bborder%2Dcolor%3A%231b6d85%7D%2Ebtn%2Dinfo%3Ahover%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%2331b0d5%3Bborder%2Dcolor%3A%23269abc%7D%2Ebtn%2Dinfo%2Eactive%2C%2Ebtn%2Dinfo%3Aactive%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Dinfo%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%2331b0d5%3Bborder%2Dcolor%3A%23269abc%7D%2Ebtn%2Dinfo%2Eactive%2Efocus%2C%2Ebtn%2Dinfo%2Eactive%3Afocus%2C%2Ebtn%2Dinfo%2Eactive%3Ahover%2C%2Ebtn%2Dinfo%3Aactive%2Efocus%2C%2Ebtn%2Dinfo%3Aactive%3Afocus%2C%2Ebtn%2Dinfo%3Aactive%3Ahover%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Dinfo%2Efocus%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Dinfo%3Afocus%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Dinfo%3Ahover%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23269abc%3Bborder%2Dcolor%3A%231b6d85%7D%2Ebtn%2Dinfo%2Eactive%2C%2Ebtn%2Dinfo%3Aactive%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Dinfo%7Bbackground%2Dimage%3Anone%7D%2Ebtn%2Dinfo%2Edisabled%2C%2Ebtn%2Dinfo%2Edisabled%2Eactive%2C%2Ebtn%2Dinfo%2Edisabled%2Efocus%2C%2Ebtn%2Dinfo%2Edisabled%3Aactive%2C%2Ebtn%2Dinfo%2Edisabled%3Afocus%2C%2Ebtn%2Dinfo%2Edisabled%3Ahover%2C%2Ebtn%2Dinfo%5Bdisabled%5D%2C%2Ebtn%2Dinfo%5Bdisabled%5D%2Eactive%2C%2Ebtn%2Dinfo%5Bdisabled%5D%2Efocus%2C%2Ebtn%2Dinfo%5Bdisabled%5D%3Aactive%2C%2Ebtn%2Dinfo%5Bdisabled%5D%3Afocus%2C%2Ebtn%2Dinfo%5Bdisabled%5D%3Ahover%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dinfo%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dinfo%2Eactive%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dinfo%2Efocus%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dinfo%3Aactive%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dinfo%3Afocus%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dinfo%3Ahover%7Bbackground%2Dcolor%3A%235bc0de%3Bborder%2Dcolor%3A%2346b8da%7D%2Ebtn%2Dinfo%20%2Ebadge%7Bcolor%3A%235bc0de%3Bbackground%2Dcolor%3A%23fff%7D%2Ebtn%2Dwarning%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23f0ad4e%3Bborder%2Dcolor%3A%23eea236%7D%2Ebtn%2Dwarning%2Efocus%2C%2Ebtn%2Dwarning%3Afocus%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23ec971f%3Bborder%2Dcolor%3A%23985f0d%7D%2Ebtn%2Dwarning%3Ahover%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23ec971f%3Bborder%2Dcolor%3A%23d58512%7D%2Ebtn%2Dwarning%2Eactive%2C%2Ebtn%2Dwarning%3Aactive%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Dwarning%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23ec971f%3Bborder%2Dcolor%3A%23d58512%7D%2Ebtn%2Dwarning%2Eactive%2Efocus%2C%2Ebtn%2Dwarning%2Eactive%3Afocus%2C%2Ebtn%2Dwarning%2Eactive%3Ahover%2C%2Ebtn%2Dwarning%3Aactive%2Efocus%2C%2Ebtn%2Dwarning%3Aactive%3Afocus%2C%2Ebtn%2Dwarning%3Aactive%3Ahover%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Dwarning%2Efocus%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Dwarning%3Afocus%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Dwarning%3Ahover%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23d58512%3Bborder%2Dcolor%3A%23985f0d%7D%2Ebtn%2Dwarning%2Eactive%2C%2Ebtn%2Dwarning%3Aactive%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Dwarning%7Bbackground%2Dimage%3Anone%7D%2Ebtn%2Dwarning%2Edisabled%2C%2Ebtn%2Dwarning%2Edisabled%2Eactive%2C%2Ebtn%2Dwarning%2Edisabled%2Efocus%2C%2Ebtn%2Dwarning%2Edisabled%3Aactive%2C%2Ebtn%2Dwarning%2Edisabled%3Afocus%2C%2Ebtn%2Dwarning%2Edisabled%3Ahover%2C%2Ebtn%2Dwarning%5Bdisabled%5D%2C%2Ebtn%2Dwarning%5Bdisabled%5D%2Eactive%2C%2Ebtn%2Dwarning%5Bdisabled%5D%2Efocus%2C%2Ebtn%2Dwarning%5Bdisabled%5D%3Aactive%2C%2Ebtn%2Dwarning%5Bdisabled%5D%3Afocus%2C%2Ebtn%2Dwarning%5Bdisabled%5D%3Ahover%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dwarning%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dwarning%2Eactive%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dwarning%2Efocus%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dwarning%3Aactive%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dwarning%3Afocus%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dwarning%3Ahover%7Bbackground%2Dcolor%3A%23f0ad4e%3Bborder%2Dcolor%3A%23eea236%7D%2Ebtn%2Dwarning%20%2Ebadge%7Bcolor%3A%23f0ad4e%3Bbackground%2Dcolor%3A%23fff%7D%2Ebtn%2Ddanger%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23d9534f%3Bborder%2Dcolor%3A%23d43f3a%7D%2Ebtn%2Ddanger%2Efocus%2C%2Ebtn%2Ddanger%3Afocus%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23c9302c%3Bborder%2Dcolor%3A%23761c19%7D%2Ebtn%2Ddanger%3Ahover%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23c9302c%3Bborder%2Dcolor%3A%23ac2925%7D%2Ebtn%2Ddanger%2Eactive%2C%2Ebtn%2Ddanger%3Aactive%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Ddanger%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23c9302c%3Bborder%2Dcolor%3A%23ac2925%7D%2Ebtn%2Ddanger%2Eactive%2Efocus%2C%2Ebtn%2Ddanger%2Eactive%3Afocus%2C%2Ebtn%2Ddanger%2Eactive%3Ahover%2C%2Ebtn%2Ddanger%3Aactive%2Efocus%2C%2Ebtn%2Ddanger%3Aactive%3Afocus%2C%2Ebtn%2Ddanger%3Aactive%3Ahover%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Ddanger%2Efocus%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Ddanger%3Afocus%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Ddanger%3Ahover%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23ac2925%3Bborder%2Dcolor%3A%23761c19%7D%2Ebtn%2Ddanger%2Eactive%2C%2Ebtn%2Ddanger%3Aactive%2C%2Eopen%3E%2Edropdown%2Dtoggle%2Ebtn%2Ddanger%7Bbackground%2Dimage%3Anone%7D%2Ebtn%2Ddanger%2Edisabled%2C%2Ebtn%2Ddanger%2Edisabled%2Eactive%2C%2Ebtn%2Ddanger%2Edisabled%2Efocus%2C%2Ebtn%2Ddanger%2Edisabled%3Aactive%2C%2Ebtn%2Ddanger%2Edisabled%3Afocus%2C%2Ebtn%2Ddanger%2Edisabled%3Ahover%2C%2Ebtn%2Ddanger%5Bdisabled%5D%2C%2Ebtn%2Ddanger%5Bdisabled%5D%2Eactive%2C%2Ebtn%2Ddanger%5Bdisabled%5D%2Efocus%2C%2Ebtn%2Ddanger%5Bdisabled%5D%3Aactive%2C%2Ebtn%2Ddanger%5Bdisabled%5D%3Afocus%2C%2Ebtn%2Ddanger%5Bdisabled%5D%3Ahover%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Ddanger%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Ddanger%2Eactive%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Ddanger%2Efocus%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Ddanger%3Aactive%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Ddanger%3Afocus%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Ddanger%3Ahover%7Bbackground%2Dcolor%3A%23d9534f%3Bborder%2Dcolor%3A%23d43f3a%7D%2Ebtn%2Ddanger%20%2Ebadge%7Bcolor%3A%23d9534f%3Bbackground%2Dcolor%3A%23fff%7D%2Ebtn%2Dlink%7Bfont%2Dweight%3A400%3Bcolor%3A%23337ab7%3Bborder%2Dradius%3A0%7D%2Ebtn%2Dlink%2C%2Ebtn%2Dlink%2Eactive%2C%2Ebtn%2Dlink%3Aactive%2C%2Ebtn%2Dlink%5Bdisabled%5D%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dlink%7Bbackground%2Dcolor%3Atransparent%3B%2Dwebkit%2Dbox%2Dshadow%3Anone%3Bbox%2Dshadow%3Anone%7D%2Ebtn%2Dlink%2C%2Ebtn%2Dlink%3Aactive%2C%2Ebtn%2Dlink%3Afocus%2C%2Ebtn%2Dlink%3Ahover%7Bborder%2Dcolor%3Atransparent%7D%2Ebtn%2Dlink%3Afocus%2C%2Ebtn%2Dlink%3Ahover%7Bcolor%3A%2323527c%3Btext%2Ddecoration%3Aunderline%3Bbackground%2Dcolor%3Atransparent%7D%2Ebtn%2Dlink%5Bdisabled%5D%3Afocus%2C%2Ebtn%2Dlink%5Bdisabled%5D%3Ahover%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dlink%3Afocus%2Cfieldset%5Bdisabled%5D%20%2Ebtn%2Dlink%3Ahover%7Bcolor%3A%23777%3Btext%2Ddecoration%3Anone%7D%2Ebtn%2Dgroup%2Dlg%3E%2Ebtn%2C%2Ebtn%2Dlg%7Bpadding%3A10px%2016px%3Bfont%2Dsize%3A18px%3Bline%2Dheight%3A1%2E3333333%3Bborder%2Dradius%3A6px%7D%2Ebtn%2Dgroup%2Dsm%3E%2Ebtn%2C%2Ebtn%2Dsm%7Bpadding%3A5px%2010px%3Bfont%2Dsize%3A12px%3Bline%2Dheight%3A1%2E5%3Bborder%2Dradius%3A3px%7D%2Ebtn%2Dgroup%2Dxs%3E%2Ebtn%2C%2Ebtn%2Dxs%7Bpadding%3A1px%205px%3Bfont%2Dsize%3A12px%3Bline%2Dheight%3A1%2E5%3Bborder%2Dradius%3A3px%7D%2Ebtn%2Dblock%7Bdisplay%3Ablock%3Bwidth%3A100%25%7D%2Ebtn%2Dblock%2B%2Ebtn%2Dblock%7Bmargin%2Dtop%3A5px%7Dinput%5Btype%3Dbutton%5D%2Ebtn%2Dblock%2Cinput%5Btype%3Dreset%5D%2Ebtn%2Dblock%2Cinput%5Btype%3Dsubmit%5D%2Ebtn%2Dblock%7Bwidth%3A100%25%7D%2Efade%7Bopacity%3A0%3B%2Dwebkit%2Dtransition%3Aopacity%20%2E15s%20linear%3B%2Do%2Dtransition%3Aopacity%20%2E15s%20linear%3Btransition%3Aopacity%20%2E15s%20linear%7D%2Efade%2Ein%7Bopacity%3A1%7D%2Ecollapse%7Bdisplay%3Anone%7D%2Ecollapse%2Ein%7Bdisplay%3Ablock%7Dtr%2Ecollapse%2Ein%7Bdisplay%3Atable%2Drow%7Dtbody%2Ecollapse%2Ein%7Bdisplay%3Atable%2Drow%2Dgroup%7D%2Ecollapsing%7Bposition%3Arelative%3Bheight%3A0%3Boverflow%3Ahidden%3B%2Dwebkit%2Dtransition%2Dtiming%2Dfunction%3Aease%3B%2Do%2Dtransition%2Dtiming%2Dfunction%3Aease%3Btransition%2Dtiming%2Dfunction%3Aease%3B%2Dwebkit%2Dtransition%2Dduration%3A%2E35s%3B%2Do%2Dtransition%2Dduration%3A%2E35s%3Btransition%2Dduration%3A%2E35s%3B%2Dwebkit%2Dtransition%2Dproperty%3Aheight%2Cvisibility%3B%2Do%2Dtransition%2Dproperty%3Aheight%2Cvisibility%3Btransition%2Dproperty%3Aheight%2Cvisibility%7D%2Ecaret%7Bdisplay%3Ainline%2Dblock%3Bwidth%3A0%3Bheight%3A0%3Bmargin%2Dleft%3A2px%3Bvertical%2Dalign%3Amiddle%3Bborder%2Dtop%3A4px%20dashed%3Bborder%2Dtop%3A4px%20solid%5C9%3Bborder%2Dright%3A4px%20solid%20transparent%3Bborder%2Dleft%3A4px%20solid%20transparent%7D%2Edropdown%2C%2Edropup%7Bposition%3Arelative%7D%2Edropdown%2Dtoggle%3Afocus%7Boutline%3A0%7D%2Edropdown%2Dmenu%7Bposition%3Aabsolute%3Btop%3A100%25%3Bleft%3A0%3Bz%2Dindex%3A1000%3Bdisplay%3Anone%3Bfloat%3Aleft%3Bmin%2Dwidth%3A160px%3Bpadding%3A5px%200%3Bmargin%3A2px%200%200%3Bfont%2Dsize%3A14px%3Btext%2Dalign%3Aleft%3Blist%2Dstyle%3Anone%3Bbackground%2Dcolor%3A%23fff%3B%2Dwebkit%2Dbackground%2Dclip%3Apadding%2Dbox%3Bbackground%2Dclip%3Apadding%2Dbox%3Bborder%3A1px%20solid%20%23ccc%3Bborder%3A1px%20solid%20rgba%280%2C0%2C0%2C%2E15%29%3Bborder%2Dradius%3A4px%3B%2Dwebkit%2Dbox%2Dshadow%3A0%206px%2012px%20rgba%280%2C0%2C0%2C%2E175%29%3Bbox%2Dshadow%3A0%206px%2012px%20rgba%280%2C0%2C0%2C%2E175%29%7D%2Edropdown%2Dmenu%2Epull%2Dright%7Bright%3A0%3Bleft%3Aauto%7D%2Edropdown%2Dmenu%20%2Edivider%7Bheight%3A1px%3Bmargin%3A9px%200%3Boverflow%3Ahidden%3Bbackground%2Dcolor%3A%23e5e5e5%7D%2Edropdown%2Dmenu%3Eli%3Ea%7Bdisplay%3Ablock%3Bpadding%3A3px%2020px%3Bclear%3Aboth%3Bfont%2Dweight%3A400%3Bline%2Dheight%3A1%2E42857143%3Bcolor%3A%23333%3Bwhite%2Dspace%3Anowrap%7D%2Edropdown%2Dmenu%3Eli%3Ea%3Afocus%2C%2Edropdown%2Dmenu%3Eli%3Ea%3Ahover%7Bcolor%3A%23262626%3Btext%2Ddecoration%3Anone%3Bbackground%2Dcolor%3A%23f5f5f5%7D%2Edropdown%2Dmenu%3E%2Eactive%3Ea%2C%2Edropdown%2Dmenu%3E%2Eactive%3Ea%3Afocus%2C%2Edropdown%2Dmenu%3E%2Eactive%3Ea%3Ahover%7Bcolor%3A%23fff%3Btext%2Ddecoration%3Anone%3Bbackground%2Dcolor%3A%23337ab7%3Boutline%3A0%7D%2Edropdown%2Dmenu%3E%2Edisabled%3Ea%2C%2Edropdown%2Dmenu%3E%2Edisabled%3Ea%3Afocus%2C%2Edropdown%2Dmenu%3E%2Edisabled%3Ea%3Ahover%7Bcolor%3A%23777%7D%2Edropdown%2Dmenu%3E%2Edisabled%3Ea%3Afocus%2C%2Edropdown%2Dmenu%3E%2Edisabled%3Ea%3Ahover%7Btext%2Ddecoration%3Anone%3Bcursor%3Anot%2Dallowed%3Bbackground%2Dcolor%3Atransparent%3Bbackground%2Dimage%3Anone%3Bfilter%3Aprogid%3ADXImageTransform%2EMicrosoft%2Egradient%28enabled%3Dfalse%29%7D%2Eopen%3E%2Edropdown%2Dmenu%7Bdisplay%3Ablock%7D%2Eopen%3Ea%7Boutline%3A0%7D%2Edropdown%2Dmenu%2Dright%7Bright%3A0%3Bleft%3Aauto%7D%2Edropdown%2Dmenu%2Dleft%7Bright%3Aauto%3Bleft%3A0%7D%2Edropdown%2Dheader%7Bdisplay%3Ablock%3Bpadding%3A3px%2020px%3Bfont%2Dsize%3A12px%3Bline%2Dheight%3A1%2E42857143%3Bcolor%3A%23777%3Bwhite%2Dspace%3Anowrap%7D%2Edropdown%2Dbackdrop%7Bposition%3Afixed%3Btop%3A0%3Bright%3A0%3Bbottom%3A0%3Bleft%3A0%3Bz%2Dindex%3A990%7D%2Epull%2Dright%3E%2Edropdown%2Dmenu%7Bright%3A0%3Bleft%3Aauto%7D%2Edropup%20%2Ecaret%2C%2Enavbar%2Dfixed%2Dbottom%20%2Edropdown%20%2Ecaret%7Bcontent%3A%22%22%3Bborder%2Dtop%3A0%3Bborder%2Dbottom%3A4px%20dashed%3Bborder%2Dbottom%3A4px%20solid%5C9%7D%2Edropup%20%2Edropdown%2Dmenu%2C%2Enavbar%2Dfixed%2Dbottom%20%2Edropdown%20%2Edropdown%2Dmenu%7Btop%3Aauto%3Bbottom%3A100%25%3Bmargin%2Dbottom%3A2px%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Enavbar%2Dright%20%2Edropdown%2Dmenu%7Bright%3A0%3Bleft%3Aauto%7D%2Enavbar%2Dright%20%2Edropdown%2Dmenu%2Dleft%7Bright%3Aauto%3Bleft%3A0%7D%7D%2Ebtn%2Dgroup%2C%2Ebtn%2Dgroup%2Dvertical%7Bposition%3Arelative%3Bdisplay%3Ainline%2Dblock%3Bvertical%2Dalign%3Amiddle%7D%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%2C%2Ebtn%2Dgroup%3E%2Ebtn%7Bposition%3Arelative%3Bfloat%3Aleft%7D%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%2Eactive%2C%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%3Aactive%2C%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%3Afocus%2C%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%3Ahover%2C%2Ebtn%2Dgroup%3E%2Ebtn%2Eactive%2C%2Ebtn%2Dgroup%3E%2Ebtn%3Aactive%2C%2Ebtn%2Dgroup%3E%2Ebtn%3Afocus%2C%2Ebtn%2Dgroup%3E%2Ebtn%3Ahover%7Bz%2Dindex%3A2%7D%2Ebtn%2Dgroup%20%2Ebtn%2B%2Ebtn%2C%2Ebtn%2Dgroup%20%2Ebtn%2B%2Ebtn%2Dgroup%2C%2Ebtn%2Dgroup%20%2Ebtn%2Dgroup%2B%2Ebtn%2C%2Ebtn%2Dgroup%20%2Ebtn%2Dgroup%2B%2Ebtn%2Dgroup%7Bmargin%2Dleft%3A%2D1px%7D%2Ebtn%2Dtoolbar%7Bmargin%2Dleft%3A%2D5px%7D%2Ebtn%2Dtoolbar%20%2Ebtn%2C%2Ebtn%2Dtoolbar%20%2Ebtn%2Dgroup%2C%2Ebtn%2Dtoolbar%20%2Einput%2Dgroup%7Bfloat%3Aleft%7D%2Ebtn%2Dtoolbar%3E%2Ebtn%2C%2Ebtn%2Dtoolbar%3E%2Ebtn%2Dgroup%2C%2Ebtn%2Dtoolbar%3E%2Einput%2Dgroup%7Bmargin%2Dleft%3A5px%7D%2Ebtn%2Dgroup%3E%2Ebtn%3Anot%28%3Afirst%2Dchild%29%3Anot%28%3Alast%2Dchild%29%3Anot%28%2Edropdown%2Dtoggle%29%7Bborder%2Dradius%3A0%7D%2Ebtn%2Dgroup%3E%2Ebtn%3Afirst%2Dchild%7Bmargin%2Dleft%3A0%7D%2Ebtn%2Dgroup%3E%2Ebtn%3Afirst%2Dchild%3Anot%28%3Alast%2Dchild%29%3Anot%28%2Edropdown%2Dtoggle%29%7Bborder%2Dtop%2Dright%2Dradius%3A0%3Bborder%2Dbottom%2Dright%2Dradius%3A0%7D%2Ebtn%2Dgroup%3E%2Ebtn%3Alast%2Dchild%3Anot%28%3Afirst%2Dchild%29%2C%2Ebtn%2Dgroup%3E%2Edropdown%2Dtoggle%3Anot%28%3Afirst%2Dchild%29%7Bborder%2Dtop%2Dleft%2Dradius%3A0%3Bborder%2Dbottom%2Dleft%2Dradius%3A0%7D%2Ebtn%2Dgroup%3E%2Ebtn%2Dgroup%7Bfloat%3Aleft%7D%2Ebtn%2Dgroup%3E%2Ebtn%2Dgroup%3Anot%28%3Afirst%2Dchild%29%3Anot%28%3Alast%2Dchild%29%3E%2Ebtn%7Bborder%2Dradius%3A0%7D%2Ebtn%2Dgroup%3E%2Ebtn%2Dgroup%3Afirst%2Dchild%3Anot%28%3Alast%2Dchild%29%3E%2Ebtn%3Alast%2Dchild%2C%2Ebtn%2Dgroup%3E%2Ebtn%2Dgroup%3Afirst%2Dchild%3Anot%28%3Alast%2Dchild%29%3E%2Edropdown%2Dtoggle%7Bborder%2Dtop%2Dright%2Dradius%3A0%3Bborder%2Dbottom%2Dright%2Dradius%3A0%7D%2Ebtn%2Dgroup%3E%2Ebtn%2Dgroup%3Alast%2Dchild%3Anot%28%3Afirst%2Dchild%29%3E%2Ebtn%3Afirst%2Dchild%7Bborder%2Dtop%2Dleft%2Dradius%3A0%3Bborder%2Dbottom%2Dleft%2Dradius%3A0%7D%2Ebtn%2Dgroup%20%2Edropdown%2Dtoggle%3Aactive%2C%2Ebtn%2Dgroup%2Eopen%20%2Edropdown%2Dtoggle%7Boutline%3A0%7D%2Ebtn%2Dgroup%3E%2Ebtn%2B%2Edropdown%2Dtoggle%7Bpadding%2Dright%3A8px%3Bpadding%2Dleft%3A8px%7D%2Ebtn%2Dgroup%3E%2Ebtn%2Dlg%2B%2Edropdown%2Dtoggle%7Bpadding%2Dright%3A12px%3Bpadding%2Dleft%3A12px%7D%2Ebtn%2Dgroup%2Eopen%20%2Edropdown%2Dtoggle%7B%2Dwebkit%2Dbox%2Dshadow%3Ainset%200%203px%205px%20rgba%280%2C0%2C0%2C%2E125%29%3Bbox%2Dshadow%3Ainset%200%203px%205px%20rgba%280%2C0%2C0%2C%2E125%29%7D%2Ebtn%2Dgroup%2Eopen%20%2Edropdown%2Dtoggle%2Ebtn%2Dlink%7B%2Dwebkit%2Dbox%2Dshadow%3Anone%3Bbox%2Dshadow%3Anone%7D%2Ebtn%20%2Ecaret%7Bmargin%2Dleft%3A0%7D%2Ebtn%2Dlg%20%2Ecaret%7Bborder%2Dwidth%3A5px%205px%200%3Bborder%2Dbottom%2Dwidth%3A0%7D%2Edropup%20%2Ebtn%2Dlg%20%2Ecaret%7Bborder%2Dwidth%3A0%205px%205px%7D%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%2C%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%2Dgroup%2C%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%2Dgroup%3E%2Ebtn%7Bdisplay%3Ablock%3Bfloat%3Anone%3Bwidth%3A100%25%3Bmax%2Dwidth%3A100%25%7D%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%2Dgroup%3E%2Ebtn%7Bfloat%3Anone%7D%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%2B%2Ebtn%2C%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%2B%2Ebtn%2Dgroup%2C%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%2Dgroup%2B%2Ebtn%2C%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%2Dgroup%2B%2Ebtn%2Dgroup%7Bmargin%2Dtop%3A%2D1px%3Bmargin%2Dleft%3A0%7D%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%3Anot%28%3Afirst%2Dchild%29%3Anot%28%3Alast%2Dchild%29%7Bborder%2Dradius%3A0%7D%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%3Afirst%2Dchild%3Anot%28%3Alast%2Dchild%29%7Bborder%2Dtop%2Dright%2Dradius%3A4px%3Bborder%2Dbottom%2Dright%2Dradius%3A0%3Bborder%2Dbottom%2Dleft%2Dradius%3A0%7D%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%3Alast%2Dchild%3Anot%28%3Afirst%2Dchild%29%7Bborder%2Dtop%2Dleft%2Dradius%3A0%3Bborder%2Dtop%2Dright%2Dradius%3A0%3Bborder%2Dbottom%2Dleft%2Dradius%3A4px%7D%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%2Dgroup%3Anot%28%3Afirst%2Dchild%29%3Anot%28%3Alast%2Dchild%29%3E%2Ebtn%7Bborder%2Dradius%3A0%7D%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%2Dgroup%3Afirst%2Dchild%3Anot%28%3Alast%2Dchild%29%3E%2Ebtn%3Alast%2Dchild%2C%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%2Dgroup%3Afirst%2Dchild%3Anot%28%3Alast%2Dchild%29%3E%2Edropdown%2Dtoggle%7Bborder%2Dbottom%2Dright%2Dradius%3A0%3Bborder%2Dbottom%2Dleft%2Dradius%3A0%7D%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%2Dgroup%3Alast%2Dchild%3Anot%28%3Afirst%2Dchild%29%3E%2Ebtn%3Afirst%2Dchild%7Bborder%2Dtop%2Dleft%2Dradius%3A0%3Bborder%2Dtop%2Dright%2Dradius%3A0%7D%2Ebtn%2Dgroup%2Djustified%7Bdisplay%3Atable%3Bwidth%3A100%25%3Btable%2Dlayout%3Afixed%3Bborder%2Dcollapse%3Aseparate%7D%2Ebtn%2Dgroup%2Djustified%3E%2Ebtn%2C%2Ebtn%2Dgroup%2Djustified%3E%2Ebtn%2Dgroup%7Bdisplay%3Atable%2Dcell%3Bfloat%3Anone%3Bwidth%3A1%25%7D%2Ebtn%2Dgroup%2Djustified%3E%2Ebtn%2Dgroup%20%2Ebtn%7Bwidth%3A100%25%7D%2Ebtn%2Dgroup%2Djustified%3E%2Ebtn%2Dgroup%20%2Edropdown%2Dmenu%7Bleft%3Aauto%7D%5Bdata%2Dtoggle%3Dbuttons%5D%3E%2Ebtn%20input%5Btype%3Dcheckbox%5D%2C%5Bdata%2Dtoggle%3Dbuttons%5D%3E%2Ebtn%20input%5Btype%3Dradio%5D%2C%5Bdata%2Dtoggle%3Dbuttons%5D%3E%2Ebtn%2Dgroup%3E%2Ebtn%20input%5Btype%3Dcheckbox%5D%2C%5Bdata%2Dtoggle%3Dbuttons%5D%3E%2Ebtn%2Dgroup%3E%2Ebtn%20input%5Btype%3Dradio%5D%7Bposition%3Aabsolute%3Bclip%3Arect%280%2C0%2C0%2C0%29%3Bpointer%2Devents%3Anone%7D%2Einput%2Dgroup%7Bposition%3Arelative%3Bdisplay%3Atable%3Bborder%2Dcollapse%3Aseparate%7D%2Einput%2Dgroup%5Bclass%2A%3Dcol%2D%5D%7Bfloat%3Anone%3Bpadding%2Dright%3A0%3Bpadding%2Dleft%3A0%7D%2Einput%2Dgroup%20%2Eform%2Dcontrol%7Bposition%3Arelative%3Bz%2Dindex%3A2%3Bfloat%3Aleft%3Bwidth%3A100%25%3Bmargin%2Dbottom%3A0%7D%2Einput%2Dgroup%2Dlg%3E%2Eform%2Dcontrol%2C%2Einput%2Dgroup%2Dlg%3E%2Einput%2Dgroup%2Daddon%2C%2Einput%2Dgroup%2Dlg%3E%2Einput%2Dgroup%2Dbtn%3E%2Ebtn%7Bheight%3A46px%3Bpadding%3A10px%2016px%3Bfont%2Dsize%3A18px%3Bline%2Dheight%3A1%2E3333333%3Bborder%2Dradius%3A6px%7Dselect%2Einput%2Dgroup%2Dlg%3E%2Eform%2Dcontrol%2Cselect%2Einput%2Dgroup%2Dlg%3E%2Einput%2Dgroup%2Daddon%2Cselect%2Einput%2Dgroup%2Dlg%3E%2Einput%2Dgroup%2Dbtn%3E%2Ebtn%7Bheight%3A46px%3Bline%2Dheight%3A46px%7Dselect%5Bmultiple%5D%2Einput%2Dgroup%2Dlg%3E%2Eform%2Dcontrol%2Cselect%5Bmultiple%5D%2Einput%2Dgroup%2Dlg%3E%2Einput%2Dgroup%2Daddon%2Cselect%5Bmultiple%5D%2Einput%2Dgroup%2Dlg%3E%2Einput%2Dgroup%2Dbtn%3E%2Ebtn%2Ctextarea%2Einput%2Dgroup%2Dlg%3E%2Eform%2Dcontrol%2Ctextarea%2Einput%2Dgroup%2Dlg%3E%2Einput%2Dgroup%2Daddon%2Ctextarea%2Einput%2Dgroup%2Dlg%3E%2Einput%2Dgroup%2Dbtn%3E%2Ebtn%7Bheight%3Aauto%7D%2Einput%2Dgroup%2Dsm%3E%2Eform%2Dcontrol%2C%2Einput%2Dgroup%2Dsm%3E%2Einput%2Dgroup%2Daddon%2C%2Einput%2Dgroup%2Dsm%3E%2Einput%2Dgroup%2Dbtn%3E%2Ebtn%7Bheight%3A30px%3Bpadding%3A5px%2010px%3Bfont%2Dsize%3A12px%3Bline%2Dheight%3A1%2E5%3Bborder%2Dradius%3A3px%7Dselect%2Einput%2Dgroup%2Dsm%3E%2Eform%2Dcontrol%2Cselect%2Einput%2Dgroup%2Dsm%3E%2Einput%2Dgroup%2Daddon%2Cselect%2Einput%2Dgroup%2Dsm%3E%2Einput%2Dgroup%2Dbtn%3E%2Ebtn%7Bheight%3A30px%3Bline%2Dheight%3A30px%7Dselect%5Bmultiple%5D%2Einput%2Dgroup%2Dsm%3E%2Eform%2Dcontrol%2Cselect%5Bmultiple%5D%2Einput%2Dgroup%2Dsm%3E%2Einput%2Dgroup%2Daddon%2Cselect%5Bmultiple%5D%2Einput%2Dgroup%2Dsm%3E%2Einput%2Dgroup%2Dbtn%3E%2Ebtn%2Ctextarea%2Einput%2Dgroup%2Dsm%3E%2Eform%2Dcontrol%2Ctextarea%2Einput%2Dgroup%2Dsm%3E%2Einput%2Dgroup%2Daddon%2Ctextarea%2Einput%2Dgroup%2Dsm%3E%2Einput%2Dgroup%2Dbtn%3E%2Ebtn%7Bheight%3Aauto%7D%2Einput%2Dgroup%20%2Eform%2Dcontrol%2C%2Einput%2Dgroup%2Daddon%2C%2Einput%2Dgroup%2Dbtn%7Bdisplay%3Atable%2Dcell%7D%2Einput%2Dgroup%20%2Eform%2Dcontrol%3Anot%28%3Afirst%2Dchild%29%3Anot%28%3Alast%2Dchild%29%2C%2Einput%2Dgroup%2Daddon%3Anot%28%3Afirst%2Dchild%29%3Anot%28%3Alast%2Dchild%29%2C%2Einput%2Dgroup%2Dbtn%3Anot%28%3Afirst%2Dchild%29%3Anot%28%3Alast%2Dchild%29%7Bborder%2Dradius%3A0%7D%2Einput%2Dgroup%2Daddon%2C%2Einput%2Dgroup%2Dbtn%7Bwidth%3A1%25%3Bwhite%2Dspace%3Anowrap%3Bvertical%2Dalign%3Amiddle%7D%2Einput%2Dgroup%2Daddon%7Bpadding%3A6px%2012px%3Bfont%2Dsize%3A14px%3Bfont%2Dweight%3A400%3Bline%2Dheight%3A1%3Bcolor%3A%23555%3Btext%2Dalign%3Acenter%3Bbackground%2Dcolor%3A%23eee%3Bborder%3A1px%20solid%20%23ccc%3Bborder%2Dradius%3A4px%7D%2Einput%2Dgroup%2Daddon%2Einput%2Dsm%7Bpadding%3A5px%2010px%3Bfont%2Dsize%3A12px%3Bborder%2Dradius%3A3px%7D%2Einput%2Dgroup%2Daddon%2Einput%2Dlg%7Bpadding%3A10px%2016px%3Bfont%2Dsize%3A18px%3Bborder%2Dradius%3A6px%7D%2Einput%2Dgroup%2Daddon%20input%5Btype%3Dcheckbox%5D%2C%2Einput%2Dgroup%2Daddon%20input%5Btype%3Dradio%5D%7Bmargin%2Dtop%3A0%7D%2Einput%2Dgroup%20%2Eform%2Dcontrol%3Afirst%2Dchild%2C%2Einput%2Dgroup%2Daddon%3Afirst%2Dchild%2C%2Einput%2Dgroup%2Dbtn%3Afirst%2Dchild%3E%2Ebtn%2C%2Einput%2Dgroup%2Dbtn%3Afirst%2Dchild%3E%2Ebtn%2Dgroup%3E%2Ebtn%2C%2Einput%2Dgroup%2Dbtn%3Afirst%2Dchild%3E%2Edropdown%2Dtoggle%2C%2Einput%2Dgroup%2Dbtn%3Alast%2Dchild%3E%2Ebtn%2Dgroup%3Anot%28%3Alast%2Dchild%29%3E%2Ebtn%2C%2Einput%2Dgroup%2Dbtn%3Alast%2Dchild%3E%2Ebtn%3Anot%28%3Alast%2Dchild%29%3Anot%28%2Edropdown%2Dtoggle%29%7Bborder%2Dtop%2Dright%2Dradius%3A0%3Bborder%2Dbottom%2Dright%2Dradius%3A0%7D%2Einput%2Dgroup%2Daddon%3Afirst%2Dchild%7Bborder%2Dright%3A0%7D%2Einput%2Dgroup%20%2Eform%2Dcontrol%3Alast%2Dchild%2C%2Einput%2Dgroup%2Daddon%3Alast%2Dchild%2C%2Einput%2Dgroup%2Dbtn%3Afirst%2Dchild%3E%2Ebtn%2Dgroup%3Anot%28%3Afirst%2Dchild%29%3E%2Ebtn%2C%2Einput%2Dgroup%2Dbtn%3Afirst%2Dchild%3E%2Ebtn%3Anot%28%3Afirst%2Dchild%29%2C%2Einput%2Dgroup%2Dbtn%3Alast%2Dchild%3E%2Ebtn%2C%2Einput%2Dgroup%2Dbtn%3Alast%2Dchild%3E%2Ebtn%2Dgroup%3E%2Ebtn%2C%2Einput%2Dgroup%2Dbtn%3Alast%2Dchild%3E%2Edropdown%2Dtoggle%7Bborder%2Dtop%2Dleft%2Dradius%3A0%3Bborder%2Dbottom%2Dleft%2Dradius%3A0%7D%2Einput%2Dgroup%2Daddon%3Alast%2Dchild%7Bborder%2Dleft%3A0%7D%2Einput%2Dgroup%2Dbtn%7Bposition%3Arelative%3Bfont%2Dsize%3A0%3Bwhite%2Dspace%3Anowrap%7D%2Einput%2Dgroup%2Dbtn%3E%2Ebtn%7Bposition%3Arelative%7D%2Einput%2Dgroup%2Dbtn%3E%2Ebtn%2B%2Ebtn%7Bmargin%2Dleft%3A%2D1px%7D%2Einput%2Dgroup%2Dbtn%3E%2Ebtn%3Aactive%2C%2Einput%2Dgroup%2Dbtn%3E%2Ebtn%3Afocus%2C%2Einput%2Dgroup%2Dbtn%3E%2Ebtn%3Ahover%7Bz%2Dindex%3A2%7D%2Einput%2Dgroup%2Dbtn%3Afirst%2Dchild%3E%2Ebtn%2C%2Einput%2Dgroup%2Dbtn%3Afirst%2Dchild%3E%2Ebtn%2Dgroup%7Bmargin%2Dright%3A%2D1px%7D%2Einput%2Dgroup%2Dbtn%3Alast%2Dchild%3E%2Ebtn%2C%2Einput%2Dgroup%2Dbtn%3Alast%2Dchild%3E%2Ebtn%2Dgroup%7Bz%2Dindex%3A2%3Bmargin%2Dleft%3A%2D1px%7D%2Enav%7Bpadding%2Dleft%3A0%3Bmargin%2Dbottom%3A0%3Blist%2Dstyle%3Anone%7D%2Enav%3Eli%7Bposition%3Arelative%3Bdisplay%3Ablock%7D%2Enav%3Eli%3Ea%7Bposition%3Arelative%3Bdisplay%3Ablock%3Bpadding%3A10px%2015px%7D%2Enav%3Eli%3Ea%3Afocus%2C%2Enav%3Eli%3Ea%3Ahover%7Btext%2Ddecoration%3Anone%3Bbackground%2Dcolor%3A%23eee%7D%2Enav%3Eli%2Edisabled%3Ea%7Bcolor%3A%23777%7D%2Enav%3Eli%2Edisabled%3Ea%3Afocus%2C%2Enav%3Eli%2Edisabled%3Ea%3Ahover%7Bcolor%3A%23777%3Btext%2Ddecoration%3Anone%3Bcursor%3Anot%2Dallowed%3Bbackground%2Dcolor%3Atransparent%7D%2Enav%20%2Eopen%3Ea%2C%2Enav%20%2Eopen%3Ea%3Afocus%2C%2Enav%20%2Eopen%3Ea%3Ahover%7Bbackground%2Dcolor%3A%23eee%3Bborder%2Dcolor%3A%23337ab7%7D%2Enav%20%2Enav%2Ddivider%7Bheight%3A1px%3Bmargin%3A9px%200%3Boverflow%3Ahidden%3Bbackground%2Dcolor%3A%23e5e5e5%7D%2Enav%3Eli%3Ea%3Eimg%7Bmax%2Dwidth%3Anone%7D%2Enav%2Dtabs%7Bborder%2Dbottom%3A1px%20solid%20%23ddd%7D%2Enav%2Dtabs%3Eli%7Bfloat%3Aleft%3Bmargin%2Dbottom%3A%2D1px%7D%2Enav%2Dtabs%3Eli%3Ea%7Bmargin%2Dright%3A2px%3Bline%2Dheight%3A1%2E42857143%3Bborder%3A1px%20solid%20transparent%3Bborder%2Dradius%3A4px%204px%200%200%7D%2Enav%2Dtabs%3Eli%3Ea%3Ahover%7Bborder%2Dcolor%3A%23eee%20%23eee%20%23ddd%7D%2Enav%2Dtabs%3Eli%2Eactive%3Ea%2C%2Enav%2Dtabs%3Eli%2Eactive%3Ea%3Afocus%2C%2Enav%2Dtabs%3Eli%2Eactive%3Ea%3Ahover%7Bcolor%3A%23555%3Bcursor%3Adefault%3Bbackground%2Dcolor%3A%23fff%3Bborder%3A1px%20solid%20%23ddd%3Bborder%2Dbottom%2Dcolor%3Atransparent%7D%2Enav%2Dtabs%2Enav%2Djustified%7Bwidth%3A100%25%3Bborder%2Dbottom%3A0%7D%2Enav%2Dtabs%2Enav%2Djustified%3Eli%7Bfloat%3Anone%7D%2Enav%2Dtabs%2Enav%2Djustified%3Eli%3Ea%7Bmargin%2Dbottom%3A5px%3Btext%2Dalign%3Acenter%7D%2Enav%2Dtabs%2Enav%2Djustified%3E%2Edropdown%20%2Edropdown%2Dmenu%7Btop%3Aauto%3Bleft%3Aauto%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Enav%2Dtabs%2Enav%2Djustified%3Eli%7Bdisplay%3Atable%2Dcell%3Bwidth%3A1%25%7D%2Enav%2Dtabs%2Enav%2Djustified%3Eli%3Ea%7Bmargin%2Dbottom%3A0%7D%7D%2Enav%2Dtabs%2Enav%2Djustified%3Eli%3Ea%7Bmargin%2Dright%3A0%3Bborder%2Dradius%3A4px%7D%2Enav%2Dtabs%2Enav%2Djustified%3E%2Eactive%3Ea%2C%2Enav%2Dtabs%2Enav%2Djustified%3E%2Eactive%3Ea%3Afocus%2C%2Enav%2Dtabs%2Enav%2Djustified%3E%2Eactive%3Ea%3Ahover%7Bborder%3A1px%20solid%20%23ddd%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Enav%2Dtabs%2Enav%2Djustified%3Eli%3Ea%7Bborder%2Dbottom%3A1px%20solid%20%23ddd%3Bborder%2Dradius%3A4px%204px%200%200%7D%2Enav%2Dtabs%2Enav%2Djustified%3E%2Eactive%3Ea%2C%2Enav%2Dtabs%2Enav%2Djustified%3E%2Eactive%3Ea%3Afocus%2C%2Enav%2Dtabs%2Enav%2Djustified%3E%2Eactive%3Ea%3Ahover%7Bborder%2Dbottom%2Dcolor%3A%23fff%7D%7D%2Enav%2Dpills%3Eli%7Bfloat%3Aleft%7D%2Enav%2Dpills%3Eli%3Ea%7Bborder%2Dradius%3A4px%7D%2Enav%2Dpills%3Eli%2Bli%7Bmargin%2Dleft%3A2px%7D%2Enav%2Dpills%3Eli%2Eactive%3Ea%2C%2Enav%2Dpills%3Eli%2Eactive%3Ea%3Afocus%2C%2Enav%2Dpills%3Eli%2Eactive%3Ea%3Ahover%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23337ab7%7D%2Enav%2Dstacked%3Eli%7Bfloat%3Anone%7D%2Enav%2Dstacked%3Eli%2Bli%7Bmargin%2Dtop%3A2px%3Bmargin%2Dleft%3A0%7D%2Enav%2Djustified%7Bwidth%3A100%25%7D%2Enav%2Djustified%3Eli%7Bfloat%3Anone%7D%2Enav%2Djustified%3Eli%3Ea%7Bmargin%2Dbottom%3A5px%3Btext%2Dalign%3Acenter%7D%2Enav%2Djustified%3E%2Edropdown%20%2Edropdown%2Dmenu%7Btop%3Aauto%3Bleft%3Aauto%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Enav%2Djustified%3Eli%7Bdisplay%3Atable%2Dcell%3Bwidth%3A1%25%7D%2Enav%2Djustified%3Eli%3Ea%7Bmargin%2Dbottom%3A0%7D%7D%2Enav%2Dtabs%2Djustified%7Bborder%2Dbottom%3A0%7D%2Enav%2Dtabs%2Djustified%3Eli%3Ea%7Bmargin%2Dright%3A0%3Bborder%2Dradius%3A4px%7D%2Enav%2Dtabs%2Djustified%3E%2Eactive%3Ea%2C%2Enav%2Dtabs%2Djustified%3E%2Eactive%3Ea%3Afocus%2C%2Enav%2Dtabs%2Djustified%3E%2Eactive%3Ea%3Ahover%7Bborder%3A1px%20solid%20%23ddd%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Enav%2Dtabs%2Djustified%3Eli%3Ea%7Bborder%2Dbottom%3A1px%20solid%20%23ddd%3Bborder%2Dradius%3A4px%204px%200%200%7D%2Enav%2Dtabs%2Djustified%3E%2Eactive%3Ea%2C%2Enav%2Dtabs%2Djustified%3E%2Eactive%3Ea%3Afocus%2C%2Enav%2Dtabs%2Djustified%3E%2Eactive%3Ea%3Ahover%7Bborder%2Dbottom%2Dcolor%3A%23fff%7D%7D%2Etab%2Dcontent%3E%2Etab%2Dpane%7Bdisplay%3Anone%7D%2Etab%2Dcontent%3E%2Eactive%7Bdisplay%3Ablock%7D%2Enav%2Dtabs%20%2Edropdown%2Dmenu%7Bmargin%2Dtop%3A%2D1px%3Bborder%2Dtop%2Dleft%2Dradius%3A0%3Bborder%2Dtop%2Dright%2Dradius%3A0%7D%2Enavbar%7Bposition%3Arelative%3Bmin%2Dheight%3A50px%3Bmargin%2Dbottom%3A20px%3Bborder%3A1px%20solid%20transparent%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Enavbar%7Bborder%2Dradius%3A4px%7D%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Enavbar%2Dheader%7Bfloat%3Aleft%7D%7D%2Enavbar%2Dcollapse%7Bpadding%2Dright%3A15px%3Bpadding%2Dleft%3A15px%3Boverflow%2Dx%3Avisible%3B%2Dwebkit%2Doverflow%2Dscrolling%3Atouch%3Bborder%2Dtop%3A1px%20solid%20transparent%3B%2Dwebkit%2Dbox%2Dshadow%3Ainset%200%201px%200%20rgba%28255%2C255%2C255%2C%2E1%29%3Bbox%2Dshadow%3Ainset%200%201px%200%20rgba%28255%2C255%2C255%2C%2E1%29%7D%2Enavbar%2Dcollapse%2Ein%7Boverflow%2Dy%3Aauto%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Enavbar%2Dcollapse%7Bwidth%3Aauto%3Bborder%2Dtop%3A0%3B%2Dwebkit%2Dbox%2Dshadow%3Anone%3Bbox%2Dshadow%3Anone%7D%2Enavbar%2Dcollapse%2Ecollapse%7Bdisplay%3Ablock%21important%3Bheight%3Aauto%21important%3Bpadding%2Dbottom%3A0%3Boverflow%3Avisible%21important%7D%2Enavbar%2Dcollapse%2Ein%7Boverflow%2Dy%3Avisible%7D%2Enavbar%2Dfixed%2Dbottom%20%2Enavbar%2Dcollapse%2C%2Enavbar%2Dfixed%2Dtop%20%2Enavbar%2Dcollapse%2C%2Enavbar%2Dstatic%2Dtop%20%2Enavbar%2Dcollapse%7Bpadding%2Dright%3A0%3Bpadding%2Dleft%3A0%7D%7D%2Enavbar%2Dfixed%2Dbottom%20%2Enavbar%2Dcollapse%2C%2Enavbar%2Dfixed%2Dtop%20%2Enavbar%2Dcollapse%7Bmax%2Dheight%3A340px%7D%40media%20%28max%2Ddevice%2Dwidth%3A480px%29%20and%20%28orientation%3Alandscape%29%7B%2Enavbar%2Dfixed%2Dbottom%20%2Enavbar%2Dcollapse%2C%2Enavbar%2Dfixed%2Dtop%20%2Enavbar%2Dcollapse%7Bmax%2Dheight%3A200px%7D%7D%2Econtainer%2Dfluid%3E%2Enavbar%2Dcollapse%2C%2Econtainer%2Dfluid%3E%2Enavbar%2Dheader%2C%2Econtainer%3E%2Enavbar%2Dcollapse%2C%2Econtainer%3E%2Enavbar%2Dheader%7Bmargin%2Dright%3A%2D15px%3Bmargin%2Dleft%3A%2D15px%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Econtainer%2Dfluid%3E%2Enavbar%2Dcollapse%2C%2Econtainer%2Dfluid%3E%2Enavbar%2Dheader%2C%2Econtainer%3E%2Enavbar%2Dcollapse%2C%2Econtainer%3E%2Enavbar%2Dheader%7Bmargin%2Dright%3A0%3Bmargin%2Dleft%3A0%7D%7D%2Enavbar%2Dstatic%2Dtop%7Bz%2Dindex%3A1000%3Bborder%2Dwidth%3A0%200%201px%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Enavbar%2Dstatic%2Dtop%7Bborder%2Dradius%3A0%7D%7D%2Enavbar%2Dfixed%2Dbottom%2C%2Enavbar%2Dfixed%2Dtop%7Bposition%3Afixed%3Bright%3A0%3Bleft%3A0%3Bz%2Dindex%3A1030%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Enavbar%2Dfixed%2Dbottom%2C%2Enavbar%2Dfixed%2Dtop%7Bborder%2Dradius%3A0%7D%7D%2Enavbar%2Dfixed%2Dtop%7Btop%3A0%3Bborder%2Dwidth%3A0%200%201px%7D%2Enavbar%2Dfixed%2Dbottom%7Bbottom%3A0%3Bmargin%2Dbottom%3A0%3Bborder%2Dwidth%3A1px%200%200%7D%2Enavbar%2Dbrand%7Bfloat%3Aleft%3Bheight%3A50px%3Bpadding%3A15px%2015px%3Bfont%2Dsize%3A18px%3Bline%2Dheight%3A20px%7D%2Enavbar%2Dbrand%3Afocus%2C%2Enavbar%2Dbrand%3Ahover%7Btext%2Ddecoration%3Anone%7D%2Enavbar%2Dbrand%3Eimg%7Bdisplay%3Ablock%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Enavbar%3E%2Econtainer%20%2Enavbar%2Dbrand%2C%2Enavbar%3E%2Econtainer%2Dfluid%20%2Enavbar%2Dbrand%7Bmargin%2Dleft%3A%2D15px%7D%7D%2Enavbar%2Dtoggle%7Bposition%3Arelative%3Bfloat%3Aright%3Bpadding%3A9px%2010px%3Bmargin%2Dtop%3A8px%3Bmargin%2Dright%3A15px%3Bmargin%2Dbottom%3A8px%3Bbackground%2Dcolor%3Atransparent%3Bbackground%2Dimage%3Anone%3Bborder%3A1px%20solid%20transparent%3Bborder%2Dradius%3A4px%7D%2Enavbar%2Dtoggle%3Afocus%7Boutline%3A0%7D%2Enavbar%2Dtoggle%20%2Eicon%2Dbar%7Bdisplay%3Ablock%3Bwidth%3A22px%3Bheight%3A2px%3Bborder%2Dradius%3A1px%7D%2Enavbar%2Dtoggle%20%2Eicon%2Dbar%2B%2Eicon%2Dbar%7Bmargin%2Dtop%3A4px%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Enavbar%2Dtoggle%7Bdisplay%3Anone%7D%7D%2Enavbar%2Dnav%7Bmargin%3A7%2E5px%20%2D15px%7D%2Enavbar%2Dnav%3Eli%3Ea%7Bpadding%2Dtop%3A10px%3Bpadding%2Dbottom%3A10px%3Bline%2Dheight%3A20px%7D%40media%20%28max%2Dwidth%3A767px%29%7B%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%7Bposition%3Astatic%3Bfloat%3Anone%3Bwidth%3Aauto%3Bmargin%2Dtop%3A0%3Bbackground%2Dcolor%3Atransparent%3Bborder%3A0%3B%2Dwebkit%2Dbox%2Dshadow%3Anone%3Bbox%2Dshadow%3Anone%7D%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%20%2Edropdown%2Dheader%2C%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3Eli%3Ea%7Bpadding%3A5px%2015px%205px%2025px%7D%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3Eli%3Ea%7Bline%2Dheight%3A20px%7D%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3Eli%3Ea%3Afocus%2C%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3Eli%3Ea%3Ahover%7Bbackground%2Dimage%3Anone%7D%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Enavbar%2Dnav%7Bfloat%3Aleft%3Bmargin%3A0%7D%2Enavbar%2Dnav%3Eli%7Bfloat%3Aleft%7D%2Enavbar%2Dnav%3Eli%3Ea%7Bpadding%2Dtop%3A15px%3Bpadding%2Dbottom%3A15px%7D%7D%2Enavbar%2Dform%7Bpadding%3A10px%2015px%3Bmargin%2Dtop%3A8px%3Bmargin%2Dright%3A%2D15px%3Bmargin%2Dbottom%3A8px%3Bmargin%2Dleft%3A%2D15px%3Bborder%2Dtop%3A1px%20solid%20transparent%3Bborder%2Dbottom%3A1px%20solid%20transparent%3B%2Dwebkit%2Dbox%2Dshadow%3Ainset%200%201px%200%20rgba%28255%2C255%2C255%2C%2E1%29%2C0%201px%200%20rgba%28255%2C255%2C255%2C%2E1%29%3Bbox%2Dshadow%3Ainset%200%201px%200%20rgba%28255%2C255%2C255%2C%2E1%29%2C0%201px%200%20rgba%28255%2C255%2C255%2C%2E1%29%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Enavbar%2Dform%20%2Eform%2Dgroup%7Bdisplay%3Ainline%2Dblock%3Bmargin%2Dbottom%3A0%3Bvertical%2Dalign%3Amiddle%7D%2Enavbar%2Dform%20%2Eform%2Dcontrol%7Bdisplay%3Ainline%2Dblock%3Bwidth%3Aauto%3Bvertical%2Dalign%3Amiddle%7D%2Enavbar%2Dform%20%2Eform%2Dcontrol%2Dstatic%7Bdisplay%3Ainline%2Dblock%7D%2Enavbar%2Dform%20%2Einput%2Dgroup%7Bdisplay%3Ainline%2Dtable%3Bvertical%2Dalign%3Amiddle%7D%2Enavbar%2Dform%20%2Einput%2Dgroup%20%2Eform%2Dcontrol%2C%2Enavbar%2Dform%20%2Einput%2Dgroup%20%2Einput%2Dgroup%2Daddon%2C%2Enavbar%2Dform%20%2Einput%2Dgroup%20%2Einput%2Dgroup%2Dbtn%7Bwidth%3Aauto%7D%2Enavbar%2Dform%20%2Einput%2Dgroup%3E%2Eform%2Dcontrol%7Bwidth%3A100%25%7D%2Enavbar%2Dform%20%2Econtrol%2Dlabel%7Bmargin%2Dbottom%3A0%3Bvertical%2Dalign%3Amiddle%7D%2Enavbar%2Dform%20%2Echeckbox%2C%2Enavbar%2Dform%20%2Eradio%7Bdisplay%3Ainline%2Dblock%3Bmargin%2Dtop%3A0%3Bmargin%2Dbottom%3A0%3Bvertical%2Dalign%3Amiddle%7D%2Enavbar%2Dform%20%2Echeckbox%20label%2C%2Enavbar%2Dform%20%2Eradio%20label%7Bpadding%2Dleft%3A0%7D%2Enavbar%2Dform%20%2Echeckbox%20input%5Btype%3Dcheckbox%5D%2C%2Enavbar%2Dform%20%2Eradio%20input%5Btype%3Dradio%5D%7Bposition%3Arelative%3Bmargin%2Dleft%3A0%7D%2Enavbar%2Dform%20%2Ehas%2Dfeedback%20%2Eform%2Dcontrol%2Dfeedback%7Btop%3A0%7D%7D%40media%20%28max%2Dwidth%3A767px%29%7B%2Enavbar%2Dform%20%2Eform%2Dgroup%7Bmargin%2Dbottom%3A5px%7D%2Enavbar%2Dform%20%2Eform%2Dgroup%3Alast%2Dchild%7Bmargin%2Dbottom%3A0%7D%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Enavbar%2Dform%7Bwidth%3Aauto%3Bpadding%2Dtop%3A0%3Bpadding%2Dbottom%3A0%3Bmargin%2Dright%3A0%3Bmargin%2Dleft%3A0%3Bborder%3A0%3B%2Dwebkit%2Dbox%2Dshadow%3Anone%3Bbox%2Dshadow%3Anone%7D%7D%2Enavbar%2Dnav%3Eli%3E%2Edropdown%2Dmenu%7Bmargin%2Dtop%3A0%3Bborder%2Dtop%2Dleft%2Dradius%3A0%3Bborder%2Dtop%2Dright%2Dradius%3A0%7D%2Enavbar%2Dfixed%2Dbottom%20%2Enavbar%2Dnav%3Eli%3E%2Edropdown%2Dmenu%7Bmargin%2Dbottom%3A0%3Bborder%2Dtop%2Dleft%2Dradius%3A4px%3Bborder%2Dtop%2Dright%2Dradius%3A4px%3Bborder%2Dbottom%2Dright%2Dradius%3A0%3Bborder%2Dbottom%2Dleft%2Dradius%3A0%7D%2Enavbar%2Dbtn%7Bmargin%2Dtop%3A8px%3Bmargin%2Dbottom%3A8px%7D%2Enavbar%2Dbtn%2Ebtn%2Dsm%7Bmargin%2Dtop%3A10px%3Bmargin%2Dbottom%3A10px%7D%2Enavbar%2Dbtn%2Ebtn%2Dxs%7Bmargin%2Dtop%3A14px%3Bmargin%2Dbottom%3A14px%7D%2Enavbar%2Dtext%7Bmargin%2Dtop%3A15px%3Bmargin%2Dbottom%3A15px%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Enavbar%2Dtext%7Bfloat%3Aleft%3Bmargin%2Dright%3A15px%3Bmargin%2Dleft%3A15px%7D%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Enavbar%2Dleft%7Bfloat%3Aleft%21important%7D%2Enavbar%2Dright%7Bfloat%3Aright%21important%3Bmargin%2Dright%3A%2D15px%7D%2Enavbar%2Dright%7E%2Enavbar%2Dright%7Bmargin%2Dright%3A0%7D%7D%2Enavbar%2Ddefault%7Bbackground%2Dcolor%3A%23f8f8f8%3Bborder%2Dcolor%3A%23e7e7e7%7D%2Enavbar%2Ddefault%20%2Enavbar%2Dbrand%7Bcolor%3A%23777%7D%2Enavbar%2Ddefault%20%2Enavbar%2Dbrand%3Afocus%2C%2Enavbar%2Ddefault%20%2Enavbar%2Dbrand%3Ahover%7Bcolor%3A%235e5e5e%3Bbackground%2Dcolor%3Atransparent%7D%2Enavbar%2Ddefault%20%2Enavbar%2Dtext%7Bcolor%3A%23777%7D%2Enavbar%2Ddefault%20%2Enavbar%2Dnav%3Eli%3Ea%7Bcolor%3A%23777%7D%2Enavbar%2Ddefault%20%2Enavbar%2Dnav%3Eli%3Ea%3Afocus%2C%2Enavbar%2Ddefault%20%2Enavbar%2Dnav%3Eli%3Ea%3Ahover%7Bcolor%3A%23333%3Bbackground%2Dcolor%3Atransparent%7D%2Enavbar%2Ddefault%20%2Enavbar%2Dnav%3E%2Eactive%3Ea%2C%2Enavbar%2Ddefault%20%2Enavbar%2Dnav%3E%2Eactive%3Ea%3Afocus%2C%2Enavbar%2Ddefault%20%2Enavbar%2Dnav%3E%2Eactive%3Ea%3Ahover%7Bcolor%3A%23555%3Bbackground%2Dcolor%3A%23e7e7e7%7D%2Enavbar%2Ddefault%20%2Enavbar%2Dnav%3E%2Edisabled%3Ea%2C%2Enavbar%2Ddefault%20%2Enavbar%2Dnav%3E%2Edisabled%3Ea%3Afocus%2C%2Enavbar%2Ddefault%20%2Enavbar%2Dnav%3E%2Edisabled%3Ea%3Ahover%7Bcolor%3A%23ccc%3Bbackground%2Dcolor%3Atransparent%7D%2Enavbar%2Ddefault%20%2Enavbar%2Dtoggle%7Bborder%2Dcolor%3A%23ddd%7D%2Enavbar%2Ddefault%20%2Enavbar%2Dtoggle%3Afocus%2C%2Enavbar%2Ddefault%20%2Enavbar%2Dtoggle%3Ahover%7Bbackground%2Dcolor%3A%23ddd%7D%2Enavbar%2Ddefault%20%2Enavbar%2Dtoggle%20%2Eicon%2Dbar%7Bbackground%2Dcolor%3A%23888%7D%2Enavbar%2Ddefault%20%2Enavbar%2Dcollapse%2C%2Enavbar%2Ddefault%20%2Enavbar%2Dform%7Bborder%2Dcolor%3A%23e7e7e7%7D%2Enavbar%2Ddefault%20%2Enavbar%2Dnav%3E%2Eopen%3Ea%2C%2Enavbar%2Ddefault%20%2Enavbar%2Dnav%3E%2Eopen%3Ea%3Afocus%2C%2Enavbar%2Ddefault%20%2Enavbar%2Dnav%3E%2Eopen%3Ea%3Ahover%7Bcolor%3A%23555%3Bbackground%2Dcolor%3A%23e7e7e7%7D%40media%20%28max%2Dwidth%3A767px%29%7B%2Enavbar%2Ddefault%20%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3Eli%3Ea%7Bcolor%3A%23777%7D%2Enavbar%2Ddefault%20%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3Eli%3Ea%3Afocus%2C%2Enavbar%2Ddefault%20%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3Eli%3Ea%3Ahover%7Bcolor%3A%23333%3Bbackground%2Dcolor%3Atransparent%7D%2Enavbar%2Ddefault%20%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3E%2Eactive%3Ea%2C%2Enavbar%2Ddefault%20%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3E%2Eactive%3Ea%3Afocus%2C%2Enavbar%2Ddefault%20%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3E%2Eactive%3Ea%3Ahover%7Bcolor%3A%23555%3Bbackground%2Dcolor%3A%23e7e7e7%7D%2Enavbar%2Ddefault%20%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3E%2Edisabled%3Ea%2C%2Enavbar%2Ddefault%20%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3E%2Edisabled%3Ea%3Afocus%2C%2Enavbar%2Ddefault%20%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3E%2Edisabled%3Ea%3Ahover%7Bcolor%3A%23ccc%3Bbackground%2Dcolor%3Atransparent%7D%7D%2Enavbar%2Ddefault%20%2Enavbar%2Dlink%7Bcolor%3A%23777%7D%2Enavbar%2Ddefault%20%2Enavbar%2Dlink%3Ahover%7Bcolor%3A%23333%7D%2Enavbar%2Ddefault%20%2Ebtn%2Dlink%7Bcolor%3A%23777%7D%2Enavbar%2Ddefault%20%2Ebtn%2Dlink%3Afocus%2C%2Enavbar%2Ddefault%20%2Ebtn%2Dlink%3Ahover%7Bcolor%3A%23333%7D%2Enavbar%2Ddefault%20%2Ebtn%2Dlink%5Bdisabled%5D%3Afocus%2C%2Enavbar%2Ddefault%20%2Ebtn%2Dlink%5Bdisabled%5D%3Ahover%2Cfieldset%5Bdisabled%5D%20%2Enavbar%2Ddefault%20%2Ebtn%2Dlink%3Afocus%2Cfieldset%5Bdisabled%5D%20%2Enavbar%2Ddefault%20%2Ebtn%2Dlink%3Ahover%7Bcolor%3A%23ccc%7D%2Enavbar%2Dinverse%7Bbackground%2Dcolor%3A%23222%3Bborder%2Dcolor%3A%23080808%7D%2Enavbar%2Dinverse%20%2Enavbar%2Dbrand%7Bcolor%3A%239d9d9d%7D%2Enavbar%2Dinverse%20%2Enavbar%2Dbrand%3Afocus%2C%2Enavbar%2Dinverse%20%2Enavbar%2Dbrand%3Ahover%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3Atransparent%7D%2Enavbar%2Dinverse%20%2Enavbar%2Dtext%7Bcolor%3A%239d9d9d%7D%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%3Eli%3Ea%7Bcolor%3A%239d9d9d%7D%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%3Eli%3Ea%3Afocus%2C%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%3Eli%3Ea%3Ahover%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3Atransparent%7D%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%3E%2Eactive%3Ea%2C%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%3E%2Eactive%3Ea%3Afocus%2C%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%3E%2Eactive%3Ea%3Ahover%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23080808%7D%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%3E%2Edisabled%3Ea%2C%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%3E%2Edisabled%3Ea%3Afocus%2C%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%3E%2Edisabled%3Ea%3Ahover%7Bcolor%3A%23444%3Bbackground%2Dcolor%3Atransparent%7D%2Enavbar%2Dinverse%20%2Enavbar%2Dtoggle%7Bborder%2Dcolor%3A%23333%7D%2Enavbar%2Dinverse%20%2Enavbar%2Dtoggle%3Afocus%2C%2Enavbar%2Dinverse%20%2Enavbar%2Dtoggle%3Ahover%7Bbackground%2Dcolor%3A%23333%7D%2Enavbar%2Dinverse%20%2Enavbar%2Dtoggle%20%2Eicon%2Dbar%7Bbackground%2Dcolor%3A%23fff%7D%2Enavbar%2Dinverse%20%2Enavbar%2Dcollapse%2C%2Enavbar%2Dinverse%20%2Enavbar%2Dform%7Bborder%2Dcolor%3A%23101010%7D%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%3E%2Eopen%3Ea%2C%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%3E%2Eopen%3Ea%3Afocus%2C%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%3E%2Eopen%3Ea%3Ahover%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23080808%7D%40media%20%28max%2Dwidth%3A767px%29%7B%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3E%2Edropdown%2Dheader%7Bborder%2Dcolor%3A%23080808%7D%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%20%2Edivider%7Bbackground%2Dcolor%3A%23080808%7D%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3Eli%3Ea%7Bcolor%3A%239d9d9d%7D%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3Eli%3Ea%3Afocus%2C%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3Eli%3Ea%3Ahover%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3Atransparent%7D%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3E%2Eactive%3Ea%2C%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3E%2Eactive%3Ea%3Afocus%2C%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3E%2Eactive%3Ea%3Ahover%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23080808%7D%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3E%2Edisabled%3Ea%2C%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3E%2Edisabled%3Ea%3Afocus%2C%2Enavbar%2Dinverse%20%2Enavbar%2Dnav%20%2Eopen%20%2Edropdown%2Dmenu%3E%2Edisabled%3Ea%3Ahover%7Bcolor%3A%23444%3Bbackground%2Dcolor%3Atransparent%7D%7D%2Enavbar%2Dinverse%20%2Enavbar%2Dlink%7Bcolor%3A%239d9d9d%7D%2Enavbar%2Dinverse%20%2Enavbar%2Dlink%3Ahover%7Bcolor%3A%23fff%7D%2Enavbar%2Dinverse%20%2Ebtn%2Dlink%7Bcolor%3A%239d9d9d%7D%2Enavbar%2Dinverse%20%2Ebtn%2Dlink%3Afocus%2C%2Enavbar%2Dinverse%20%2Ebtn%2Dlink%3Ahover%7Bcolor%3A%23fff%7D%2Enavbar%2Dinverse%20%2Ebtn%2Dlink%5Bdisabled%5D%3Afocus%2C%2Enavbar%2Dinverse%20%2Ebtn%2Dlink%5Bdisabled%5D%3Ahover%2Cfieldset%5Bdisabled%5D%20%2Enavbar%2Dinverse%20%2Ebtn%2Dlink%3Afocus%2Cfieldset%5Bdisabled%5D%20%2Enavbar%2Dinverse%20%2Ebtn%2Dlink%3Ahover%7Bcolor%3A%23444%7D%2Ebreadcrumb%7Bpadding%3A8px%2015px%3Bmargin%2Dbottom%3A20px%3Blist%2Dstyle%3Anone%3Bbackground%2Dcolor%3A%23f5f5f5%3Bborder%2Dradius%3A4px%7D%2Ebreadcrumb%3Eli%7Bdisplay%3Ainline%2Dblock%7D%2Ebreadcrumb%3Eli%2Bli%3Abefore%7Bpadding%3A0%205px%3Bcolor%3A%23ccc%3Bcontent%3A%22%2F%5C00a0%22%7D%2Ebreadcrumb%3E%2Eactive%7Bcolor%3A%23777%7D%2Epagination%7Bdisplay%3Ainline%2Dblock%3Bpadding%2Dleft%3A0%3Bmargin%3A20px%200%3Bborder%2Dradius%3A4px%7D%2Epagination%3Eli%7Bdisplay%3Ainline%7D%2Epagination%3Eli%3Ea%2C%2Epagination%3Eli%3Espan%7Bposition%3Arelative%3Bfloat%3Aleft%3Bpadding%3A6px%2012px%3Bmargin%2Dleft%3A%2D1px%3Bline%2Dheight%3A1%2E42857143%3Bcolor%3A%23337ab7%3Btext%2Ddecoration%3Anone%3Bbackground%2Dcolor%3A%23fff%3Bborder%3A1px%20solid%20%23ddd%7D%2Epagination%3Eli%3Afirst%2Dchild%3Ea%2C%2Epagination%3Eli%3Afirst%2Dchild%3Espan%7Bmargin%2Dleft%3A0%3Bborder%2Dtop%2Dleft%2Dradius%3A4px%3Bborder%2Dbottom%2Dleft%2Dradius%3A4px%7D%2Epagination%3Eli%3Alast%2Dchild%3Ea%2C%2Epagination%3Eli%3Alast%2Dchild%3Espan%7Bborder%2Dtop%2Dright%2Dradius%3A4px%3Bborder%2Dbottom%2Dright%2Dradius%3A4px%7D%2Epagination%3Eli%3Ea%3Afocus%2C%2Epagination%3Eli%3Ea%3Ahover%2C%2Epagination%3Eli%3Espan%3Afocus%2C%2Epagination%3Eli%3Espan%3Ahover%7Bz%2Dindex%3A3%3Bcolor%3A%2323527c%3Bbackground%2Dcolor%3A%23eee%3Bborder%2Dcolor%3A%23ddd%7D%2Epagination%3E%2Eactive%3Ea%2C%2Epagination%3E%2Eactive%3Ea%3Afocus%2C%2Epagination%3E%2Eactive%3Ea%3Ahover%2C%2Epagination%3E%2Eactive%3Espan%2C%2Epagination%3E%2Eactive%3Espan%3Afocus%2C%2Epagination%3E%2Eactive%3Espan%3Ahover%7Bz%2Dindex%3A2%3Bcolor%3A%23fff%3Bcursor%3Adefault%3Bbackground%2Dcolor%3A%23337ab7%3Bborder%2Dcolor%3A%23337ab7%7D%2Epagination%3E%2Edisabled%3Ea%2C%2Epagination%3E%2Edisabled%3Ea%3Afocus%2C%2Epagination%3E%2Edisabled%3Ea%3Ahover%2C%2Epagination%3E%2Edisabled%3Espan%2C%2Epagination%3E%2Edisabled%3Espan%3Afocus%2C%2Epagination%3E%2Edisabled%3Espan%3Ahover%7Bcolor%3A%23777%3Bcursor%3Anot%2Dallowed%3Bbackground%2Dcolor%3A%23fff%3Bborder%2Dcolor%3A%23ddd%7D%2Epagination%2Dlg%3Eli%3Ea%2C%2Epagination%2Dlg%3Eli%3Espan%7Bpadding%3A10px%2016px%3Bfont%2Dsize%3A18px%3Bline%2Dheight%3A1%2E3333333%7D%2Epagination%2Dlg%3Eli%3Afirst%2Dchild%3Ea%2C%2Epagination%2Dlg%3Eli%3Afirst%2Dchild%3Espan%7Bborder%2Dtop%2Dleft%2Dradius%3A6px%3Bborder%2Dbottom%2Dleft%2Dradius%3A6px%7D%2Epagination%2Dlg%3Eli%3Alast%2Dchild%3Ea%2C%2Epagination%2Dlg%3Eli%3Alast%2Dchild%3Espan%7Bborder%2Dtop%2Dright%2Dradius%3A6px%3Bborder%2Dbottom%2Dright%2Dradius%3A6px%7D%2Epagination%2Dsm%3Eli%3Ea%2C%2Epagination%2Dsm%3Eli%3Espan%7Bpadding%3A5px%2010px%3Bfont%2Dsize%3A12px%3Bline%2Dheight%3A1%2E5%7D%2Epagination%2Dsm%3Eli%3Afirst%2Dchild%3Ea%2C%2Epagination%2Dsm%3Eli%3Afirst%2Dchild%3Espan%7Bborder%2Dtop%2Dleft%2Dradius%3A3px%3Bborder%2Dbottom%2Dleft%2Dradius%3A3px%7D%2Epagination%2Dsm%3Eli%3Alast%2Dchild%3Ea%2C%2Epagination%2Dsm%3Eli%3Alast%2Dchild%3Espan%7Bborder%2Dtop%2Dright%2Dradius%3A3px%3Bborder%2Dbottom%2Dright%2Dradius%3A3px%7D%2Epager%7Bpadding%2Dleft%3A0%3Bmargin%3A20px%200%3Btext%2Dalign%3Acenter%3Blist%2Dstyle%3Anone%7D%2Epager%20li%7Bdisplay%3Ainline%7D%2Epager%20li%3Ea%2C%2Epager%20li%3Espan%7Bdisplay%3Ainline%2Dblock%3Bpadding%3A5px%2014px%3Bbackground%2Dcolor%3A%23fff%3Bborder%3A1px%20solid%20%23ddd%3Bborder%2Dradius%3A15px%7D%2Epager%20li%3Ea%3Afocus%2C%2Epager%20li%3Ea%3Ahover%7Btext%2Ddecoration%3Anone%3Bbackground%2Dcolor%3A%23eee%7D%2Epager%20%2Enext%3Ea%2C%2Epager%20%2Enext%3Espan%7Bfloat%3Aright%7D%2Epager%20%2Eprevious%3Ea%2C%2Epager%20%2Eprevious%3Espan%7Bfloat%3Aleft%7D%2Epager%20%2Edisabled%3Ea%2C%2Epager%20%2Edisabled%3Ea%3Afocus%2C%2Epager%20%2Edisabled%3Ea%3Ahover%2C%2Epager%20%2Edisabled%3Espan%7Bcolor%3A%23777%3Bcursor%3Anot%2Dallowed%3Bbackground%2Dcolor%3A%23fff%7D%2Elabel%7Bdisplay%3Ainline%3Bpadding%3A%2E2em%20%2E6em%20%2E3em%3Bfont%2Dsize%3A75%25%3Bfont%2Dweight%3A700%3Bline%2Dheight%3A1%3Bcolor%3A%23fff%3Btext%2Dalign%3Acenter%3Bwhite%2Dspace%3Anowrap%3Bvertical%2Dalign%3Abaseline%3Bborder%2Dradius%3A%2E25em%7Da%2Elabel%3Afocus%2Ca%2Elabel%3Ahover%7Bcolor%3A%23fff%3Btext%2Ddecoration%3Anone%3Bcursor%3Apointer%7D%2Elabel%3Aempty%7Bdisplay%3Anone%7D%2Ebtn%20%2Elabel%7Bposition%3Arelative%3Btop%3A%2D1px%7D%2Elabel%2Ddefault%7Bbackground%2Dcolor%3A%23777%7D%2Elabel%2Ddefault%5Bhref%5D%3Afocus%2C%2Elabel%2Ddefault%5Bhref%5D%3Ahover%7Bbackground%2Dcolor%3A%235e5e5e%7D%2Elabel%2Dprimary%7Bbackground%2Dcolor%3A%23337ab7%7D%2Elabel%2Dprimary%5Bhref%5D%3Afocus%2C%2Elabel%2Dprimary%5Bhref%5D%3Ahover%7Bbackground%2Dcolor%3A%23286090%7D%2Elabel%2Dsuccess%7Bbackground%2Dcolor%3A%235cb85c%7D%2Elabel%2Dsuccess%5Bhref%5D%3Afocus%2C%2Elabel%2Dsuccess%5Bhref%5D%3Ahover%7Bbackground%2Dcolor%3A%23449d44%7D%2Elabel%2Dinfo%7Bbackground%2Dcolor%3A%235bc0de%7D%2Elabel%2Dinfo%5Bhref%5D%3Afocus%2C%2Elabel%2Dinfo%5Bhref%5D%3Ahover%7Bbackground%2Dcolor%3A%2331b0d5%7D%2Elabel%2Dwarning%7Bbackground%2Dcolor%3A%23f0ad4e%7D%2Elabel%2Dwarning%5Bhref%5D%3Afocus%2C%2Elabel%2Dwarning%5Bhref%5D%3Ahover%7Bbackground%2Dcolor%3A%23ec971f%7D%2Elabel%2Ddanger%7Bbackground%2Dcolor%3A%23d9534f%7D%2Elabel%2Ddanger%5Bhref%5D%3Afocus%2C%2Elabel%2Ddanger%5Bhref%5D%3Ahover%7Bbackground%2Dcolor%3A%23c9302c%7D%2Ebadge%7Bdisplay%3Ainline%2Dblock%3Bmin%2Dwidth%3A10px%3Bpadding%3A3px%207px%3Bfont%2Dsize%3A12px%3Bfont%2Dweight%3A700%3Bline%2Dheight%3A1%3Bcolor%3A%23fff%3Btext%2Dalign%3Acenter%3Bwhite%2Dspace%3Anowrap%3Bvertical%2Dalign%3Amiddle%3Bbackground%2Dcolor%3A%23777%3Bborder%2Dradius%3A10px%7D%2Ebadge%3Aempty%7Bdisplay%3Anone%7D%2Ebtn%20%2Ebadge%7Bposition%3Arelative%3Btop%3A%2D1px%7D%2Ebtn%2Dgroup%2Dxs%3E%2Ebtn%20%2Ebadge%2C%2Ebtn%2Dxs%20%2Ebadge%7Btop%3A0%3Bpadding%3A1px%205px%7Da%2Ebadge%3Afocus%2Ca%2Ebadge%3Ahover%7Bcolor%3A%23fff%3Btext%2Ddecoration%3Anone%3Bcursor%3Apointer%7D%2Elist%2Dgroup%2Ditem%2Eactive%3E%2Ebadge%2C%2Enav%2Dpills%3E%2Eactive%3Ea%3E%2Ebadge%7Bcolor%3A%23337ab7%3Bbackground%2Dcolor%3A%23fff%7D%2Elist%2Dgroup%2Ditem%3E%2Ebadge%7Bfloat%3Aright%7D%2Elist%2Dgroup%2Ditem%3E%2Ebadge%2B%2Ebadge%7Bmargin%2Dright%3A5px%7D%2Enav%2Dpills%3Eli%3Ea%3E%2Ebadge%7Bmargin%2Dleft%3A3px%7D%2Ejumbotron%7Bpadding%2Dtop%3A30px%3Bpadding%2Dbottom%3A30px%3Bmargin%2Dbottom%3A30px%3Bcolor%3Ainherit%3Bbackground%2Dcolor%3A%23eee%7D%2Ejumbotron%20%2Eh1%2C%2Ejumbotron%20h1%7Bcolor%3Ainherit%7D%2Ejumbotron%20p%7Bmargin%2Dbottom%3A15px%3Bfont%2Dsize%3A21px%3Bfont%2Dweight%3A200%7D%2Ejumbotron%3Ehr%7Bborder%2Dtop%2Dcolor%3A%23d5d5d5%7D%2Econtainer%20%2Ejumbotron%2C%2Econtainer%2Dfluid%20%2Ejumbotron%7Bborder%2Dradius%3A6px%7D%2Ejumbotron%20%2Econtainer%7Bmax%2Dwidth%3A100%25%7D%40media%20screen%20and%20%28min%2Dwidth%3A768px%29%7B%2Ejumbotron%7Bpadding%2Dtop%3A48px%3Bpadding%2Dbottom%3A48px%7D%2Econtainer%20%2Ejumbotron%2C%2Econtainer%2Dfluid%20%2Ejumbotron%7Bpadding%2Dright%3A60px%3Bpadding%2Dleft%3A60px%7D%2Ejumbotron%20%2Eh1%2C%2Ejumbotron%20h1%7Bfont%2Dsize%3A63px%7D%7D%2Ethumbnail%7Bdisplay%3Ablock%3Bpadding%3A4px%3Bmargin%2Dbottom%3A20px%3Bline%2Dheight%3A1%2E42857143%3Bbackground%2Dcolor%3A%23fff%3Bborder%3A1px%20solid%20%23ddd%3Bborder%2Dradius%3A4px%3B%2Dwebkit%2Dtransition%3Aborder%20%2E2s%20ease%2Din%2Dout%3B%2Do%2Dtransition%3Aborder%20%2E2s%20ease%2Din%2Dout%3Btransition%3Aborder%20%2E2s%20ease%2Din%2Dout%7D%2Ethumbnail%20a%3Eimg%2C%2Ethumbnail%3Eimg%7Bmargin%2Dright%3Aauto%3Bmargin%2Dleft%3Aauto%7Da%2Ethumbnail%2Eactive%2Ca%2Ethumbnail%3Afocus%2Ca%2Ethumbnail%3Ahover%7Bborder%2Dcolor%3A%23337ab7%7D%2Ethumbnail%20%2Ecaption%7Bpadding%3A9px%3Bcolor%3A%23333%7D%2Ealert%7Bpadding%3A15px%3Bmargin%2Dbottom%3A20px%3Bborder%3A1px%20solid%20transparent%3Bborder%2Dradius%3A4px%7D%2Ealert%20h4%7Bmargin%2Dtop%3A0%3Bcolor%3Ainherit%7D%2Ealert%20%2Ealert%2Dlink%7Bfont%2Dweight%3A700%7D%2Ealert%3Ep%2C%2Ealert%3Eul%7Bmargin%2Dbottom%3A0%7D%2Ealert%3Ep%2Bp%7Bmargin%2Dtop%3A5px%7D%2Ealert%2Ddismissable%2C%2Ealert%2Ddismissible%7Bpadding%2Dright%3A35px%7D%2Ealert%2Ddismissable%20%2Eclose%2C%2Ealert%2Ddismissible%20%2Eclose%7Bposition%3Arelative%3Btop%3A%2D2px%3Bright%3A%2D21px%3Bcolor%3Ainherit%7D%2Ealert%2Dsuccess%7Bcolor%3A%233c763d%3Bbackground%2Dcolor%3A%23dff0d8%3Bborder%2Dcolor%3A%23d6e9c6%7D%2Ealert%2Dsuccess%20hr%7Bborder%2Dtop%2Dcolor%3A%23c9e2b3%7D%2Ealert%2Dsuccess%20%2Ealert%2Dlink%7Bcolor%3A%232b542c%7D%2Ealert%2Dinfo%7Bcolor%3A%2331708f%3Bbackground%2Dcolor%3A%23d9edf7%3Bborder%2Dcolor%3A%23bce8f1%7D%2Ealert%2Dinfo%20hr%7Bborder%2Dtop%2Dcolor%3A%23a6e1ec%7D%2Ealert%2Dinfo%20%2Ealert%2Dlink%7Bcolor%3A%23245269%7D%2Ealert%2Dwarning%7Bcolor%3A%238a6d3b%3Bbackground%2Dcolor%3A%23fcf8e3%3Bborder%2Dcolor%3A%23faebcc%7D%2Ealert%2Dwarning%20hr%7Bborder%2Dtop%2Dcolor%3A%23f7e1b5%7D%2Ealert%2Dwarning%20%2Ealert%2Dlink%7Bcolor%3A%2366512c%7D%2Ealert%2Ddanger%7Bcolor%3A%23a94442%3Bbackground%2Dcolor%3A%23f2dede%3Bborder%2Dcolor%3A%23ebccd1%7D%2Ealert%2Ddanger%20hr%7Bborder%2Dtop%2Dcolor%3A%23e4b9c0%7D%2Ealert%2Ddanger%20%2Ealert%2Dlink%7Bcolor%3A%23843534%7D%40%2Dwebkit%2Dkeyframes%20progress%2Dbar%2Dstripes%7Bfrom%7Bbackground%2Dposition%3A40px%200%7Dto%7Bbackground%2Dposition%3A0%200%7D%7D%40%2Do%2Dkeyframes%20progress%2Dbar%2Dstripes%7Bfrom%7Bbackground%2Dposition%3A40px%200%7Dto%7Bbackground%2Dposition%3A0%200%7D%7D%40keyframes%20progress%2Dbar%2Dstripes%7Bfrom%7Bbackground%2Dposition%3A40px%200%7Dto%7Bbackground%2Dposition%3A0%200%7D%7D%2Eprogress%7Bheight%3A20px%3Bmargin%2Dbottom%3A20px%3Boverflow%3Ahidden%3Bbackground%2Dcolor%3A%23f5f5f5%3Bborder%2Dradius%3A4px%3B%2Dwebkit%2Dbox%2Dshadow%3Ainset%200%201px%202px%20rgba%280%2C0%2C0%2C%2E1%29%3Bbox%2Dshadow%3Ainset%200%201px%202px%20rgba%280%2C0%2C0%2C%2E1%29%7D%2Eprogress%2Dbar%7Bfloat%3Aleft%3Bwidth%3A0%3Bheight%3A100%25%3Bfont%2Dsize%3A12px%3Bline%2Dheight%3A20px%3Bcolor%3A%23fff%3Btext%2Dalign%3Acenter%3Bbackground%2Dcolor%3A%23337ab7%3B%2Dwebkit%2Dbox%2Dshadow%3Ainset%200%20%2D1px%200%20rgba%280%2C0%2C0%2C%2E15%29%3Bbox%2Dshadow%3Ainset%200%20%2D1px%200%20rgba%280%2C0%2C0%2C%2E15%29%3B%2Dwebkit%2Dtransition%3Awidth%20%2E6s%20ease%3B%2Do%2Dtransition%3Awidth%20%2E6s%20ease%3Btransition%3Awidth%20%2E6s%20ease%7D%2Eprogress%2Dbar%2Dstriped%2C%2Eprogress%2Dstriped%20%2Eprogress%2Dbar%7Bbackground%2Dimage%3A%2Dwebkit%2Dlinear%2Dgradient%2845deg%2Crgba%28255%2C255%2C255%2C%2E15%29%2025%25%2Ctransparent%2025%25%2Ctransparent%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2075%25%2Ctransparent%2075%25%2Ctransparent%29%3Bbackground%2Dimage%3A%2Do%2Dlinear%2Dgradient%2845deg%2Crgba%28255%2C255%2C255%2C%2E15%29%2025%25%2Ctransparent%2025%25%2Ctransparent%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2075%25%2Ctransparent%2075%25%2Ctransparent%29%3Bbackground%2Dimage%3Alinear%2Dgradient%2845deg%2Crgba%28255%2C255%2C255%2C%2E15%29%2025%25%2Ctransparent%2025%25%2Ctransparent%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2075%25%2Ctransparent%2075%25%2Ctransparent%29%3B%2Dwebkit%2Dbackground%2Dsize%3A40px%2040px%3Bbackground%2Dsize%3A40px%2040px%7D%2Eprogress%2Dbar%2Eactive%2C%2Eprogress%2Eactive%20%2Eprogress%2Dbar%7B%2Dwebkit%2Danimation%3Aprogress%2Dbar%2Dstripes%202s%20linear%20infinite%3B%2Do%2Danimation%3Aprogress%2Dbar%2Dstripes%202s%20linear%20infinite%3Banimation%3Aprogress%2Dbar%2Dstripes%202s%20linear%20infinite%7D%2Eprogress%2Dbar%2Dsuccess%7Bbackground%2Dcolor%3A%235cb85c%7D%2Eprogress%2Dstriped%20%2Eprogress%2Dbar%2Dsuccess%7Bbackground%2Dimage%3A%2Dwebkit%2Dlinear%2Dgradient%2845deg%2Crgba%28255%2C255%2C255%2C%2E15%29%2025%25%2Ctransparent%2025%25%2Ctransparent%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2075%25%2Ctransparent%2075%25%2Ctransparent%29%3Bbackground%2Dimage%3A%2Do%2Dlinear%2Dgradient%2845deg%2Crgba%28255%2C255%2C255%2C%2E15%29%2025%25%2Ctransparent%2025%25%2Ctransparent%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2075%25%2Ctransparent%2075%25%2Ctransparent%29%3Bbackground%2Dimage%3Alinear%2Dgradient%2845deg%2Crgba%28255%2C255%2C255%2C%2E15%29%2025%25%2Ctransparent%2025%25%2Ctransparent%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2075%25%2Ctransparent%2075%25%2Ctransparent%29%7D%2Eprogress%2Dbar%2Dinfo%7Bbackground%2Dcolor%3A%235bc0de%7D%2Eprogress%2Dstriped%20%2Eprogress%2Dbar%2Dinfo%7Bbackground%2Dimage%3A%2Dwebkit%2Dlinear%2Dgradient%2845deg%2Crgba%28255%2C255%2C255%2C%2E15%29%2025%25%2Ctransparent%2025%25%2Ctransparent%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2075%25%2Ctransparent%2075%25%2Ctransparent%29%3Bbackground%2Dimage%3A%2Do%2Dlinear%2Dgradient%2845deg%2Crgba%28255%2C255%2C255%2C%2E15%29%2025%25%2Ctransparent%2025%25%2Ctransparent%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2075%25%2Ctransparent%2075%25%2Ctransparent%29%3Bbackground%2Dimage%3Alinear%2Dgradient%2845deg%2Crgba%28255%2C255%2C255%2C%2E15%29%2025%25%2Ctransparent%2025%25%2Ctransparent%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2075%25%2Ctransparent%2075%25%2Ctransparent%29%7D%2Eprogress%2Dbar%2Dwarning%7Bbackground%2Dcolor%3A%23f0ad4e%7D%2Eprogress%2Dstriped%20%2Eprogress%2Dbar%2Dwarning%7Bbackground%2Dimage%3A%2Dwebkit%2Dlinear%2Dgradient%2845deg%2Crgba%28255%2C255%2C255%2C%2E15%29%2025%25%2Ctransparent%2025%25%2Ctransparent%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2075%25%2Ctransparent%2075%25%2Ctransparent%29%3Bbackground%2Dimage%3A%2Do%2Dlinear%2Dgradient%2845deg%2Crgba%28255%2C255%2C255%2C%2E15%29%2025%25%2Ctransparent%2025%25%2Ctransparent%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2075%25%2Ctransparent%2075%25%2Ctransparent%29%3Bbackground%2Dimage%3Alinear%2Dgradient%2845deg%2Crgba%28255%2C255%2C255%2C%2E15%29%2025%25%2Ctransparent%2025%25%2Ctransparent%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2075%25%2Ctransparent%2075%25%2Ctransparent%29%7D%2Eprogress%2Dbar%2Ddanger%7Bbackground%2Dcolor%3A%23d9534f%7D%2Eprogress%2Dstriped%20%2Eprogress%2Dbar%2Ddanger%7Bbackground%2Dimage%3A%2Dwebkit%2Dlinear%2Dgradient%2845deg%2Crgba%28255%2C255%2C255%2C%2E15%29%2025%25%2Ctransparent%2025%25%2Ctransparent%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2075%25%2Ctransparent%2075%25%2Ctransparent%29%3Bbackground%2Dimage%3A%2Do%2Dlinear%2Dgradient%2845deg%2Crgba%28255%2C255%2C255%2C%2E15%29%2025%25%2Ctransparent%2025%25%2Ctransparent%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2075%25%2Ctransparent%2075%25%2Ctransparent%29%3Bbackground%2Dimage%3Alinear%2Dgradient%2845deg%2Crgba%28255%2C255%2C255%2C%2E15%29%2025%25%2Ctransparent%2025%25%2Ctransparent%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2050%25%2Crgba%28255%2C255%2C255%2C%2E15%29%2075%25%2Ctransparent%2075%25%2Ctransparent%29%7D%2Emedia%7Bmargin%2Dtop%3A15px%7D%2Emedia%3Afirst%2Dchild%7Bmargin%2Dtop%3A0%7D%2Emedia%2C%2Emedia%2Dbody%7Boverflow%3Ahidden%3Bzoom%3A1%7D%2Emedia%2Dbody%7Bwidth%3A10000px%7D%2Emedia%2Dobject%7Bdisplay%3Ablock%7D%2Emedia%2Dobject%2Eimg%2Dthumbnail%7Bmax%2Dwidth%3Anone%7D%2Emedia%2Dright%2C%2Emedia%3E%2Epull%2Dright%7Bpadding%2Dleft%3A10px%7D%2Emedia%2Dleft%2C%2Emedia%3E%2Epull%2Dleft%7Bpadding%2Dright%3A10px%7D%2Emedia%2Dbody%2C%2Emedia%2Dleft%2C%2Emedia%2Dright%7Bdisplay%3Atable%2Dcell%3Bvertical%2Dalign%3Atop%7D%2Emedia%2Dmiddle%7Bvertical%2Dalign%3Amiddle%7D%2Emedia%2Dbottom%7Bvertical%2Dalign%3Abottom%7D%2Emedia%2Dheading%7Bmargin%2Dtop%3A0%3Bmargin%2Dbottom%3A5px%7D%2Emedia%2Dlist%7Bpadding%2Dleft%3A0%3Blist%2Dstyle%3Anone%7D%2Elist%2Dgroup%7Bpadding%2Dleft%3A0%3Bmargin%2Dbottom%3A20px%7D%2Elist%2Dgroup%2Ditem%7Bposition%3Arelative%3Bdisplay%3Ablock%3Bpadding%3A10px%2015px%3Bmargin%2Dbottom%3A%2D1px%3Bbackground%2Dcolor%3A%23fff%3Bborder%3A1px%20solid%20%23ddd%7D%2Elist%2Dgroup%2Ditem%3Afirst%2Dchild%7Bborder%2Dtop%2Dleft%2Dradius%3A4px%3Bborder%2Dtop%2Dright%2Dradius%3A4px%7D%2Elist%2Dgroup%2Ditem%3Alast%2Dchild%7Bmargin%2Dbottom%3A0%3Bborder%2Dbottom%2Dright%2Dradius%3A4px%3Bborder%2Dbottom%2Dleft%2Dradius%3A4px%7Da%2Elist%2Dgroup%2Ditem%2Cbutton%2Elist%2Dgroup%2Ditem%7Bcolor%3A%23555%7Da%2Elist%2Dgroup%2Ditem%20%2Elist%2Dgroup%2Ditem%2Dheading%2Cbutton%2Elist%2Dgroup%2Ditem%20%2Elist%2Dgroup%2Ditem%2Dheading%7Bcolor%3A%23333%7Da%2Elist%2Dgroup%2Ditem%3Afocus%2Ca%2Elist%2Dgroup%2Ditem%3Ahover%2Cbutton%2Elist%2Dgroup%2Ditem%3Afocus%2Cbutton%2Elist%2Dgroup%2Ditem%3Ahover%7Bcolor%3A%23555%3Btext%2Ddecoration%3Anone%3Bbackground%2Dcolor%3A%23f5f5f5%7Dbutton%2Elist%2Dgroup%2Ditem%7Bwidth%3A100%25%3Btext%2Dalign%3Aleft%7D%2Elist%2Dgroup%2Ditem%2Edisabled%2C%2Elist%2Dgroup%2Ditem%2Edisabled%3Afocus%2C%2Elist%2Dgroup%2Ditem%2Edisabled%3Ahover%7Bcolor%3A%23777%3Bcursor%3Anot%2Dallowed%3Bbackground%2Dcolor%3A%23eee%7D%2Elist%2Dgroup%2Ditem%2Edisabled%20%2Elist%2Dgroup%2Ditem%2Dheading%2C%2Elist%2Dgroup%2Ditem%2Edisabled%3Afocus%20%2Elist%2Dgroup%2Ditem%2Dheading%2C%2Elist%2Dgroup%2Ditem%2Edisabled%3Ahover%20%2Elist%2Dgroup%2Ditem%2Dheading%7Bcolor%3Ainherit%7D%2Elist%2Dgroup%2Ditem%2Edisabled%20%2Elist%2Dgroup%2Ditem%2Dtext%2C%2Elist%2Dgroup%2Ditem%2Edisabled%3Afocus%20%2Elist%2Dgroup%2Ditem%2Dtext%2C%2Elist%2Dgroup%2Ditem%2Edisabled%3Ahover%20%2Elist%2Dgroup%2Ditem%2Dtext%7Bcolor%3A%23777%7D%2Elist%2Dgroup%2Ditem%2Eactive%2C%2Elist%2Dgroup%2Ditem%2Eactive%3Afocus%2C%2Elist%2Dgroup%2Ditem%2Eactive%3Ahover%7Bz%2Dindex%3A2%3Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23337ab7%3Bborder%2Dcolor%3A%23337ab7%7D%2Elist%2Dgroup%2Ditem%2Eactive%20%2Elist%2Dgroup%2Ditem%2Dheading%2C%2Elist%2Dgroup%2Ditem%2Eactive%20%2Elist%2Dgroup%2Ditem%2Dheading%3E%2Esmall%2C%2Elist%2Dgroup%2Ditem%2Eactive%20%2Elist%2Dgroup%2Ditem%2Dheading%3Esmall%2C%2Elist%2Dgroup%2Ditem%2Eactive%3Afocus%20%2Elist%2Dgroup%2Ditem%2Dheading%2C%2Elist%2Dgroup%2Ditem%2Eactive%3Afocus%20%2Elist%2Dgroup%2Ditem%2Dheading%3E%2Esmall%2C%2Elist%2Dgroup%2Ditem%2Eactive%3Afocus%20%2Elist%2Dgroup%2Ditem%2Dheading%3Esmall%2C%2Elist%2Dgroup%2Ditem%2Eactive%3Ahover%20%2Elist%2Dgroup%2Ditem%2Dheading%2C%2Elist%2Dgroup%2Ditem%2Eactive%3Ahover%20%2Elist%2Dgroup%2Ditem%2Dheading%3E%2Esmall%2C%2Elist%2Dgroup%2Ditem%2Eactive%3Ahover%20%2Elist%2Dgroup%2Ditem%2Dheading%3Esmall%7Bcolor%3Ainherit%7D%2Elist%2Dgroup%2Ditem%2Eactive%20%2Elist%2Dgroup%2Ditem%2Dtext%2C%2Elist%2Dgroup%2Ditem%2Eactive%3Afocus%20%2Elist%2Dgroup%2Ditem%2Dtext%2C%2Elist%2Dgroup%2Ditem%2Eactive%3Ahover%20%2Elist%2Dgroup%2Ditem%2Dtext%7Bcolor%3A%23c7ddef%7D%2Elist%2Dgroup%2Ditem%2Dsuccess%7Bcolor%3A%233c763d%3Bbackground%2Dcolor%3A%23dff0d8%7Da%2Elist%2Dgroup%2Ditem%2Dsuccess%2Cbutton%2Elist%2Dgroup%2Ditem%2Dsuccess%7Bcolor%3A%233c763d%7Da%2Elist%2Dgroup%2Ditem%2Dsuccess%20%2Elist%2Dgroup%2Ditem%2Dheading%2Cbutton%2Elist%2Dgroup%2Ditem%2Dsuccess%20%2Elist%2Dgroup%2Ditem%2Dheading%7Bcolor%3Ainherit%7Da%2Elist%2Dgroup%2Ditem%2Dsuccess%3Afocus%2Ca%2Elist%2Dgroup%2Ditem%2Dsuccess%3Ahover%2Cbutton%2Elist%2Dgroup%2Ditem%2Dsuccess%3Afocus%2Cbutton%2Elist%2Dgroup%2Ditem%2Dsuccess%3Ahover%7Bcolor%3A%233c763d%3Bbackground%2Dcolor%3A%23d0e9c6%7Da%2Elist%2Dgroup%2Ditem%2Dsuccess%2Eactive%2Ca%2Elist%2Dgroup%2Ditem%2Dsuccess%2Eactive%3Afocus%2Ca%2Elist%2Dgroup%2Ditem%2Dsuccess%2Eactive%3Ahover%2Cbutton%2Elist%2Dgroup%2Ditem%2Dsuccess%2Eactive%2Cbutton%2Elist%2Dgroup%2Ditem%2Dsuccess%2Eactive%3Afocus%2Cbutton%2Elist%2Dgroup%2Ditem%2Dsuccess%2Eactive%3Ahover%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%233c763d%3Bborder%2Dcolor%3A%233c763d%7D%2Elist%2Dgroup%2Ditem%2Dinfo%7Bcolor%3A%2331708f%3Bbackground%2Dcolor%3A%23d9edf7%7Da%2Elist%2Dgroup%2Ditem%2Dinfo%2Cbutton%2Elist%2Dgroup%2Ditem%2Dinfo%7Bcolor%3A%2331708f%7Da%2Elist%2Dgroup%2Ditem%2Dinfo%20%2Elist%2Dgroup%2Ditem%2Dheading%2Cbutton%2Elist%2Dgroup%2Ditem%2Dinfo%20%2Elist%2Dgroup%2Ditem%2Dheading%7Bcolor%3Ainherit%7Da%2Elist%2Dgroup%2Ditem%2Dinfo%3Afocus%2Ca%2Elist%2Dgroup%2Ditem%2Dinfo%3Ahover%2Cbutton%2Elist%2Dgroup%2Ditem%2Dinfo%3Afocus%2Cbutton%2Elist%2Dgroup%2Ditem%2Dinfo%3Ahover%7Bcolor%3A%2331708f%3Bbackground%2Dcolor%3A%23c4e3f3%7Da%2Elist%2Dgroup%2Ditem%2Dinfo%2Eactive%2Ca%2Elist%2Dgroup%2Ditem%2Dinfo%2Eactive%3Afocus%2Ca%2Elist%2Dgroup%2Ditem%2Dinfo%2Eactive%3Ahover%2Cbutton%2Elist%2Dgroup%2Ditem%2Dinfo%2Eactive%2Cbutton%2Elist%2Dgroup%2Ditem%2Dinfo%2Eactive%3Afocus%2Cbutton%2Elist%2Dgroup%2Ditem%2Dinfo%2Eactive%3Ahover%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%2331708f%3Bborder%2Dcolor%3A%2331708f%7D%2Elist%2Dgroup%2Ditem%2Dwarning%7Bcolor%3A%238a6d3b%3Bbackground%2Dcolor%3A%23fcf8e3%7Da%2Elist%2Dgroup%2Ditem%2Dwarning%2Cbutton%2Elist%2Dgroup%2Ditem%2Dwarning%7Bcolor%3A%238a6d3b%7Da%2Elist%2Dgroup%2Ditem%2Dwarning%20%2Elist%2Dgroup%2Ditem%2Dheading%2Cbutton%2Elist%2Dgroup%2Ditem%2Dwarning%20%2Elist%2Dgroup%2Ditem%2Dheading%7Bcolor%3Ainherit%7Da%2Elist%2Dgroup%2Ditem%2Dwarning%3Afocus%2Ca%2Elist%2Dgroup%2Ditem%2Dwarning%3Ahover%2Cbutton%2Elist%2Dgroup%2Ditem%2Dwarning%3Afocus%2Cbutton%2Elist%2Dgroup%2Ditem%2Dwarning%3Ahover%7Bcolor%3A%238a6d3b%3Bbackground%2Dcolor%3A%23faf2cc%7Da%2Elist%2Dgroup%2Ditem%2Dwarning%2Eactive%2Ca%2Elist%2Dgroup%2Ditem%2Dwarning%2Eactive%3Afocus%2Ca%2Elist%2Dgroup%2Ditem%2Dwarning%2Eactive%3Ahover%2Cbutton%2Elist%2Dgroup%2Ditem%2Dwarning%2Eactive%2Cbutton%2Elist%2Dgroup%2Ditem%2Dwarning%2Eactive%3Afocus%2Cbutton%2Elist%2Dgroup%2Ditem%2Dwarning%2Eactive%3Ahover%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%238a6d3b%3Bborder%2Dcolor%3A%238a6d3b%7D%2Elist%2Dgroup%2Ditem%2Ddanger%7Bcolor%3A%23a94442%3Bbackground%2Dcolor%3A%23f2dede%7Da%2Elist%2Dgroup%2Ditem%2Ddanger%2Cbutton%2Elist%2Dgroup%2Ditem%2Ddanger%7Bcolor%3A%23a94442%7Da%2Elist%2Dgroup%2Ditem%2Ddanger%20%2Elist%2Dgroup%2Ditem%2Dheading%2Cbutton%2Elist%2Dgroup%2Ditem%2Ddanger%20%2Elist%2Dgroup%2Ditem%2Dheading%7Bcolor%3Ainherit%7Da%2Elist%2Dgroup%2Ditem%2Ddanger%3Afocus%2Ca%2Elist%2Dgroup%2Ditem%2Ddanger%3Ahover%2Cbutton%2Elist%2Dgroup%2Ditem%2Ddanger%3Afocus%2Cbutton%2Elist%2Dgroup%2Ditem%2Ddanger%3Ahover%7Bcolor%3A%23a94442%3Bbackground%2Dcolor%3A%23ebcccc%7Da%2Elist%2Dgroup%2Ditem%2Ddanger%2Eactive%2Ca%2Elist%2Dgroup%2Ditem%2Ddanger%2Eactive%3Afocus%2Ca%2Elist%2Dgroup%2Ditem%2Ddanger%2Eactive%3Ahover%2Cbutton%2Elist%2Dgroup%2Ditem%2Ddanger%2Eactive%2Cbutton%2Elist%2Dgroup%2Ditem%2Ddanger%2Eactive%3Afocus%2Cbutton%2Elist%2Dgroup%2Ditem%2Ddanger%2Eactive%3Ahover%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23a94442%3Bborder%2Dcolor%3A%23a94442%7D%2Elist%2Dgroup%2Ditem%2Dheading%7Bmargin%2Dtop%3A0%3Bmargin%2Dbottom%3A5px%7D%2Elist%2Dgroup%2Ditem%2Dtext%7Bmargin%2Dbottom%3A0%3Bline%2Dheight%3A1%2E3%7D%2Epanel%7Bmargin%2Dbottom%3A20px%3Bbackground%2Dcolor%3A%23fff%3Bborder%3A1px%20solid%20transparent%3Bborder%2Dradius%3A4px%3B%2Dwebkit%2Dbox%2Dshadow%3A0%201px%201px%20rgba%280%2C0%2C0%2C%2E05%29%3Bbox%2Dshadow%3A0%201px%201px%20rgba%280%2C0%2C0%2C%2E05%29%7D%2Epanel%2Dbody%7Bpadding%3A15px%7D%2Epanel%2Dheading%7Bpadding%3A10px%2015px%3Bborder%2Dbottom%3A1px%20solid%20transparent%3Bborder%2Dtop%2Dleft%2Dradius%3A3px%3Bborder%2Dtop%2Dright%2Dradius%3A3px%7D%2Epanel%2Dheading%3E%2Edropdown%20%2Edropdown%2Dtoggle%7Bcolor%3Ainherit%7D%2Epanel%2Dtitle%7Bmargin%2Dtop%3A0%3Bmargin%2Dbottom%3A0%3Bfont%2Dsize%3A16px%3Bcolor%3Ainherit%7D%2Epanel%2Dtitle%3E%2Esmall%2C%2Epanel%2Dtitle%3E%2Esmall%3Ea%2C%2Epanel%2Dtitle%3Ea%2C%2Epanel%2Dtitle%3Esmall%2C%2Epanel%2Dtitle%3Esmall%3Ea%7Bcolor%3Ainherit%7D%2Epanel%2Dfooter%7Bpadding%3A10px%2015px%3Bbackground%2Dcolor%3A%23f5f5f5%3Bborder%2Dtop%3A1px%20solid%20%23ddd%3Bborder%2Dbottom%2Dright%2Dradius%3A3px%3Bborder%2Dbottom%2Dleft%2Dradius%3A3px%7D%2Epanel%3E%2Elist%2Dgroup%2C%2Epanel%3E%2Epanel%2Dcollapse%3E%2Elist%2Dgroup%7Bmargin%2Dbottom%3A0%7D%2Epanel%3E%2Elist%2Dgroup%20%2Elist%2Dgroup%2Ditem%2C%2Epanel%3E%2Epanel%2Dcollapse%3E%2Elist%2Dgroup%20%2Elist%2Dgroup%2Ditem%7Bborder%2Dwidth%3A1px%200%3Bborder%2Dradius%3A0%7D%2Epanel%3E%2Elist%2Dgroup%3Afirst%2Dchild%20%2Elist%2Dgroup%2Ditem%3Afirst%2Dchild%2C%2Epanel%3E%2Epanel%2Dcollapse%3E%2Elist%2Dgroup%3Afirst%2Dchild%20%2Elist%2Dgroup%2Ditem%3Afirst%2Dchild%7Bborder%2Dtop%3A0%3Bborder%2Dtop%2Dleft%2Dradius%3A3px%3Bborder%2Dtop%2Dright%2Dradius%3A3px%7D%2Epanel%3E%2Elist%2Dgroup%3Alast%2Dchild%20%2Elist%2Dgroup%2Ditem%3Alast%2Dchild%2C%2Epanel%3E%2Epanel%2Dcollapse%3E%2Elist%2Dgroup%3Alast%2Dchild%20%2Elist%2Dgroup%2Ditem%3Alast%2Dchild%7Bborder%2Dbottom%3A0%3Bborder%2Dbottom%2Dright%2Dradius%3A3px%3Bborder%2Dbottom%2Dleft%2Dradius%3A3px%7D%2Epanel%3E%2Epanel%2Dheading%2B%2Epanel%2Dcollapse%3E%2Elist%2Dgroup%20%2Elist%2Dgroup%2Ditem%3Afirst%2Dchild%7Bborder%2Dtop%2Dleft%2Dradius%3A0%3Bborder%2Dtop%2Dright%2Dradius%3A0%7D%2Epanel%2Dheading%2B%2Elist%2Dgroup%20%2Elist%2Dgroup%2Ditem%3Afirst%2Dchild%7Bborder%2Dtop%2Dwidth%3A0%7D%2Elist%2Dgroup%2B%2Epanel%2Dfooter%7Bborder%2Dtop%2Dwidth%3A0%7D%2Epanel%3E%2Epanel%2Dcollapse%3E%2Etable%2C%2Epanel%3E%2Etable%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%7Bmargin%2Dbottom%3A0%7D%2Epanel%3E%2Epanel%2Dcollapse%3E%2Etable%20caption%2C%2Epanel%3E%2Etable%20caption%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%20caption%7Bpadding%2Dright%3A15px%3Bpadding%2Dleft%3A15px%7D%2Epanel%3E%2Etable%2Dresponsive%3Afirst%2Dchild%3E%2Etable%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%3Afirst%2Dchild%7Bborder%2Dtop%2Dleft%2Dradius%3A3px%3Bborder%2Dtop%2Dright%2Dradius%3A3px%7D%2Epanel%3E%2Etable%2Dresponsive%3Afirst%2Dchild%3E%2Etable%3Afirst%2Dchild%3Etbody%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3Afirst%2Dchild%3E%2Etable%3Afirst%2Dchild%3Ethead%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%3Afirst%2Dchild%3Etbody%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%3Afirst%2Dchild%3Ethead%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%7Bborder%2Dtop%2Dleft%2Dradius%3A3px%3Bborder%2Dtop%2Dright%2Dradius%3A3px%7D%2Epanel%3E%2Etable%2Dresponsive%3Afirst%2Dchild%3E%2Etable%3Afirst%2Dchild%3Etbody%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%20td%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3Afirst%2Dchild%3E%2Etable%3Afirst%2Dchild%3Etbody%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%20th%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3Afirst%2Dchild%3E%2Etable%3Afirst%2Dchild%3Ethead%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%20td%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3Afirst%2Dchild%3E%2Etable%3Afirst%2Dchild%3Ethead%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%20th%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%3Afirst%2Dchild%3Etbody%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%20td%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%3Afirst%2Dchild%3Etbody%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%20th%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%3Afirst%2Dchild%3Ethead%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%20td%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%3Afirst%2Dchild%3Ethead%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%20th%3Afirst%2Dchild%7Bborder%2Dtop%2Dleft%2Dradius%3A3px%7D%2Epanel%3E%2Etable%2Dresponsive%3Afirst%2Dchild%3E%2Etable%3Afirst%2Dchild%3Etbody%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%20td%3Alast%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3Afirst%2Dchild%3E%2Etable%3Afirst%2Dchild%3Etbody%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%20th%3Alast%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3Afirst%2Dchild%3E%2Etable%3Afirst%2Dchild%3Ethead%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%20td%3Alast%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3Afirst%2Dchild%3E%2Etable%3Afirst%2Dchild%3Ethead%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%20th%3Alast%2Dchild%2C%2Epanel%3E%2Etable%3Afirst%2Dchild%3Etbody%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%20td%3Alast%2Dchild%2C%2Epanel%3E%2Etable%3Afirst%2Dchild%3Etbody%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%20th%3Alast%2Dchild%2C%2Epanel%3E%2Etable%3Afirst%2Dchild%3Ethead%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%20td%3Alast%2Dchild%2C%2Epanel%3E%2Etable%3Afirst%2Dchild%3Ethead%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%20th%3Alast%2Dchild%7Bborder%2Dtop%2Dright%2Dradius%3A3px%7D%2Epanel%3E%2Etable%2Dresponsive%3Alast%2Dchild%3E%2Etable%3Alast%2Dchild%2C%2Epanel%3E%2Etable%3Alast%2Dchild%7Bborder%2Dbottom%2Dright%2Dradius%3A3px%3Bborder%2Dbottom%2Dleft%2Dradius%3A3px%7D%2Epanel%3E%2Etable%2Dresponsive%3Alast%2Dchild%3E%2Etable%3Alast%2Dchild%3Etbody%3Alast%2Dchild%3Etr%3Alast%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3Alast%2Dchild%3E%2Etable%3Alast%2Dchild%3Etfoot%3Alast%2Dchild%3Etr%3Alast%2Dchild%2C%2Epanel%3E%2Etable%3Alast%2Dchild%3Etbody%3Alast%2Dchild%3Etr%3Alast%2Dchild%2C%2Epanel%3E%2Etable%3Alast%2Dchild%3Etfoot%3Alast%2Dchild%3Etr%3Alast%2Dchild%7Bborder%2Dbottom%2Dright%2Dradius%3A3px%3Bborder%2Dbottom%2Dleft%2Dradius%3A3px%7D%2Epanel%3E%2Etable%2Dresponsive%3Alast%2Dchild%3E%2Etable%3Alast%2Dchild%3Etbody%3Alast%2Dchild%3Etr%3Alast%2Dchild%20td%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3Alast%2Dchild%3E%2Etable%3Alast%2Dchild%3Etbody%3Alast%2Dchild%3Etr%3Alast%2Dchild%20th%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3Alast%2Dchild%3E%2Etable%3Alast%2Dchild%3Etfoot%3Alast%2Dchild%3Etr%3Alast%2Dchild%20td%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3Alast%2Dchild%3E%2Etable%3Alast%2Dchild%3Etfoot%3Alast%2Dchild%3Etr%3Alast%2Dchild%20th%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%3Alast%2Dchild%3Etbody%3Alast%2Dchild%3Etr%3Alast%2Dchild%20td%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%3Alast%2Dchild%3Etbody%3Alast%2Dchild%3Etr%3Alast%2Dchild%20th%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%3Alast%2Dchild%3Etfoot%3Alast%2Dchild%3Etr%3Alast%2Dchild%20td%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%3Alast%2Dchild%3Etfoot%3Alast%2Dchild%3Etr%3Alast%2Dchild%20th%3Afirst%2Dchild%7Bborder%2Dbottom%2Dleft%2Dradius%3A3px%7D%2Epanel%3E%2Etable%2Dresponsive%3Alast%2Dchild%3E%2Etable%3Alast%2Dchild%3Etbody%3Alast%2Dchild%3Etr%3Alast%2Dchild%20td%3Alast%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3Alast%2Dchild%3E%2Etable%3Alast%2Dchild%3Etbody%3Alast%2Dchild%3Etr%3Alast%2Dchild%20th%3Alast%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3Alast%2Dchild%3E%2Etable%3Alast%2Dchild%3Etfoot%3Alast%2Dchild%3Etr%3Alast%2Dchild%20td%3Alast%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3Alast%2Dchild%3E%2Etable%3Alast%2Dchild%3Etfoot%3Alast%2Dchild%3Etr%3Alast%2Dchild%20th%3Alast%2Dchild%2C%2Epanel%3E%2Etable%3Alast%2Dchild%3Etbody%3Alast%2Dchild%3Etr%3Alast%2Dchild%20td%3Alast%2Dchild%2C%2Epanel%3E%2Etable%3Alast%2Dchild%3Etbody%3Alast%2Dchild%3Etr%3Alast%2Dchild%20th%3Alast%2Dchild%2C%2Epanel%3E%2Etable%3Alast%2Dchild%3Etfoot%3Alast%2Dchild%3Etr%3Alast%2Dchild%20td%3Alast%2Dchild%2C%2Epanel%3E%2Etable%3Alast%2Dchild%3Etfoot%3Alast%2Dchild%3Etr%3Alast%2Dchild%20th%3Alast%2Dchild%7Bborder%2Dbottom%2Dright%2Dradius%3A3px%7D%2Epanel%3E%2Epanel%2Dbody%2B%2Etable%2C%2Epanel%3E%2Epanel%2Dbody%2B%2Etable%2Dresponsive%2C%2Epanel%3E%2Etable%2B%2Epanel%2Dbody%2C%2Epanel%3E%2Etable%2Dresponsive%2B%2Epanel%2Dbody%7Bborder%2Dtop%3A1px%20solid%20%23ddd%7D%2Epanel%3E%2Etable%3Etbody%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%20td%2C%2Epanel%3E%2Etable%3Etbody%3Afirst%2Dchild%3Etr%3Afirst%2Dchild%20th%7Bborder%2Dtop%3A0%7D%2Epanel%3E%2Etable%2Dbordered%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%2Dbordered%7Bborder%3A0%7D%2Epanel%3E%2Etable%2Dbordered%3Etbody%3Etr%3Etd%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%2Dbordered%3Etbody%3Etr%3Eth%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%2Dbordered%3Etfoot%3Etr%3Etd%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%2Dbordered%3Etfoot%3Etr%3Eth%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%2Dbordered%3Ethead%3Etr%3Etd%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%2Dbordered%3Ethead%3Etr%3Eth%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etbody%3Etr%3Etd%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etbody%3Etr%3Eth%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etfoot%3Etr%3Etd%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etfoot%3Etr%3Eth%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Ethead%3Etr%3Etd%3Afirst%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Ethead%3Etr%3Eth%3Afirst%2Dchild%7Bborder%2Dleft%3A0%7D%2Epanel%3E%2Etable%2Dbordered%3Etbody%3Etr%3Etd%3Alast%2Dchild%2C%2Epanel%3E%2Etable%2Dbordered%3Etbody%3Etr%3Eth%3Alast%2Dchild%2C%2Epanel%3E%2Etable%2Dbordered%3Etfoot%3Etr%3Etd%3Alast%2Dchild%2C%2Epanel%3E%2Etable%2Dbordered%3Etfoot%3Etr%3Eth%3Alast%2Dchild%2C%2Epanel%3E%2Etable%2Dbordered%3Ethead%3Etr%3Etd%3Alast%2Dchild%2C%2Epanel%3E%2Etable%2Dbordered%3Ethead%3Etr%3Eth%3Alast%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etbody%3Etr%3Etd%3Alast%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etbody%3Etr%3Eth%3Alast%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etfoot%3Etr%3Etd%3Alast%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etfoot%3Etr%3Eth%3Alast%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Ethead%3Etr%3Etd%3Alast%2Dchild%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Ethead%3Etr%3Eth%3Alast%2Dchild%7Bborder%2Dright%3A0%7D%2Epanel%3E%2Etable%2Dbordered%3Etbody%3Etr%3Afirst%2Dchild%3Etd%2C%2Epanel%3E%2Etable%2Dbordered%3Etbody%3Etr%3Afirst%2Dchild%3Eth%2C%2Epanel%3E%2Etable%2Dbordered%3Ethead%3Etr%3Afirst%2Dchild%3Etd%2C%2Epanel%3E%2Etable%2Dbordered%3Ethead%3Etr%3Afirst%2Dchild%3Eth%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etbody%3Etr%3Afirst%2Dchild%3Etd%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etbody%3Etr%3Afirst%2Dchild%3Eth%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Ethead%3Etr%3Afirst%2Dchild%3Etd%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Ethead%3Etr%3Afirst%2Dchild%3Eth%7Bborder%2Dbottom%3A0%7D%2Epanel%3E%2Etable%2Dbordered%3Etbody%3Etr%3Alast%2Dchild%3Etd%2C%2Epanel%3E%2Etable%2Dbordered%3Etbody%3Etr%3Alast%2Dchild%3Eth%2C%2Epanel%3E%2Etable%2Dbordered%3Etfoot%3Etr%3Alast%2Dchild%3Etd%2C%2Epanel%3E%2Etable%2Dbordered%3Etfoot%3Etr%3Alast%2Dchild%3Eth%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etbody%3Etr%3Alast%2Dchild%3Etd%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etbody%3Etr%3Alast%2Dchild%3Eth%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etfoot%3Etr%3Alast%2Dchild%3Etd%2C%2Epanel%3E%2Etable%2Dresponsive%3E%2Etable%2Dbordered%3Etfoot%3Etr%3Alast%2Dchild%3Eth%7Bborder%2Dbottom%3A0%7D%2Epanel%3E%2Etable%2Dresponsive%7Bmargin%2Dbottom%3A0%3Bborder%3A0%7D%2Epanel%2Dgroup%7Bmargin%2Dbottom%3A20px%7D%2Epanel%2Dgroup%20%2Epanel%7Bmargin%2Dbottom%3A0%3Bborder%2Dradius%3A4px%7D%2Epanel%2Dgroup%20%2Epanel%2B%2Epanel%7Bmargin%2Dtop%3A5px%7D%2Epanel%2Dgroup%20%2Epanel%2Dheading%7Bborder%2Dbottom%3A0%7D%2Epanel%2Dgroup%20%2Epanel%2Dheading%2B%2Epanel%2Dcollapse%3E%2Elist%2Dgroup%2C%2Epanel%2Dgroup%20%2Epanel%2Dheading%2B%2Epanel%2Dcollapse%3E%2Epanel%2Dbody%7Bborder%2Dtop%3A1px%20solid%20%23ddd%7D%2Epanel%2Dgroup%20%2Epanel%2Dfooter%7Bborder%2Dtop%3A0%7D%2Epanel%2Dgroup%20%2Epanel%2Dfooter%2B%2Epanel%2Dcollapse%20%2Epanel%2Dbody%7Bborder%2Dbottom%3A1px%20solid%20%23ddd%7D%2Epanel%2Ddefault%7Bborder%2Dcolor%3A%23ddd%7D%2Epanel%2Ddefault%3E%2Epanel%2Dheading%7Bcolor%3A%23333%3Bbackground%2Dcolor%3A%23f5f5f5%3Bborder%2Dcolor%3A%23ddd%7D%2Epanel%2Ddefault%3E%2Epanel%2Dheading%2B%2Epanel%2Dcollapse%3E%2Epanel%2Dbody%7Bborder%2Dtop%2Dcolor%3A%23ddd%7D%2Epanel%2Ddefault%3E%2Epanel%2Dheading%20%2Ebadge%7Bcolor%3A%23f5f5f5%3Bbackground%2Dcolor%3A%23333%7D%2Epanel%2Ddefault%3E%2Epanel%2Dfooter%2B%2Epanel%2Dcollapse%3E%2Epanel%2Dbody%7Bborder%2Dbottom%2Dcolor%3A%23ddd%7D%2Epanel%2Dprimary%7Bborder%2Dcolor%3A%23337ab7%7D%2Epanel%2Dprimary%3E%2Epanel%2Dheading%7Bcolor%3A%23fff%3Bbackground%2Dcolor%3A%23337ab7%3Bborder%2Dcolor%3A%23337ab7%7D%2Epanel%2Dprimary%3E%2Epanel%2Dheading%2B%2Epanel%2Dcollapse%3E%2Epanel%2Dbody%7Bborder%2Dtop%2Dcolor%3A%23337ab7%7D%2Epanel%2Dprimary%3E%2Epanel%2Dheading%20%2Ebadge%7Bcolor%3A%23337ab7%3Bbackground%2Dcolor%3A%23fff%7D%2Epanel%2Dprimary%3E%2Epanel%2Dfooter%2B%2Epanel%2Dcollapse%3E%2Epanel%2Dbody%7Bborder%2Dbottom%2Dcolor%3A%23337ab7%7D%2Epanel%2Dsuccess%7Bborder%2Dcolor%3A%23d6e9c6%7D%2Epanel%2Dsuccess%3E%2Epanel%2Dheading%7Bcolor%3A%233c763d%3Bbackground%2Dcolor%3A%23dff0d8%3Bborder%2Dcolor%3A%23d6e9c6%7D%2Epanel%2Dsuccess%3E%2Epanel%2Dheading%2B%2Epanel%2Dcollapse%3E%2Epanel%2Dbody%7Bborder%2Dtop%2Dcolor%3A%23d6e9c6%7D%2Epanel%2Dsuccess%3E%2Epanel%2Dheading%20%2Ebadge%7Bcolor%3A%23dff0d8%3Bbackground%2Dcolor%3A%233c763d%7D%2Epanel%2Dsuccess%3E%2Epanel%2Dfooter%2B%2Epanel%2Dcollapse%3E%2Epanel%2Dbody%7Bborder%2Dbottom%2Dcolor%3A%23d6e9c6%7D%2Epanel%2Dinfo%7Bborder%2Dcolor%3A%23bce8f1%7D%2Epanel%2Dinfo%3E%2Epanel%2Dheading%7Bcolor%3A%2331708f%3Bbackground%2Dcolor%3A%23d9edf7%3Bborder%2Dcolor%3A%23bce8f1%7D%2Epanel%2Dinfo%3E%2Epanel%2Dheading%2B%2Epanel%2Dcollapse%3E%2Epanel%2Dbody%7Bborder%2Dtop%2Dcolor%3A%23bce8f1%7D%2Epanel%2Dinfo%3E%2Epanel%2Dheading%20%2Ebadge%7Bcolor%3A%23d9edf7%3Bbackground%2Dcolor%3A%2331708f%7D%2Epanel%2Dinfo%3E%2Epanel%2Dfooter%2B%2Epanel%2Dcollapse%3E%2Epanel%2Dbody%7Bborder%2Dbottom%2Dcolor%3A%23bce8f1%7D%2Epanel%2Dwarning%7Bborder%2Dcolor%3A%23faebcc%7D%2Epanel%2Dwarning%3E%2Epanel%2Dheading%7Bcolor%3A%238a6d3b%3Bbackground%2Dcolor%3A%23fcf8e3%3Bborder%2Dcolor%3A%23faebcc%7D%2Epanel%2Dwarning%3E%2Epanel%2Dheading%2B%2Epanel%2Dcollapse%3E%2Epanel%2Dbody%7Bborder%2Dtop%2Dcolor%3A%23faebcc%7D%2Epanel%2Dwarning%3E%2Epanel%2Dheading%20%2Ebadge%7Bcolor%3A%23fcf8e3%3Bbackground%2Dcolor%3A%238a6d3b%7D%2Epanel%2Dwarning%3E%2Epanel%2Dfooter%2B%2Epanel%2Dcollapse%3E%2Epanel%2Dbody%7Bborder%2Dbottom%2Dcolor%3A%23faebcc%7D%2Epanel%2Ddanger%7Bborder%2Dcolor%3A%23ebccd1%7D%2Epanel%2Ddanger%3E%2Epanel%2Dheading%7Bcolor%3A%23a94442%3Bbackground%2Dcolor%3A%23f2dede%3Bborder%2Dcolor%3A%23ebccd1%7D%2Epanel%2Ddanger%3E%2Epanel%2Dheading%2B%2Epanel%2Dcollapse%3E%2Epanel%2Dbody%7Bborder%2Dtop%2Dcolor%3A%23ebccd1%7D%2Epanel%2Ddanger%3E%2Epanel%2Dheading%20%2Ebadge%7Bcolor%3A%23f2dede%3Bbackground%2Dcolor%3A%23a94442%7D%2Epanel%2Ddanger%3E%2Epanel%2Dfooter%2B%2Epanel%2Dcollapse%3E%2Epanel%2Dbody%7Bborder%2Dbottom%2Dcolor%3A%23ebccd1%7D%2Eembed%2Dresponsive%7Bposition%3Arelative%3Bdisplay%3Ablock%3Bheight%3A0%3Bpadding%3A0%3Boverflow%3Ahidden%7D%2Eembed%2Dresponsive%20%2Eembed%2Dresponsive%2Ditem%2C%2Eembed%2Dresponsive%20embed%2C%2Eembed%2Dresponsive%20iframe%2C%2Eembed%2Dresponsive%20object%2C%2Eembed%2Dresponsive%20video%7Bposition%3Aabsolute%3Btop%3A0%3Bbottom%3A0%3Bleft%3A0%3Bwidth%3A100%25%3Bheight%3A100%25%3Bborder%3A0%7D%2Eembed%2Dresponsive%2D16by9%7Bpadding%2Dbottom%3A56%2E25%25%7D%2Eembed%2Dresponsive%2D4by3%7Bpadding%2Dbottom%3A75%25%7D%2Ewell%7Bmin%2Dheight%3A20px%3Bpadding%3A19px%3Bmargin%2Dbottom%3A20px%3Bbackground%2Dcolor%3A%23f5f5f5%3Bborder%3A1px%20solid%20%23e3e3e3%3Bborder%2Dradius%3A4px%3B%2Dwebkit%2Dbox%2Dshadow%3Ainset%200%201px%201px%20rgba%280%2C0%2C0%2C%2E05%29%3Bbox%2Dshadow%3Ainset%200%201px%201px%20rgba%280%2C0%2C0%2C%2E05%29%7D%2Ewell%20blockquote%7Bborder%2Dcolor%3A%23ddd%3Bborder%2Dcolor%3Argba%280%2C0%2C0%2C%2E15%29%7D%2Ewell%2Dlg%7Bpadding%3A24px%3Bborder%2Dradius%3A6px%7D%2Ewell%2Dsm%7Bpadding%3A9px%3Bborder%2Dradius%3A3px%7D%2Eclose%7Bfloat%3Aright%3Bfont%2Dsize%3A21px%3Bfont%2Dweight%3A700%3Bline%2Dheight%3A1%3Bcolor%3A%23000%3Btext%2Dshadow%3A0%201px%200%20%23fff%3Bfilter%3Aalpha%28opacity%3D20%29%3Bopacity%3A%2E2%7D%2Eclose%3Afocus%2C%2Eclose%3Ahover%7Bcolor%3A%23000%3Btext%2Ddecoration%3Anone%3Bcursor%3Apointer%3Bfilter%3Aalpha%28opacity%3D50%29%3Bopacity%3A%2E5%7Dbutton%2Eclose%7B%2Dwebkit%2Dappearance%3Anone%3Bpadding%3A0%3Bcursor%3Apointer%3Bbackground%3A0%200%3Bborder%3A0%7D%2Emodal%2Dopen%7Boverflow%3Ahidden%7D%2Emodal%7Bposition%3Afixed%3Btop%3A0%3Bright%3A0%3Bbottom%3A0%3Bleft%3A0%3Bz%2Dindex%3A1050%3Bdisplay%3Anone%3Boverflow%3Ahidden%3B%2Dwebkit%2Doverflow%2Dscrolling%3Atouch%3Boutline%3A0%7D%2Emodal%2Efade%20%2Emodal%2Ddialog%7B%2Dwebkit%2Dtransition%3A%2Dwebkit%2Dtransform%20%2E3s%20ease%2Dout%3B%2Do%2Dtransition%3A%2Do%2Dtransform%20%2E3s%20ease%2Dout%3Btransition%3Atransform%20%2E3s%20ease%2Dout%3B%2Dwebkit%2Dtransform%3Atranslate%280%2C%2D25%25%29%3B%2Dms%2Dtransform%3Atranslate%280%2C%2D25%25%29%3B%2Do%2Dtransform%3Atranslate%280%2C%2D25%25%29%3Btransform%3Atranslate%280%2C%2D25%25%29%7D%2Emodal%2Ein%20%2Emodal%2Ddialog%7B%2Dwebkit%2Dtransform%3Atranslate%280%2C0%29%3B%2Dms%2Dtransform%3Atranslate%280%2C0%29%3B%2Do%2Dtransform%3Atranslate%280%2C0%29%3Btransform%3Atranslate%280%2C0%29%7D%2Emodal%2Dopen%20%2Emodal%7Boverflow%2Dx%3Ahidden%3Boverflow%2Dy%3Aauto%7D%2Emodal%2Ddialog%7Bposition%3Arelative%3Bwidth%3Aauto%3Bmargin%3A10px%7D%2Emodal%2Dcontent%7Bposition%3Arelative%3Bbackground%2Dcolor%3A%23fff%3B%2Dwebkit%2Dbackground%2Dclip%3Apadding%2Dbox%3Bbackground%2Dclip%3Apadding%2Dbox%3Bborder%3A1px%20solid%20%23999%3Bborder%3A1px%20solid%20rgba%280%2C0%2C0%2C%2E2%29%3Bborder%2Dradius%3A6px%3Boutline%3A0%3B%2Dwebkit%2Dbox%2Dshadow%3A0%203px%209px%20rgba%280%2C0%2C0%2C%2E5%29%3Bbox%2Dshadow%3A0%203px%209px%20rgba%280%2C0%2C0%2C%2E5%29%7D%2Emodal%2Dbackdrop%7Bposition%3Afixed%3Btop%3A0%3Bright%3A0%3Bbottom%3A0%3Bleft%3A0%3Bz%2Dindex%3A1040%3Bbackground%2Dcolor%3A%23000%7D%2Emodal%2Dbackdrop%2Efade%7Bfilter%3Aalpha%28opacity%3D0%29%3Bopacity%3A0%7D%2Emodal%2Dbackdrop%2Ein%7Bfilter%3Aalpha%28opacity%3D50%29%3Bopacity%3A%2E5%7D%2Emodal%2Dheader%7Bmin%2Dheight%3A16%2E43px%3Bpadding%3A15px%3Bborder%2Dbottom%3A1px%20solid%20%23e5e5e5%7D%2Emodal%2Dheader%20%2Eclose%7Bmargin%2Dtop%3A%2D2px%7D%2Emodal%2Dtitle%7Bmargin%3A0%3Bline%2Dheight%3A1%2E42857143%7D%2Emodal%2Dbody%7Bposition%3Arelative%3Bpadding%3A15px%7D%2Emodal%2Dfooter%7Bpadding%3A15px%3Btext%2Dalign%3Aright%3Bborder%2Dtop%3A1px%20solid%20%23e5e5e5%7D%2Emodal%2Dfooter%20%2Ebtn%2B%2Ebtn%7Bmargin%2Dbottom%3A0%3Bmargin%2Dleft%3A5px%7D%2Emodal%2Dfooter%20%2Ebtn%2Dgroup%20%2Ebtn%2B%2Ebtn%7Bmargin%2Dleft%3A%2D1px%7D%2Emodal%2Dfooter%20%2Ebtn%2Dblock%2B%2Ebtn%2Dblock%7Bmargin%2Dleft%3A0%7D%2Emodal%2Dscrollbar%2Dmeasure%7Bposition%3Aabsolute%3Btop%3A%2D9999px%3Bwidth%3A50px%3Bheight%3A50px%3Boverflow%3Ascroll%7D%40media%20%28min%2Dwidth%3A768px%29%7B%2Emodal%2Ddialog%7Bwidth%3A600px%3Bmargin%3A30px%20auto%7D%2Emodal%2Dcontent%7B%2Dwebkit%2Dbox%2Dshadow%3A0%205px%2015px%20rgba%280%2C0%2C0%2C%2E5%29%3Bbox%2Dshadow%3A0%205px%2015px%20rgba%280%2C0%2C0%2C%2E5%29%7D%2Emodal%2Dsm%7Bwidth%3A300px%7D%7D%40media%20%28min%2Dwidth%3A992px%29%7B%2Emodal%2Dlg%7Bwidth%3A900px%7D%7D%2Etooltip%7Bposition%3Aabsolute%3Bz%2Dindex%3A1070%3Bdisplay%3Ablock%3Bfont%2Dfamily%3A%22Helvetica%20Neue%22%2CHelvetica%2CArial%2Csans%2Dserif%3Bfont%2Dsize%3A12px%3Bfont%2Dstyle%3Anormal%3Bfont%2Dweight%3A400%3Bline%2Dheight%3A1%2E42857143%3Btext%2Dalign%3Aleft%3Btext%2Dalign%3Astart%3Btext%2Ddecoration%3Anone%3Btext%2Dshadow%3Anone%3Btext%2Dtransform%3Anone%3Bletter%2Dspacing%3Anormal%3Bword%2Dbreak%3Anormal%3Bword%2Dspacing%3Anormal%3Bword%2Dwrap%3Anormal%3Bwhite%2Dspace%3Anormal%3Bfilter%3Aalpha%28opacity%3D0%29%3Bopacity%3A0%3Bline%2Dbreak%3Aauto%7D%2Etooltip%2Ein%7Bfilter%3Aalpha%28opacity%3D90%29%3Bopacity%3A%2E9%7D%2Etooltip%2Etop%7Bpadding%3A5px%200%3Bmargin%2Dtop%3A%2D3px%7D%2Etooltip%2Eright%7Bpadding%3A0%205px%3Bmargin%2Dleft%3A3px%7D%2Etooltip%2Ebottom%7Bpadding%3A5px%200%3Bmargin%2Dtop%3A3px%7D%2Etooltip%2Eleft%7Bpadding%3A0%205px%3Bmargin%2Dleft%3A%2D3px%7D%2Etooltip%2Dinner%7Bmax%2Dwidth%3A200px%3Bpadding%3A3px%208px%3Bcolor%3A%23fff%3Btext%2Dalign%3Acenter%3Bbackground%2Dcolor%3A%23000%3Bborder%2Dradius%3A4px%7D%2Etooltip%2Darrow%7Bposition%3Aabsolute%3Bwidth%3A0%3Bheight%3A0%3Bborder%2Dcolor%3Atransparent%3Bborder%2Dstyle%3Asolid%7D%2Etooltip%2Etop%20%2Etooltip%2Darrow%7Bbottom%3A0%3Bleft%3A50%25%3Bmargin%2Dleft%3A%2D5px%3Bborder%2Dwidth%3A5px%205px%200%3Bborder%2Dtop%2Dcolor%3A%23000%7D%2Etooltip%2Etop%2Dleft%20%2Etooltip%2Darrow%7Bright%3A5px%3Bbottom%3A0%3Bmargin%2Dbottom%3A%2D5px%3Bborder%2Dwidth%3A5px%205px%200%3Bborder%2Dtop%2Dcolor%3A%23000%7D%2Etooltip%2Etop%2Dright%20%2Etooltip%2Darrow%7Bbottom%3A0%3Bleft%3A5px%3Bmargin%2Dbottom%3A%2D5px%3Bborder%2Dwidth%3A5px%205px%200%3Bborder%2Dtop%2Dcolor%3A%23000%7D%2Etooltip%2Eright%20%2Etooltip%2Darrow%7Btop%3A50%25%3Bleft%3A0%3Bmargin%2Dtop%3A%2D5px%3Bborder%2Dwidth%3A5px%205px%205px%200%3Bborder%2Dright%2Dcolor%3A%23000%7D%2Etooltip%2Eleft%20%2Etooltip%2Darrow%7Btop%3A50%25%3Bright%3A0%3Bmargin%2Dtop%3A%2D5px%3Bborder%2Dwidth%3A5px%200%205px%205px%3Bborder%2Dleft%2Dcolor%3A%23000%7D%2Etooltip%2Ebottom%20%2Etooltip%2Darrow%7Btop%3A0%3Bleft%3A50%25%3Bmargin%2Dleft%3A%2D5px%3Bborder%2Dwidth%3A0%205px%205px%3Bborder%2Dbottom%2Dcolor%3A%23000%7D%2Etooltip%2Ebottom%2Dleft%20%2Etooltip%2Darrow%7Btop%3A0%3Bright%3A5px%3Bmargin%2Dtop%3A%2D5px%3Bborder%2Dwidth%3A0%205px%205px%3Bborder%2Dbottom%2Dcolor%3A%23000%7D%2Etooltip%2Ebottom%2Dright%20%2Etooltip%2Darrow%7Btop%3A0%3Bleft%3A5px%3Bmargin%2Dtop%3A%2D5px%3Bborder%2Dwidth%3A0%205px%205px%3Bborder%2Dbottom%2Dcolor%3A%23000%7D%2Epopover%7Bposition%3Aabsolute%3Btop%3A0%3Bleft%3A0%3Bz%2Dindex%3A1060%3Bdisplay%3Anone%3Bmax%2Dwidth%3A276px%3Bpadding%3A1px%3Bfont%2Dfamily%3A%22Helvetica%20Neue%22%2CHelvetica%2CArial%2Csans%2Dserif%3Bfont%2Dsize%3A14px%3Bfont%2Dstyle%3Anormal%3Bfont%2Dweight%3A400%3Bline%2Dheight%3A1%2E42857143%3Btext%2Dalign%3Aleft%3Btext%2Dalign%3Astart%3Btext%2Ddecoration%3Anone%3Btext%2Dshadow%3Anone%3Btext%2Dtransform%3Anone%3Bletter%2Dspacing%3Anormal%3Bword%2Dbreak%3Anormal%3Bword%2Dspacing%3Anormal%3Bword%2Dwrap%3Anormal%3Bwhite%2Dspace%3Anormal%3Bbackground%2Dcolor%3A%23fff%3B%2Dwebkit%2Dbackground%2Dclip%3Apadding%2Dbox%3Bbackground%2Dclip%3Apadding%2Dbox%3Bborder%3A1px%20solid%20%23ccc%3Bborder%3A1px%20solid%20rgba%280%2C0%2C0%2C%2E2%29%3Bborder%2Dradius%3A6px%3B%2Dwebkit%2Dbox%2Dshadow%3A0%205px%2010px%20rgba%280%2C0%2C0%2C%2E2%29%3Bbox%2Dshadow%3A0%205px%2010px%20rgba%280%2C0%2C0%2C%2E2%29%3Bline%2Dbreak%3Aauto%7D%2Epopover%2Etop%7Bmargin%2Dtop%3A%2D10px%7D%2Epopover%2Eright%7Bmargin%2Dleft%3A10px%7D%2Epopover%2Ebottom%7Bmargin%2Dtop%3A10px%7D%2Epopover%2Eleft%7Bmargin%2Dleft%3A%2D10px%7D%2Epopover%2Dtitle%7Bpadding%3A8px%2014px%3Bmargin%3A0%3Bfont%2Dsize%3A14px%3Bbackground%2Dcolor%3A%23f7f7f7%3Bborder%2Dbottom%3A1px%20solid%20%23ebebeb%3Bborder%2Dradius%3A5px%205px%200%200%7D%2Epopover%2Dcontent%7Bpadding%3A9px%2014px%7D%2Epopover%3E%2Earrow%2C%2Epopover%3E%2Earrow%3Aafter%7Bposition%3Aabsolute%3Bdisplay%3Ablock%3Bwidth%3A0%3Bheight%3A0%3Bborder%2Dcolor%3Atransparent%3Bborder%2Dstyle%3Asolid%7D%2Epopover%3E%2Earrow%7Bborder%2Dwidth%3A11px%7D%2Epopover%3E%2Earrow%3Aafter%7Bcontent%3A%22%22%3Bborder%2Dwidth%3A10px%7D%2Epopover%2Etop%3E%2Earrow%7Bbottom%3A%2D11px%3Bleft%3A50%25%3Bmargin%2Dleft%3A%2D11px%3Bborder%2Dtop%2Dcolor%3A%23999%3Bborder%2Dtop%2Dcolor%3Argba%280%2C0%2C0%2C%2E25%29%3Bborder%2Dbottom%2Dwidth%3A0%7D%2Epopover%2Etop%3E%2Earrow%3Aafter%7Bbottom%3A1px%3Bmargin%2Dleft%3A%2D10px%3Bcontent%3A%22%20%22%3Bborder%2Dtop%2Dcolor%3A%23fff%3Bborder%2Dbottom%2Dwidth%3A0%7D%2Epopover%2Eright%3E%2Earrow%7Btop%3A50%25%3Bleft%3A%2D11px%3Bmargin%2Dtop%3A%2D11px%3Bborder%2Dright%2Dcolor%3A%23999%3Bborder%2Dright%2Dcolor%3Argba%280%2C0%2C0%2C%2E25%29%3Bborder%2Dleft%2Dwidth%3A0%7D%2Epopover%2Eright%3E%2Earrow%3Aafter%7Bbottom%3A%2D10px%3Bleft%3A1px%3Bcontent%3A%22%20%22%3Bborder%2Dright%2Dcolor%3A%23fff%3Bborder%2Dleft%2Dwidth%3A0%7D%2Epopover%2Ebottom%3E%2Earrow%7Btop%3A%2D11px%3Bleft%3A50%25%3Bmargin%2Dleft%3A%2D11px%3Bborder%2Dtop%2Dwidth%3A0%3Bborder%2Dbottom%2Dcolor%3A%23999%3Bborder%2Dbottom%2Dcolor%3Argba%280%2C0%2C0%2C%2E25%29%7D%2Epopover%2Ebottom%3E%2Earrow%3Aafter%7Btop%3A1px%3Bmargin%2Dleft%3A%2D10px%3Bcontent%3A%22%20%22%3Bborder%2Dtop%2Dwidth%3A0%3Bborder%2Dbottom%2Dcolor%3A%23fff%7D%2Epopover%2Eleft%3E%2Earrow%7Btop%3A50%25%3Bright%3A%2D11px%3Bmargin%2Dtop%3A%2D11px%3Bborder%2Dright%2Dwidth%3A0%3Bborder%2Dleft%2Dcolor%3A%23999%3Bborder%2Dleft%2Dcolor%3Argba%280%2C0%2C0%2C%2E25%29%7D%2Epopover%2Eleft%3E%2Earrow%3Aafter%7Bright%3A1px%3Bbottom%3A%2D10px%3Bcontent%3A%22%20%22%3Bborder%2Dright%2Dwidth%3A0%3Bborder%2Dleft%2Dcolor%3A%23fff%7D%2Ecarousel%7Bposition%3Arelative%7D%2Ecarousel%2Dinner%7Bposition%3Arelative%3Bwidth%3A100%25%3Boverflow%3Ahidden%7D%2Ecarousel%2Dinner%3E%2Eitem%7Bposition%3Arelative%3Bdisplay%3Anone%3B%2Dwebkit%2Dtransition%3A%2E6s%20ease%2Din%2Dout%20left%3B%2Do%2Dtransition%3A%2E6s%20ease%2Din%2Dout%20left%3Btransition%3A%2E6s%20ease%2Din%2Dout%20left%7D%2Ecarousel%2Dinner%3E%2Eitem%3Ea%3Eimg%2C%2Ecarousel%2Dinner%3E%2Eitem%3Eimg%7Bline%2Dheight%3A1%7D%40media%20all%20and%20%28transform%2D3d%29%2C%28%2Dwebkit%2Dtransform%2D3d%29%7B%2Ecarousel%2Dinner%3E%2Eitem%7B%2Dwebkit%2Dtransition%3A%2Dwebkit%2Dtransform%20%2E6s%20ease%2Din%2Dout%3B%2Do%2Dtransition%3A%2Do%2Dtransform%20%2E6s%20ease%2Din%2Dout%3Btransition%3Atransform%20%2E6s%20ease%2Din%2Dout%3B%2Dwebkit%2Dbackface%2Dvisibility%3Ahidden%3Bbackface%2Dvisibility%3Ahidden%3B%2Dwebkit%2Dperspective%3A1000px%3Bperspective%3A1000px%7D%2Ecarousel%2Dinner%3E%2Eitem%2Eactive%2Eright%2C%2Ecarousel%2Dinner%3E%2Eitem%2Enext%7Bleft%3A0%3B%2Dwebkit%2Dtransform%3Atranslate3d%28100%25%2C0%2C0%29%3Btransform%3Atranslate3d%28100%25%2C0%2C0%29%7D%2Ecarousel%2Dinner%3E%2Eitem%2Eactive%2Eleft%2C%2Ecarousel%2Dinner%3E%2Eitem%2Eprev%7Bleft%3A0%3B%2Dwebkit%2Dtransform%3Atranslate3d%28%2D100%25%2C0%2C0%29%3Btransform%3Atranslate3d%28%2D100%25%2C0%2C0%29%7D%2Ecarousel%2Dinner%3E%2Eitem%2Eactive%2C%2Ecarousel%2Dinner%3E%2Eitem%2Enext%2Eleft%2C%2Ecarousel%2Dinner%3E%2Eitem%2Eprev%2Eright%7Bleft%3A0%3B%2Dwebkit%2Dtransform%3Atranslate3d%280%2C0%2C0%29%3Btransform%3Atranslate3d%280%2C0%2C0%29%7D%7D%2Ecarousel%2Dinner%3E%2Eactive%2C%2Ecarousel%2Dinner%3E%2Enext%2C%2Ecarousel%2Dinner%3E%2Eprev%7Bdisplay%3Ablock%7D%2Ecarousel%2Dinner%3E%2Eactive%7Bleft%3A0%7D%2Ecarousel%2Dinner%3E%2Enext%2C%2Ecarousel%2Dinner%3E%2Eprev%7Bposition%3Aabsolute%3Btop%3A0%3Bwidth%3A100%25%7D%2Ecarousel%2Dinner%3E%2Enext%7Bleft%3A100%25%7D%2Ecarousel%2Dinner%3E%2Eprev%7Bleft%3A%2D100%25%7D%2Ecarousel%2Dinner%3E%2Enext%2Eleft%2C%2Ecarousel%2Dinner%3E%2Eprev%2Eright%7Bleft%3A0%7D%2Ecarousel%2Dinner%3E%2Eactive%2Eleft%7Bleft%3A%2D100%25%7D%2Ecarousel%2Dinner%3E%2Eactive%2Eright%7Bleft%3A100%25%7D%2Ecarousel%2Dcontrol%7Bposition%3Aabsolute%3Btop%3A0%3Bbottom%3A0%3Bleft%3A0%3Bwidth%3A15%25%3Bfont%2Dsize%3A20px%3Bcolor%3A%23fff%3Btext%2Dalign%3Acenter%3Btext%2Dshadow%3A0%201px%202px%20rgba%280%2C0%2C0%2C%2E6%29%3Bfilter%3Aalpha%28opacity%3D50%29%3Bopacity%3A%2E5%7D%2Ecarousel%2Dcontrol%2Eleft%7Bbackground%2Dimage%3A%2Dwebkit%2Dlinear%2Dgradient%28left%2Crgba%280%2C0%2C0%2C%2E5%29%200%2Crgba%280%2C0%2C0%2C%2E0001%29%20100%25%29%3Bbackground%2Dimage%3A%2Do%2Dlinear%2Dgradient%28left%2Crgba%280%2C0%2C0%2C%2E5%29%200%2Crgba%280%2C0%2C0%2C%2E0001%29%20100%25%29%3Bbackground%2Dimage%3A%2Dwebkit%2Dgradient%28linear%2Cleft%20top%2Cright%20top%2Cfrom%28rgba%280%2C0%2C0%2C%2E5%29%29%2Cto%28rgba%280%2C0%2C0%2C%2E0001%29%29%29%3Bbackground%2Dimage%3Alinear%2Dgradient%28to%20right%2Crgba%280%2C0%2C0%2C%2E5%29%200%2Crgba%280%2C0%2C0%2C%2E0001%29%20100%25%29%3Bfilter%3Aprogid%3ADXImageTransform%2EMicrosoft%2Egradient%28startColorstr%3D%27%2380000000%27%2C%20endColorstr%3D%27%2300000000%27%2C%20GradientType%3D1%29%3Bbackground%2Drepeat%3Arepeat%2Dx%7D%2Ecarousel%2Dcontrol%2Eright%7Bright%3A0%3Bleft%3Aauto%3Bbackground%2Dimage%3A%2Dwebkit%2Dlinear%2Dgradient%28left%2Crgba%280%2C0%2C0%2C%2E0001%29%200%2Crgba%280%2C0%2C0%2C%2E5%29%20100%25%29%3Bbackground%2Dimage%3A%2Do%2Dlinear%2Dgradient%28left%2Crgba%280%2C0%2C0%2C%2E0001%29%200%2Crgba%280%2C0%2C0%2C%2E5%29%20100%25%29%3Bbackground%2Dimage%3A%2Dwebkit%2Dgradient%28linear%2Cleft%20top%2Cright%20top%2Cfrom%28rgba%280%2C0%2C0%2C%2E0001%29%29%2Cto%28rgba%280%2C0%2C0%2C%2E5%29%29%29%3Bbackground%2Dimage%3Alinear%2Dgradient%28to%20right%2Crgba%280%2C0%2C0%2C%2E0001%29%200%2Crgba%280%2C0%2C0%2C%2E5%29%20100%25%29%3Bfilter%3Aprogid%3ADXImageTransform%2EMicrosoft%2Egradient%28startColorstr%3D%27%2300000000%27%2C%20endColorstr%3D%27%2380000000%27%2C%20GradientType%3D1%29%3Bbackground%2Drepeat%3Arepeat%2Dx%7D%2Ecarousel%2Dcontrol%3Afocus%2C%2Ecarousel%2Dcontrol%3Ahover%7Bcolor%3A%23fff%3Btext%2Ddecoration%3Anone%3Bfilter%3Aalpha%28opacity%3D90%29%3Boutline%3A0%3Bopacity%3A%2E9%7D%2Ecarousel%2Dcontrol%20%2Eglyphicon%2Dchevron%2Dleft%2C%2Ecarousel%2Dcontrol%20%2Eglyphicon%2Dchevron%2Dright%2C%2Ecarousel%2Dcontrol%20%2Eicon%2Dnext%2C%2Ecarousel%2Dcontrol%20%2Eicon%2Dprev%7Bposition%3Aabsolute%3Btop%3A50%25%3Bz%2Dindex%3A5%3Bdisplay%3Ainline%2Dblock%3Bmargin%2Dtop%3A%2D10px%7D%2Ecarousel%2Dcontrol%20%2Eglyphicon%2Dchevron%2Dleft%2C%2Ecarousel%2Dcontrol%20%2Eicon%2Dprev%7Bleft%3A50%25%3Bmargin%2Dleft%3A%2D10px%7D%2Ecarousel%2Dcontrol%20%2Eglyphicon%2Dchevron%2Dright%2C%2Ecarousel%2Dcontrol%20%2Eicon%2Dnext%7Bright%3A50%25%3Bmargin%2Dright%3A%2D10px%7D%2Ecarousel%2Dcontrol%20%2Eicon%2Dnext%2C%2Ecarousel%2Dcontrol%20%2Eicon%2Dprev%7Bwidth%3A20px%3Bheight%3A20px%3Bfont%2Dfamily%3Aserif%3Bline%2Dheight%3A1%7D%2Ecarousel%2Dcontrol%20%2Eicon%2Dprev%3Abefore%7Bcontent%3A%27%5C2039%27%7D%2Ecarousel%2Dcontrol%20%2Eicon%2Dnext%3Abefore%7Bcontent%3A%27%5C203a%27%7D%2Ecarousel%2Dindicators%7Bposition%3Aabsolute%3Bbottom%3A10px%3Bleft%3A50%25%3Bz%2Dindex%3A15%3Bwidth%3A60%25%3Bpadding%2Dleft%3A0%3Bmargin%2Dleft%3A%2D30%25%3Btext%2Dalign%3Acenter%3Blist%2Dstyle%3Anone%7D%2Ecarousel%2Dindicators%20li%7Bdisplay%3Ainline%2Dblock%3Bwidth%3A10px%3Bheight%3A10px%3Bmargin%3A1px%3Btext%2Dindent%3A%2D999px%3Bcursor%3Apointer%3Bbackground%2Dcolor%3A%23000%5C9%3Bbackground%2Dcolor%3Argba%280%2C0%2C0%2C0%29%3Bborder%3A1px%20solid%20%23fff%3Bborder%2Dradius%3A10px%7D%2Ecarousel%2Dindicators%20%2Eactive%7Bwidth%3A12px%3Bheight%3A12px%3Bmargin%3A0%3Bbackground%2Dcolor%3A%23fff%7D%2Ecarousel%2Dcaption%7Bposition%3Aabsolute%3Bright%3A15%25%3Bbottom%3A20px%3Bleft%3A15%25%3Bz%2Dindex%3A10%3Bpadding%2Dtop%3A20px%3Bpadding%2Dbottom%3A20px%3Bcolor%3A%23fff%3Btext%2Dalign%3Acenter%3Btext%2Dshadow%3A0%201px%202px%20rgba%280%2C0%2C0%2C%2E6%29%7D%2Ecarousel%2Dcaption%20%2Ebtn%7Btext%2Dshadow%3Anone%7D%40media%20screen%20and%20%28min%2Dwidth%3A768px%29%7B%2Ecarousel%2Dcontrol%20%2Eglyphicon%2Dchevron%2Dleft%2C%2Ecarousel%2Dcontrol%20%2Eglyphicon%2Dchevron%2Dright%2C%2Ecarousel%2Dcontrol%20%2Eicon%2Dnext%2C%2Ecarousel%2Dcontrol%20%2Eicon%2Dprev%7Bwidth%3A30px%3Bheight%3A30px%3Bmargin%2Dtop%3A%2D15px%3Bfont%2Dsize%3A30px%7D%2Ecarousel%2Dcontrol%20%2Eglyphicon%2Dchevron%2Dleft%2C%2Ecarousel%2Dcontrol%20%2Eicon%2Dprev%7Bmargin%2Dleft%3A%2D15px%7D%2Ecarousel%2Dcontrol%20%2Eglyphicon%2Dchevron%2Dright%2C%2Ecarousel%2Dcontrol%20%2Eicon%2Dnext%7Bmargin%2Dright%3A%2D15px%7D%2Ecarousel%2Dcaption%7Bright%3A20%25%3Bleft%3A20%25%3Bpadding%2Dbottom%3A30px%7D%2Ecarousel%2Dindicators%7Bbottom%3A20px%7D%7D%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%2Dgroup%3Aafter%2C%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%2Dgroup%3Abefore%2C%2Ebtn%2Dtoolbar%3Aafter%2C%2Ebtn%2Dtoolbar%3Abefore%2C%2Eclearfix%3Aafter%2C%2Eclearfix%3Abefore%2C%2Econtainer%2Dfluid%3Aafter%2C%2Econtainer%2Dfluid%3Abefore%2C%2Econtainer%3Aafter%2C%2Econtainer%3Abefore%2C%2Edl%2Dhorizontal%20dd%3Aafter%2C%2Edl%2Dhorizontal%20dd%3Abefore%2C%2Eform%2Dhorizontal%20%2Eform%2Dgroup%3Aafter%2C%2Eform%2Dhorizontal%20%2Eform%2Dgroup%3Abefore%2C%2Emodal%2Dfooter%3Aafter%2C%2Emodal%2Dfooter%3Abefore%2C%2Enav%3Aafter%2C%2Enav%3Abefore%2C%2Enavbar%2Dcollapse%3Aafter%2C%2Enavbar%2Dcollapse%3Abefore%2C%2Enavbar%2Dheader%3Aafter%2C%2Enavbar%2Dheader%3Abefore%2C%2Enavbar%3Aafter%2C%2Enavbar%3Abefore%2C%2Epager%3Aafter%2C%2Epager%3Abefore%2C%2Epanel%2Dbody%3Aafter%2C%2Epanel%2Dbody%3Abefore%2C%2Erow%3Aafter%2C%2Erow%3Abefore%7Bdisplay%3Atable%3Bcontent%3A%22%20%22%7D%2Ebtn%2Dgroup%2Dvertical%3E%2Ebtn%2Dgroup%3Aafter%2C%2Ebtn%2Dtoolbar%3Aafter%2C%2Eclearfix%3Aafter%2C%2Econtainer%2Dfluid%3Aafter%2C%2Econtainer%3Aafter%2C%2Edl%2Dhorizontal%20dd%3Aafter%2C%2Eform%2Dhorizontal%20%2Eform%2Dgroup%3Aafter%2C%2Emodal%2Dfooter%3Aafter%2C%2Enav%3Aafter%2C%2Enavbar%2Dcollapse%3Aafter%2C%2Enavbar%2Dheader%3Aafter%2C%2Enavbar%3Aafter%2C%2Epager%3Aafter%2C%2Epanel%2Dbody%3Aafter%2C%2Erow%3Aafter%7Bclear%3Aboth%7D%2Ecenter%2Dblock%7Bdisplay%3Ablock%3Bmargin%2Dright%3Aauto%3Bmargin%2Dleft%3Aauto%7D%2Epull%2Dright%7Bfloat%3Aright%21important%7D%2Epull%2Dleft%7Bfloat%3Aleft%21important%7D%2Ehide%7Bdisplay%3Anone%21important%7D%2Eshow%7Bdisplay%3Ablock%21important%7D%2Einvisible%7Bvisibility%3Ahidden%7D%2Etext%2Dhide%7Bfont%3A0%2F0%20a%3Bcolor%3Atransparent%3Btext%2Dshadow%3Anone%3Bbackground%2Dcolor%3Atransparent%3Bborder%3A0%7D%2Ehidden%7Bdisplay%3Anone%21important%7D%2Eaffix%7Bposition%3Afixed%7D%40%2Dms%2Dviewport%7Bwidth%3Adevice%2Dwidth%7D%2Evisible%2Dlg%2C%2Evisible%2Dmd%2C%2Evisible%2Dsm%2C%2Evisible%2Dxs%7Bdisplay%3Anone%21important%7D%2Evisible%2Dlg%2Dblock%2C%2Evisible%2Dlg%2Dinline%2C%2Evisible%2Dlg%2Dinline%2Dblock%2C%2Evisible%2Dmd%2Dblock%2C%2Evisible%2Dmd%2Dinline%2C%2Evisible%2Dmd%2Dinline%2Dblock%2C%2Evisible%2Dsm%2Dblock%2C%2Evisible%2Dsm%2Dinline%2C%2Evisible%2Dsm%2Dinline%2Dblock%2C%2Evisible%2Dxs%2Dblock%2C%2Evisible%2Dxs%2Dinline%2C%2Evisible%2Dxs%2Dinline%2Dblock%7Bdisplay%3Anone%21important%7D%40media%20%28max%2Dwidth%3A767px%29%7B%2Evisible%2Dxs%7Bdisplay%3Ablock%21important%7Dtable%2Evisible%2Dxs%7Bdisplay%3Atable%21important%7Dtr%2Evisible%2Dxs%7Bdisplay%3Atable%2Drow%21important%7Dtd%2Evisible%2Dxs%2Cth%2Evisible%2Dxs%7Bdisplay%3Atable%2Dcell%21important%7D%7D%40media%20%28max%2Dwidth%3A767px%29%7B%2Evisible%2Dxs%2Dblock%7Bdisplay%3Ablock%21important%7D%7D%40media%20%28max%2Dwidth%3A767px%29%7B%2Evisible%2Dxs%2Dinline%7Bdisplay%3Ainline%21important%7D%7D%40media%20%28max%2Dwidth%3A767px%29%7B%2Evisible%2Dxs%2Dinline%2Dblock%7Bdisplay%3Ainline%2Dblock%21important%7D%7D%40media%20%28min%2Dwidth%3A768px%29%20and%20%28max%2Dwidth%3A991px%29%7B%2Evisible%2Dsm%7Bdisplay%3Ablock%21important%7Dtable%2Evisible%2Dsm%7Bdisplay%3Atable%21important%7Dtr%2Evisible%2Dsm%7Bdisplay%3Atable%2Drow%21important%7Dtd%2Evisible%2Dsm%2Cth%2Evisible%2Dsm%7Bdisplay%3Atable%2Dcell%21important%7D%7D%40media%20%28min%2Dwidth%3A768px%29%20and%20%28max%2Dwidth%3A991px%29%7B%2Evisible%2Dsm%2Dblock%7Bdisplay%3Ablock%21important%7D%7D%40media%20%28min%2Dwidth%3A768px%29%20and%20%28max%2Dwidth%3A991px%29%7B%2Evisible%2Dsm%2Dinline%7Bdisplay%3Ainline%21important%7D%7D%40media%20%28min%2Dwidth%3A768px%29%20and%20%28max%2Dwidth%3A991px%29%7B%2Evisible%2Dsm%2Dinline%2Dblock%7Bdisplay%3Ainline%2Dblock%21important%7D%7D%40media%20%28min%2Dwidth%3A992px%29%20and%20%28max%2Dwidth%3A1199px%29%7B%2Evisible%2Dmd%7Bdisplay%3Ablock%21important%7Dtable%2Evisible%2Dmd%7Bdisplay%3Atable%21important%7Dtr%2Evisible%2Dmd%7Bdisplay%3Atable%2Drow%21important%7Dtd%2Evisible%2Dmd%2Cth%2Evisible%2Dmd%7Bdisplay%3Atable%2Dcell%21important%7D%7D%40media%20%28min%2Dwidth%3A992px%29%20and%20%28max%2Dwidth%3A1199px%29%7B%2Evisible%2Dmd%2Dblock%7Bdisplay%3Ablock%21important%7D%7D%40media%20%28min%2Dwidth%3A992px%29%20and%20%28max%2Dwidth%3A1199px%29%7B%2Evisible%2Dmd%2Dinline%7Bdisplay%3Ainline%21important%7D%7D%40media%20%28min%2Dwidth%3A992px%29%20and%20%28max%2Dwidth%3A1199px%29%7B%2Evisible%2Dmd%2Dinline%2Dblock%7Bdisplay%3Ainline%2Dblock%21important%7D%7D%40media%20%28min%2Dwidth%3A1200px%29%7B%2Evisible%2Dlg%7Bdisplay%3Ablock%21important%7Dtable%2Evisible%2Dlg%7Bdisplay%3Atable%21important%7Dtr%2Evisible%2Dlg%7Bdisplay%3Atable%2Drow%21important%7Dtd%2Evisible%2Dlg%2Cth%2Evisible%2Dlg%7Bdisplay%3Atable%2Dcell%21important%7D%7D%40media%20%28min%2Dwidth%3A1200px%29%7B%2Evisible%2Dlg%2Dblock%7Bdisplay%3Ablock%21important%7D%7D%40media%20%28min%2Dwidth%3A1200px%29%7B%2Evisible%2Dlg%2Dinline%7Bdisplay%3Ainline%21important%7D%7D%40media%20%28min%2Dwidth%3A1200px%29%7B%2Evisible%2Dlg%2Dinline%2Dblock%7Bdisplay%3Ainline%2Dblock%21important%7D%7D%40media%20%28max%2Dwidth%3A767px%29%7B%2Ehidden%2Dxs%7Bdisplay%3Anone%21important%7D%7D%40media%20%28min%2Dwidth%3A768px%29%20and%20%28max%2Dwidth%3A991px%29%7B%2Ehidden%2Dsm%7Bdisplay%3Anone%21important%7D%7D%40media%20%28min%2Dwidth%3A992px%29%20and%20%28max%2Dwidth%3A1199px%29%7B%2Ehidden%2Dmd%7Bdisplay%3Anone%21important%7D%7D%40media%20%28min%2Dwidth%3A1200px%29%7B%2Ehidden%2Dlg%7Bdisplay%3Anone%21important%7D%7D%2Evisible%2Dprint%7Bdisplay%3Anone%21important%7D%40media%20print%7B%2Evisible%2Dprint%7Bdisplay%3Ablock%21important%7Dtable%2Evisible%2Dprint%7Bdisplay%3Atable%21important%7Dtr%2Evisible%2Dprint%7Bdisplay%3Atable%2Drow%21important%7Dtd%2Evisible%2Dprint%2Cth%2Evisible%2Dprint%7Bdisplay%3Atable%2Dcell%21important%7D%7D%2Evisible%2Dprint%2Dblock%7Bdisplay%3Anone%21important%7D%40media%20print%7B%2Evisible%2Dprint%2Dblock%7Bdisplay%3Ablock%21important%7D%7D%2Evisible%2Dprint%2Dinline%7Bdisplay%3Anone%21important%7D%40media%20print%7B%2Evisible%2Dprint%2Dinline%7Bdisplay%3Ainline%21important%7D%7D%2Evisible%2Dprint%2Dinline%2Dblock%7Bdisplay%3Anone%21important%7D%40media%20print%7B%2Evisible%2Dprint%2Dinline%2Dblock%7Bdisplay%3Ainline%2Dblock%21important%7D%7D%40media%20print%7B%2Ehidden%2Dprint%7Bdisplay%3Anone%21important%7D%7D%0A" rel="stylesheet" />
<script src="data:application/x-javascript;base64,/*!
 * Bootstrap v3.3.5 (http://getbootstrap.com)
 * Copyright 2011-2015 Twitter, Inc.
 * Licensed under the MIT license
 */
if("undefined"==typeof jQuery)throw new Error("Bootstrap's JavaScript requires jQuery");+function(a){"use strict";var b=a.fn.jquery.split(" ")[0].split(".");if(b[0]<2&&b[1]<9||1==b[0]&&9==b[1]&&b[2]<1)throw new Error("Bootstrap's JavaScript requires jQuery version 1.9.1 or higher")}(jQuery),+function(a){"use strict";function b(){var a=document.createElement("bootstrap"),b={WebkitTransition:"webkitTransitionEnd",MozTransition:"transitionend",OTransition:"oTransitionEnd otransitionend",transition:"transitionend"};for(var c in b)if(void 0!==a.style[c])return{end:b[c]};return!1}a.fn.emulateTransitionEnd=function(b){var c=!1,d=this;a(this).one("bsTransitionEnd",function(){c=!0});var e=function(){c||a(d).trigger(a.support.transition.end)};return setTimeout(e,b),this},a(function(){a.support.transition=b(),a.support.transition&&(a.event.special.bsTransitionEnd={bindType:a.support.transition.end,delegateType:a.support.transition.end,handle:function(b){return a(b.target).is(this)?b.handleObj.handler.apply(this,arguments):void 0}})})}(jQuery),+function(a){"use strict";function b(b){return this.each(function(){var c=a(this),e=c.data("bs.alert");e||c.data("bs.alert",e=new d(this)),"string"==typeof b&&e[b].call(c)})}var c='[data-dismiss="alert"]',d=function(b){a(b).on("click",c,this.close)};d.VERSION="3.3.5",d.TRANSITION_DURATION=150,d.prototype.close=function(b){function c(){g.detach().trigger("closed.bs.alert").remove()}var e=a(this),f=e.attr("data-target");f||(f=e.attr("href"),f=f&&f.replace(/.*(?=#[^\s]*$)/,""));var g=a(f);b&&b.preventDefault(),g.length||(g=e.closest(".alert")),g.trigger(b=a.Event("close.bs.alert")),b.isDefaultPrevented()||(g.removeClass("in"),a.support.transition&&g.hasClass("fade")?g.one("bsTransitionEnd",c).emulateTransitionEnd(d.TRANSITION_DURATION):c())};var e=a.fn.alert;a.fn.alert=b,a.fn.alert.Constructor=d,a.fn.alert.noConflict=function(){return a.fn.alert=e,this},a(document).on("click.bs.alert.data-api",c,d.prototype.close)}(jQuery),+function(a){"use strict";function b(b){return this.each(function(){var d=a(this),e=d.data("bs.button"),f="object"==typeof b&&b;e||d.data("bs.button",e=new c(this,f)),"toggle"==b?e.toggle():b&&e.setState(b)})}var c=function(b,d){this.$element=a(b),this.options=a.extend({},c.DEFAULTS,d),this.isLoading=!1};c.VERSION="3.3.5",c.DEFAULTS={loadingText:"loading..."},c.prototype.setState=function(b){var c="disabled",d=this.$element,e=d.is("input")?"val":"html",f=d.data();b+="Text",null==f.resetText&&d.data("resetText",d[e]()),setTimeout(a.proxy(function(){d[e](null==f[b]?this.options[b]:f[b]),"loadingText"==b?(this.isLoading=!0,d.addClass(c).attr(c,c)):this.isLoading&&(this.isLoading=!1,d.removeClass(c).removeAttr(c))},this),0)},c.prototype.toggle=function(){var a=!0,b=this.$element.closest('[data-toggle="buttons"]');if(b.length){var c=this.$element.find("input");"radio"==c.prop("type")?(c.prop("checked")&&(a=!1),b.find(".active").removeClass("active"),this.$element.addClass("active")):"checkbox"==c.prop("type")&&(c.prop("checked")!==this.$element.hasClass("active")&&(a=!1),this.$element.toggleClass("active")),c.prop("checked",this.$element.hasClass("active")),a&&c.trigger("change")}else this.$element.attr("aria-pressed",!this.$element.hasClass("active")),this.$element.toggleClass("active")};var d=a.fn.button;a.fn.button=b,a.fn.button.Constructor=c,a.fn.button.noConflict=function(){return a.fn.button=d,this},a(document).on("click.bs.button.data-api",'[data-toggle^="button"]',function(c){var d=a(c.target);d.hasClass("btn")||(d=d.closest(".btn")),b.call(d,"toggle"),a(c.target).is('input[type="radio"]')||a(c.target).is('input[type="checkbox"]')||c.preventDefault()}).on("focus.bs.button.data-api blur.bs.button.data-api",'[data-toggle^="button"]',function(b){a(b.target).closest(".btn").toggleClass("focus",/^focus(in)?$/.test(b.type))})}(jQuery),+function(a){"use strict";function b(b){return this.each(function(){var d=a(this),e=d.data("bs.carousel"),f=a.extend({},c.DEFAULTS,d.data(),"object"==typeof b&&b),g="string"==typeof b?b:f.slide;e||d.data("bs.carousel",e=new c(this,f)),"number"==typeof b?e.to(b):g?e[g]():f.interval&&e.pause().cycle()})}var c=function(b,c){this.$element=a(b),this.$indicators=this.$element.find(".carousel-indicators"),this.options=c,this.paused=null,this.sliding=null,this.interval=null,this.$active=null,this.$items=null,this.options.keyboard&&this.$element.on("keydown.bs.carousel",a.proxy(this.keydown,this)),"hover"==this.options.pause&&!("ontouchstart"in document.documentElement)&&this.$element.on("mouseenter.bs.carousel",a.proxy(this.pause,this)).on("mouseleave.bs.carousel",a.proxy(this.cycle,this))};c.VERSION="3.3.5",c.TRANSITION_DURATION=600,c.DEFAULTS={interval:5e3,pause:"hover",wrap:!0,keyboard:!0},c.prototype.keydown=function(a){if(!/input|textarea/i.test(a.target.tagName)){switch(a.which){case 37:this.prev();break;case 39:this.next();break;default:return}a.preventDefault()}},c.prototype.cycle=function(b){return b||(this.paused=!1),this.interval&&clearInterval(this.interval),this.options.interval&&!this.paused&&(this.interval=setInterval(a.proxy(this.next,this),this.options.interval)),this},c.prototype.getItemIndex=function(a){return this.$items=a.parent().children(".item"),this.$items.index(a||this.$active)},c.prototype.getItemForDirection=function(a,b){var c=this.getItemIndex(b),d="prev"==a&&0===c||"next"==a&&c==this.$items.length-1;if(d&&!this.options.wrap)return b;var e="prev"==a?-1:1,f=(c+e)%this.$items.length;return this.$items.eq(f)},c.prototype.to=function(a){var b=this,c=this.getItemIndex(this.$active=this.$element.find(".item.active"));return a>this.$items.length-1||0>a?void 0:this.sliding?this.$element.one("slid.bs.carousel",function(){b.to(a)}):c==a?this.pause().cycle():this.slide(a>c?"next":"prev",this.$items.eq(a))},c.prototype.pause=function(b){return b||(this.paused=!0),this.$element.find(".next, .prev").length&&a.support.transition&&(this.$element.trigger(a.support.transition.end),this.cycle(!0)),this.interval=clearInterval(this.interval),this},c.prototype.next=function(){return this.sliding?void 0:this.slide("next")},c.prototype.prev=function(){return this.sliding?void 0:this.slide("prev")},c.prototype.slide=function(b,d){var e=this.$element.find(".item.active"),f=d||this.getItemForDirection(b,e),g=this.interval,h="next"==b?"left":"right",i=this;if(f.hasClass("active"))return this.sliding=!1;var j=f[0],k=a.Event("slide.bs.carousel",{relatedTarget:j,direction:h});if(this.$element.trigger(k),!k.isDefaultPrevented()){if(this.sliding=!0,g&&this.pause(),this.$indicators.length){this.$indicators.find(".active").removeClass("active");var l=a(this.$indicators.children()[this.getItemIndex(f)]);l&&l.addClass("active")}var m=a.Event("slid.bs.carousel",{relatedTarget:j,direction:h});return a.support.transition&&this.$element.hasClass("slide")?(f.addClass(b),f[0].offsetWidth,e.addClass(h),f.addClass(h),e.one("bsTransitionEnd",function(){f.removeClass([b,h].join(" ")).addClass("active"),e.removeClass(["active",h].join(" ")),i.sliding=!1,setTimeout(function(){i.$element.trigger(m)},0)}).emulateTransitionEnd(c.TRANSITION_DURATION)):(e.removeClass("active"),f.addClass("active"),this.sliding=!1,this.$element.trigger(m)),g&&this.cycle(),this}};var d=a.fn.carousel;a.fn.carousel=b,a.fn.carousel.Constructor=c,a.fn.carousel.noConflict=function(){return a.fn.carousel=d,this};var e=function(c){var d,e=a(this),f=a(e.attr("data-target")||(d=e.attr("href"))&&d.replace(/.*(?=#[^\s]+$)/,""));if(f.hasClass("carousel")){var g=a.extend({},f.data(),e.data()),h=e.attr("data-slide-to");h&&(g.interval=!1),b.call(f,g),h&&f.data("bs.carousel").to(h),c.preventDefault()}};a(document).on("click.bs.carousel.data-api","[data-slide]",e).on("click.bs.carousel.data-api","[data-slide-to]",e),a(window).on("load",function(){a('[data-ride="carousel"]').each(function(){var c=a(this);b.call(c,c.data())})})}(jQuery),+function(a){"use strict";function b(b){var c,d=b.attr("data-target")||(c=b.attr("href"))&&c.replace(/.*(?=#[^\s]+$)/,"");return a(d)}function c(b){return this.each(function(){var c=a(this),e=c.data("bs.collapse"),f=a.extend({},d.DEFAULTS,c.data(),"object"==typeof b&&b);!e&&f.toggle&&/show|hide/.test(b)&&(f.toggle=!1),e||c.data("bs.collapse",e=new d(this,f)),"string"==typeof b&&e[b]()})}var d=function(b,c){this.$element=a(b),this.options=a.extend({},d.DEFAULTS,c),this.$trigger=a('[data-toggle="collapse"][href="#'+b.id+'"],[data-toggle="collapse"][data-target="#'+b.id+'"]'),this.transitioning=null,this.options.parent?this.$parent=this.getParent():this.addAriaAndCollapsedClass(this.$element,this.$trigger),this.options.toggle&&this.toggle()};d.VERSION="3.3.5",d.TRANSITION_DURATION=350,d.DEFAULTS={toggle:!0},d.prototype.dimension=function(){var a=this.$element.hasClass("width");return a?"width":"height"},d.prototype.show=function(){if(!this.transitioning&&!this.$element.hasClass("in")){var b,e=this.$parent&&this.$parent.children(".panel").children(".in, .collapsing");if(!(e&&e.length&&(b=e.data("bs.collapse"),b&&b.transitioning))){var f=a.Event("show.bs.collapse");if(this.$element.trigger(f),!f.isDefaultPrevented()){e&&e.length&&(c.call(e,"hide"),b||e.data("bs.collapse",null));var g=this.dimension();this.$element.removeClass("collapse").addClass("collapsing")[g](0).attr("aria-expanded",!0),this.$trigger.removeClass("collapsed").attr("aria-expanded",!0),this.transitioning=1;var h=function(){this.$element.removeClass("collapsing").addClass("collapse in")[g](""),this.transitioning=0,this.$element.trigger("shown.bs.collapse")};if(!a.support.transition)return h.call(this);var i=a.camelCase(["scroll",g].join("-"));this.$element.one("bsTransitionEnd",a.proxy(h,this)).emulateTransitionEnd(d.TRANSITION_DURATION)[g](this.$element[0][i])}}}},d.prototype.hide=function(){if(!this.transitioning&&this.$element.hasClass("in")){var b=a.Event("hide.bs.collapse");if(this.$element.trigger(b),!b.isDefaultPrevented()){var c=this.dimension();this.$element[c](this.$element[c]())[0].offsetHeight,this.$element.addClass("collapsing").removeClass("collapse in").attr("aria-expanded",!1),this.$trigger.addClass("collapsed").attr("aria-expanded",!1),this.transitioning=1;var e=function(){this.transitioning=0,this.$element.removeClass("collapsing").addClass("collapse").trigger("hidden.bs.collapse")};return a.support.transition?void this.$element[c](0).one("bsTransitionEnd",a.proxy(e,this)).emulateTransitionEnd(d.TRANSITION_DURATION):e.call(this)}}},d.prototype.toggle=function(){this[this.$element.hasClass("in")?"hide":"show"]()},d.prototype.getParent=function(){return a(this.options.parent).find('[data-toggle="collapse"][data-parent="'+this.options.parent+'"]').each(a.proxy(function(c,d){var e=a(d);this.addAriaAndCollapsedClass(b(e),e)},this)).end()},d.prototype.addAriaAndCollapsedClass=function(a,b){var c=a.hasClass("in");a.attr("aria-expanded",c),b.toggleClass("collapsed",!c).attr("aria-expanded",c)};var e=a.fn.collapse;a.fn.collapse=c,a.fn.collapse.Constructor=d,a.fn.collapse.noConflict=function(){return a.fn.collapse=e,this},a(document).on("click.bs.collapse.data-api",'[data-toggle="collapse"]',function(d){var e=a(this);e.attr("data-target")||d.preventDefault();var f=b(e),g=f.data("bs.collapse"),h=g?"toggle":e.data();c.call(f,h)})}(jQuery),+function(a){"use strict";function b(b){var c=b.attr("data-target");c||(c=b.attr("href"),c=c&&/#[A-Za-z]/.test(c)&&c.replace(/.*(?=#[^\s]*$)/,""));var d=c&&a(c);return d&&d.length?d:b.parent()}function c(c){c&&3===c.which||(a(e).remove(),a(f).each(function(){var d=a(this),e=b(d),f={relatedTarget:this};e.hasClass("open")&&(c&&"click"==c.type&&/input|textarea/i.test(c.target.tagName)&&a.contains(e[0],c.target)||(e.trigger(c=a.Event("hide.bs.dropdown",f)),c.isDefaultPrevented()||(d.attr("aria-expanded","false"),e.removeClass("open").trigger("hidden.bs.dropdown",f))))}))}function d(b){return this.each(function(){var c=a(this),d=c.data("bs.dropdown");d||c.data("bs.dropdown",d=new g(this)),"string"==typeof b&&d[b].call(c)})}var e=".dropdown-backdrop",f='[data-toggle="dropdown"]',g=function(b){a(b).on("click.bs.dropdown",this.toggle)};g.VERSION="3.3.5",g.prototype.toggle=function(d){var e=a(this);if(!e.is(".disabled, :disabled")){var f=b(e),g=f.hasClass("open");if(c(),!g){"ontouchstart"in document.documentElement&&!f.closest(".navbar-nav").length&&a(document.createElement("div")).addClass("dropdown-backdrop").insertAfter(a(this)).on("click",c);var h={relatedTarget:this};if(f.trigger(d=a.Event("show.bs.dropdown",h)),d.isDefaultPrevented())return;e.trigger("focus").attr("aria-expanded","true"),f.toggleClass("open").trigger("shown.bs.dropdown",h)}return!1}},g.prototype.keydown=function(c){if(/(38|40|27|32)/.test(c.which)&&!/input|textarea/i.test(c.target.tagName)){var d=a(this);if(c.preventDefault(),c.stopPropagation(),!d.is(".disabled, :disabled")){var e=b(d),g=e.hasClass("open");if(!g&&27!=c.which||g&&27==c.which)return 27==c.which&&e.find(f).trigger("focus"),d.trigger("click");var h=" li:not(.disabled):visible a",i=e.find(".dropdown-menu"+h);if(i.length){var j=i.index(c.target);38==c.which&&j>0&&j--,40==c.which&&j<i.length-1&&j++,~j||(j=0),i.eq(j).trigger("focus")}}}};var h=a.fn.dropdown;a.fn.dropdown=d,a.fn.dropdown.Constructor=g,a.fn.dropdown.noConflict=function(){return a.fn.dropdown=h,this},a(document).on("click.bs.dropdown.data-api",c).on("click.bs.dropdown.data-api",".dropdown form",function(a){a.stopPropagation()}).on("click.bs.dropdown.data-api",f,g.prototype.toggle).on("keydown.bs.dropdown.data-api",f,g.prototype.keydown).on("keydown.bs.dropdown.data-api",".dropdown-menu",g.prototype.keydown)}(jQuery),+function(a){"use strict";function b(b,d){return this.each(function(){var e=a(this),f=e.data("bs.modal"),g=a.extend({},c.DEFAULTS,e.data(),"object"==typeof b&&b);f||e.data("bs.modal",f=new c(this,g)),"string"==typeof b?f[b](d):g.show&&f.show(d)})}var c=function(b,c){this.options=c,this.$body=a(document.body),this.$element=a(b),this.$dialog=this.$element.find(".modal-dialog"),this.$backdrop=null,this.isShown=null,this.originalBodyPad=null,this.scrollbarWidth=0,this.ignoreBackdropClick=!1,this.options.remote&&this.$element.find(".modal-content").load(this.options.remote,a.proxy(function(){this.$element.trigger("loaded.bs.modal")},this))};c.VERSION="3.3.5",c.TRANSITION_DURATION=300,c.BACKDROP_TRANSITION_DURATION=150,c.DEFAULTS={backdrop:!0,keyboard:!0,show:!0},c.prototype.toggle=function(a){return this.isShown?this.hide():this.show(a)},c.prototype.show=function(b){var d=this,e=a.Event("show.bs.modal",{relatedTarget:b});this.$element.trigger(e),this.isShown||e.isDefaultPrevented()||(this.isShown=!0,this.checkScrollbar(),this.setScrollbar(),this.$body.addClass("modal-open"),this.escape(),this.resize(),this.$element.on("click.dismiss.bs.modal",'[data-dismiss="modal"]',a.proxy(this.hide,this)),this.$dialog.on("mousedown.dismiss.bs.modal",function(){d.$element.one("mouseup.dismiss.bs.modal",function(b){a(b.target).is(d.$element)&&(d.ignoreBackdropClick=!0)})}),this.backdrop(function(){var e=a.support.transition&&d.$element.hasClass("fade");d.$element.parent().length||d.$element.appendTo(d.$body),d.$element.show().scrollTop(0),d.adjustDialog(),e&&d.$element[0].offsetWidth,d.$element.addClass("in"),d.enforceFocus();var f=a.Event("shown.bs.modal",{relatedTarget:b});e?d.$dialog.one("bsTransitionEnd",function(){d.$element.trigger("focus").trigger(f)}).emulateTransitionEnd(c.TRANSITION_DURATION):d.$element.trigger("focus").trigger(f)}))},c.prototype.hide=function(b){b&&b.preventDefault(),b=a.Event("hide.bs.modal"),this.$element.trigger(b),this.isShown&&!b.isDefaultPrevented()&&(this.isShown=!1,this.escape(),this.resize(),a(document).off("focusin.bs.modal"),this.$element.removeClass("in").off("click.dismiss.bs.modal").off("mouseup.dismiss.bs.modal"),this.$dialog.off("mousedown.dismiss.bs.modal"),a.support.transition&&this.$element.hasClass("fade")?this.$element.one("bsTransitionEnd",a.proxy(this.hideModal,this)).emulateTransitionEnd(c.TRANSITION_DURATION):this.hideModal())},c.prototype.enforceFocus=function(){a(document).off("focusin.bs.modal").on("focusin.bs.modal",a.proxy(function(a){this.$element[0]===a.target||this.$element.has(a.target).length||this.$element.trigger("focus")},this))},c.prototype.escape=function(){this.isShown&&this.options.keyboard?this.$element.on("keydown.dismiss.bs.modal",a.proxy(function(a){27==a.which&&this.hide()},this)):this.isShown||this.$element.off("keydown.dismiss.bs.modal")},c.prototype.resize=function(){this.isShown?a(window).on("resize.bs.modal",a.proxy(this.handleUpdate,this)):a(window).off("resize.bs.modal")},c.prototype.hideModal=function(){var a=this;this.$element.hide(),this.backdrop(function(){a.$body.removeClass("modal-open"),a.resetAdjustments(),a.resetScrollbar(),a.$element.trigger("hidden.bs.modal")})},c.prototype.removeBackdrop=function(){this.$backdrop&&this.$backdrop.remove(),this.$backdrop=null},c.prototype.backdrop=function(b){var d=this,e=this.$element.hasClass("fade")?"fade":"";if(this.isShown&&this.options.backdrop){var f=a.support.transition&&e;if(this.$backdrop=a(document.createElement("div")).addClass("modal-backdrop "+e).appendTo(this.$body),this.$element.on("click.dismiss.bs.modal",a.proxy(function(a){return this.ignoreBackdropClick?void(this.ignoreBackdropClick=!1):void(a.target===a.currentTarget&&("static"==this.options.backdrop?this.$element[0].focus():this.hide()))},this)),f&&this.$backdrop[0].offsetWidth,this.$backdrop.addClass("in"),!b)return;f?this.$backdrop.one("bsTransitionEnd",b).emulateTransitionEnd(c.BACKDROP_TRANSITION_DURATION):b()}else if(!this.isShown&&this.$backdrop){this.$backdrop.removeClass("in");var g=function(){d.removeBackdrop(),b&&b()};a.support.transition&&this.$element.hasClass("fade")?this.$backdrop.one("bsTransitionEnd",g).emulateTransitionEnd(c.BACKDROP_TRANSITION_DURATION):g()}else b&&b()},c.prototype.handleUpdate=function(){this.adjustDialog()},c.prototype.adjustDialog=function(){var a=this.$element[0].scrollHeight>document.documentElement.clientHeight;this.$element.css({paddingLeft:!this.bodyIsOverflowing&&a?this.scrollbarWidth:"",paddingRight:this.bodyIsOverflowing&&!a?this.scrollbarWidth:""})},c.prototype.resetAdjustments=function(){this.$element.css({paddingLeft:"",paddingRight:""})},c.prototype.checkScrollbar=function(){var a=window.innerWidth;if(!a){var b=document.documentElement.getBoundingClientRect();a=b.right-Math.abs(b.left)}this.bodyIsOverflowing=document.body.clientWidth<a,this.scrollbarWidth=this.measureScrollbar()},c.prototype.setScrollbar=function(){var a=parseInt(this.$body.css("padding-right")||0,10);this.originalBodyPad=document.body.style.paddingRight||"",this.bodyIsOverflowing&&this.$body.css("padding-right",a+this.scrollbarWidth)},c.prototype.resetScrollbar=function(){this.$body.css("padding-right",this.originalBodyPad)},c.prototype.measureScrollbar=function(){var a=document.createElement("div");a.className="modal-scrollbar-measure",this.$body.append(a);var b=a.offsetWidth-a.clientWidth;return this.$body[0].removeChild(a),b};var d=a.fn.modal;a.fn.modal=b,a.fn.modal.Constructor=c,a.fn.modal.noConflict=function(){return a.fn.modal=d,this},a(document).on("click.bs.modal.data-api",'[data-toggle="modal"]',function(c){var d=a(this),e=d.attr("href"),f=a(d.attr("data-target")||e&&e.replace(/.*(?=#[^\s]+$)/,"")),g=f.data("bs.modal")?"toggle":a.extend({remote:!/#/.test(e)&&e},f.data(),d.data());d.is("a")&&c.preventDefault(),f.one("show.bs.modal",function(a){a.isDefaultPrevented()||f.one("hidden.bs.modal",function(){d.is(":visible")&&d.trigger("focus")})}),b.call(f,g,this)})}(jQuery),+function(a){"use strict";function b(b){return this.each(function(){var d=a(this),e=d.data("bs.tooltip"),f="object"==typeof b&&b;(e||!/destroy|hide/.test(b))&&(e||d.data("bs.tooltip",e=new c(this,f)),"string"==typeof b&&e[b]())})}var c=function(a,b){this.type=null,this.options=null,this.enabled=null,this.timeout=null,this.hoverState=null,this.$element=null,this.inState=null,this.init("tooltip",a,b)};c.VERSION="3.3.5",c.TRANSITION_DURATION=150,c.DEFAULTS={animation:!0,placement:"top",selector:!1,template:'<div class="tooltip" role="tooltip"><div class="tooltip-arrow"></div><div class="tooltip-inner"></div></div>',trigger:"hover focus",title:"",delay:0,html:!1,container:!1,viewport:{selector:"body",padding:0}},c.prototype.init=function(b,c,d){if(this.enabled=!0,this.type=b,this.$element=a(c),this.options=this.getOptions(d),this.$viewport=this.options.viewport&&a(a.isFunction(this.options.viewport)?this.options.viewport.call(this,this.$element):this.options.viewport.selector||this.options.viewport),this.inState={click:!1,hover:!1,focus:!1},this.$element[0]instanceof document.constructor&&!this.options.selector)throw new Error("`selector` option must be specified when initializing "+this.type+" on the window.document object!");for(var e=this.options.trigger.split(" "),f=e.length;f--;){var g=e[f];if("click"==g)this.$element.on("click."+this.type,this.options.selector,a.proxy(this.toggle,this));else if("manual"!=g){var h="hover"==g?"mouseenter":"focusin",i="hover"==g?"mouseleave":"focusout";this.$element.on(h+"."+this.type,this.options.selector,a.proxy(this.enter,this)),this.$element.on(i+"."+this.type,this.options.selector,a.proxy(this.leave,this))}}this.options.selector?this._options=a.extend({},this.options,{trigger:"manual",selector:""}):this.fixTitle()},c.prototype.getDefaults=function(){return c.DEFAULTS},c.prototype.getOptions=function(b){return b=a.extend({},this.getDefaults(),this.$element.data(),b),b.delay&&"number"==typeof b.delay&&(b.delay={show:b.delay,hide:b.delay}),b},c.prototype.getDelegateOptions=function(){var b={},c=this.getDefaults();return this._options&&a.each(this._options,function(a,d){c[a]!=d&&(b[a]=d)}),b},c.prototype.enter=function(b){var c=b instanceof this.constructor?b:a(b.currentTarget).data("bs."+this.type);return c||(c=new this.constructor(b.currentTarget,this.getDelegateOptions()),a(b.currentTarget).data("bs."+this.type,c)),b instanceof a.Event&&(c.inState["focusin"==b.type?"focus":"hover"]=!0),c.tip().hasClass("in")||"in"==c.hoverState?void(c.hoverState="in"):(clearTimeout(c.timeout),c.hoverState="in",c.options.delay&&c.options.delay.show?void(c.timeout=setTimeout(function(){"in"==c.hoverState&&c.show()},c.options.delay.show)):c.show())},c.prototype.isInStateTrue=function(){for(var a in this.inState)if(this.inState[a])return!0;return!1},c.prototype.leave=function(b){var c=b instanceof this.constructor?b:a(b.currentTarget).data("bs."+this.type);return c||(c=new this.constructor(b.currentTarget,this.getDelegateOptions()),a(b.currentTarget).data("bs."+this.type,c)),b instanceof a.Event&&(c.inState["focusout"==b.type?"focus":"hover"]=!1),c.isInStateTrue()?void 0:(clearTimeout(c.timeout),c.hoverState="out",c.options.delay&&c.options.delay.hide?void(c.timeout=setTimeout(function(){"out"==c.hoverState&&c.hide()},c.options.delay.hide)):c.hide())},c.prototype.show=function(){var b=a.Event("show.bs."+this.type);if(this.hasContent()&&this.enabled){this.$element.trigger(b);var d=a.contains(this.$element[0].ownerDocument.documentElement,this.$element[0]);if(b.isDefaultPrevented()||!d)return;var e=this,f=this.tip(),g=this.getUID(this.type);this.setContent(),f.attr("id",g),this.$element.attr("aria-describedby",g),this.options.animation&&f.addClass("fade");var h="function"==typeof this.options.placement?this.options.placement.call(this,f[0],this.$element[0]):this.options.placement,i=/\s?auto?\s?/i,j=i.test(h);j&&(h=h.replace(i,"")||"top"),f.detach().css({top:0,left:0,display:"block"}).addClass(h).data("bs."+this.type,this),this.options.container?f.appendTo(this.options.container):f.insertAfter(this.$element),this.$element.trigger("inserted.bs."+this.type);var k=this.getPosition(),l=f[0].offsetWidth,m=f[0].offsetHeight;if(j){var n=h,o=this.getPosition(this.$viewport);h="bottom"==h&&k.bottom+m>o.bottom?"top":"top"==h&&k.top-m<o.top?"bottom":"right"==h&&k.right+l>o.width?"left":"left"==h&&k.left-l<o.left?"right":h,f.removeClass(n).addClass(h)}var p=this.getCalculatedOffset(h,k,l,m);this.applyPlacement(p,h);var q=function(){var a=e.hoverState;e.$element.trigger("shown.bs."+e.type),e.hoverState=null,"out"==a&&e.leave(e)};a.support.transition&&this.$tip.hasClass("fade")?f.one("bsTransitionEnd",q).emulateTransitionEnd(c.TRANSITION_DURATION):q()}},c.prototype.applyPlacement=function(b,c){var d=this.tip(),e=d[0].offsetWidth,f=d[0].offsetHeight,g=parseInt(d.css("margin-top"),10),h=parseInt(d.css("margin-left"),10);isNaN(g)&&(g=0),isNaN(h)&&(h=0),b.top+=g,b.left+=h,a.offset.setOffset(d[0],a.extend({using:function(a){d.css({top:Math.round(a.top),left:Math.round(a.left)})}},b),0),d.addClass("in");var i=d[0].offsetWidth,j=d[0].offsetHeight;"top"==c&&j!=f&&(b.top=b.top+f-j);var k=this.getViewportAdjustedDelta(c,b,i,j);k.left?b.left+=k.left:b.top+=k.top;var l=/top|bottom/.test(c),m=l?2*k.left-e+i:2*k.top-f+j,n=l?"offsetWidth":"offsetHeight";d.offset(b),this.replaceArrow(m,d[0][n],l)},c.prototype.replaceArrow=function(a,b,c){this.arrow().css(c?"left":"top",50*(1-a/b)+"%").css(c?"top":"left","")},c.prototype.setContent=function(){var a=this.tip(),b=this.getTitle();a.find(".tooltip-inner")[this.options.html?"html":"text"](b),a.removeClass("fade in top bottom left right")},c.prototype.hide=function(b){function d(){"in"!=e.hoverState&&f.detach(),e.$element.removeAttr("aria-describedby").trigger("hidden.bs."+e.type),b&&b()}var e=this,f=a(this.$tip),g=a.Event("hide.bs."+this.type);return this.$element.trigger(g),g.isDefaultPrevented()?void 0:(f.removeClass("in"),a.support.transition&&f.hasClass("fade")?f.one("bsTransitionEnd",d).emulateTransitionEnd(c.TRANSITION_DURATION):d(),this.hoverState=null,this)},c.prototype.fixTitle=function(){var a=this.$element;(a.attr("title")||"string"!=typeof a.attr("data-original-title"))&&a.attr("data-original-title",a.attr("title")||"").attr("title","")},c.prototype.hasContent=function(){return this.getTitle()},c.prototype.getPosition=function(b){b=b||this.$element;var c=b[0],d="BODY"==c.tagName,e=c.getBoundingClientRect();null==e.width&&(e=a.extend({},e,{width:e.right-e.left,height:e.bottom-e.top}));var f=d?{top:0,left:0}:b.offset(),g={scroll:d?document.documentElement.scrollTop||document.body.scrollTop:b.scrollTop()},h=d?{width:a(window).width(),height:a(window).height()}:null;return a.extend({},e,g,h,f)},c.prototype.getCalculatedOffset=function(a,b,c,d){return"bottom"==a?{top:b.top+b.height,left:b.left+b.width/2-c/2}:"top"==a?{top:b.top-d,left:b.left+b.width/2-c/2}:"left"==a?{top:b.top+b.height/2-d/2,left:b.left-c}:{top:b.top+b.height/2-d/2,left:b.left+b.width}},c.prototype.getViewportAdjustedDelta=function(a,b,c,d){var e={top:0,left:0};if(!this.$viewport)return e;var f=this.options.viewport&&this.options.viewport.padding||0,g=this.getPosition(this.$viewport);if(/right|left/.test(a)){var h=b.top-f-g.scroll,i=b.top+f-g.scroll+d;h<g.top?e.top=g.top-h:i>g.top+g.height&&(e.top=g.top+g.height-i)}else{var j=b.left-f,k=b.left+f+c;j<g.left?e.left=g.left-j:k>g.right&&(e.left=g.left+g.width-k)}return e},c.prototype.getTitle=function(){var a,b=this.$element,c=this.options;return a=b.attr("data-original-title")||("function"==typeof c.title?c.title.call(b[0]):c.title)},c.prototype.getUID=function(a){do a+=~~(1e6*Math.random());while(document.getElementById(a));return a},c.prototype.tip=function(){if(!this.$tip&&(this.$tip=a(this.options.template),1!=this.$tip.length))throw new Error(this.type+" `template` option must consist of exactly 1 top-level element!");return this.$tip},c.prototype.arrow=function(){return this.$arrow=this.$arrow||this.tip().find(".tooltip-arrow")},c.prototype.enable=function(){this.enabled=!0},c.prototype.disable=function(){this.enabled=!1},c.prototype.toggleEnabled=function(){this.enabled=!this.enabled},c.prototype.toggle=function(b){var c=this;b&&(c=a(b.currentTarget).data("bs."+this.type),c||(c=new this.constructor(b.currentTarget,this.getDelegateOptions()),a(b.currentTarget).data("bs."+this.type,c))),b?(c.inState.click=!c.inState.click,c.isInStateTrue()?c.enter(c):c.leave(c)):c.tip().hasClass("in")?c.leave(c):c.enter(c)},c.prototype.destroy=function(){var a=this;clearTimeout(this.timeout),this.hide(function(){a.$element.off("."+a.type).removeData("bs."+a.type),a.$tip&&a.$tip.detach(),a.$tip=null,a.$arrow=null,a.$viewport=null})};var d=a.fn.tooltip;a.fn.tooltip=b,a.fn.tooltip.Constructor=c,a.fn.tooltip.noConflict=function(){return a.fn.tooltip=d,this}}(jQuery),+function(a){"use strict";function b(b){return this.each(function(){var d=a(this),e=d.data("bs.popover"),f="object"==typeof b&&b;(e||!/destroy|hide/.test(b))&&(e||d.data("bs.popover",e=new c(this,f)),"string"==typeof b&&e[b]())})}var c=function(a,b){this.init("popover",a,b)};if(!a.fn.tooltip)throw new Error("Popover requires tooltip.js");c.VERSION="3.3.5",c.DEFAULTS=a.extend({},a.fn.tooltip.Constructor.DEFAULTS,{placement:"right",trigger:"click",content:"",template:'<div class="popover" role="tooltip"><div class="arrow"></div><h3 class="popover-title"></h3><div class="popover-content"></div></div>'}),c.prototype=a.extend({},a.fn.tooltip.Constructor.prototype),c.prototype.constructor=c,c.prototype.getDefaults=function(){return c.DEFAULTS},c.prototype.setContent=function(){var a=this.tip(),b=this.getTitle(),c=this.getContent();a.find(".popover-title")[this.options.html?"html":"text"](b),a.find(".popover-content").children().detach().end()[this.options.html?"string"==typeof c?"html":"append":"text"](c),a.removeClass("fade top bottom left right in"),a.find(".popover-title").html()||a.find(".popover-title").hide()},c.prototype.hasContent=function(){return this.getTitle()||this.getContent()},c.prototype.getContent=function(){var a=this.$element,b=this.options;return a.attr("data-content")||("function"==typeof b.content?b.content.call(a[0]):b.content)},c.prototype.arrow=function(){return this.$arrow=this.$arrow||this.tip().find(".arrow")};var d=a.fn.popover;a.fn.popover=b,a.fn.popover.Constructor=c,a.fn.popover.noConflict=function(){return a.fn.popover=d,this}}(jQuery),+function(a){"use strict";function b(c,d){this.$body=a(document.body),this.$scrollElement=a(a(c).is(document.body)?window:c),this.options=a.extend({},b.DEFAULTS,d),this.selector=(this.options.target||"")+" .nav li > a",this.offsets=[],this.targets=[],this.activeTarget=null,this.scrollHeight=0,this.$scrollElement.on("scroll.bs.scrollspy",a.proxy(this.process,this)),this.refresh(),this.process()}function c(c){return this.each(function(){var d=a(this),e=d.data("bs.scrollspy"),f="object"==typeof c&&c;e||d.data("bs.scrollspy",e=new b(this,f)),"string"==typeof c&&e[c]()})}b.VERSION="3.3.5",b.DEFAULTS={offset:10},b.prototype.getScrollHeight=function(){return this.$scrollElement[0].scrollHeight||Math.max(this.$body[0].scrollHeight,document.documentElement.scrollHeight)},b.prototype.refresh=function(){var b=this,c="offset",d=0;this.offsets=[],this.targets=[],this.scrollHeight=this.getScrollHeight(),a.isWindow(this.$scrollElement[0])||(c="position",d=this.$scrollElement.scrollTop()),this.$body.find(this.selector).map(function(){var b=a(this),e=b.data("target")||b.attr("href"),f=/^#./.test(e)&&a(e);return f&&f.length&&f.is(":visible")&&[[f[c]().top+d,e]]||null}).sort(function(a,b){return a[0]-b[0]}).each(function(){b.offsets.push(this[0]),b.targets.push(this[1])})},b.prototype.process=function(){var a,b=this.$scrollElement.scrollTop()+this.options.offset,c=this.getScrollHeight(),d=this.options.offset+c-this.$scrollElement.height(),e=this.offsets,f=this.targets,g=this.activeTarget;if(this.scrollHeight!=c&&this.refresh(),b>=d)return g!=(a=f[f.length-1])&&this.activate(a);if(g&&b<e[0])return this.activeTarget=null,this.clear();for(a=e.length;a--;)g!=f[a]&&b>=e[a]&&(void 0===e[a+1]||b<e[a+1])&&this.activate(f[a])},b.prototype.activate=function(b){this.activeTarget=b,this.clear();var c=this.selector+'[data-target="'+b+'"],'+this.selector+'[href="'+b+'"]',d=a(c).parents("li").addClass("active");d.parent(".dropdown-menu").length&&(d=d.closest("li.dropdown").addClass("active")),
d.trigger("activate.bs.scrollspy")},b.prototype.clear=function(){a(this.selector).parentsUntil(this.options.target,".active").removeClass("active")};var d=a.fn.scrollspy;a.fn.scrollspy=c,a.fn.scrollspy.Constructor=b,a.fn.scrollspy.noConflict=function(){return a.fn.scrollspy=d,this},a(window).on("load.bs.scrollspy.data-api",function(){a('[data-spy="scroll"]').each(function(){var b=a(this);c.call(b,b.data())})})}(jQuery),+function(a){"use strict";function b(b){return this.each(function(){var d=a(this),e=d.data("bs.tab");e||d.data("bs.tab",e=new c(this)),"string"==typeof b&&e[b]()})}var c=function(b){this.element=a(b)};c.VERSION="3.3.5",c.TRANSITION_DURATION=150,c.prototype.show=function(){var b=this.element,c=b.closest("ul:not(.dropdown-menu)"),d=b.data("target");if(d||(d=b.attr("href"),d=d&&d.replace(/.*(?=#[^\s]*$)/,"")),!b.parent("li").hasClass("active")){var e=c.find(".active:last a"),f=a.Event("hide.bs.tab",{relatedTarget:b[0]}),g=a.Event("show.bs.tab",{relatedTarget:e[0]});if(e.trigger(f),b.trigger(g),!g.isDefaultPrevented()&&!f.isDefaultPrevented()){var h=a(d);this.activate(b.closest("li"),c),this.activate(h,h.parent(),function(){e.trigger({type:"hidden.bs.tab",relatedTarget:b[0]}),b.trigger({type:"shown.bs.tab",relatedTarget:e[0]})})}}},c.prototype.activate=function(b,d,e){function f(){g.removeClass("active").find("> .dropdown-menu > .active").removeClass("active").end().find('[data-toggle="tab"]').attr("aria-expanded",!1),b.addClass("active").find('[data-toggle="tab"]').attr("aria-expanded",!0),h?(b[0].offsetWidth,b.addClass("in")):b.removeClass("fade"),b.parent(".dropdown-menu").length&&b.closest("li.dropdown").addClass("active").end().find('[data-toggle="tab"]').attr("aria-expanded",!0),e&&e()}var g=d.find("> .active"),h=e&&a.support.transition&&(g.length&&g.hasClass("fade")||!!d.find("> .fade").length);g.length&&h?g.one("bsTransitionEnd",f).emulateTransitionEnd(c.TRANSITION_DURATION):f(),g.removeClass("in")};var d=a.fn.tab;a.fn.tab=b,a.fn.tab.Constructor=c,a.fn.tab.noConflict=function(){return a.fn.tab=d,this};var e=function(c){c.preventDefault(),b.call(a(this),"show")};a(document).on("click.bs.tab.data-api",'[data-toggle="tab"]',e).on("click.bs.tab.data-api",'[data-toggle="pill"]',e)}(jQuery),+function(a){"use strict";function b(b){return this.each(function(){var d=a(this),e=d.data("bs.affix"),f="object"==typeof b&&b;e||d.data("bs.affix",e=new c(this,f)),"string"==typeof b&&e[b]()})}var c=function(b,d){this.options=a.extend({},c.DEFAULTS,d),this.$target=a(this.options.target).on("scroll.bs.affix.data-api",a.proxy(this.checkPosition,this)).on("click.bs.affix.data-api",a.proxy(this.checkPositionWithEventLoop,this)),this.$element=a(b),this.affixed=null,this.unpin=null,this.pinnedOffset=null,this.checkPosition()};c.VERSION="3.3.5",c.RESET="affix affix-top affix-bottom",c.DEFAULTS={offset:0,target:window},c.prototype.getState=function(a,b,c,d){var e=this.$target.scrollTop(),f=this.$element.offset(),g=this.$target.height();if(null!=c&&"top"==this.affixed)return c>e?"top":!1;if("bottom"==this.affixed)return null!=c?e+this.unpin<=f.top?!1:"bottom":a-d>=e+g?!1:"bottom";var h=null==this.affixed,i=h?e:f.top,j=h?g:b;return null!=c&&c>=e?"top":null!=d&&i+j>=a-d?"bottom":!1},c.prototype.getPinnedOffset=function(){if(this.pinnedOffset)return this.pinnedOffset;this.$element.removeClass(c.RESET).addClass("affix");var a=this.$target.scrollTop(),b=this.$element.offset();return this.pinnedOffset=b.top-a},c.prototype.checkPositionWithEventLoop=function(){setTimeout(a.proxy(this.checkPosition,this),1)},c.prototype.checkPosition=function(){if(this.$element.is(":visible")){var b=this.$element.height(),d=this.options.offset,e=d.top,f=d.bottom,g=Math.max(a(document).height(),a(document.body).height());"object"!=typeof d&&(f=e=d),"function"==typeof e&&(e=d.top(this.$element)),"function"==typeof f&&(f=d.bottom(this.$element));var h=this.getState(g,b,e,f);if(this.affixed!=h){null!=this.unpin&&this.$element.css("top","");var i="affix"+(h?"-"+h:""),j=a.Event(i+".bs.affix");if(this.$element.trigger(j),j.isDefaultPrevented())return;this.affixed=h,this.unpin="bottom"==h?this.getPinnedOffset():null,this.$element.removeClass(c.RESET).addClass(i).trigger(i.replace("affix","affixed")+".bs.affix")}"bottom"==h&&this.$element.offset({top:g-b-f})}};var d=a.fn.affix;a.fn.affix=b,a.fn.affix.Constructor=c,a.fn.affix.noConflict=function(){return a.fn.affix=d,this},a(window).on("load",function(){a('[data-spy="affix"]').each(function(){var c=a(this),d=c.data();d.offset=d.offset||{},null!=d.offsetBottom&&(d.offset.bottom=d.offsetBottom),null!=d.offsetTop&&(d.offset.top=d.offsetTop),b.call(c,d)})})}(jQuery);"></script>
<script src="data:application/x-javascript;base64,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"></script>
<script src="data:application/x-javascript;base64,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"></script>
<link href="data:text/css;charset=utf-8,%2Epagedtable%20%7B%0Aoverflow%3A%20auto%3B%0Apadding%2Dleft%3A%208px%3B%0Apadding%2Dright%3A%208px%3B%0A%7D%0A%2Epagedtable%2Dwrapper%20%7B%0Aborder%3A%201px%20solid%20%23ccc%3B%0Aborder%2Dradius%3A%204px%3B%0Amargin%2Dbottom%3A%2010px%3B%0A%7D%0A%2Epagedtable%20table%20%7B%0Awidth%3A%20100%25%3B%0Amax%2Dwidth%3A%20100%25%3B%0Amargin%3A%200%3B%0A%7D%0A%2Epagedtable%20th%20%7B%0Apadding%3A%200%205px%200%205px%3B%0Aborder%3A%20none%3B%0Aborder%2Dbottom%3A%202px%20solid%20%23dddddd%3B%0Amin%2Dwidth%3A%2045px%3B%0A%7D%0A%2Epagedtable%2Dempty%20th%20%7B%0Adisplay%3A%20none%3B%0A%7D%0A%2Epagedtable%20td%20%7B%0Apadding%3A%200%204px%200%204px%3B%0A%7D%0A%2Epagedtable%20%2Eeven%20%7B%0Abackground%2Dcolor%3A%20rgba%28140%2C%20140%2C%20140%2C%200%2E1%29%3B%0A%7D%0A%2Epagedtable%2Dpadding%2Dcol%20%7B%0Adisplay%3A%20none%3B%0A%7D%0A%2Epagedtable%20a%20%7B%0A%2Dwebkit%2Dtouch%2Dcallout%3A%20none%3B%0A%2Dwebkit%2Duser%2Dselect%3A%20none%3B%0A%2Dkhtml%2Duser%2Dselect%3A%20none%3B%0A%2Dmoz%2Duser%2Dselect%3A%20none%3B%0A%2Dms%2Duser%2Dselect%3A%20none%3B%0Auser%2Dselect%3A%20none%3B%0A%7D%0A%2Epagedtable%2Dindex%2Dnav%20%7B%0Acursor%3A%20pointer%3B%0Apadding%3A%200%205px%200%205px%3B%0Afloat%3A%20right%3B%0Aborder%3A%200%3B%0A%7D%0A%2Epagedtable%2Dindex%2Dnav%2Ddisabled%20%7B%0Acursor%3A%20default%3B%0Atext%2Ddecoration%3A%20none%3B%0Acolor%3A%20%23999%3B%0A%7D%0Aa%2Epagedtable%2Dindex%2Dnav%2Ddisabled%3Ahover%20%7B%0Atext%2Ddecoration%3A%20none%3B%0Acolor%3A%20%23999%3B%0A%7D%0A%2Epagedtable%2Dindexes%20%7B%0Acursor%3A%20pointer%3B%0Afloat%3A%20right%3B%0Aborder%3A%200%3B%0A%7D%0A%2Epagedtable%2Dindex%2Dcurrent%20%7B%0Acursor%3A%20default%3B%0Atext%2Ddecoration%3A%20none%3B%0Afont%2Dweight%3A%20bold%3B%0Acolor%3A%20%23333%3B%0Aborder%3A%200%3B%0A%7D%0Aa%2Epagedtable%2Dindex%2Dcurrent%3Ahover%20%7B%0Atext%2Ddecoration%3A%20none%3B%0Afont%2Dweight%3A%20bold%3B%0Acolor%3A%20%23333%3B%0A%7D%0A%2Epagedtable%2Dindex%20%7B%0Awidth%3A%2030px%3B%0Adisplay%3A%20inline%2Dblock%3B%0Atext%2Dalign%3A%20center%3B%0Aborder%3A%200%3B%0A%7D%0A%2Epagedtable%2Dindex%2Dseparator%2Dleft%20%7B%0Adisplay%3A%20inline%2Dblock%3B%0Acolor%3A%20%23333%3B%0Afont%2Dsize%3A%209px%3B%0Apadding%3A%200%200%200%200%3B%0Acursor%3A%20default%3B%0A%7D%0A%2Epagedtable%2Dindex%2Dseparator%2Dright%20%7B%0Adisplay%3A%20inline%2Dblock%3B%0Acolor%3A%20%23333%3B%0Afont%2Dsize%3A%209px%3B%0Apadding%3A%200%204px%200%200%3B%0Acursor%3A%20default%3B%0A%7D%0A%2Epagedtable%2Dfooter%20%7B%0Apadding%2Dtop%3A%204px%3B%0Apadding%2Dbottom%3A%205px%3B%0A%7D%0A%2Epagedtable%2Dnot%2Dempty%20%2Epagedtable%2Dfooter%20%7B%0Aborder%2Dtop%3A%202px%20solid%20%23dddddd%3B%0A%7D%0A%2Epagedtable%2Dinfo%20%7B%0Aoverflow%3A%20hidden%3B%0Acolor%3A%20%23999%3B%0Awhite%2Dspace%3A%20nowrap%3B%0Atext%2Doverflow%3A%20ellipsis%3B%0A%7D%0A%2Epagedtable%2Dheader%2Dname%20%7B%0Aoverflow%3A%20hidden%3B%0Atext%2Doverflow%3A%20ellipsis%3B%0A%7D%0A%2Epagedtable%2Dheader%2Dtype%20%7B%0Acolor%3A%20%23999%3B%0Afont%2Dweight%3A%20400%3B%0A%7D%0A%2Epagedtable%2Dna%2Dcell%20%7B%0Afont%2Dstyle%3A%20italic%3B%0Aopacity%3A%200%2E3%3B%0A%7D%0A" rel="stylesheet" />
<script src="data:application/x-javascript;base64,// Production steps of ECMA-262, Edition 5, 15.4.4.18
// Reference: http://es5.github.io/#x15.4.4.18
if (!Array.prototype.forEach) {

  Array.prototype.forEach = function(callback, thisArg) {

    var T, k;

    if (this === null) {
      throw new TypeError(' this is null or not defined');
    }

    // 1. Let O be the result of calling toObject() passing the
    // |this| value as the argument.
    var O = Object(this);

    // 2. Let lenValue be the result of calling the Get() internal
    // method of O with the argument "length".
    // 3. Let len be toUint32(lenValue).
    var len = O.length >>> 0;

    // 4. If isCallable(callback) is false, throw a TypeError exception.
    // See: http://es5.github.com/#x9.11
    if (typeof callback !== "function") {
      throw new TypeError(callback + ' is not a function');
    }

    // 5. If thisArg was supplied, let T be thisArg; else let
    // T be undefined.
    if (arguments.length > 1) {
      T = thisArg;
    }

    // 6. Let k be 0
    k = 0;

    // 7. Repeat, while k < len
    while (k < len) {

      var kValue;

      // a. Let Pk be ToString(k).
      //    This is implicit for LHS operands of the in operator
      // b. Let kPresent be the result of calling the HasProperty
      //    internal method of O with argument Pk.
      //    This step can be combined with c
      // c. If kPresent is true, then
      if (k in O) {

        // i. Let kValue be the result of calling the Get internal
        // method of O with argument Pk.
        kValue = O[k];

        // ii. Call the Call internal method of callback with T as
        // the this value and argument list containing kValue, k, and O.
        callback.call(T, kValue, k, O);
      }
      // d. Increase k by 1.
      k++;
    }
    // 8. return undefined
  };
}

// Production steps of ECMA-262, Edition 5, 15.4.4.19
// Reference: http://es5.github.io/#x15.4.4.19
if (!Array.prototype.map) {

  Array.prototype.map = function(callback, thisArg) {

    var T, A, k;

    if (this == null) {
      throw new TypeError(' this is null or not defined');
    }

    // 1. Let O be the result of calling ToObject passing the |this|
    //    value as the argument.
    var O = Object(this);

    // 2. Let lenValue be the result of calling the Get internal
    //    method of O with the argument "length".
    // 3. Let len be ToUint32(lenValue).
    var len = O.length >>> 0;

    // 4. If IsCallable(callback) is false, throw a TypeError exception.
    // See: http://es5.github.com/#x9.11
    if (typeof callback !== 'function') {
      throw new TypeError(callback + ' is not a function');
    }

    // 5. If thisArg was supplied, let T be thisArg; else let T be undefined.
    if (arguments.length > 1) {
      T = thisArg;
    }

    // 6. Let A be a new array created as if by the expression new Array(len)
    //    where Array is the standard built-in constructor with that name and
    //    len is the value of len.
    A = new Array(len);

    // 7. Let k be 0
    k = 0;

    // 8. Repeat, while k < len
    while (k < len) {

      var kValue, mappedValue;

      // a. Let Pk be ToString(k).
      //   This is implicit for LHS operands of the in operator
      // b. Let kPresent be the result of calling the HasProperty internal
      //    method of O with argument Pk.
      //   This step can be combined with c
      // c. If kPresent is true, then
      if (k in O) {

        // i. Let kValue be the result of calling the Get internal
        //    method of O with argument Pk.
        kValue = O[k];

        // ii. Let mappedValue be the result of calling the Call internal
        //     method of callback with T as the this value and argument
        //     list containing kValue, k, and O.
        mappedValue = callback.call(T, kValue, k, O);

        // iii. Call the DefineOwnProperty internal method of A with arguments
        // Pk, Property Descriptor
        // { Value: mappedValue,
        //   Writable: true,
        //   Enumerable: true,
        //   Configurable: true },
        // and false.

        // In browsers that support Object.defineProperty, use the following:
        // Object.defineProperty(A, k, {
        //   value: mappedValue,
        //   writable: true,
        //   enumerable: true,
        //   configurable: true
        // });

        // For best browser support, use the following:
        A[k] = mappedValue;
      }
      // d. Increase k by 1.
      k++;
    }

    // 9. return A
    return A;
  };
}

var PagedTable = function (pagedTable) {
  var me = this;

  var source = function(pagedTable) {
    var sourceElems = [].slice.call(pagedTable.children).filter(function(e) {
      return e.hasAttribute("data-pagedtable-source");
    });

    if (sourceElems === null || sourceElems.length !== 1) {
      throw("A single data-pagedtable-source was not found");
    }

    return JSON.parse(sourceElems[0].innerHTML);
  }(pagedTable);

  var options = function(source) {
    var options = typeof(source.options) !== "undefined" &&
      source.options !== null ? source.options : {};

    var columns = typeof(options.columns) !== "undefined" ? options.columns : {};
    var rows = typeof(options.rows) !== "undefined" ? options.rows : {};

    var positiveIntOrNull = function(value) {
      return parseInt(value) >= 0 ? parseInt(value) : null;
    };

    return {
      pages: positiveIntOrNull(options.pages),
      rows: {
        min: positiveIntOrNull(rows.min),
        max: positiveIntOrNull(rows.max),
        total: positiveIntOrNull(rows.total)
      },
      columns: {
        min: positiveIntOrNull(columns.min),
        max: positiveIntOrNull(columns.max),
        total: positiveIntOrNull(columns.total)
      }
    };
  }(source);

  var Measurer = function() {

    // set some default initial values that will get adjusted in runtime
    me.measures = {
      padding: 12,
      character: 8,
      height: 15,
      defaults: true
    };

    me.calculate = function(measuresCell) {
      if (!me.measures.defaults)
        return;

      var measuresCellStyle = window.getComputedStyle(measuresCell, null);

      var newPadding = parsePadding(measuresCellStyle.paddingLeft) +
            parsePadding(measuresCellStyle.paddingRight);

      var sampleString = "ABCDEFGHIJ0123456789";
      var newCharacter = Math.ceil(measuresCell.clientWidth / sampleString.length);

      if (newPadding <= 0 || newCharacter <= 0)
        return;

      me.measures.padding = newPadding;
      me.measures.character = newCharacter;
      me.measures.height = measuresCell.clientHeight;
      me.measures.defaults = false;
    };

    return me;
  };

  var Page = function(data, options) {
    var me = this;

    var defaults = {
      max: 7,
      rows: 10
    };

    var totalPages = function() {
      return Math.ceil(data.length / me.rows);
    };

    me.number = 0;
    me.max = options.pages !== null ? options.pages : defaults.max;
    me.visible = me.max;
    me.rows = options.rows.min !== null ? options.rows.min : defaults.rows;
    me.total = totalPages();

    me.setRows = function(newRows) {
      me.rows = newRows;
      me.total = totalPages();
    };

    me.setPageNumber = function(newPageNumber) {
      if (newPageNumber < 0) newPageNumber = 0;
      if (newPageNumber >= me.total) newPageNumber = me.total - 1;

      me.number = newPageNumber;
    };

    me.setVisiblePages = function(visiblePages) {
      me.visible = Math.min(me.max, visiblePages);
      me.setPageNumber(me.number);
    };

    me.getVisiblePageRange = function() {
      var start = me.number - Math.max(Math.floor((me.visible - 1) / 2), 0);
      var end = me.number + Math.floor(me.visible / 2) + 1;
      var pageCount = me.total;

      if (start < 0) {
        var diffToStart = 0 - start;
        start += diffToStart;
        end += diffToStart;
      }

      if (end > pageCount) {
        var diffToEnd = end - pageCount;
        start -= diffToEnd;
        end -= diffToEnd;
      }

      start = start < 0 ? 0 : start;
      end = end >= pageCount ? pageCount : end;

      var first = false;
      var last = false;

      if (start > 0 && me.visible > 1) {
        start = start + 1;
        first = true;
      }

      if (end < pageCount && me.visible > 2) {
        end = end - 1;
        last = true;
      }

      return {
        first: first,
        start: start,
        end: end,
        last: last
      };
    };

    me.getRowStart = function() {
      var rowStart = page.number * page.rows;
      if (rowStart < 0)
        rowStart = 0;

      return rowStart;
    };

    me.getRowEnd = function() {
      var rowStart = me.getRowStart();
      return Math.min(rowStart + me.rows, data.length);
    };

    me.getPaddingRows = function() {
      var rowStart = me.getRowStart();
      var rowEnd = me.getRowEnd();
      return data.length > me.rows ? me.rows - (rowEnd - rowStart) : 0;
    };
  };

  var Columns = function(data, columns, options) {
    var me = this;

    me.defaults = {
      min: 5
    };

    me.number = 0;
    me.visible = 0;
    me.total = columns.length;
    me.subset = [];
    me.padding = 0;
    me.min = options.columns.min !== null ? options.columns.min : me.defaults.min;
    me.max = options.columns.max !== null ? options.columns.max : null;
    me.widths = {};

    var widthsLookAhead = Math.max(100, options.rows.min);
    var paddingColChars = 10;

    me.emptyNames = function() {
      columns.forEach(function(column) {
        if (columns.label !== null && columns.label !== "")
          return false;
      });

      return true;
    };

    var parsePadding = function(value) {
      return parseInt(value) >= 0 ? parseInt(value) : 0;
    };

    me.calculateWidths = function(measures) {
      columns.forEach(function(column) {
        var maxChars = Math.max(
          column.label.toString().length,
          column.type.toString().length
        );

        for (var idxRow = 0; idxRow < Math.min(widthsLookAhead, data.length); idxRow++) {
          maxChars = Math.max(maxChars, data[idxRow][column.name.toString()].length);
        }

        me.widths[column.name] = {
          // width in characters
          chars: maxChars,
          // width for the inner html columns
          inner: maxChars * measures.character,
          // width adding outer styles like padding
          outer: maxChars * measures.character + measures.padding
        };
      });
    };

    me.getWidth = function() {
      var widthOuter = 0;
      for (var idxCol = 0; idxCol < me.subset.length; idxCol++) {
        var columnName = me.subset[idxCol].name;
        widthOuter = widthOuter + me.widths[columnName].outer;
      }

      widthOuter = widthOuter + me.padding * paddingColChars * measurer.measures.character;

      if (me.hasMoreLeftColumns()) {
        widthOuter = widthOuter + columnNavigationWidthPX + measurer.measures.padding;
      }

      if (me.hasMoreRightColumns()) {
        widthOuter = widthOuter + columnNavigationWidthPX + measurer.measures.padding;
      }

      return widthOuter;
    };

    me.updateSlice = function() {
      if (me.number + me.visible >= me.total)
        me.number = me.total - me.visible;

      if (me.number < 0) me.number = 0;

      me.subset = columns.slice(me.number, Math.min(me.number + me.visible, me.total));

      me.subset = me.subset.map(function(column) {
        Object.keys(column).forEach(function(colKey) {
          column[colKey] = column[colKey] === null ? "" : column[colKey].toString();
        });

        column.width = null;
        return column;
      });
    };

    me.setVisibleColumns = function(columnNumber, newVisibleColumns, paddingCount) {
      me.number = columnNumber;
      me.visible = newVisibleColumns;
      me.padding = paddingCount;

      me.updateSlice();
    };

    me.incColumnNumber = function(increment) {
      me.number = me.number + increment;
    };

    me.setColumnNumber = function(newNumber) {
      me.number = newNumber;
    };

    me.setPaddingCount = function(newPadding) {
      me.padding = newPadding;
    };

    me.getPaddingCount = function() {
      return me.padding;
    };

    me.hasMoreLeftColumns = function() {
      return me.number > 0;
    };

    me.hasMoreRightColumns = function() {
      return me.number + me.visible < me.total;
    };

    me.updateSlice(0);
    return me;
  };

  var data = source.data;
  var page = new Page(data, options);
  var measurer = new Measurer(data, options);
  var columns = new Columns(data, source.columns, options);

  var table = null;
  var tableDiv = null;
  var header = null;
  var footer = null;
  var tbody = null;

  // Caches pagedTable.clientWidth, specially for webkit
  var cachedPagedTableClientWidth = null;

  var onChangeCallbacks = [];

  var clearSelection = function() {
    if(document.selection && document.selection.empty) {
      document.selection.empty();
    } else if(window.getSelection) {
      var sel = window.getSelection();
      sel.removeAllRanges();
    }
  };

  var columnNavigationWidthPX = 5;

  var renderColumnNavigation = function(increment, backwards) {
    var arrow = document.createElement("div");
    arrow.setAttribute("style",
      "border-top: " + columnNavigationWidthPX + "px solid transparent;" +
      "border-bottom: " + columnNavigationWidthPX + "px solid transparent;" +
      "border-" + (backwards ? "right" : "left") + ": " + columnNavigationWidthPX + "px solid;");

    var header = document.createElement("th");
    header.appendChild(arrow);
    header.setAttribute("style",
      "cursor: pointer;" +
      "vertical-align: middle;" +
      "min-width: " + columnNavigationWidthPX + "px;" +
      "width: " + columnNavigationWidthPX + "px;");

    header.onclick = function() {
      columns.incColumnNumber(backwards ? -1 : increment);

      me.animateColumns(backwards);
      renderFooter();

      clearSelection();
      triggerOnChange();
    };

    return header;
  };

  var maxColumnWidth = function(width) {
    var padding = 80;
    var columnMax = Math.max(cachedPagedTableClientWidth - padding, 0);

    return parseInt(width) > 0 ?
      Math.min(columnMax, parseInt(width)) + "px" :
      columnMax + "px";
  };

  var clearHeader = function() {
    var thead = pagedTable.querySelectorAll("thead")[0];
    thead.innerHTML = "";
  };

  var renderHeader = function(clear) {
    cachedPagedTableClientWidth = pagedTable.clientWidth;

    var fragment = document.createDocumentFragment();

    header = document.createElement("tr");
    fragment.appendChild(header);

    if (columns.number > 0)
      header.appendChild(renderColumnNavigation(-columns.visible, true));

    columns.subset = columns.subset.map(function(columnData) {
      var column = document.createElement("th");
      column.setAttribute("align", columnData.align);
      column.style.textAlign = columnData.align;

      column.style.maxWidth = maxColumnWidth(null);
      if (columnData.width) {
        column.style.minWidth =
          column.style.maxWidth = maxColumnWidth(columnData.width);
      }

      var columnName = document.createElement("div");
      columnName.setAttribute("class", "pagedtable-header-name");
      if (columnData.label === "") {
        columnName.innerHTML = "&nbsp;";
      }
      else {
        columnName.appendChild(document.createTextNode(columnData.label));
      }
      column.appendChild(columnName);

      var columnType = document.createElement("div");
      columnType.setAttribute("class", "pagedtable-header-type");
      if (columnData.type === "") {
        columnType.innerHTML = "&nbsp;";
      }
      else {
        columnType.appendChild(document.createTextNode("<" + columnData.type + ">"));
      }
      column.appendChild(columnType);

      header.appendChild(column);

      columnData.element = column;

      return columnData;
    });

    for (var idx = 0; idx < columns.getPaddingCount(); idx++) {
      var paddingCol = document.createElement("th");
      paddingCol.setAttribute("class", "pagedtable-padding-col");
      header.appendChild(paddingCol);
    }

    if (columns.number + columns.visible < columns.total)
      header.appendChild(renderColumnNavigation(columns.visible, false));

    if (typeof(clear) == "undefined" || clear) clearHeader();
    var thead = pagedTable.querySelectorAll("thead")[0];
    thead.appendChild(fragment);
  };

  me.animateColumns = function(backwards) {
    var thead = pagedTable.querySelectorAll("thead")[0];

    var headerOld = thead.querySelectorAll("tr")[0];
    var tbodyOld = table.querySelectorAll("tbody")[0];

    me.fitColumns(backwards);

    renderHeader(false);

    header.style.opacity = "0";
    header.style.transform = backwards ? "translateX(-30px)" : "translateX(30px)";
    header.style.transition = "transform 200ms linear, opacity 200ms";
    header.style.transitionDelay = "0";

    renderBody(false);

    if (headerOld) {
      headerOld.style.position = "absolute";
      headerOld.style.transform = "translateX(0px)";
      headerOld.style.opacity = "1";
      headerOld.style.transition = "transform 100ms linear, opacity 100ms";
      headerOld.setAttribute("class", "pagedtable-remove-head");
      if (headerOld.style.transitionEnd) {
        headerOld.addEventListener("transitionend", function() {
          var headerOldByClass = thead.querySelector(".pagedtable-remove-head");
          if (headerOldByClass) thead.removeChild(headerOldByClass);
        });
      }
      else {
        thead.removeChild(headerOld);
      }
    }

    if (tbodyOld) table.removeChild(tbodyOld);

    tbody.style.opacity = "0";
    tbody.style.transition = "transform 200ms linear, opacity 200ms";
    tbody.style.transitionDelay = "0ms";

    // force relayout
    window.getComputedStyle(header).opacity;
    window.getComputedStyle(tbody).opacity;

    if (headerOld) {
      headerOld.style.transform = backwards ? "translateX(20px)" : "translateX(-30px)";
      headerOld.style.opacity = "0";
    }

    header.style.transform = "translateX(0px)";
    header.style.opacity = "1";

    tbody.style.opacity = "1";
  }

  me.onChange = function(callback) {
    onChangeCallbacks.push(callback);
  };

  var triggerOnChange = function() {
    onChangeCallbacks.forEach(function(onChange) {
      onChange();
    });
  };

  var clearBody = function() {
    if (tbody) {
      table.removeChild(tbody);
      tbody = null;
    }
  };

  var renderBody = function(clear) {
    cachedPagedTableClientWidth = pagedTable.clientWidth

    var fragment = document.createDocumentFragment();

    var pageData = data.slice(page.getRowStart(), page.getRowEnd());

    pageData.forEach(function(dataRow, idxRow) {
      var htmlRow = document.createElement("tr");
      htmlRow.setAttribute("class", (idxRow % 2 !==0) ? "even" : "odd");

      if (columns.hasMoreLeftColumns())
        htmlRow.appendChild(document.createElement("td"));

      columns.subset.forEach(function(columnData) {
        var cellName = columnData.name;
        var dataCell = dataRow[cellName];
        var htmlCell = document.createElement("td");

        if (dataCell === "NA") htmlCell.setAttribute("class", "pagedtable-na-cell");
        if (dataCell === "__NA__") dataCell = "NA";

        var cellText = document.createTextNode(dataCell);
        htmlCell.appendChild(cellText);
        if (dataCell.length > 50) {
          htmlCell.setAttribute("title", dataCell);
        }
        htmlCell.setAttribute("align", columnData.align);
        htmlCell.style.textAlign = columnData.align;
        htmlCell.style.maxWidth = maxColumnWidth(null);
        if (columnData.width) {
          htmlCell.style.minWidth = htmlCell.style.maxWidth = maxColumnWidth(columnData.width);
        }
        htmlRow.appendChild(htmlCell);
      });

      for (var idx = 0; idx < columns.getPaddingCount(); idx++) {
        var paddingCol = document.createElement("td");
        paddingCol.setAttribute("class", "pagedtable-padding-col");
        htmlRow.appendChild(paddingCol);
      }

      if (columns.hasMoreRightColumns())
        htmlRow.appendChild(document.createElement("td"));

      fragment.appendChild(htmlRow);
    });

    for (var idxPadding = 0; idxPadding < page.getPaddingRows(); idxPadding++) {
      var paddingRow = document.createElement("tr");

      var paddingCellRow = document.createElement("td");
      paddingCellRow.innerHTML = "&nbsp;";
      paddingCellRow.setAttribute("colspan", "100%");
      paddingRow.appendChild(paddingCellRow);

      fragment.appendChild(paddingRow);
    }

    if (typeof(clear) == "undefined" || clear) clearBody();
    tbody = document.createElement("tbody");
    tbody.appendChild(fragment);

    table.appendChild(tbody);
  };

  var getLabelInfo = function() {
    var pageStart = page.getRowStart();
    var pageEnd = page.getRowEnd();
    var totalRows = data.length;

    var totalRowsLabel = options.rows.total ? options.rows.total : totalRows;
    var totalRowsLabelFormat = totalRowsLabel.toString().replace(/(\d)(?=(\d\d\d)+(?!\d))/g, '$1,');

    var infoText = (pageStart + 1) + "-" + pageEnd + " of " + totalRowsLabelFormat + " rows";
    if (totalRows < page.rows) {
      infoText = totalRowsLabel + " row" + (totalRows != 1 ? "s" : "");
    }
    if (columns.total > columns.visible) {
      var totalColumnsLabel = options.columns.total ? options.columns.total : columns.total;

      infoText = infoText + " | " + (columns.number + 1) + "-" +
        (Math.min(columns.number + columns.visible, columns.total)) +
        " of " + totalColumnsLabel + " columns";
    }

    return infoText;
  };

  var clearFooter = function() {
    footer = pagedTable.querySelectorAll("div.pagedtable-footer")[0];
    footer.innerHTML = "";

    return footer;
  };

  var createPageLink = function(idxPage) {
    var pageLink = document.createElement("a");
    pageLinkClass = idxPage === page.number ? "pagedtable-index pagedtable-index-current" : "pagedtable-index";
    pageLink.setAttribute("class", pageLinkClass);
    pageLink.setAttribute("data-page-index", idxPage);
    pageLink.onclick = function() {
      page.setPageNumber(parseInt(this.getAttribute("data-page-index")));
      renderBody();
      renderFooter();

      triggerOnChange();
    };

    pageLink.appendChild(document.createTextNode(idxPage + 1));

    return pageLink;
  }

  var renderFooter = function() {
    footer = clearFooter();

    var next = document.createElement("a");
    next.appendChild(document.createTextNode("Next"));
    next.onclick = function() {
      page.setPageNumber(page.number + 1);
      renderBody();
      renderFooter();

      triggerOnChange();
    };
    if (data.length > page.rows) footer.appendChild(next);

    var pageNumbers = document.createElement("div");
    pageNumbers.setAttribute("class", "pagedtable-indexes");

    var pageRange = page.getVisiblePageRange();

    if (pageRange.first) {
      var pageLink = createPageLink(0);
      pageNumbers.appendChild(pageLink);

      var pageSeparator = document.createElement("div");
      pageSeparator.setAttribute("class", "pagedtable-index-separator-left");
      pageSeparator.appendChild(document.createTextNode("..."))
      pageNumbers.appendChild(pageSeparator);
    }

    for (var idxPage = pageRange.start; idxPage < pageRange.end; idxPage++) {
      var pageLink = createPageLink(idxPage);

      pageNumbers.appendChild(pageLink);
    }

    if (pageRange.last) {
      var pageSeparator = document.createElement("div");
      pageSeparator.setAttribute("class", "pagedtable-index-separator-right");
      pageSeparator.appendChild(document.createTextNode("..."))
      pageNumbers.appendChild(pageSeparator);

      var pageLink = createPageLink(page.total - 1);
      pageNumbers.appendChild(pageLink);
    }

    if (data.length > page.rows) footer.appendChild(pageNumbers);

    var previous = document.createElement("a");
    previous.appendChild(document.createTextNode("Previous"));
    previous.onclick = function() {
      page.setPageNumber(page.number - 1);
      renderBody();
      renderFooter();

      triggerOnChange();
    };
    if (data.length > page.rows) footer.appendChild(previous);

    var infoLabel = document.createElement("div");
    infoLabel.setAttribute("class", "pagedtable-info");
    infoLabel.setAttribute("title", getLabelInfo());
    infoLabel.appendChild(document.createTextNode(getLabelInfo()));
    footer.appendChild(infoLabel);

    var enabledClass = "pagedtable-index-nav";
    var disabledClass = "pagedtable-index-nav pagedtable-index-nav-disabled";
    previous.setAttribute("class", page.number <= 0 ? disabledClass : enabledClass);
    next.setAttribute("class", (page.number + 1) * page.rows >= data.length ? disabledClass : enabledClass);
  };

  var measuresCell = null;

  var renderMeasures = function() {
    var measuresTable = document.createElement("table");
    measuresTable.style.visibility = "hidden";
    measuresTable.style.position = "absolute";
    measuresTable.style.whiteSpace = "nowrap";
    measuresTable.style.height = "auto";
    measuresTable.style.width = "auto";

    var measuresRow = document.createElement("tr");
    measuresTable.appendChild(measuresRow);

    measuresCell = document.createElement("td");
    var sampleString = "ABCDEFGHIJ0123456789";
    measuresCell.appendChild(document.createTextNode(sampleString));

    measuresRow.appendChild(measuresCell);

    tableDiv.appendChild(measuresTable);
  }

  me.init = function() {
    tableDiv = document.createElement("div");
    pagedTable.appendChild(tableDiv);
    var pagedTableClass = data.length > 0 ?
      "pagedtable pagedtable-not-empty" :
      "pagedtable pagedtable-empty";

    if (columns.total == 0 || (columns.emptyNames() && data.length == 0)) {
      pagedTableClass = pagedTableClass + " pagedtable-empty-columns";
    }

    tableDiv.setAttribute("class", pagedTableClass);

    renderMeasures();
    measurer.calculate(measuresCell);
    columns.calculateWidths(measurer.measures);

    table = document.createElement("table");
    table.setAttribute("cellspacing", "0");
    table.setAttribute("class", "table table-condensed");
    tableDiv.appendChild(table);

    table.appendChild(document.createElement("thead"));

    var footerDiv = document.createElement("div");
    footerDiv.setAttribute("class", "pagedtable-footer");
    tableDiv.appendChild(footerDiv);

    // if the host has not yet provided horizontal space, render hidden
    if (tableDiv.clientWidth <= 0) {
      tableDiv.style.opacity = "0";
    }

    me.render();

    // retry seizing columns later if the host has not provided space
    function retryFit() {
      if (tableDiv.clientWidth <= 0) {
        setTimeout(retryFit, 100);
      } else {
        me.render();
        triggerOnChange();
      }
    }
    if (tableDiv.clientWidth <= 0) {
      retryFit();
    }
  };

  var registerWidths = function() {
    columns.subset = columns.subset.map(function(column) {
      column.width = columns.widths[column.name].inner;
      return column;
    });
  };

  var parsePadding = function(value) {
    return parseInt(value) >= 0 ? parseInt(value) : 0;
  };

  me.fixedHeight = function() {
    return options.rows.max != null;
  }

  me.fitRows = function() {
    if (me.fixedHeight())
      return;

    measurer.calculate(measuresCell);

    var rows = options.rows.min !== null ? options.rows.min : 0;
    var headerHeight = header !== null && header.offsetHeight > 0 ? header.offsetHeight : 0;
    var footerHeight = footer !== null && footer.offsetHeight > 0 ? footer.offsetHeight : 0;

    if (pagedTable.offsetHeight > 0) {
      var availableHeight = pagedTable.offsetHeight - headerHeight - footerHeight;
      rows = Math.floor((availableHeight) / measurer.measures.height);
    }

    rows = options.rows.min !== null ? Math.max(options.rows.min, rows) : rows;

    page.setRows(rows);
  }

  // The goal of this function is to add as many columns as possible
  // starting from left-to-right, when the right most limit is reached
  // it tries to add columns from the left as well.
  //
  // When startBackwards is true columns are added from right-to-left
  me.fitColumns = function(startBackwards) {
    measurer.calculate(measuresCell);
    columns.calculateWidths(measurer.measures);

    if (tableDiv.clientWidth > 0) {
      tableDiv.style.opacity = 1;
    }

    var visibleColumns = tableDiv.clientWidth <= 0 ? Math.max(columns.min, 1) : 1;
    var columnNumber = columns.number;
    var paddingCount = 0;

    // track a list of added columns as we build the visible ones to allow us
    // to remove columns when they don't fit anymore.
    var columnHistory = [];

    var lastTableHeight = 0;
    var backwards = startBackwards;

    var tableDivStyle = window.getComputedStyle(tableDiv, null);
    var tableDivPadding = parsePadding(tableDivStyle.paddingLeft) +
      parsePadding(tableDivStyle.paddingRight);

    var addPaddingCol = false;
    var currentWidth = 0;

    while (true) {
      columns.setVisibleColumns(columnNumber, visibleColumns, paddingCount);
      currentWidth = columns.getWidth();

      if (tableDiv.clientWidth - tableDivPadding < currentWidth) {
        break;
      }

      columnHistory.push({
        columnNumber: columnNumber,
        visibleColumns: visibleColumns,
        paddingCount: paddingCount
      });

      if (columnHistory.length > 100) {
        console.error("More than 100 tries to fit columns, aborting");
        break;
      }

      if (columns.max !== null &&
        columns.visible + columns.getPaddingCount() >= columns.max) {
        break;
      }

      // if we run out of right-columns
      if (!backwards && columnNumber + columns.visible >= columns.total) {
        // if we started adding right-columns, try adding left-columns
        if (!startBackwards && columnNumber > 0) {
          backwards = true;
        }
        else if (columns.min === null || visibleColumns + columns.getPaddingCount() >= columns.min) {
          break;
        }
        else {
          paddingCount = paddingCount + 1;
        }
      }

      // if we run out of left-columns
      if (backwards && columnNumber == 0) {
        // if we started adding left-columns, try adding right-columns
        if (startBackwards && columnNumber + columns.visible < columns.total) {
          backwards = false;
        }
        else if (columns.min === null || visibleColumns + columns.getPaddingCount() >= columns.min) {
          break;
        }
        else {
          paddingCount = paddingCount + 1;
        }
      }

      // when moving backwards try fitting left columns first
      if (backwards && columnNumber > 0) {
        columnNumber = columnNumber - 1;
      }

      if (columnNumber + visibleColumns < columns.total) {
        visibleColumns = visibleColumns + 1;
      }
    }

    var lastRenderableColumn = {
        columnNumber: columnNumber,
        visibleColumns: visibleColumns,
        paddingCount: paddingCount
    };

    if (columnHistory.length > 0) {
      lastRenderableColumn = columnHistory[columnHistory.length - 1];
    }

    columns.setVisibleColumns(
      lastRenderableColumn.columnNumber,
      lastRenderableColumn.visibleColumns,
      lastRenderableColumn.paddingCount);

    if (pagedTable.offsetWidth > 0) {
      page.setVisiblePages(Math.max(Math.ceil(1.0 * (pagedTable.offsetWidth - 250) / 40), 2));
    }

    registerWidths();
  };

  me.fit = function(startBackwards) {
    me.fitRows();
    me.fitColumns(startBackwards);
  }

  me.render = function() {
    me.fitColumns(false);

    // render header/footer to measure height accurately
    renderHeader();
    renderFooter();

    me.fitRows();
    renderBody();

    // re-render footer to match new rows
    renderFooter();
  }

  var resizeLastWidth = -1;
  var resizeLastHeight = -1;
  var resizeNewWidth = -1;
  var resizeNewHeight = -1;
  var resizePending = false;

  me.resize = function(newWidth, newHeight) {

    function resizeDelayed() {
      resizePending = false;

      if (
        (resizeNewWidth !== resizeLastWidth) ||
        (!me.fixedHeight() && resizeNewHeight !== resizeLastHeight)
      ) {
        resizeLastWidth = resizeNewWidth;
        resizeLastHeight = resizeNewHeight;

        setTimeout(resizeDelayed, 200);
        resizePending = true;
      } else {
        me.render();
        triggerOnChange();

        resizeLastWidth = -1;
        resizeLastHeight = -1;
      }
    }

    resizeNewWidth = newWidth;
    resizeNewHeight = newHeight;

    if (!resizePending) resizeDelayed();
  };
};

var PagedTableDoc;
(function (PagedTableDoc) {
  var allPagedTables = [];

  PagedTableDoc.initAll = function() {
    allPagedTables = [];

    var pagedTables = [].slice.call(document.querySelectorAll('[data-pagedtable="false"],[data-pagedtable=""]'));
    pagedTables.forEach(function(pagedTable, idx) {
      pagedTable.setAttribute("data-pagedtable", "true");
      pagedTable.setAttribute("pagedtable-page", 0);
      pagedTable.setAttribute("class", "pagedtable-wrapper");

      var pagedTableInstance = new PagedTable(pagedTable);
      pagedTableInstance.init();

      allPagedTables.push(pagedTableInstance);
    });
  };

  PagedTableDoc.resizeAll = function() {
    allPagedTables.forEach(function(pagedTable) {
      pagedTable.render();
    });
  };

  window.addEventListener("resize", PagedTableDoc.resizeAll);

  return PagedTableDoc;
})(PagedTableDoc || (PagedTableDoc = {}));

window.onload = function() {
  PagedTableDoc.initAll();
};
"></script>
<script src="data:application/x-javascript;base64,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"></script>
<script src="data:application/x-javascript;base64,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"></script>
<script src="data:application/x-javascript;base64,CndpbmRvdy5pbml0aWFsaXplU291cmNlRW1iZWQgPSBmdW5jdGlvbihmaWxlbmFtZSkgewogICQoIiNybWQtZG93bmxvYWQtc291cmNlIikuY2xpY2soZnVuY3Rpb24oKSB7CiAgICB2YXIgc3JjID0gJCgiI3JtZC1zb3VyY2UtY29kZSIpLmh0bWwoKTsKICAgIHZhciBhID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYScpOwogICAgYS5ocmVmID0gImRhdGE6dGV4dC94LXItbWFya2Rvd247YmFzZTY0LCIgKyBzcmM7CiAgICBhLmRvd25sb2FkID0gZmlsZW5hbWU7CiAgICBkb2N1bWVudC5ib2R5LmFwcGVuZENoaWxkKGEpOwogICAgYS5jbGljaygpOwogICAgZG9jdW1lbnQuYm9keS5yZW1vdmVDaGlsZChhKTsKICB9KTsKfTsK"></script>
<link href="data:text/css;charset=utf-8,%2Ehljs%2Dliteral%20%7B%0Acolor%3A%20rgb%2888%2C%2072%2C%20246%29%3B%0A%7D%0A%2Ehljs%2Dnumber%20%7B%0Acolor%3A%20rgb%280%2C%200%2C%20205%29%3B%0A%7D%0A%2Ehljs%2Dcomment%20%7B%0Acolor%3A%20rgb%2876%2C%20136%2C%20107%29%3B%0A%7D%0A%2Ehljs%2Dkeyword%20%7B%0Acolor%3A%20rgb%280%2C%200%2C%20255%29%3B%0A%7D%0A%2Ehljs%2Dstring%20%7B%0Acolor%3A%20rgb%283%2C%20106%2C%207%29%3B%0A%7D%0A" rel="stylesheet" />
<script src="data:application/x-javascript;base64,/*! highlight.js v9.12.0 | BSD3 License | git.io/hljslicense */
!function(e){var n="object"==typeof window&&window||"object"==typeof self&&self;"undefined"!=typeof exports?e(exports):n&&(n.hljs=e({}),"function"==typeof define&&define.amd&&define([],function(){return n.hljs}))}(function(e){function n(e){return e.replace(/&/g,"&amp;").replace(/</g,"&lt;").replace(/>/g,"&gt;")}function t(e){return e.nodeName.toLowerCase()}function r(e,n){var t=e&&e.exec(n);return t&&0===t.index}function a(e){return k.test(e)}function i(e){var n,t,r,i,o=e.className+" ";if(o+=e.parentNode?e.parentNode.className:"",t=B.exec(o))return w(t[1])?t[1]:"no-highlight";for(o=o.split(/\s+/),n=0,r=o.length;r>n;n++)if(i=o[n],a(i)||w(i))return i}function o(e){var n,t={},r=Array.prototype.slice.call(arguments,1);for(n in e)t[n]=e[n];return r.forEach(function(e){for(n in e)t[n]=e[n]}),t}function u(e){var n=[];return function r(e,a){for(var i=e.firstChild;i;i=i.nextSibling)3===i.nodeType?a+=i.nodeValue.length:1===i.nodeType&&(n.push({event:"start",offset:a,node:i}),a=r(i,a),t(i).match(/br|hr|img|input/)||n.push({event:"stop",offset:a,node:i}));return a}(e,0),n}function c(e,r,a){function i(){return e.length&&r.length?e[0].offset!==r[0].offset?e[0].offset<r[0].offset?e:r:"start"===r[0].event?e:r:e.length?e:r}function o(e){function r(e){return" "+e.nodeName+'="'+n(e.value).replace('"',"&quot;")+'"'}s+="<"+t(e)+E.map.call(e.attributes,r).join("")+">"}function u(e){s+="</"+t(e)+">"}function c(e){("start"===e.event?o:u)(e.node)}for(var l=0,s="",f=[];e.length||r.length;){var g=i();if(s+=n(a.substring(l,g[0].offset)),l=g[0].offset,g===e){f.reverse().forEach(u);do c(g.splice(0,1)[0]),g=i();while(g===e&&g.length&&g[0].offset===l);f.reverse().forEach(o)}else"start"===g[0].event?f.push(g[0].node):f.pop(),c(g.splice(0,1)[0])}return s+n(a.substr(l))}function l(e){return e.v&&!e.cached_variants&&(e.cached_variants=e.v.map(function(n){return o(e,{v:null},n)})),e.cached_variants||e.eW&&[o(e)]||[e]}function s(e){function n(e){return e&&e.source||e}function t(t,r){return new RegExp(n(t),"m"+(e.cI?"i":"")+(r?"g":""))}function r(a,i){if(!a.compiled){if(a.compiled=!0,a.k=a.k||a.bK,a.k){var o={},u=function(n,t){e.cI&&(t=t.toLowerCase()),t.split(" ").forEach(function(e){var t=e.split("|");o[t[0]]=[n,t[1]?Number(t[1]):1]})};"string"==typeof a.k?u("keyword",a.k):x(a.k).forEach(function(e){u(e,a.k[e])}),a.k=o}a.lR=t(a.l||/\w+/,!0),i&&(a.bK&&(a.b="\\b("+a.bK.split(" ").join("|")+")\\b"),a.b||(a.b=/\B|\b/),a.bR=t(a.b),a.e||a.eW||(a.e=/\B|\b/),a.e&&(a.eR=t(a.e)),a.tE=n(a.e)||"",a.eW&&i.tE&&(a.tE+=(a.e?"|":"")+i.tE)),a.i&&(a.iR=t(a.i)),null==a.r&&(a.r=1),a.c||(a.c=[]),a.c=Array.prototype.concat.apply([],a.c.map(function(e){return l("self"===e?a:e)})),a.c.forEach(function(e){r(e,a)}),a.starts&&r(a.starts,i);var c=a.c.map(function(e){return e.bK?"\\.?("+e.b+")\\.?":e.b}).concat([a.tE,a.i]).map(n).filter(Boolean);a.t=c.length?t(c.join("|"),!0):{exec:function(){return null}}}}r(e)}function f(e,t,a,i){function o(e,n){var t,a;for(t=0,a=n.c.length;a>t;t++)if(r(n.c[t].bR,e))return n.c[t]}function u(e,n){if(r(e.eR,n)){for(;e.endsParent&&e.parent;)e=e.parent;return e}return e.eW?u(e.parent,n):void 0}function c(e,n){return!a&&r(n.iR,e)}function l(e,n){var t=N.cI?n[0].toLowerCase():n[0];return e.k.hasOwnProperty(t)&&e.k[t]}function p(e,n,t,r){var a=r?"":I.classPrefix,i='<span class="'+a,o=t?"":C;return i+=e+'">',i+n+o}function h(){var e,t,r,a;if(!E.k)return n(k);for(a="",t=0,E.lR.lastIndex=0,r=E.lR.exec(k);r;)a+=n(k.substring(t,r.index)),e=l(E,r),e?(B+=e[1],a+=p(e[0],n(r[0]))):a+=n(r[0]),t=E.lR.lastIndex,r=E.lR.exec(k);return a+n(k.substr(t))}function d(){var e="string"==typeof E.sL;if(e&&!y[E.sL])return n(k);var t=e?f(E.sL,k,!0,x[E.sL]):g(k,E.sL.length?E.sL:void 0);return E.r>0&&(B+=t.r),e&&(x[E.sL]=t.top),p(t.language,t.value,!1,!0)}function b(){L+=null!=E.sL?d():h(),k=""}function v(e){L+=e.cN?p(e.cN,"",!0):"",E=Object.create(e,{parent:{value:E}})}function m(e,n){if(k+=e,null==n)return b(),0;var t=o(n,E);if(t)return t.skip?k+=n:(t.eB&&(k+=n),b(),t.rB||t.eB||(k=n)),v(t,n),t.rB?0:n.length;var r=u(E,n);if(r){var a=E;a.skip?k+=n:(a.rE||a.eE||(k+=n),b(),a.eE&&(k=n));do E.cN&&(L+=C),E.skip||(B+=E.r),E=E.parent;while(E!==r.parent);return r.starts&&v(r.starts,""),a.rE?0:n.length}if(c(n,E))throw new Error('Illegal lexeme "'+n+'" for mode "'+(E.cN||"<unnamed>")+'"');return k+=n,n.length||1}var N=w(e);if(!N)throw new Error('Unknown language: "'+e+'"');s(N);var R,E=i||N,x={},L="";for(R=E;R!==N;R=R.parent)R.cN&&(L=p(R.cN,"",!0)+L);var k="",B=0;try{for(var M,j,O=0;;){if(E.t.lastIndex=O,M=E.t.exec(t),!M)break;j=m(t.substring(O,M.index),M[0]),O=M.index+j}for(m(t.substr(O)),R=E;R.parent;R=R.parent)R.cN&&(L+=C);return{r:B,value:L,language:e,top:E}}catch(T){if(T.message&&-1!==T.message.indexOf("Illegal"))return{r:0,value:n(t)};throw T}}function g(e,t){t=t||I.languages||x(y);var r={r:0,value:n(e)},a=r;return t.filter(w).forEach(function(n){var t=f(n,e,!1);t.language=n,t.r>a.r&&(a=t),t.r>r.r&&(a=r,r=t)}),a.language&&(r.second_best=a),r}function p(e){return I.tabReplace||I.useBR?e.replace(M,function(e,n){return I.useBR&&"\n"===e?"<br>":I.tabReplace?n.replace(/\t/g,I.tabReplace):""}):e}function h(e,n,t){var r=n?L[n]:t,a=[e.trim()];return e.match(/\bhljs\b/)||a.push("hljs"),-1===e.indexOf(r)&&a.push(r),a.join(" ").trim()}function d(e){var n,t,r,o,l,s=i(e);a(s)||(I.useBR?(n=document.createElementNS("http://www.w3.org/1999/xhtml","div"),n.innerHTML=e.innerHTML.replace(/\n/g,"").replace(/<br[ \/]*>/g,"\n")):n=e,l=n.textContent,r=s?f(s,l,!0):g(l),t=u(n),t.length&&(o=document.createElementNS("http://www.w3.org/1999/xhtml","div"),o.innerHTML=r.value,r.value=c(t,u(o),l)),r.value=p(r.value),e.innerHTML=r.value,e.className=h(e.className,s,r.language),e.result={language:r.language,re:r.r},r.second_best&&(e.second_best={language:r.second_best.language,re:r.second_best.r}))}function b(e){I=o(I,e)}function v(){if(!v.called){v.called=!0;var e=document.querySelectorAll("pre code");E.forEach.call(e,d)}}function m(){addEventListener("DOMContentLoaded",v,!1),addEventListener("load",v,!1)}function N(n,t){var r=y[n]=t(e);r.aliases&&r.aliases.forEach(function(e){L[e]=n})}function R(){return x(y)}function w(e){return e=(e||"").toLowerCase(),y[e]||y[L[e]]}var E=[],x=Object.keys,y={},L={},k=/^(no-?highlight|plain|text)$/i,B=/\blang(?:uage)?-([\w-]+)\b/i,M=/((^(<[^>]+>|\t|)+|(?:\n)))/gm,C="</span>",I={classPrefix:"hljs-",tabReplace:null,useBR:!1,languages:void 0};return e.highlight=f,e.highlightAuto=g,e.fixMarkup=p,e.highlightBlock=d,e.configure=b,e.initHighlighting=v,e.initHighlightingOnLoad=m,e.registerLanguage=N,e.listLanguages=R,e.getLanguage=w,e.inherit=o,e.IR="[a-zA-Z]\\w*",e.UIR="[a-zA-Z_]\\w*",e.NR="\\b\\d+(\\.\\d+)?",e.CNR="(-?)(\\b0[xX][a-fA-F0-9]+|(\\b\\d+(\\.\\d*)?|\\.\\d+)([eE][-+]?\\d+)?)",e.BNR="\\b(0b[01]+)",e.RSR="!|!=|!==|%|%=|&|&&|&=|\\*|\\*=|\\+|\\+=|,|-|-=|/=|/|:|;|<<|<<=|<=|<|===|==|=|>>>=|>>=|>=|>>>|>>|>|\\?|\\[|\\{|\\(|\\^|\\^=|\\||\\|=|\\|\\||~",e.BE={b:"\\\\[\\s\\S]",r:0},e.ASM={cN:"string",b:"'",e:"'",i:"\\n",c:[e.BE]},e.QSM={cN:"string",b:'"',e:'"',i:"\\n",c:[e.BE]},e.PWM={b:/\b(a|an|the|are|I'm|isn't|don't|doesn't|won't|but|just|should|pretty|simply|enough|gonna|going|wtf|so|such|will|you|your|they|like|more)\b/},e.C=function(n,t,r){var a=e.inherit({cN:"comment",b:n,e:t,c:[]},r||{});return a.c.push(e.PWM),a.c.push({cN:"doctag",b:"(?:TODO|FIXME|NOTE|BUG|XXX):",r:0}),a},e.CLCM=e.C("//","$"),e.CBCM=e.C("/\\*","\\*/"),e.HCM=e.C("#","$"),e.NM={cN:"number",b:e.NR,r:0},e.CNM={cN:"number",b:e.CNR,r:0},e.BNM={cN:"number",b:e.BNR,r:0},e.CSSNM={cN:"number",b:e.NR+"(%|em|ex|ch|rem|vw|vh|vmin|vmax|cm|mm|in|pt|pc|px|deg|grad|rad|turn|s|ms|Hz|kHz|dpi|dpcm|dppx)?",r:0},e.RM={cN:"regexp",b:/\//,e:/\/[gimuy]*/,i:/\n/,c:[e.BE,{b:/\[/,e:/\]/,r:0,c:[e.BE]}]},e.TM={cN:"title",b:e.IR,r:0},e.UTM={cN:"title",b:e.UIR,r:0},e.METHOD_GUARD={b:"\\.\\s*"+e.UIR,r:0},e});hljs.registerLanguage("sql",function(e){var t=e.C("--","$");return{cI:!0,i:/[<>{}*#]/,c:[{bK:"begin end start commit rollback savepoint lock alter create drop rename call delete do handler insert load replace select truncate update set show pragma grant merge describe use explain help declare prepare execute deallocate release unlock purge reset change stop analyze cache flush optimize repair kill install uninstall checksum restore check backup revoke comment",e:/;/,eW:!0,l:/[\w\.]+/,k:{keyword:"abort abs absolute acc acce accep accept access accessed accessible account acos action activate add addtime admin administer advanced advise aes_decrypt aes_encrypt after agent aggregate ali alia alias allocate allow alter always analyze ancillary and any anydata anydataset anyschema anytype apply archive archived archivelog are as asc ascii asin assembly assertion associate asynchronous at atan atn2 attr attri attrib attribu attribut attribute attributes audit authenticated authentication authid authors auto autoallocate autodblink autoextend automatic availability avg backup badfile basicfile before begin beginning benchmark between bfile bfile_base big bigfile bin binary_double binary_float binlog bit_and bit_count bit_length bit_or bit_xor bitmap blob_base block blocksize body both bound buffer_cache buffer_pool build bulk by byte byteordermark bytes cache caching call calling cancel capacity cascade cascaded case cast catalog category ceil ceiling chain change changed char_base char_length character_length characters characterset charindex charset charsetform charsetid check checksum checksum_agg child choose chr chunk class cleanup clear client clob clob_base clone close cluster_id cluster_probability cluster_set clustering coalesce coercibility col collate collation collect colu colum column column_value columns columns_updated comment commit compact compatibility compiled complete composite_limit compound compress compute concat concat_ws concurrent confirm conn connec connect connect_by_iscycle connect_by_isleaf connect_by_root connect_time connection consider consistent constant constraint constraints constructor container content contents context contributors controlfile conv convert convert_tz corr corr_k corr_s corresponding corruption cos cost count count_big counted covar_pop covar_samp cpu_per_call cpu_per_session crc32 create creation critical cross cube cume_dist curdate current current_date current_time current_timestamp current_user cursor curtime customdatum cycle data database databases datafile datafiles datalength date_add date_cache date_format date_sub dateadd datediff datefromparts datename datepart datetime2fromparts day day_to_second dayname dayofmonth dayofweek dayofyear days db_role_change dbtimezone ddl deallocate declare decode decompose decrement decrypt deduplicate def defa defau defaul default defaults deferred defi defin define degrees delayed delegate delete delete_all delimited demand dense_rank depth dequeue des_decrypt des_encrypt des_key_file desc descr descri describ describe descriptor deterministic diagnostics difference dimension direct_load directory disable disable_all disallow disassociate discardfile disconnect diskgroup distinct distinctrow distribute distributed div do document domain dotnet double downgrade drop dumpfile duplicate duration each edition editionable editions element ellipsis else elsif elt empty enable enable_all enclosed encode encoding encrypt end end-exec endian enforced engine engines enqueue enterprise entityescaping eomonth error errors escaped evalname evaluate event eventdata events except exception exceptions exchange exclude excluding execu execut execute exempt exists exit exp expire explain export export_set extended extent external external_1 external_2 externally extract failed failed_login_attempts failover failure far fast feature_set feature_value fetch field fields file file_name_convert filesystem_like_logging final finish first first_value fixed flash_cache flashback floor flush following follows for forall force form forma format found found_rows freelist freelists freepools fresh from from_base64 from_days ftp full function general generated get get_format get_lock getdate getutcdate global global_name globally go goto grant grants greatest group group_concat group_id grouping grouping_id groups gtid_subtract guarantee guard handler hash hashkeys having hea head headi headin heading heap help hex hierarchy high high_priority hosts hour http id ident_current ident_incr ident_seed identified identity idle_time if ifnull ignore iif ilike ilm immediate import in include including increment index indexes indexing indextype indicator indices inet6_aton inet6_ntoa inet_aton inet_ntoa infile initial initialized initially initrans inmemory inner innodb input insert install instance instantiable instr interface interleaved intersect into invalidate invisible is is_free_lock is_ipv4 is_ipv4_compat is_not is_not_null is_used_lock isdate isnull isolation iterate java join json json_exists keep keep_duplicates key keys kill language large last last_day last_insert_id last_value lax lcase lead leading least leaves left len lenght length less level levels library like like2 like4 likec limit lines link list listagg little ln load load_file lob lobs local localtime localtimestamp locate locator lock locked log log10 log2 logfile logfiles logging logical logical_reads_per_call logoff logon logs long loop low low_priority lower lpad lrtrim ltrim main make_set makedate maketime managed management manual map mapping mask master master_pos_wait match matched materialized max maxextents maximize maxinstances maxlen maxlogfiles maxloghistory maxlogmembers maxsize maxtrans md5 measures median medium member memcompress memory merge microsecond mid migration min minextents minimum mining minus minute minvalue missing mod mode model modification modify module monitoring month months mount move movement multiset mutex name name_const names nan national native natural nav nchar nclob nested never new newline next nextval no no_write_to_binlog noarchivelog noaudit nobadfile nocheck nocompress nocopy nocycle nodelay nodiscardfile noentityescaping noguarantee nokeep nologfile nomapping nomaxvalue nominimize nominvalue nomonitoring none noneditionable nonschema noorder nopr nopro noprom nopromp noprompt norely noresetlogs noreverse normal norowdependencies noschemacheck noswitch not nothing notice notrim novalidate now nowait nth_value nullif nulls num numb numbe nvarchar nvarchar2 object ocicoll ocidate ocidatetime ociduration ociinterval ociloblocator ocinumber ociref ocirefcursor ocirowid ocistring ocitype oct octet_length of off offline offset oid oidindex old on online only opaque open operations operator optimal optimize option optionally or oracle oracle_date oradata ord ordaudio orddicom orddoc order ordimage ordinality ordvideo organization orlany orlvary out outer outfile outline output over overflow overriding package pad parallel parallel_enable parameters parent parse partial partition partitions pascal passing password password_grace_time password_lock_time password_reuse_max password_reuse_time password_verify_function patch path patindex pctincrease pctthreshold pctused pctversion percent percent_rank percentile_cont percentile_disc performance period period_add period_diff permanent physical pi pipe pipelined pivot pluggable plugin policy position post_transaction pow power pragma prebuilt precedes preceding precision prediction prediction_cost prediction_details prediction_probability prediction_set prepare present preserve prior priority private private_sga privileges procedural procedure procedure_analyze processlist profiles project prompt protection public publishingservername purge quarter query quick quiesce quota quotename radians raise rand range rank raw read reads readsize rebuild record records recover recovery recursive recycle redo reduced ref reference referenced references referencing refresh regexp_like register regr_avgx regr_avgy regr_count regr_intercept regr_r2 regr_slope regr_sxx regr_sxy reject rekey relational relative relaylog release release_lock relies_on relocate rely rem remainder rename repair repeat replace replicate replication required reset resetlogs resize resource respect restore restricted result result_cache resumable resume retention return returning returns reuse reverse revoke right rlike role roles rollback rolling rollup round row row_count rowdependencies rowid rownum rows rtrim rules safe salt sample save savepoint sb1 sb2 sb4 scan schema schemacheck scn scope scroll sdo_georaster sdo_topo_geometry search sec_to_time second section securefile security seed segment select self sequence sequential serializable server servererror session session_user sessions_per_user set sets settings sha sha1 sha2 share shared shared_pool short show shrink shutdown si_averagecolor si_colorhistogram si_featurelist si_positionalcolor si_stillimage si_texture siblings sid sign sin size size_t sizes skip slave sleep smalldatetimefromparts smallfile snapshot some soname sort soundex source space sparse spfile split sql sql_big_result sql_buffer_result sql_cache sql_calc_found_rows sql_small_result sql_variant_property sqlcode sqldata sqlerror sqlname sqlstate sqrt square standalone standby start starting startup statement static statistics stats_binomial_test stats_crosstab stats_ks_test stats_mode stats_mw_test stats_one_way_anova stats_t_test_ stats_t_test_indep stats_t_test_one stats_t_test_paired stats_wsr_test status std stddev stddev_pop stddev_samp stdev stop storage store stored str str_to_date straight_join strcmp strict string struct stuff style subdate subpartition subpartitions substitutable substr substring subtime subtring_index subtype success sum suspend switch switchoffset switchover sync synchronous synonym sys sys_xmlagg sysasm sysaux sysdate sysdatetimeoffset sysdba sysoper system system_user sysutcdatetime table tables tablespace tan tdo template temporary terminated tertiary_weights test than then thread through tier ties time time_format time_zone timediff timefromparts timeout timestamp timestampadd timestampdiff timezone_abbr timezone_minute timezone_region to to_base64 to_date to_days to_seconds todatetimeoffset trace tracking transaction transactional translate translation treat trigger trigger_nestlevel triggers trim truncate try_cast try_convert try_parse type ub1 ub2 ub4 ucase unarchived unbounded uncompress under undo unhex unicode uniform uninstall union unique unix_timestamp unknown unlimited unlock unpivot unrecoverable unsafe unsigned until untrusted unusable unused update updated upgrade upped upper upsert url urowid usable usage use use_stored_outlines user user_data user_resources users using utc_date utc_timestamp uuid uuid_short validate validate_password_strength validation valist value values var var_samp varcharc vari varia variab variabl variable variables variance varp varraw varrawc varray verify version versions view virtual visible void wait wallet warning warnings week weekday weekofyear wellformed when whene whenev wheneve whenever where while whitespace with within without work wrapped xdb xml xmlagg xmlattributes xmlcast xmlcolattval xmlelement xmlexists xmlforest xmlindex xmlnamespaces xmlpi xmlquery xmlroot xmlschema xmlserialize xmltable xmltype xor year year_to_month years yearweek",literal:"true false null",built_in:"array bigint binary bit blob boolean char character date dec decimal float int int8 integer interval number numeric real record serial serial8 smallint text varchar varying void"},c:[{cN:"string",b:"'",e:"'",c:[e.BE,{b:"''"}]},{cN:"string",b:'"',e:'"',c:[e.BE,{b:'""'}]},{cN:"string",b:"`",e:"`",c:[e.BE]},e.CNM,e.CBCM,t]},e.CBCM,t]}});hljs.registerLanguage("r",function(e){var r="([a-zA-Z]|\\.[a-zA-Z.])[a-zA-Z0-9._]*";return{c:[e.HCM,{b:r,l:r,k:{keyword:"function if in break next repeat else for return switch while try tryCatch stop warning require library attach detach source setMethod setGeneric setGroupGeneric setClass ...",literal:"NULL NA TRUE FALSE T F Inf NaN NA_integer_|10 NA_real_|10 NA_character_|10 NA_complex_|10"},r:0},{cN:"number",b:"0[xX][0-9a-fA-F]+[Li]?\\b",r:0},{cN:"number",b:"\\d+(?:[eE][+\\-]?\\d*)?L\\b",r:0},{cN:"number",b:"\\d+\\.(?!\\d)(?:i\\b)?",r:0},{cN:"number",b:"\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",r:0},{b:"`",e:"`",r:0},{cN:"string",c:[e.BE],v:[{b:'"',e:'"'},{b:"'",e:"'"}]}]}});hljs.registerLanguage("perl",function(e){var t="getpwent getservent quotemeta msgrcv scalar kill dbmclose undef lc ma syswrite tr send umask sysopen shmwrite vec qx utime local oct semctl localtime readpipe do return format read sprintf dbmopen pop getpgrp not getpwnam rewinddir qqfileno qw endprotoent wait sethostent bless s|0 opendir continue each sleep endgrent shutdown dump chomp connect getsockname die socketpair close flock exists index shmgetsub for endpwent redo lstat msgctl setpgrp abs exit select print ref gethostbyaddr unshift fcntl syscall goto getnetbyaddr join gmtime symlink semget splice x|0 getpeername recv log setsockopt cos last reverse gethostbyname getgrnam study formline endhostent times chop length gethostent getnetent pack getprotoent getservbyname rand mkdir pos chmod y|0 substr endnetent printf next open msgsnd readdir use unlink getsockopt getpriority rindex wantarray hex system getservbyport endservent int chr untie rmdir prototype tell listen fork shmread ucfirst setprotoent else sysseek link getgrgid shmctl waitpid unpack getnetbyname reset chdir grep split require caller lcfirst until warn while values shift telldir getpwuid my getprotobynumber delete and sort uc defined srand accept package seekdir getprotobyname semop our rename seek if q|0 chroot sysread setpwent no crypt getc chown sqrt write setnetent setpriority foreach tie sin msgget map stat getlogin unless elsif truncate exec keys glob tied closedirioctl socket readlink eval xor readline binmode setservent eof ord bind alarm pipe atan2 getgrent exp time push setgrent gt lt or ne m|0 break given say state when",r={cN:"subst",b:"[$@]\\{",e:"\\}",k:t},s={b:"->{",e:"}"},n={v:[{b:/\$\d/},{b:/[\$%@](\^\w\b|#\w+(::\w+)*|{\w+}|\w+(::\w*)*)/},{b:/[\$%@][^\s\w{]/,r:0}]},i=[e.BE,r,n],o=[n,e.HCM,e.C("^\\=\\w","\\=cut",{eW:!0}),s,{cN:"string",c:i,v:[{b:"q[qwxr]?\\s*\\(",e:"\\)",r:5},{b:"q[qwxr]?\\s*\\[",e:"\\]",r:5},{b:"q[qwxr]?\\s*\\{",e:"\\}",r:5},{b:"q[qwxr]?\\s*\\|",e:"\\|",r:5},{b:"q[qwxr]?\\s*\\<",e:"\\>",r:5},{b:"qw\\s+q",e:"q",r:5},{b:"'",e:"'",c:[e.BE]},{b:'"',e:'"'},{b:"`",e:"`",c:[e.BE]},{b:"{\\w+}",c:[],r:0},{b:"-?\\w+\\s*\\=\\>",c:[],r:0}]},{cN:"number",b:"(\\b0[0-7_]+)|(\\b0x[0-9a-fA-F_]+)|(\\b[1-9][0-9_]*(\\.[0-9_]+)?)|[0_]\\b",r:0},{b:"(\\/\\/|"+e.RSR+"|\\b(split|return|print|reverse|grep)\\b)\\s*",k:"split return print reverse grep",r:0,c:[e.HCM,{cN:"regexp",b:"(s|tr|y)/(\\\\.|[^/])*/(\\\\.|[^/])*/[a-z]*",r:10},{cN:"regexp",b:"(m|qr)?/",e:"/[a-z]*",c:[e.BE],r:0}]},{cN:"function",bK:"sub",e:"(\\s*\\(.*?\\))?[;{]",eE:!0,r:5,c:[e.TM]},{b:"-\\w\\b",r:0},{b:"^__DATA__$",e:"^__END__$",sL:"mojolicious",c:[{b:"^@@.*",e:"$",cN:"comment"}]}];return r.c=o,s.c=o,{aliases:["pl","pm"],l:/[\w\.]+/,k:t,c:o}});hljs.registerLanguage("ini",function(e){var b={cN:"string",c:[e.BE],v:[{b:"'''",e:"'''",r:10},{b:'"""',e:'"""',r:10},{b:'"',e:'"'},{b:"'",e:"'"}]};return{aliases:["toml"],cI:!0,i:/\S/,c:[e.C(";","$"),e.HCM,{cN:"section",b:/^\s*\[+/,e:/\]+/},{b:/^[a-z0-9\[\]_-]+\s*=\s*/,e:"$",rB:!0,c:[{cN:"attr",b:/[a-z0-9\[\]_-]+/},{b:/=/,eW:!0,r:0,c:[{cN:"literal",b:/\bon|off|true|false|yes|no\b/},{cN:"variable",v:[{b:/\$[\w\d"][\w\d_]*/},{b:/\$\{(.*?)}/}]},b,{cN:"number",b:/([\+\-]+)?[\d]+_[\d_]+/},e.NM]}]}]}});hljs.registerLanguage("diff",function(e){return{aliases:["patch"],c:[{cN:"meta",r:10,v:[{b:/^@@ +\-\d+,\d+ +\+\d+,\d+ +@@$/},{b:/^\*\*\* +\d+,\d+ +\*\*\*\*$/},{b:/^\-\-\- +\d+,\d+ +\-\-\-\-$/}]},{cN:"comment",v:[{b:/Index: /,e:/$/},{b:/={3,}/,e:/$/},{b:/^\-{3}/,e:/$/},{b:/^\*{3} /,e:/$/},{b:/^\+{3}/,e:/$/},{b:/\*{5}/,e:/\*{5}$/}]},{cN:"addition",b:"^\\+",e:"$"},{cN:"deletion",b:"^\\-",e:"$"},{cN:"addition",b:"^\\!",e:"$"}]}});hljs.registerLanguage("go",function(e){var t={keyword:"break default func interface select case map struct chan else goto package switch const fallthrough if range type continue for import return var go defer bool byte complex64 complex128 float32 float64 int8 int16 int32 int64 string uint8 uint16 uint32 uint64 int uint uintptr rune",literal:"true false iota nil",built_in:"append cap close complex copy imag len make new panic print println real recover delete"};return{aliases:["golang"],k:t,i:"</",c:[e.CLCM,e.CBCM,{cN:"string",v:[e.QSM,{b:"'",e:"[^\\\\]'"},{b:"`",e:"`"}]},{cN:"number",v:[{b:e.CNR+"[dflsi]",r:1},e.CNM]},{b:/:=/},{cN:"function",bK:"func",e:/\s*\{/,eE:!0,c:[e.TM,{cN:"params",b:/\(/,e:/\)/,k:t,i:/["']/}]}]}});hljs.registerLanguage("bash",function(e){var t={cN:"variable",v:[{b:/\$[\w\d#@][\w\d_]*/},{b:/\$\{(.*?)}/}]},s={cN:"string",b:/"/,e:/"/,c:[e.BE,t,{cN:"variable",b:/\$\(/,e:/\)/,c:[e.BE]}]},a={cN:"string",b:/'/,e:/'/};return{aliases:["sh","zsh"],l:/\b-?[a-z\._]+\b/,k:{keyword:"if then else elif fi for while in do done case esac function",literal:"true false",built_in:"break cd continue eval exec exit export getopts hash pwd readonly return shift test times trap umask unset alias bind builtin caller command declare echo enable help let local logout mapfile printf read readarray source type typeset ulimit unalias set shopt autoload bg bindkey bye cap chdir clone comparguments compcall compctl compdescribe compfiles compgroups compquote comptags comptry compvalues dirs disable disown echotc echoti emulate fc fg float functions getcap getln history integer jobs kill limit log noglob popd print pushd pushln rehash sched setcap setopt stat suspend ttyctl unfunction unhash unlimit unsetopt vared wait whence where which zcompile zformat zftp zle zmodload zparseopts zprof zpty zregexparse zsocket zstyle ztcp",_:"-ne -eq -lt -gt -f -d -e -s -l -a"},c:[{cN:"meta",b:/^#![^\n]+sh\s*$/,r:10},{cN:"function",b:/\w[\w\d_]*\s*\(\s*\)\s*\{/,rB:!0,c:[e.inherit(e.TM,{b:/\w[\w\d_]*/})],r:0},e.HCM,s,a,t]}});hljs.registerLanguage("python",function(e){var r={keyword:"and elif is global as in if from raise for except finally print import pass return exec else break not with class assert yield try while continue del or def lambda async await nonlocal|10 None True False",built_in:"Ellipsis NotImplemented"},b={cN:"meta",b:/^(>>>|\.\.\.) /},c={cN:"subst",b:/\{/,e:/\}/,k:r,i:/#/},a={cN:"string",c:[e.BE],v:[{b:/(u|b)?r?'''/,e:/'''/,c:[b],r:10},{b:/(u|b)?r?"""/,e:/"""/,c:[b],r:10},{b:/(fr|rf|f)'''/,e:/'''/,c:[b,c]},{b:/(fr|rf|f)"""/,e:/"""/,c:[b,c]},{b:/(u|r|ur)'/,e:/'/,r:10},{b:/(u|r|ur)"/,e:/"/,r:10},{b:/(b|br)'/,e:/'/},{b:/(b|br)"/,e:/"/},{b:/(fr|rf|f)'/,e:/'/,c:[c]},{b:/(fr|rf|f)"/,e:/"/,c:[c]},e.ASM,e.QSM]},s={cN:"number",r:0,v:[{b:e.BNR+"[lLjJ]?"},{b:"\\b(0o[0-7]+)[lLjJ]?"},{b:e.CNR+"[lLjJ]?"}]},i={cN:"params",b:/\(/,e:/\)/,c:["self",b,s,a]};return c.c=[a,s,b],{aliases:["py","gyp"],k:r,i:/(<\/|->|\?)|=>/,c:[b,s,a,e.HCM,{v:[{cN:"function",bK:"def"},{cN:"class",bK:"class"}],e:/:/,i:/[${=;\n,]/,c:[e.UTM,i,{b:/->/,eW:!0,k:"None"}]},{cN:"meta",b:/^[\t ]*@/,e:/$/},{b:/\b(print|exec)\(/}]}});hljs.registerLanguage("julia",function(e){var r={keyword:"in isa where baremodule begin break catch ccall const continue do else elseif end export false finally for function global if import importall let local macro module quote return true try using while type immutable abstract bitstype typealias ",literal:"true false ARGS C_NULL DevNull ENDIAN_BOM ENV I Inf Inf16 Inf32 Inf64 InsertionSort JULIA_HOME LOAD_PATH MergeSort NaN NaN16 NaN32 NaN64 PROGRAM_FILE QuickSort RoundDown RoundFromZero RoundNearest RoundNearestTiesAway RoundNearestTiesUp RoundToZero RoundUp STDERR STDIN STDOUT VERSION catalan e|0 eu|0 eulergamma golden im nothing pi γ π φ ",built_in:"ANY AbstractArray AbstractChannel AbstractFloat AbstractMatrix AbstractRNG AbstractSerializer AbstractSet AbstractSparseArray AbstractSparseMatrix AbstractSparseVector AbstractString AbstractUnitRange AbstractVecOrMat AbstractVector Any ArgumentError Array AssertionError Associative Base64DecodePipe Base64EncodePipe Bidiagonal BigFloat BigInt BitArray BitMatrix BitVector Bool BoundsError BufferStream CachingPool CapturedException CartesianIndex CartesianRange Cchar Cdouble Cfloat Channel Char Cint Cintmax_t Clong Clonglong ClusterManager Cmd CodeInfo Colon Complex Complex128 Complex32 Complex64 CompositeException Condition ConjArray ConjMatrix ConjVector Cptrdiff_t Cshort Csize_t Cssize_t Cstring Cuchar Cuint Cuintmax_t Culong Culonglong Cushort Cwchar_t Cwstring DataType Date DateFormat DateTime DenseArray DenseMatrix DenseVecOrMat DenseVector Diagonal Dict DimensionMismatch Dims DirectIndexString Display DivideError DomainError EOFError EachLine Enum Enumerate ErrorException Exception ExponentialBackOff Expr Factorization FileMonitor Float16 Float32 Float64 Function Future GlobalRef GotoNode HTML Hermitian IO IOBuffer IOContext IOStream IPAddr IPv4 IPv6 IndexCartesian IndexLinear IndexStyle InexactError InitError Int Int128 Int16 Int32 Int64 Int8 IntSet Integer InterruptException InvalidStateException Irrational KeyError LabelNode LinSpace LineNumberNode LoadError LowerTriangular MIME Matrix MersenneTwister Method MethodError MethodTable Module NTuple NewvarNode NullException Nullable Number ObjectIdDict OrdinalRange OutOfMemoryError OverflowError Pair ParseError PartialQuickSort PermutedDimsArray Pipe PollingFileWatcher ProcessExitedException Ptr QuoteNode RandomDevice Range RangeIndex Rational RawFD ReadOnlyMemoryError Real ReentrantLock Ref Regex RegexMatch RemoteChannel RemoteException RevString RoundingMode RowVector SSAValue SegmentationFault SerializationState Set SharedArray SharedMatrix SharedVector Signed SimpleVector Slot SlotNumber SparseMatrixCSC SparseVector StackFrame StackOverflowError StackTrace StepRange StepRangeLen StridedArray StridedMatrix StridedVecOrMat StridedVector String SubArray SubString SymTridiagonal Symbol Symmetric SystemError TCPSocket Task Text TextDisplay Timer Tridiagonal Tuple Type TypeError TypeMapEntry TypeMapLevel TypeName TypeVar TypedSlot UDPSocket UInt UInt128 UInt16 UInt32 UInt64 UInt8 UndefRefError UndefVarError UnicodeError UniformScaling Union UnionAll UnitRange Unsigned UpperTriangular Val Vararg VecElement VecOrMat Vector VersionNumber Void WeakKeyDict WeakRef WorkerConfig WorkerPool "},t="[A-Za-z_\\u00A1-\\uFFFF][A-Za-z_0-9\\u00A1-\\uFFFF]*",a={l:t,k:r,i:/<\//},n={cN:"number",b:/(\b0x[\d_]*(\.[\d_]*)?|0x\.\d[\d_]*)p[-+]?\d+|\b0[box][a-fA-F0-9][a-fA-F0-9_]*|(\b\d[\d_]*(\.[\d_]*)?|\.\d[\d_]*)([eEfF][-+]?\d+)?/,r:0},o={cN:"string",b:/'(.|\\[xXuU][a-zA-Z0-9]+)'/},i={cN:"subst",b:/\$\(/,e:/\)/,k:r},l={cN:"variable",b:"\\$"+t},c={cN:"string",c:[e.BE,i,l],v:[{b:/\w*"""/,e:/"""\w*/,r:10},{b:/\w*"/,e:/"\w*/}]},s={cN:"string",c:[e.BE,i,l],b:"`",e:"`"},d={cN:"meta",b:"@"+t},u={cN:"comment",v:[{b:"#=",e:"=#",r:10},{b:"#",e:"$"}]};return a.c=[n,o,c,s,d,u,e.HCM,{cN:"keyword",b:"\\b(((abstract|primitive)\\s+)type|(mutable\\s+)?struct)\\b"},{b:/<:/}],i.c=a.c,a});hljs.registerLanguage("coffeescript",function(e){var c={keyword:"in if for while finally new do return else break catch instanceof throw try this switch continue typeof delete debugger super yield import export from as default await then unless until loop of by when and or is isnt not",literal:"true false null undefined yes no on off",built_in:"npm require console print module global window document"},n="[A-Za-z$_][0-9A-Za-z$_]*",r={cN:"subst",b:/#\{/,e:/}/,k:c},i=[e.BNM,e.inherit(e.CNM,{starts:{e:"(\\s*/)?",r:0}}),{cN:"string",v:[{b:/'''/,e:/'''/,c:[e.BE]},{b:/'/,e:/'/,c:[e.BE]},{b:/"""/,e:/"""/,c:[e.BE,r]},{b:/"/,e:/"/,c:[e.BE,r]}]},{cN:"regexp",v:[{b:"///",e:"///",c:[r,e.HCM]},{b:"//[gim]*",r:0},{b:/\/(?![ *])(\\\/|.)*?\/[gim]*(?=\W|$)/}]},{b:"@"+n},{sL:"javascript",eB:!0,eE:!0,v:[{b:"```",e:"```"},{b:"`",e:"`"}]}];r.c=i;var s=e.inherit(e.TM,{b:n}),t="(\\(.*\\))?\\s*\\B[-=]>",o={cN:"params",b:"\\([^\\(]",rB:!0,c:[{b:/\(/,e:/\)/,k:c,c:["self"].concat(i)}]};return{aliases:["coffee","cson","iced"],k:c,i:/\/\*/,c:i.concat([e.C("###","###"),e.HCM,{cN:"function",b:"^\\s*"+n+"\\s*=\\s*"+t,e:"[-=]>",rB:!0,c:[s,o]},{b:/[:\(,=]\s*/,r:0,c:[{cN:"function",b:t,e:"[-=]>",rB:!0,c:[o]}]},{cN:"class",bK:"class",e:"$",i:/[:="\[\]]/,c:[{bK:"extends",eW:!0,i:/[:="\[\]]/,c:[s]},s]},{b:n+":",e:":",rB:!0,rE:!0,r:0}])}});hljs.registerLanguage("cpp",function(t){var e={cN:"keyword",b:"\\b[a-z\\d_]*_t\\b"},r={cN:"string",v:[{b:'(u8?|U)?L?"',e:'"',i:"\\n",c:[t.BE]},{b:'(u8?|U)?R"',e:'"',c:[t.BE]},{b:"'\\\\?.",e:"'",i:"."}]},s={cN:"number",v:[{b:"\\b(0b[01']+)"},{b:"(-?)\\b([\\d']+(\\.[\\d']*)?|\\.[\\d']+)(u|U|l|L|ul|UL|f|F|b|B)"},{b:"(-?)(\\b0[xX][a-fA-F0-9']+|(\\b[\\d']+(\\.[\\d']*)?|\\.[\\d']+)([eE][-+]?[\\d']+)?)"}],r:0},i={cN:"meta",b:/#\s*[a-z]+\b/,e:/$/,k:{"meta-keyword":"if else elif endif define undef warning error line pragma ifdef ifndef include"},c:[{b:/\\\n/,r:0},t.inherit(r,{cN:"meta-string"}),{cN:"meta-string",b:/<[^\n>]*>/,e:/$/,i:"\\n"},t.CLCM,t.CBCM]},a=t.IR+"\\s*\\(",c={keyword:"int float while private char catch import module export virtual operator sizeof dynamic_cast|10 typedef const_cast|10 const for static_cast|10 union namespace unsigned long volatile static protected bool template mutable if public friend do goto auto void enum else break extern using asm case typeid short reinterpret_cast|10 default double register explicit signed typename try this switch continue inline delete alignof constexpr decltype noexcept static_assert thread_local restrict _Bool complex _Complex _Imaginary atomic_bool atomic_char atomic_schar atomic_uchar atomic_short atomic_ushort atomic_int atomic_uint atomic_long atomic_ulong atomic_llong atomic_ullong new throw return and or not",built_in:"std string cin cout cerr clog stdin stdout stderr stringstream istringstream ostringstream auto_ptr deque list queue stack vector map set bitset multiset multimap unordered_set unordered_map unordered_multiset unordered_multimap array shared_ptr abort abs acos asin atan2 atan calloc ceil cosh cos exit exp fabs floor fmod fprintf fputs free frexp fscanf isalnum isalpha iscntrl isdigit isgraph islower isprint ispunct isspace isupper isxdigit tolower toupper labs ldexp log10 log malloc realloc memchr memcmp memcpy memset modf pow printf putchar puts scanf sinh sin snprintf sprintf sqrt sscanf strcat strchr strcmp strcpy strcspn strlen strncat strncmp strncpy strpbrk strrchr strspn strstr tanh tan vfprintf vprintf vsprintf endl initializer_list unique_ptr",literal:"true false nullptr NULL"},n=[e,t.CLCM,t.CBCM,s,r];return{aliases:["c","cc","h","c++","h++","hpp"],k:c,i:"</",c:n.concat([i,{b:"\\b(deque|list|queue|stack|vector|map|set|bitset|multiset|multimap|unordered_map|unordered_set|unordered_multiset|unordered_multimap|array)\\s*<",e:">",k:c,c:["self",e]},{b:t.IR+"::",k:c},{v:[{b:/=/,e:/;/},{b:/\(/,e:/\)/},{bK:"new throw return else",e:/;/}],k:c,c:n.concat([{b:/\(/,e:/\)/,k:c,c:n.concat(["self"]),r:0}]),r:0},{cN:"function",b:"("+t.IR+"[\\*&\\s]+)+"+a,rB:!0,e:/[{;=]/,eE:!0,k:c,i:/[^\w\s\*&]/,c:[{b:a,rB:!0,c:[t.TM],r:0},{cN:"params",b:/\(/,e:/\)/,k:c,r:0,c:[t.CLCM,t.CBCM,r,s,e]},t.CLCM,t.CBCM,i]},{cN:"class",bK:"class struct",e:/[{;:]/,c:[{b:/</,e:/>/,c:["self"]},t.TM]}]),exports:{preprocessor:i,strings:r,k:c}}});hljs.registerLanguage("ruby",function(e){var b="[a-zA-Z_]\\w*[!?=]?|[-+~]\\@|<<|>>|=~|===?|<=>|[<>]=?|\\*\\*|[-/+%^&*~`|]|\\[\\]=?",r={keyword:"and then defined module in return redo if BEGIN retry end for self when next until do begin unless END rescue else break undef not super class case require yield alias while ensure elsif or include attr_reader attr_writer attr_accessor",literal:"true false nil"},c={cN:"doctag",b:"@[A-Za-z]+"},a={b:"#<",e:">"},s=[e.C("#","$",{c:[c]}),e.C("^\\=begin","^\\=end",{c:[c],r:10}),e.C("^__END__","\\n$")],n={cN:"subst",b:"#\\{",e:"}",k:r},t={cN:"string",c:[e.BE,n],v:[{b:/'/,e:/'/},{b:/"/,e:/"/},{b:/`/,e:/`/},{b:"%[qQwWx]?\\(",e:"\\)"},{b:"%[qQwWx]?\\[",e:"\\]"},{b:"%[qQwWx]?{",e:"}"},{b:"%[qQwWx]?<",e:">"},{b:"%[qQwWx]?/",e:"/"},{b:"%[qQwWx]?%",e:"%"},{b:"%[qQwWx]?-",e:"-"},{b:"%[qQwWx]?\\|",e:"\\|"},{b:/\B\?(\\\d{1,3}|\\x[A-Fa-f0-9]{1,2}|\\u[A-Fa-f0-9]{4}|\\?\S)\b/},{b:/<<(-?)\w+$/,e:/^\s*\w+$/}]},i={cN:"params",b:"\\(",e:"\\)",endsParent:!0,k:r},d=[t,a,{cN:"class",bK:"class module",e:"$|;",i:/=/,c:[e.inherit(e.TM,{b:"[A-Za-z_]\\w*(::\\w+)*(\\?|\\!)?"}),{b:"<\\s*",c:[{b:"("+e.IR+"::)?"+e.IR}]}].concat(s)},{cN:"function",bK:"def",e:"$|;",c:[e.inherit(e.TM,{b:b}),i].concat(s)},{b:e.IR+"::"},{cN:"symbol",b:e.UIR+"(\\!|\\?)?:",r:0},{cN:"symbol",b:":(?!\\s)",c:[t,{b:b}],r:0},{cN:"number",b:"(\\b0[0-7_]+)|(\\b0x[0-9a-fA-F_]+)|(\\b[1-9][0-9_]*(\\.[0-9_]+)?)|[0_]\\b",r:0},{b:"(\\$\\W)|((\\$|\\@\\@?)(\\w+))"},{cN:"params",b:/\|/,e:/\|/,k:r},{b:"("+e.RSR+"|unless)\\s*",k:"unless",c:[a,{cN:"regexp",c:[e.BE,n],i:/\n/,v:[{b:"/",e:"/[a-z]*"},{b:"%r{",e:"}[a-z]*"},{b:"%r\\(",e:"\\)[a-z]*"},{b:"%r!",e:"![a-z]*"},{b:"%r\\[",e:"\\][a-z]*"}]}].concat(s),r:0}].concat(s);n.c=d,i.c=d;var l="[>?]>",o="[\\w#]+\\(\\w+\\):\\d+:\\d+>",u="(\\w+-)?\\d+\\.\\d+\\.\\d(p\\d+)?[^>]+>",w=[{b:/^\s*=>/,starts:{e:"$",c:d}},{cN:"meta",b:"^("+l+"|"+o+"|"+u+")",starts:{e:"$",c:d}}];return{aliases:["rb","gemspec","podspec","thor","irb"],k:r,i:/\/\*/,c:s.concat(w).concat(d)}});hljs.registerLanguage("yaml",function(e){var b="true false yes no null",a="^[ \\-]*",r="[a-zA-Z_][\\w\\-]*",t={cN:"attr",v:[{b:a+r+":"},{b:a+'"'+r+'":'},{b:a+"'"+r+"':"}]},c={cN:"template-variable",v:[{b:"{{",e:"}}"},{b:"%{",e:"}"}]},l={cN:"string",r:0,v:[{b:/'/,e:/'/},{b:/"/,e:/"/},{b:/\S+/}],c:[e.BE,c]};return{cI:!0,aliases:["yml","YAML","yaml"],c:[t,{cN:"meta",b:"^---s*$",r:10},{cN:"string",b:"[\\|>] *$",rE:!0,c:l.c,e:t.v[0].b},{b:"<%[%=-]?",e:"[%-]?%>",sL:"ruby",eB:!0,eE:!0,r:0},{cN:"type",b:"!!"+e.UIR},{cN:"meta",b:"&"+e.UIR+"$"},{cN:"meta",b:"\\*"+e.UIR+"$"},{cN:"bullet",b:"^ *-",r:0},e.HCM,{bK:b,k:{literal:b}},e.CNM,l]}});hljs.registerLanguage("css",function(e){var c="[a-zA-Z-][a-zA-Z0-9_-]*",t={b:/[A-Z\_\.\-]+\s*:/,rB:!0,e:";",eW:!0,c:[{cN:"attribute",b:/\S/,e:":",eE:!0,starts:{eW:!0,eE:!0,c:[{b:/[\w-]+\(/,rB:!0,c:[{cN:"built_in",b:/[\w-]+/},{b:/\(/,e:/\)/,c:[e.ASM,e.QSM]}]},e.CSSNM,e.QSM,e.ASM,e.CBCM,{cN:"number",b:"#[0-9A-Fa-f]+"},{cN:"meta",b:"!important"}]}}]};return{cI:!0,i:/[=\/|'\$]/,c:[e.CBCM,{cN:"selector-id",b:/#[A-Za-z0-9_-]+/},{cN:"selector-class",b:/\.[A-Za-z0-9_-]+/},{cN:"selector-attr",b:/\[/,e:/\]/,i:"$"},{cN:"selector-pseudo",b:/:(:)?[a-zA-Z0-9\_\-\+\(\)"'.]+/},{b:"@(font-face|page)",l:"[a-z-]+",k:"font-face page"},{b:"@",e:"[{;]",i:/:/,c:[{cN:"keyword",b:/\w+/},{b:/\s/,eW:!0,eE:!0,r:0,c:[e.ASM,e.QSM,e.CSSNM]}]},{cN:"selector-tag",b:c,r:0},{b:"{",e:"}",i:/\S/,c:[e.CBCM,t]}]}});hljs.registerLanguage("fortran",function(e){var t={cN:"params",b:"\\(",e:"\\)"},n={literal:".False. .True.",keyword:"kind do while private call intrinsic where elsewhere type endtype endmodule endselect endinterface end enddo endif if forall endforall only contains default return stop then public subroutine|10 function program .and. .or. .not. .le. .eq. .ge. .gt. .lt. goto save else use module select case access blank direct exist file fmt form formatted iostat name named nextrec number opened rec recl sequential status unformatted unit continue format pause cycle exit c_null_char c_alert c_backspace c_form_feed flush wait decimal round iomsg synchronous nopass non_overridable pass protected volatile abstract extends import non_intrinsic value deferred generic final enumerator class associate bind enum c_int c_short c_long c_long_long c_signed_char c_size_t c_int8_t c_int16_t c_int32_t c_int64_t c_int_least8_t c_int_least16_t c_int_least32_t c_int_least64_t c_int_fast8_t c_int_fast16_t c_int_fast32_t c_int_fast64_t c_intmax_t C_intptr_t c_float c_double c_long_double c_float_complex c_double_complex c_long_double_complex c_bool c_char c_null_ptr c_null_funptr c_new_line c_carriage_return c_horizontal_tab c_vertical_tab iso_c_binding c_loc c_funloc c_associated  c_f_pointer c_ptr c_funptr iso_fortran_env character_storage_size error_unit file_storage_size input_unit iostat_end iostat_eor numeric_storage_size output_unit c_f_procpointer ieee_arithmetic ieee_support_underflow_control ieee_get_underflow_mode ieee_set_underflow_mode newunit contiguous recursive pad position action delim readwrite eor advance nml interface procedure namelist include sequence elemental pure integer real character complex logical dimension allocatable|10 parameter external implicit|10 none double precision assign intent optional pointer target in out common equivalence data",built_in:"alog alog10 amax0 amax1 amin0 amin1 amod cabs ccos cexp clog csin csqrt dabs dacos dasin datan datan2 dcos dcosh ddim dexp dint dlog dlog10 dmax1 dmin1 dmod dnint dsign dsin dsinh dsqrt dtan dtanh float iabs idim idint idnint ifix isign max0 max1 min0 min1 sngl algama cdabs cdcos cdexp cdlog cdsin cdsqrt cqabs cqcos cqexp cqlog cqsin cqsqrt dcmplx dconjg derf derfc dfloat dgamma dimag dlgama iqint qabs qacos qasin qatan qatan2 qcmplx qconjg qcos qcosh qdim qerf qerfc qexp qgamma qimag qlgama qlog qlog10 qmax1 qmin1 qmod qnint qsign qsin qsinh qsqrt qtan qtanh abs acos aimag aint anint asin atan atan2 char cmplx conjg cos cosh exp ichar index int log log10 max min nint sign sin sinh sqrt tan tanh print write dim lge lgt lle llt mod nullify allocate deallocate adjustl adjustr all allocated any associated bit_size btest ceiling count cshift date_and_time digits dot_product eoshift epsilon exponent floor fraction huge iand ibclr ibits ibset ieor ior ishft ishftc lbound len_trim matmul maxexponent maxloc maxval merge minexponent minloc minval modulo mvbits nearest pack present product radix random_number random_seed range repeat reshape rrspacing scale scan selected_int_kind selected_real_kind set_exponent shape size spacing spread sum system_clock tiny transpose trim ubound unpack verify achar iachar transfer dble entry dprod cpu_time command_argument_count get_command get_command_argument get_environment_variable is_iostat_end ieee_arithmetic ieee_support_underflow_control ieee_get_underflow_mode ieee_set_underflow_mode is_iostat_eor move_alloc new_line selected_char_kind same_type_as extends_type_ofacosh asinh atanh bessel_j0 bessel_j1 bessel_jn bessel_y0 bessel_y1 bessel_yn erf erfc erfc_scaled gamma log_gamma hypot norm2 atomic_define atomic_ref execute_command_line leadz trailz storage_size merge_bits bge bgt ble blt dshiftl dshiftr findloc iall iany iparity image_index lcobound ucobound maskl maskr num_images parity popcnt poppar shifta shiftl shiftr this_image"};return{cI:!0,aliases:["f90","f95"],k:n,i:/\/\*/,c:[e.inherit(e.ASM,{cN:"string",r:0}),e.inherit(e.QSM,{cN:"string",r:0}),{cN:"function",bK:"subroutine function program",i:"[${=\\n]",c:[e.UTM,t]},e.C("!","$",{r:0}),{cN:"number",b:"(?=\\b|\\+|\\-|\\.)(?=\\.\\d|\\d)(?:\\d+)?(?:\\.?\\d*)(?:[de][+-]?\\d+)?\\b\\.?",r:0}]}});hljs.registerLanguage("awk",function(e){var r={cN:"variable",v:[{b:/\$[\w\d#@][\w\d_]*/},{b:/\$\{(.*?)}/}]},b="BEGIN END if else while do for in break continue delete next nextfile function func exit|10",n={cN:"string",c:[e.BE],v:[{b:/(u|b)?r?'''/,e:/'''/,r:10},{b:/(u|b)?r?"""/,e:/"""/,r:10},{b:/(u|r|ur)'/,e:/'/,r:10},{b:/(u|r|ur)"/,e:/"/,r:10},{b:/(b|br)'/,e:/'/},{b:/(b|br)"/,e:/"/},e.ASM,e.QSM]};return{k:{keyword:b},c:[r,n,e.RM,e.HCM,e.NM]}});hljs.registerLanguage("makefile",function(e){var i={cN:"variable",v:[{b:"\\$\\("+e.UIR+"\\)",c:[e.BE]},{b:/\$[@%<?\^\+\*]/}]},r={cN:"string",b:/"/,e:/"/,c:[e.BE,i]},a={cN:"variable",b:/\$\([\w-]+\s/,e:/\)/,k:{built_in:"subst patsubst strip findstring filter filter-out sort word wordlist firstword lastword dir notdir suffix basename addsuffix addprefix join wildcard realpath abspath error warning shell origin flavor foreach if or and call eval file value"},c:[i]},n={b:"^"+e.UIR+"\\s*[:+?]?=",i:"\\n",rB:!0,c:[{b:"^"+e.UIR,e:"[:+?]?=",eE:!0}]},t={cN:"meta",b:/^\.PHONY:/,e:/$/,k:{"meta-keyword":".PHONY"},l:/[\.\w]+/},l={cN:"section",b:/^[^\s]+:/,e:/$/,c:[i]};return{aliases:["mk","mak"],k:"define endef undefine ifdef ifndef ifeq ifneq else endif include -include sinclude override export unexport private vpath",l:/[\w-]+/,c:[e.HCM,i,r,a,n,t,l]}});hljs.registerLanguage("java",function(e){var a="[À-ʸa-zA-Z_$][À-ʸa-zA-Z_$0-9]*",t=a+"(<"+a+"(\\s*,\\s*"+a+")*>)?",r="false synchronized int abstract float private char boolean static null if const for true while long strictfp finally protected import native final void enum else break transient catch instanceof byte super volatile case assert short package default double public try this switch continue throws protected public private module requires exports do",s="\\b(0[bB]([01]+[01_]+[01]+|[01]+)|0[xX]([a-fA-F0-9]+[a-fA-F0-9_]+[a-fA-F0-9]+|[a-fA-F0-9]+)|(([\\d]+[\\d_]+[\\d]+|[\\d]+)(\\.([\\d]+[\\d_]+[\\d]+|[\\d]+))?|\\.([\\d]+[\\d_]+[\\d]+|[\\d]+))([eE][-+]?\\d+)?)[lLfF]?",c={cN:"number",b:s,r:0};return{aliases:["jsp"],k:r,i:/<\/|#/,c:[e.C("/\\*\\*","\\*/",{r:0,c:[{b:/\w+@/,r:0},{cN:"doctag",b:"@[A-Za-z]+"}]}),e.CLCM,e.CBCM,e.ASM,e.QSM,{cN:"class",bK:"class interface",e:/[{;=]/,eE:!0,k:"class interface",i:/[:"\[\]]/,c:[{bK:"extends implements"},e.UTM]},{bK:"new throw return else",r:0},{cN:"function",b:"("+t+"\\s+)+"+e.UIR+"\\s*\\(",rB:!0,e:/[{;=]/,eE:!0,k:r,c:[{b:e.UIR+"\\s*\\(",rB:!0,r:0,c:[e.UTM]},{cN:"params",b:/\(/,e:/\)/,k:r,r:0,c:[e.ASM,e.QSM,e.CNM,e.CBCM]},e.CLCM,e.CBCM]},c,{cN:"meta",b:"@[A-Za-z]+"}]}});hljs.registerLanguage("stan",function(e){return{c:[e.HCM,e.CLCM,e.CBCM,{b:e.UIR,l:e.UIR,k:{name:"for in while repeat until if then else",symbol:"bernoulli bernoulli_logit binomial binomial_logit beta_binomial hypergeometric categorical categorical_logit ordered_logistic neg_binomial neg_binomial_2 neg_binomial_2_log poisson poisson_log multinomial normal exp_mod_normal skew_normal student_t cauchy double_exponential logistic gumbel lognormal chi_square inv_chi_square scaled_inv_chi_square exponential inv_gamma weibull frechet rayleigh wiener pareto pareto_type_2 von_mises uniform multi_normal multi_normal_prec multi_normal_cholesky multi_gp multi_gp_cholesky multi_student_t gaussian_dlm_obs dirichlet lkj_corr lkj_corr_cholesky wishart inv_wishart","selector-tag":"int real vector simplex unit_vector ordered positive_ordered row_vector matrix cholesky_factor_corr cholesky_factor_cov corr_matrix cov_matrix",title:"functions model data parameters quantities transformed generated",literal:"true false"},r:0},{cN:"number",b:"0[xX][0-9a-fA-F]+[Li]?\\b",r:0},{cN:"number",b:"0[xX][0-9a-fA-F]+[Li]?\\b",r:0},{cN:"number",b:"\\d+(?:[eE][+\\-]?\\d*)?L\\b",r:0},{cN:"number",b:"\\d+\\.(?!\\d)(?:i\\b)?",r:0},{cN:"number",b:"\\d+(?:\\.\\d*)?(?:[eE][+\\-]?\\d*)?i?\\b",r:0},{cN:"number",b:"\\.\\d+(?:[eE][+\\-]?\\d*)?i?\\b",r:0}]}});hljs.registerLanguage("javascript",function(e){var r="[A-Za-z$_][0-9A-Za-z$_]*",t={keyword:"in of if for while finally var new function do return void else break catch instanceof with throw case default try this switch continue typeof delete let yield const export super debugger as async await static import from as",literal:"true false null undefined NaN Infinity",built_in:"eval isFinite isNaN parseFloat parseInt decodeURI decodeURIComponent encodeURI encodeURIComponent escape unescape Object Function Boolean Error EvalError InternalError RangeError ReferenceError StopIteration SyntaxError TypeError URIError Number Math Date String RegExp Array Float32Array Float64Array Int16Array Int32Array Int8Array Uint16Array Uint32Array Uint8Array Uint8ClampedArray ArrayBuffer DataView JSON Intl arguments require module console window document Symbol Set Map WeakSet WeakMap Proxy Reflect Promise"},a={cN:"number",v:[{b:"\\b(0[bB][01]+)"},{b:"\\b(0[oO][0-7]+)"},{b:e.CNR}],r:0},n={cN:"subst",b:"\\$\\{",e:"\\}",k:t,c:[]},c={cN:"string",b:"`",e:"`",c:[e.BE,n]};n.c=[e.ASM,e.QSM,c,a,e.RM];var s=n.c.concat([e.CBCM,e.CLCM]);return{aliases:["js","jsx"],k:t,c:[{cN:"meta",r:10,b:/^\s*['"]use (strict|asm)['"]/},{cN:"meta",b:/^#!/,e:/$/},e.ASM,e.QSM,c,e.CLCM,e.CBCM,a,{b:/[{,]\s*/,r:0,c:[{b:r+"\\s*:",rB:!0,r:0,c:[{cN:"attr",b:r,r:0}]}]},{b:"("+e.RSR+"|\\b(case|return|throw)\\b)\\s*",k:"return throw case",c:[e.CLCM,e.CBCM,e.RM,{cN:"function",b:"(\\(.*?\\)|"+r+")\\s*=>",rB:!0,e:"\\s*=>",c:[{cN:"params",v:[{b:r},{b:/\(\s*\)/},{b:/\(/,e:/\)/,eB:!0,eE:!0,k:t,c:s}]}]},{b:/</,e:/(\/\w+|\w+\/)>/,sL:"xml",c:[{b:/<\w+\s*\/>/,skip:!0},{b:/<\w+/,e:/(\/\w+|\w+\/)>/,skip:!0,c:[{b:/<\w+\s*\/>/,skip:!0},"self"]}]}],r:0},{cN:"function",bK:"function",e:/\{/,eE:!0,c:[e.inherit(e.TM,{b:r}),{cN:"params",b:/\(/,e:/\)/,eB:!0,eE:!0,c:s}],i:/\[|%/},{b:/\$[(.]/},e.METHOD_GUARD,{cN:"class",bK:"class",e:/[{;=]/,eE:!0,i:/[:"\[\]]/,c:[{bK:"extends"},e.UTM]},{bK:"constructor",e:/\{/,eE:!0}],i:/#(?!!)/}});hljs.registerLanguage("tex",function(c){var e={cN:"tag",b:/\\/,r:0,c:[{cN:"name",v:[{b:/[a-zA-Zа-яА-я]+[*]?/},{b:/[^a-zA-Zа-яА-я0-9]/}],starts:{eW:!0,r:0,c:[{cN:"string",v:[{b:/\[/,e:/\]/},{b:/\{/,e:/\}/}]},{b:/\s*=\s*/,eW:!0,r:0,c:[{cN:"number",b:/-?\d*\.?\d+(pt|pc|mm|cm|in|dd|cc|ex|em)?/}]}]}}]};return{c:[e,{cN:"formula",c:[e],r:0,v:[{b:/\$\$/,e:/\$\$/},{b:/\$/,e:/\$/}]},c.C("%","$",{r:0})]}});hljs.registerLanguage("xml",function(s){var e="[A-Za-z0-9\\._:-]+",t={eW:!0,i:/</,r:0,c:[{cN:"attr",b:e,r:0},{b:/=\s*/,r:0,c:[{cN:"string",endsParent:!0,v:[{b:/"/,e:/"/},{b:/'/,e:/'/},{b:/[^\s"'=<>`]+/}]}]}]};return{aliases:["html","xhtml","rss","atom","xjb","xsd","xsl","plist"],cI:!0,c:[{cN:"meta",b:"<!DOCTYPE",e:">",r:10,c:[{b:"\\[",e:"\\]"}]},s.C("<!--","-->",{r:10}),{b:"<\\!\\[CDATA\\[",e:"\\]\\]>",r:10},{b:/<\?(php)?/,e:/\?>/,sL:"php",c:[{b:"/\\*",e:"\\*/",skip:!0}]},{cN:"tag",b:"<style(?=\\s|>|$)",e:">",k:{name:"style"},c:[t],starts:{e:"</style>",rE:!0,sL:["css","xml"]}},{cN:"tag",b:"<script(?=\\s|>|$)",e:">",k:{name:"script"},c:[t],starts:{e:"</script>",rE:!0,sL:["actionscript","javascript","handlebars","xml"]}},{cN:"meta",v:[{b:/<\?xml/,e:/\?>/,r:10},{b:/<\?\w+/,e:/\?>/}]},{cN:"tag",b:"</?",e:"/?>",c:[{cN:"name",b:/[^\/><\s]+/,r:0},t]}]}});hljs.registerLanguage("markdown",function(e){return{aliases:["md","mkdown","mkd"],c:[{cN:"section",v:[{b:"^#{1,6}",e:"$"},{b:"^.+?\\n[=-]{2,}$"}]},{b:"<",e:">",sL:"xml",r:0},{cN:"bullet",b:"^([*+-]|(\\d+\\.))\\s+"},{cN:"strong",b:"[*_]{2}.+?[*_]{2}"},{cN:"emphasis",v:[{b:"\\*.+?\\*"},{b:"_.+?_",r:0}]},{cN:"quote",b:"^>\\s+",e:"$"},{cN:"code",v:[{b:"^```w*s*$",e:"^```s*$"},{b:"`.+?`"},{b:"^( {4}|	)",e:"$",r:0}]},{b:"^[-\\*]{3,}",e:"$"},{b:"\\[.+?\\][\\(\\[].*?[\\)\\]]",rB:!0,c:[{cN:"string",b:"\\[",e:"\\]",eB:!0,rE:!0,r:0},{cN:"link",b:"\\]\\(",e:"\\)",eB:!0,eE:!0},{cN:"symbol",b:"\\]\\[",e:"\\]",eB:!0,eE:!0}],r:10},{b:/^\[[^\n]+\]:/,rB:!0,c:[{cN:"symbol",b:/\[/,e:/\]/,eB:!0,eE:!0},{cN:"link",b:/:\s*/,e:/$/,eB:!0}]}]}});hljs.registerLanguage("json",function(e){var i={literal:"true false null"},n=[e.QSM,e.CNM],r={e:",",eW:!0,eE:!0,c:n,k:i},t={b:"{",e:"}",c:[{cN:"attr",b:/"/,e:/"/,c:[e.BE],i:"\\n"},e.inherit(r,{b:/:/})],i:"\\S"},c={b:"\\[",e:"\\]",c:[e.inherit(r)],i:"\\S"};return n.splice(n.length,0,t,c),{c:n,k:i,i:"\\S"}});"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
#rmd-source-code {
  display: none;
}
</style>


</head>

<body>

<style type="text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>

<style type="text/css">
.kable-table {
  border: 1px solid #ccc;
  border-radius: 4px;
  overflow: auto;
  padding-left: 8px;
  padding-right: 8px;
  margin-bottom: 20px;
  max-height: 350px;
}

.kable-table table {
  margin-bottom: 0px;
}

.kable-table table>thead>tr>th {
  border: none;
  border-bottom: 2px solid #dddddd;
}

.kable-table table>thead {
  background-color: #fff;
}
</style>


<div class="container-fluid main-container">

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>
<script>
$(document).ready(function () {
  window.initializeSourceEmbed("pubmed_abstracts.Rmd");
  window.initializeCodeFolding("show" === "show");
});
</script>





<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
<li role="separator" class="divider"></li>
<li><a id="rmd-download-source" href="#">Download Rmd</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Analysing pubmed abstracts</h1>

</div>


<!-- rnb-text-begin -->
<!-- rnb-text-end -->
<!-- rnb-chunk-begin -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxua25pdHI6Om9wdHNfY2h1bmskc2V0KGNhY2hlID0gVFJVRSwgd2FybmluZyA9IEZBTFNFLCBtZXNzYWdlID0gRkFMU0UsIGVjaG8gPSBUUlVFKVxubGlicmFyeShwdXJycilcbmBgYCJ9 -->
<pre class="r"><code>knitr::opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE, echo = TRUE)
library(purrr)</code></pre>
<!-- rnb-source-end -->
<!-- rnb-chunk-end -->
<!-- rnb-text-begin -->
<div id="searching-and-analysing-medical-literature-with-r" class="section level1">
<h1>Searching and analysing medical literature with R</h1>
<p>We have developed a workflow in R to extract abstracts from Pubmed and apply natural language processing techniques to rapidly extract relevant information and analysis.</p>
<p>To assist this we can use the <code>pubmedAbstractR</code> function from the <code>myScrapers</code> package. This searches pubmed and allows the user to download abstracts directly into R. It is based on the <code>RISmed</code> package. It takes a number of arguments:</p>
<ul>
<li><em>search</em> - a search term which can be simple or complex (see below)</li>
<li><em>start</em> - a start data (or year) to begin the search</li>
<li><em>end</em> - an end data (or year) to complete the search</li>
<li><em>n</em> - number of abstracts to be downloaded - by default the first 1000 are downloaded</li>
<li><em>keyword</em> - if set to TRUE will download keywords</li>
<li><em>authors</em> - if set to TRUE will download authors and author order</li>
</ul>
<div id="getting-started" class="section level2">
<h2>Getting started</h2>
<p>For this exercise we need to install the <code>myScrapers</code> package as follows:</p>
<!-- rnb-text-end -->
<!-- rnb-chunk-begin -->
<!-- rnb-source-begin eyJkYXRhIjpbImlmKCFyZXF1aXJlKFwibXlTY3JhcGVyc1wiKSkiLCJkZXZ0b29sczo6aW5zdGFsbF9naXQoXCJodHRwczovL2dpdGxhYi5waGUuZ292LnVrL3BhY2thZ2VzL215U2NyYXBlcnNcIiwgZm9yY2UgPSBUUlVFKSIsImxpYnJhcnkobXlTY3JhcGVycykiXX0= -->
<pre class="r"><code>if(!require(&quot;myScrapers&quot;))
devtools::install_git(&quot;https://gitlab.phe.gov.uk/packages/myScrapers&quot;, force = TRUE)
library(myScrapers)</code></pre>
<!-- rnb-source-end -->
<!-- rnb-chunk-end -->
<!-- rnb-text-begin -->
</div>
<div id="example" class="section level2">
<h2>Example</h2>
<div id="non-specific-searching" class="section level3">
<h3>Non-specific searching</h3>
<p>Let us say we want to search for <em>machine learning in public health</em>. We can pass this as a search term to <code>pubmedAbstractR</code> as follows. Let’s set n = 1 to begin with.</p>
<!-- rnb-text-end -->
<!-- rnb-chunk-begin -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxubGlicmFyeShteVNjcmFwZXJzKVxubGlicmFyeSh0aWR5dmVyc2UpXG5zZWFyY2ggPC0gXCJtYWNoaW5lIGxlYXJuaW5nIHB1YmxpYyBoZWFsdGhcIlxuc3RhcnQgPC0gMjAwOFxuZW5kIDwtIDIwMThcbm4gPC0gMVxuICBcbiAgXG5hYnN0cmFjdHMgPC0gcHVibWVkQWJzdHJhY3RSKHNlYXJjaCA9IHNlYXJjaCwgc3RhcnQgPSBzdGFydCwgZW5kID0gZW5kLCBuID0gMSlcbmBgYCJ9 -->
<pre class="r"><code>library(myScrapers)
library(tidyverse)
search &lt;- &quot;machine learning public health&quot;
start &lt;- 2008
end &lt;- 2018
n &lt;- 1
  
  
abstracts &lt;- pubmedAbstractR(search = search, start = start, end = end, n = 1)</code></pre>
<!-- rnb-source-end -->
<!-- rnb-output-begin eyJkYXRhIjoiUGxlYXNlIHdhaXQuLi5Zb3VyIHF1ZXJ5IGlzICgoXCJtYWNoaW5lIGxlYXJuaW5nXCJbTWVTSCBUZXJtc10gT1IgKFwibWFjaGluZVwiW0FsbCBGaWVsZHNdIEFORCBcImxlYXJuaW5nXCJbQWxsIEZpZWxkc10pIE9SIFwibWFjaGluZSBsZWFybmluZ1wiW0FsbCBGaWVsZHNdKSBBTkQgKFwicHVibGljIGhlYWx0aFwiW01lU0ggVGVybXNdIE9SIChcInB1YmxpY1wiW0FsbCBGaWVsZHNdIEFORCBcImhlYWx0aFwiW0FsbCBGaWVsZHNdKSBPUiBcInB1YmxpYyBoZWFsdGhcIltBbGwgRmllbGRzXSkpIEFORCAyMDA4W1BEQVRdIDogMjAxOFtQREFUXS4gVGhpcyByZXR1cm5zIDk1MjIgYWJzdHJhY3RzLiBCeSBkZWZhdWx0IDEwMDAgYWJzdHJhY3RzIGFyZSBkb3dubG9hZGVkLiBZb3UgZG93bmxvYWRlZCAxIGFic3RyYWN0cy4gVG8gcmV0cmlldmUgbW9yZSBzZXQgJ24gPScgYXJndW1lbnQgdG8gdGhlIGRlc2lyZWQgdmFsdWVcbiJ9 -->
<pre><code>Please wait...Your query is ((&quot;machine learning&quot;[MeSH Terms] OR (&quot;machine&quot;[All Fields] AND &quot;learning&quot;[All Fields]) OR &quot;machine learning&quot;[All Fields]) AND (&quot;public health&quot;[MeSH Terms] OR (&quot;public&quot;[All Fields] AND &quot;health&quot;[All Fields]) OR &quot;public health&quot;[All Fields])) AND 2008[PDAT] : 2018[PDAT]. This returns 9522 abstracts. By default 1000 abstracts are downloaded. You downloaded 1 abstracts. To retrieve more set 'n =' argument to the desired value</code></pre>
<!-- rnb-output-end -->
<!-- rnb-chunk-end -->
<!-- rnb-text-begin -->
<p>We can see this gives a non-specific search which would return 9518 abstracts.</p>
</div>
<div id="specific-searching" class="section level3">
<h3>Specific searching</h3>
<p>We can make the search more specific to include only those abstracts which have Medical Subject Headings (MeSH) keywords for ‘machine learning’ and ‘public health’.</p>
<!-- rnb-text-end -->
<!-- rnb-chunk-begin -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxubGlicmFyeShteVNjcmFwZXJzKVxuc2VhcmNoIDwtIFwibWFjaGluZSBsZWFybmluZ1tNZVNIXSBhbmQgcHVibGljIGhlYWx0aFtNZVNIXVwiXG5zdGFydCA8LSAyMDA4XG5lbmQgPC0gMjAxOFxubiA8LSAxXG4gIFxuICBcbmFic3RyYWN0cyA8LSBwdWJtZWRBYnN0cmFjdFIoc2VhcmNoID0gc2VhcmNoLCBzdGFydCA9IHN0YXJ0LCBlbmQgPSBlbmQsIG4gPSAxKVxuYGBgIn0= -->
<pre class="r"><code>library(myScrapers)
search &lt;- &quot;machine learning[MeSH] and public health[MeSH]&quot;
start &lt;- 2008
end &lt;- 2018
n &lt;- 1
  
  
abstracts &lt;- pubmedAbstractR(search = search, start = start, end = end, n = 1)</code></pre>
<!-- rnb-source-end -->
<!-- rnb-output-begin eyJkYXRhIjoiUGxlYXNlIHdhaXQuLi5Zb3VyIHF1ZXJ5IGlzIFwibWFjaGluZSBsZWFybmluZ1wiW01lU0ggVGVybXNdIEFORCBcInB1YmxpYyBoZWFsdGhcIltNZVNIIFRlcm1zXSBBTkQgMjAwOFtQREFUXSA6IDIwMThbUERBVF0uIFRoaXMgcmV0dXJucyA1NTAyIGFic3RyYWN0cy4gQnkgZGVmYXVsdCAxMDAwIGFic3RyYWN0cyBhcmUgZG93bmxvYWRlZC4gWW91IGRvd25sb2FkZWQgMSBhYnN0cmFjdHMuIFRvIHJldHJpZXZlIG1vcmUgc2V0ICduID0nIGFyZ3VtZW50IHRvIHRoZSBkZXNpcmVkIHZhbHVlXG4ifQ== -->
<pre><code>Please wait...Your query is &quot;machine learning&quot;[MeSH Terms] AND &quot;public health&quot;[MeSH Terms] AND 2008[PDAT] : 2018[PDAT]. This returns 5502 abstracts. By default 1000 abstracts are downloaded. You downloaded 1 abstracts. To retrieve more set 'n =' argument to the desired value</code></pre>
<!-- rnb-output-end -->
<!-- rnb-chunk-end -->
<!-- rnb-text-begin -->
<p>There are now 5502 abstracts. We will download these for future reference.</p>
<!-- rnb-text-end -->
<!-- rnb-chunk-begin -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxubGlicmFyeShteVNjcmFwZXJzKVxuc2VhcmNoIDwtIFwibWFjaGluZSBsZWFybmluZ1tNZVNIXSBhbmQgcHVibGljIGhlYWx0aFtNZVNIXVwiXG5zdGFydCA8LSAyMDA4XG5lbmQgPC0gMjAxOFxubiA8LSA1NTAyXG4gIFxuICBcbmFic3RyYWN0czEgPC0gcHVibWVkQWJzdHJhY3RSKHNlYXJjaCA9IHNlYXJjaCwgc3RhcnQgPSBzdGFydCwgZW5kID0gZW5kLCBuID0gbilcbmBgYCJ9 -->
<pre class="r"><code>library(myScrapers)
search &lt;- &quot;machine learning[MeSH] and public health[MeSH]&quot;
start &lt;- 2008
end &lt;- 2018
n &lt;- 5502
  
  
abstracts1 &lt;- pubmedAbstractR(search = search, start = start, end = end, n = n)</code></pre>
<!-- rnb-source-end -->
<!-- rnb-output-begin eyJkYXRhIjoiUGxlYXNlIHdhaXQuLi5Zb3VyIHF1ZXJ5IGlzIFwibWFjaGluZSBsZWFybmluZ1wiW01lU0ggVGVybXNdIEFORCBcInB1YmxpYyBoZWFsdGhcIltNZVNIIFRlcm1zXSBBTkQgMjAwOFtQREFUXSA6IDIwMThbUERBVF0uIFRoaXMgcmV0dXJucyA1NTAyIGFic3RyYWN0cy4gQnkgZGVmYXVsdCAxMDAwIGFic3RyYWN0cyBhcmUgZG93bmxvYWRlZC4gWW91IGRvd25sb2FkZWQgNTUwMiBhYnN0cmFjdHMuIFRvIHJldHJpZXZlIG1vcmUgc2V0ICduID0nIGFyZ3VtZW50IHRvIHRoZSBkZXNpcmVkIHZhbHVlXG4ifQ== -->
<pre><code>Please wait...Your query is &quot;machine learning&quot;[MeSH Terms] AND &quot;public health&quot;[MeSH Terms] AND 2008[PDAT] : 2018[PDAT]. This returns 5502 abstracts. By default 1000 abstracts are downloaded. You downloaded 5502 abstracts. To retrieve more set 'n =' argument to the desired value</code></pre>
<!-- rnb-output-end -->
<!-- rnb-chunk-end -->
<!-- rnb-text-begin -->
<p>Lets download the most recent 10 with associated keywords and authors (NB this may take a few minutes)</p>
<!-- rnb-text-end -->
<!-- rnb-chunk-begin -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxubGlicmFyeShteVNjcmFwZXJzKVxuc2VhcmNoIDwtIFwibWFjaGluZSBsZWFybmluZ1tNZVNIXSBhbmQgcHVibGljIGhlYWx0aFtNZVNIXVwiXG5zdGFydCA8LSAyMDA4XG5lbmQgPC0gMjAxOFxubiA8LSAxMFxuICBcbiAgXG5hYnN0cmFjdHMgPC0gcHVibWVkQWJzdHJhY3RSKHNlYXJjaCA9IHNlYXJjaCwgc3RhcnQgPSBzdGFydCwgZW5kID0gZW5kLCBuID0gbiwgYXV0aG9ycyA9IFRSVUUsIGtleXdvcmQgPSBUUlVFKVxuYGBgIn0= -->
<pre class="r"><code>library(myScrapers)
search &lt;- &quot;machine learning[MeSH] and public health[MeSH]&quot;
start &lt;- 2008
end &lt;- 2018
n &lt;- 10
  
  
abstracts &lt;- pubmedAbstractR(search = search, start = start, end = end, n = n, authors = TRUE, keyword = TRUE)</code></pre>
<!-- rnb-source-end -->
<!-- rnb-output-begin eyJkYXRhIjoiUGxlYXNlIHdhaXQuLi5Zb3VyIHF1ZXJ5IGlzIFwibWFjaGluZSBsZWFybmluZ1wiW01lU0ggVGVybXNdIEFORCBcInB1YmxpYyBoZWFsdGhcIltNZVNIIFRlcm1zXSBBTkQgMjAwOFtQREFUXSA6IDIwMThbUERBVF0uIFRoaXMgcmV0dXJucyA1NDk5IGFic3RyYWN0cy4gQnkgZGVmYXVsdCAxMDAwIGFic3RyYWN0cyBhcmUgZG93bmxvYWRlZC4gWW91IGRvd25sb2FkZWQgMTAgYWJzdHJhY3RzLiBUbyByZXRyaWV2ZSBtb3JlIHNldCAnbiA9JyBhcmd1bWVudCB0byB0aGUgZGVzaXJlZCB2YWx1ZVxuIn0= -->
<pre><code>Please wait...Your query is &quot;machine learning&quot;[MeSH Terms] AND &quot;public health&quot;[MeSH Terms] AND 2008[PDAT] : 2018[PDAT]. This returns 5499 abstracts. By default 1000 abstracts are downloaded. You downloaded 10 abstracts. To retrieve more set 'n =' argument to the desired value</code></pre>
<!-- rnb-output-end -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuYWJzdHJhY3RzXG5gYGAifQ== -->
<pre class="r"><code>abstracts</code></pre>
<!-- rnb-source-end -->
<!-- rnb-frame-begin {"metadata":{"classes":["tbl_df","tbl","data.frame"],"ncol":9,"nrow":1106},"rdf":"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"} -->
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["title"],"name":[1],"type":["chr"],"align":["left"]},{"label":["abstract"],"name":[2],"type":["chr"],"align":["left"]},{"label":["journal"],"name":[3],"type":["chr"],"align":["left"]},{"label":["DOI"],"name":[4],"type":["chr"],"align":["left"]},{"label":["year"],"name":[5],"type":["chr"],"align":["left"]},{"label":["keyword"],"name":[6],"type":["chr"],"align":["left"]},{"label":["LastName"],"name":[7],"type":["chr"],"align":["left"]},{"label":["Initials"],"name":[8],"type":["chr"],"align":["left"]},{"label":["order"],"name":[9],"type":["int"],"align":["right"]}],"data":[{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"Algorithms","7":"Huang","8":"S","9":"1"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"Biomedical Research","7":"Huang","8":"S","9":"1"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"methods","7":"Huang","8":"S","9":"1"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"trends","7":"Huang","8":"S","9":"1"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"Computational Biology","7":"Huang","8":"S","9":"1"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"methods","7":"Huang","8":"S","9":"1"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"trends","7":"Huang","8":"S","9":"1"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"Data Mining","7":"Huang","8":"S","9":"1"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"Electronic Health Records","7":"Huang","8":"S","9":"1"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"Genome-Wide Association Study","7":"Huang","8":"S","9":"1"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"Humans","7":"Huang","8":"S","9":"1"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"Machine Learning","7":"Huang","8":"S","9":"1"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"Models, Theoretical","7":"Huang","8":"S","9":"1"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Cell Line, Tumor","7":"He","8":"Y","9":"1"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Cell Line, Tumor","7":"Jiang","8":"Z","9":"2"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Cell Line, Tumor","7":"Chen","8":"C","9":"3"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Cell Line, Tumor","7":"Wang","8":"X","9":"4"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Female","7":"He","8":"Y","9":"1"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Female","7":"Jiang","8":"Z","9":"2"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Female","7":"Chen","8":"C","9":"3"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Female","7":"Wang","8":"X","9":"4"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Humans","7":"He","8":"Y","9":"1"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Humans","7":"Jiang","8":"Z","9":"2"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Humans","7":"Chen","8":"C","9":"3"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Humans","7":"Wang","8":"X","9":"4"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Immunogenetics","7":"He","8":"Y","9":"1"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Immunogenetics","7":"Jiang","8":"Z","9":"2"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Immunogenetics","7":"Chen","8":"C","9":"3"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Immunogenetics","7":"Wang","8":"X","9":"4"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"methods","7":"He","8":"Y","9":"1"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"methods","7":"Jiang","8":"Z","9":"2"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"methods","7":"Chen","8":"C","9":"3"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"methods","7":"Wang","8":"X","9":"4"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Machine Learning","7":"He","8":"Y","9":"1"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Machine Learning","7":"Jiang","8":"Z","9":"2"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Machine Learning","7":"Chen","8":"C","9":"3"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Machine Learning","7":"Wang","8":"X","9":"4"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Signal Transduction","7":"He","8":"Y","9":"1"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Signal Transduction","7":"Jiang","8":"Z","9":"2"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Signal Transduction","7":"Chen","8":"C","9":"3"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Signal Transduction","7":"Wang","8":"X","9":"4"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Survival Analysis","7":"He","8":"Y","9":"1"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Survival Analysis","7":"Jiang","8":"Z","9":"2"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Survival Analysis","7":"Chen","8":"C","9":"3"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Survival Analysis","7":"Wang","8":"X","9":"4"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Triple Negative Breast Neoplasms","7":"He","8":"Y","9":"1"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Triple Negative Breast Neoplasms","7":"Jiang","8":"Z","9":"2"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Triple Negative Breast Neoplasms","7":"Chen","8":"C","9":"3"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Triple Negative Breast Neoplasms","7":"Wang","8":"X","9":"4"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Colorectal Neoplasms","7":"de Lange","8":"T","9":"1"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Colorectal Neoplasms","7":"Halvorsen","8":"P","9":"2"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Colorectal Neoplasms","7":"Riegler","8":"M","9":"3"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"diagnostic imaging","7":"de Lange","8":"T","9":"1"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"diagnostic imaging","7":"Halvorsen","8":"P","9":"2"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"diagnostic imaging","7":"Riegler","8":"M","9":"3"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Diagnosis, Computer-Assisted","7":"de Lange","8":"T","9":"1"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Diagnosis, Computer-Assisted","7":"Halvorsen","8":"P","9":"2"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Diagnosis, Computer-Assisted","7":"Riegler","8":"M","9":"3"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"methods","7":"de Lange","8":"T","9":"1"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"methods","7":"Halvorsen","8":"P","9":"2"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"methods","7":"Riegler","8":"M","9":"3"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Endoscopy, Gastrointestinal","7":"de Lange","8":"T","9":"1"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Endoscopy, Gastrointestinal","7":"Halvorsen","8":"P","9":"2"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Endoscopy, Gastrointestinal","7":"Riegler","8":"M","9":"3"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"methods","7":"de Lange","8":"T","9":"1"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"methods","7":"Halvorsen","8":"P","9":"2"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"methods","7":"Riegler","8":"M","9":"3"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Humans","7":"de Lange","8":"T","9":"1"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Humans","7":"Halvorsen","8":"P","9":"2"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Humans","7":"Riegler","8":"M","9":"3"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Image Processing, Computer-Assisted","7":"de Lange","8":"T","9":"1"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Image Processing, Computer-Assisted","7":"Halvorsen","8":"P","9":"2"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Image Processing, Computer-Assisted","7":"Riegler","8":"M","9":"3"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"methods","7":"de Lange","8":"T","9":"1"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"methods","7":"Halvorsen","8":"P","9":"2"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"methods","7":"Riegler","8":"M","9":"3"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Machine Learning","7":"de Lange","8":"T","9":"1"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Machine Learning","7":"Halvorsen","8":"P","9":"2"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Machine Learning","7":"Riegler","8":"M","9":"3"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Neural Networks (Computer)","7":"de Lange","8":"T","9":"1"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Neural Networks (Computer)","7":"Halvorsen","8":"P","9":"2"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Neural Networks (Computer)","7":"Riegler","8":"M","9":"3"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Observer Variation","7":"de Lange","8":"T","9":"1"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Observer Variation","7":"Halvorsen","8":"P","9":"2"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Observer Variation","7":"Riegler","8":"M","9":"3"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Brain Neoplasms","7":"Fabelo","8":"H","9":"1"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Brain Neoplasms","7":"Ortega","8":"S","9":"2"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Brain Neoplasms","7":"Casselden","8":"E","9":"3"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Brain Neoplasms","7":"Loh","8":"J","9":"4"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Brain Neoplasms","7":"Bulstrode","8":"H","9":"5"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Brain Neoplasms","7":"Zolnourian","8":"A","9":"6"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Brain Neoplasms","7":"Grundy","8":"P","9":"7"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Brain Neoplasms","7":"Callico","8":"GM","9":"8"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Brain Neoplasms","7":"Bulters","8":"D","9":"9"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Brain Neoplasms","7":"Sarmiento","8":"R","9":"10"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"diagnosis","7":"Fabelo","8":"H","9":"1"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"diagnosis","7":"Ortega","8":"S","9":"2"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"diagnosis","7":"Casselden","8":"E","9":"3"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"diagnosis","7":"Loh","8":"J","9":"4"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"diagnosis","7":"Bulstrode","8":"H","9":"5"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"diagnosis","7":"Zolnourian","8":"A","9":"6"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"diagnosis","7":"Grundy","8":"P","9":"7"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"diagnosis","7":"Callico","8":"GM","9":"8"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"diagnosis","7":"Bulters","8":"D","9":"9"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"diagnosis","7":"Sarmiento","8":"R","9":"10"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Humans","7":"Fabelo","8":"H","9":"1"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Humans","7":"Ortega","8":"S","9":"2"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Humans","7":"Casselden","8":"E","9":"3"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Humans","7":"Loh","8":"J","9":"4"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Humans","7":"Bulstrode","8":"H","9":"5"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Humans","7":"Zolnourian","8":"A","9":"6"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Humans","7":"Grundy","8":"P","9":"7"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Humans","7":"Callico","8":"GM","9":"8"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Humans","7":"Bulters","8":"D","9":"9"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Humans","7":"Sarmiento","8":"R","9":"10"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Sensitivity and Specificity","7":"Fabelo","8":"H","9":"1"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Sensitivity and Specificity","7":"Ortega","8":"S","9":"2"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Sensitivity and Specificity","7":"Casselden","8":"E","9":"3"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Sensitivity and Specificity","7":"Loh","8":"J","9":"4"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Sensitivity and Specificity","7":"Bulstrode","8":"H","9":"5"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Sensitivity and Specificity","7":"Zolnourian","8":"A","9":"6"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Sensitivity and Specificity","7":"Grundy","8":"P","9":"7"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Sensitivity and Specificity","7":"Callico","8":"GM","9":"8"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Sensitivity and Specificity","7":"Bulters","8":"D","9":"9"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Sensitivity and Specificity","7":"Sarmiento","8":"R","9":"10"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Spectrophotometry, Infrared","7":"Fabelo","8":"H","9":"1"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Spectrophotometry, Infrared","7":"Ortega","8":"S","9":"2"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Spectrophotometry, Infrared","7":"Casselden","8":"E","9":"3"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Spectrophotometry, Infrared","7":"Loh","8":"J","9":"4"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Spectrophotometry, Infrared","7":"Bulstrode","8":"H","9":"5"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Spectrophotometry, Infrared","7":"Zolnourian","8":"A","9":"6"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Spectrophotometry, Infrared","7":"Grundy","8":"P","9":"7"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Spectrophotometry, Infrared","7":"Callico","8":"GM","9":"8"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Spectrophotometry, Infrared","7":"Bulters","8":"D","9":"9"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Spectrophotometry, Infrared","7":"Sarmiento","8":"R","9":"10"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Support Vector Machine","7":"Fabelo","8":"H","9":"1"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Support Vector Machine","7":"Ortega","8":"S","9":"2"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Support Vector Machine","7":"Casselden","8":"E","9":"3"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Support Vector Machine","7":"Loh","8":"J","9":"4"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Support Vector Machine","7":"Bulstrode","8":"H","9":"5"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Support Vector Machine","7":"Zolnourian","8":"A","9":"6"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Support Vector Machine","7":"Grundy","8":"P","9":"7"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Support Vector Machine","7":"Callico","8":"GM","9":"8"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Support Vector Machine","7":"Bulters","8":"D","9":"9"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Support Vector Machine","7":"Sarmiento","8":"R","9":"10"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Adult","7":"Ogino","8":"M","9":"1"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Adult","7":"Mitsukura","8":"Y","9":"2"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Electrodes","7":"Ogino","8":"M","9":"1"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Electrodes","7":"Mitsukura","8":"Y","9":"2"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Electroencephalography","7":"Ogino","8":"M","9":"1"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Electroencephalography","7":"Mitsukura","8":"Y","9":"2"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Female","7":"Ogino","8":"M","9":"1"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Female","7":"Mitsukura","8":"Y","9":"2"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Humans","7":"Ogino","8":"M","9":"1"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Humans","7":"Mitsukura","8":"Y","9":"2"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Male","7":"Ogino","8":"M","9":"1"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Male","7":"Mitsukura","8":"Y","9":"2"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Prefrontal Cortex","7":"Ogino","8":"M","9":"1"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Prefrontal Cortex","7":"Mitsukura","8":"Y","9":"2"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"physiology","7":"Ogino","8":"M","9":"1"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"physiology","7":"Mitsukura","8":"Y","9":"2"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Probability","7":"Ogino","8":"M","9":"1"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Probability","7":"Mitsukura","8":"Y","9":"2"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"ROC Curve","7":"Ogino","8":"M","9":"1"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"ROC Curve","7":"Mitsukura","8":"Y","9":"2"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Sleep","7":"Ogino","8":"M","9":"1"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Sleep","7":"Mitsukura","8":"Y","9":"2"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"physiology","7":"Ogino","8":"M","9":"1"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"physiology","7":"Mitsukura","8":"Y","9":"2"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Support Vector Machine","7":"Ogino","8":"M","9":"1"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Support Vector Machine","7":"Mitsukura","8":"Y","9":"2"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Altitude","7":"Cao","8":"F","9":"1"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Altitude","7":"Liu","8":"F","9":"2"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Altitude","7":"Guo","8":"H","9":"3"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Altitude","7":"Kong","8":"W","9":"4"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Altitude","7":"Zhang","8":"C","9":"5"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Altitude","7":"He","8":"Y","9":"6"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Ascomycota","7":"Cao","8":"F","9":"1"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Ascomycota","7":"Liu","8":"F","9":"2"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Ascomycota","7":"Guo","8":"H","9":"3"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Ascomycota","7":"Kong","8":"W","9":"4"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Ascomycota","7":"Zhang","8":"C","9":"5"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Ascomycota","7":"He","8":"Y","9":"6"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"isolation &amp; purification","7":"Cao","8":"F","9":"1"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"isolation &amp; purification","7":"Liu","8":"F","9":"2"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"isolation &amp; purification","7":"Guo","8":"H","9":"3"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"isolation &amp; purification","7":"Kong","8":"W","9":"4"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"isolation &amp; purification","7":"Zhang","8":"C","9":"5"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"isolation &amp; purification","7":"He","8":"Y","9":"6"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Bayes Theorem","7":"Cao","8":"F","9":"1"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Bayes Theorem","7":"Liu","8":"F","9":"2"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Bayes Theorem","7":"Guo","8":"H","9":"3"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Bayes Theorem","7":"Kong","8":"W","9":"4"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Bayes Theorem","7":"Zhang","8":"C","9":"5"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Bayes Theorem","7":"He","8":"Y","9":"6"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Brassica napus","7":"Cao","8":"F","9":"1"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Brassica napus","7":"Liu","8":"F","9":"2"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Brassica napus","7":"Guo","8":"H","9":"3"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Brassica napus","7":"Kong","8":"W","9":"4"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Brassica napus","7":"Zhang","8":"C","9":"5"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Brassica napus","7":"He","8":"Y","9":"6"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"microbiology","7":"Cao","8":"F","9":"1"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"microbiology","7":"Liu","8":"F","9":"2"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"microbiology","7":"Guo","8":"H","9":"3"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"microbiology","7":"Kong","8":"W","9":"4"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"microbiology","7":"Zhang","8":"C","9":"5"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"microbiology","7":"He","8":"Y","9":"6"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Cold Temperature","7":"Cao","8":"F","9":"1"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Cold Temperature","7":"Liu","8":"F","9":"2"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Cold Temperature","7":"Guo","8":"H","9":"3"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Cold Temperature","7":"Kong","8":"W","9":"4"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Cold Temperature","7":"Zhang","8":"C","9":"5"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Cold Temperature","7":"He","8":"Y","9":"6"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Image Processing, Computer-Assisted","7":"Cao","8":"F","9":"1"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Image Processing, Computer-Assisted","7":"Liu","8":"F","9":"2"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Image Processing, Computer-Assisted","7":"Guo","8":"H","9":"3"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Image Processing, Computer-Assisted","7":"Kong","8":"W","9":"4"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Image Processing, Computer-Assisted","7":"Zhang","8":"C","9":"5"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Image Processing, Computer-Assisted","7":"He","8":"Y","9":"6"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Plant Leaves","7":"Cao","8":"F","9":"1"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Plant Leaves","7":"Liu","8":"F","9":"2"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Plant Leaves","7":"Guo","8":"H","9":"3"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Plant Leaves","7":"Kong","8":"W","9":"4"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Plant Leaves","7":"Zhang","8":"C","9":"5"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Plant Leaves","7":"He","8":"Y","9":"6"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"microbiology","7":"Cao","8":"F","9":"1"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"microbiology","7":"Liu","8":"F","9":"2"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"microbiology","7":"Guo","8":"H","9":"3"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"microbiology","7":"Kong","8":"W","9":"4"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"microbiology","7":"Zhang","8":"C","9":"5"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"microbiology","7":"He","8":"Y","9":"6"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Remote Sensing Technology","7":"Cao","8":"F","9":"1"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Remote Sensing Technology","7":"Liu","8":"F","9":"2"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Remote Sensing Technology","7":"Guo","8":"H","9":"3"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Remote Sensing Technology","7":"Kong","8":"W","9":"4"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Remote Sensing Technology","7":"Zhang","8":"C","9":"5"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Remote Sensing Technology","7":"He","8":"Y","9":"6"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"methods","7":"Cao","8":"F","9":"1"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"methods","7":"Liu","8":"F","9":"2"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"methods","7":"Guo","8":"H","9":"3"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"methods","7":"Kong","8":"W","9":"4"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"methods","7":"Zhang","8":"C","9":"5"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"methods","7":"He","8":"Y","9":"6"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Support Vector Machine","7":"Cao","8":"F","9":"1"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Support Vector Machine","7":"Liu","8":"F","9":"2"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Support Vector Machine","7":"Guo","8":"H","9":"3"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Support Vector Machine","7":"Kong","8":"W","9":"4"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Support Vector Machine","7":"Zhang","8":"C","9":"5"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Support Vector Machine","7":"He","8":"Y","9":"6"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Wang","8":"D","9":"1"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Liu","8":"S","9":"2"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Warrell","8":"J","9":"3"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Won","8":"H","9":"4"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Shi","8":"X","9":"5"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Navarro","8":"FCP","9":"6"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Clarke","8":"D","9":"7"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Gu","8":"M","9":"8"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Emani","8":"P","9":"9"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Yang","8":"YT","9":"10"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Xu","8":"M","9":"11"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Gandal","8":"MJ","9":"12"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Lou","8":"S","9":"13"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Zhang","8":"J","9":"14"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Park","8":"JJ","9":"15"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Yan","8":"C","9":"16"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Rhie","8":"SK","9":"17"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Manakongtreecheep","8":"K","9":"18"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Zhou","8":"H","9":"19"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Nathan","8":"A","9":"20"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Peters","8":"M","9":"21"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Mattei","8":"E","9":"22"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Fitzgerald","8":"D","9":"23"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Brunetti","8":"T","9":"24"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Moore","8":"J","9":"25"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Jiang","8":"Y","9":"26"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Girdhar","8":"K","9":"27"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Hoffman","8":"GE","9":"28"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Kalayci","8":"S","9":"29"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Gümüs","8":"ZH","9":"30"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Crawford","8":"GE","9":"31"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Roussos","8":"P","9":"32"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Akbarian","8":"S","9":"33"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Jaffe","8":"AE","9":"34"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"White","8":"KP","9":"35"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Weng","8":"Z","9":"36"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Sestan","8":"N","9":"37"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Geschwind","8":"DH","9":"38"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Knowles","8":"JA","9":"39"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain","7":"Gerstein","8":"MB","9":"40"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Wang","8":"D","9":"1"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Liu","8":"S","9":"2"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Warrell","8":"J","9":"3"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Won","8":"H","9":"4"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Shi","8":"X","9":"5"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Navarro","8":"FCP","9":"6"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Clarke","8":"D","9":"7"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Gu","8":"M","9":"8"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Emani","8":"P","9":"9"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Yang","8":"YT","9":"10"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Xu","8":"M","9":"11"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Gandal","8":"MJ","9":"12"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Lou","8":"S","9":"13"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Zhang","8":"J","9":"14"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Park","8":"JJ","9":"15"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Yan","8":"C","9":"16"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Rhie","8":"SK","9":"17"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Manakongtreecheep","8":"K","9":"18"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Zhou","8":"H","9":"19"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Nathan","8":"A","9":"20"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Peters","8":"M","9":"21"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Mattei","8":"E","9":"22"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Fitzgerald","8":"D","9":"23"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Brunetti","8":"T","9":"24"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Moore","8":"J","9":"25"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Jiang","8":"Y","9":"26"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Girdhar","8":"K","9":"27"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Hoffman","8":"GE","9":"28"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Kalayci","8":"S","9":"29"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Gümüs","8":"ZH","9":"30"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Crawford","8":"GE","9":"31"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Roussos","8":"P","9":"32"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Akbarian","8":"S","9":"33"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Jaffe","8":"AE","9":"34"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"White","8":"KP","9":"35"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Weng","8":"Z","9":"36"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Sestan","8":"N","9":"37"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Geschwind","8":"DH","9":"38"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Knowles","8":"JA","9":"39"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism","7":"Gerstein","8":"MB","9":"40"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Wang","8":"D","9":"1"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Liu","8":"S","9":"2"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Warrell","8":"J","9":"3"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Won","8":"H","9":"4"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Shi","8":"X","9":"5"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Navarro","8":"FCP","9":"6"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Clarke","8":"D","9":"7"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Gu","8":"M","9":"8"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Emani","8":"P","9":"9"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Yang","8":"YT","9":"10"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Xu","8":"M","9":"11"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Gandal","8":"MJ","9":"12"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Lou","8":"S","9":"13"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Zhang","8":"J","9":"14"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Park","8":"JJ","9":"15"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Yan","8":"C","9":"16"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Rhie","8":"SK","9":"17"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Manakongtreecheep","8":"K","9":"18"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Zhou","8":"H","9":"19"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Nathan","8":"A","9":"20"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Peters","8":"M","9":"21"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Mattei","8":"E","9":"22"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Fitzgerald","8":"D","9":"23"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Brunetti","8":"T","9":"24"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Moore","8":"J","9":"25"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Jiang","8":"Y","9":"26"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Girdhar","8":"K","9":"27"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Hoffman","8":"GE","9":"28"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Kalayci","8":"S","9":"29"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Gümüs","8":"ZH","9":"30"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Crawford","8":"GE","9":"31"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Roussos","8":"P","9":"32"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Akbarian","8":"S","9":"33"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Jaffe","8":"AE","9":"34"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"White","8":"KP","9":"35"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Weng","8":"Z","9":"36"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Sestan","8":"N","9":"37"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Geschwind","8":"DH","9":"38"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Knowles","8":"JA","9":"39"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic","7":"Gerstein","8":"MB","9":"40"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Wang","8":"D","9":"1"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Liu","8":"S","9":"2"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Warrell","8":"J","9":"3"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Won","8":"H","9":"4"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Shi","8":"X","9":"5"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Navarro","8":"FCP","9":"6"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Clarke","8":"D","9":"7"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Gu","8":"M","9":"8"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Emani","8":"P","9":"9"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Yang","8":"YT","9":"10"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Xu","8":"M","9":"11"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Gandal","8":"MJ","9":"12"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Lou","8":"S","9":"13"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Zhang","8":"J","9":"14"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Park","8":"JJ","9":"15"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Yan","8":"C","9":"16"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Rhie","8":"SK","9":"17"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Manakongtreecheep","8":"K","9":"18"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Zhou","8":"H","9":"19"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Nathan","8":"A","9":"20"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Peters","8":"M","9":"21"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Mattei","8":"E","9":"22"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Fitzgerald","8":"D","9":"23"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Brunetti","8":"T","9":"24"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Moore","8":"J","9":"25"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Jiang","8":"Y","9":"26"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Girdhar","8":"K","9":"27"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Hoffman","8":"GE","9":"28"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Kalayci","8":"S","9":"29"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Gümüs","8":"ZH","9":"30"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Crawford","8":"GE","9":"31"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Roussos","8":"P","9":"32"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Akbarian","8":"S","9":"33"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Jaffe","8":"AE","9":"34"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"White","8":"KP","9":"35"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Weng","8":"Z","9":"36"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Sestan","8":"N","9":"37"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Geschwind","8":"DH","9":"38"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Knowles","8":"JA","9":"39"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning","7":"Gerstein","8":"MB","9":"40"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Wang","8":"D","9":"1"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Liu","8":"S","9":"2"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Warrell","8":"J","9":"3"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Won","8":"H","9":"4"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Shi","8":"X","9":"5"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Navarro","8":"FCP","9":"6"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Clarke","8":"D","9":"7"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Gu","8":"M","9":"8"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Emani","8":"P","9":"9"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Yang","8":"YT","9":"10"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Xu","8":"M","9":"11"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Gandal","8":"MJ","9":"12"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Lou","8":"S","9":"13"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Zhang","8":"J","9":"14"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Park","8":"JJ","9":"15"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Yan","8":"C","9":"16"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Rhie","8":"SK","9":"17"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Manakongtreecheep","8":"K","9":"18"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Zhou","8":"H","9":"19"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Nathan","8":"A","9":"20"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Peters","8":"M","9":"21"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Mattei","8":"E","9":"22"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Fitzgerald","8":"D","9":"23"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Brunetti","8":"T","9":"24"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Moore","8":"J","9":"25"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Jiang","8":"Y","9":"26"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Girdhar","8":"K","9":"27"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Hoffman","8":"GE","9":"28"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Kalayci","8":"S","9":"29"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Gümüs","8":"ZH","9":"30"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Crawford","8":"GE","9":"31"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Roussos","8":"P","9":"32"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Akbarian","8":"S","9":"33"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Jaffe","8":"AE","9":"34"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"White","8":"KP","9":"35"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Weng","8":"Z","9":"36"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Sestan","8":"N","9":"37"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Geschwind","8":"DH","9":"38"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Knowles","8":"JA","9":"39"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic","7":"Gerstein","8":"MB","9":"40"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Wang","8":"D","9":"1"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Liu","8":"S","9":"2"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Warrell","8":"J","9":"3"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Won","8":"H","9":"4"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Shi","8":"X","9":"5"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Navarro","8":"FCP","9":"6"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Clarke","8":"D","9":"7"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Gu","8":"M","9":"8"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Emani","8":"P","9":"9"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Yang","8":"YT","9":"10"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Xu","8":"M","9":"11"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Gandal","8":"MJ","9":"12"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Lou","8":"S","9":"13"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Zhang","8":"J","9":"14"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Park","8":"JJ","9":"15"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Yan","8":"C","9":"16"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Rhie","8":"SK","9":"17"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Manakongtreecheep","8":"K","9":"18"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Zhou","8":"H","9":"19"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Nathan","8":"A","9":"20"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Peters","8":"M","9":"21"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Mattei","8":"E","9":"22"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Fitzgerald","8":"D","9":"23"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Brunetti","8":"T","9":"24"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Moore","8":"J","9":"25"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Jiang","8":"Y","9":"26"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Girdhar","8":"K","9":"27"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Hoffman","8":"GE","9":"28"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Kalayci","8":"S","9":"29"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Gümüs","8":"ZH","9":"30"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Crawford","8":"GE","9":"31"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Roussos","8":"P","9":"32"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Akbarian","8":"S","9":"33"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Jaffe","8":"AE","9":"34"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"White","8":"KP","9":"35"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Weng","8":"Z","9":"36"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Sestan","8":"N","9":"37"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Geschwind","8":"DH","9":"38"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Knowles","8":"JA","9":"39"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic","7":"Gerstein","8":"MB","9":"40"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Wang","8":"D","9":"1"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Liu","8":"S","9":"2"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Warrell","8":"J","9":"3"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Won","8":"H","9":"4"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Shi","8":"X","9":"5"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Navarro","8":"FCP","9":"6"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Clarke","8":"D","9":"7"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Gu","8":"M","9":"8"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Emani","8":"P","9":"9"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Yang","8":"YT","9":"10"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Xu","8":"M","9":"11"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Gandal","8":"MJ","9":"12"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Lou","8":"S","9":"13"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Zhang","8":"J","9":"14"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Park","8":"JJ","9":"15"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Yan","8":"C","9":"16"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Rhie","8":"SK","9":"17"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Manakongtreecheep","8":"K","9":"18"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Zhou","8":"H","9":"19"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Nathan","8":"A","9":"20"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Peters","8":"M","9":"21"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Mattei","8":"E","9":"22"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Fitzgerald","8":"D","9":"23"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Brunetti","8":"T","9":"24"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Moore","8":"J","9":"25"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Jiang","8":"Y","9":"26"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Girdhar","8":"K","9":"27"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Hoffman","8":"GE","9":"28"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Kalayci","8":"S","9":"29"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Gümüs","8":"ZH","9":"30"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Crawford","8":"GE","9":"31"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Roussos","8":"P","9":"32"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Akbarian","8":"S","9":"33"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Jaffe","8":"AE","9":"34"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"White","8":"KP","9":"35"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Weng","8":"Z","9":"36"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Sestan","8":"N","9":"37"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Geschwind","8":"DH","9":"38"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Knowles","8":"JA","9":"39"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics","7":"Gerstein","8":"MB","9":"40"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Wang","8":"D","9":"1"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Liu","8":"S","9":"2"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Warrell","8":"J","9":"3"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Won","8":"H","9":"4"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Shi","8":"X","9":"5"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Navarro","8":"FCP","9":"6"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Clarke","8":"D","9":"7"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Gu","8":"M","9":"8"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Emani","8":"P","9":"9"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Yang","8":"YT","9":"10"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Xu","8":"M","9":"11"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Gandal","8":"MJ","9":"12"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Lou","8":"S","9":"13"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Zhang","8":"J","9":"14"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Park","8":"JJ","9":"15"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Yan","8":"C","9":"16"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Rhie","8":"SK","9":"17"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Manakongtreecheep","8":"K","9":"18"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Zhou","8":"H","9":"19"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Nathan","8":"A","9":"20"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Peters","8":"M","9":"21"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Mattei","8":"E","9":"22"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Fitzgerald","8":"D","9":"23"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Brunetti","8":"T","9":"24"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Moore","8":"J","9":"25"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Jiang","8":"Y","9":"26"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Girdhar","8":"K","9":"27"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Hoffman","8":"GE","9":"28"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Kalayci","8":"S","9":"29"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Gümüs","8":"ZH","9":"30"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Crawford","8":"GE","9":"31"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Roussos","8":"P","9":"32"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Akbarian","8":"S","9":"33"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Jaffe","8":"AE","9":"34"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"White","8":"KP","9":"35"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Weng","8":"Z","9":"36"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Sestan","8":"N","9":"37"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Geschwind","8":"DH","9":"38"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Knowles","8":"JA","9":"39"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation","7":"Gerstein","8":"MB","9":"40"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Wang","8":"D","9":"1"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Liu","8":"S","9":"2"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Warrell","8":"J","9":"3"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Won","8":"H","9":"4"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Shi","8":"X","9":"5"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Navarro","8":"FCP","9":"6"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Clarke","8":"D","9":"7"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Gu","8":"M","9":"8"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Emani","8":"P","9":"9"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Yang","8":"YT","9":"10"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Xu","8":"M","9":"11"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Gandal","8":"MJ","9":"12"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Lou","8":"S","9":"13"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Zhang","8":"J","9":"14"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Park","8":"JJ","9":"15"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Yan","8":"C","9":"16"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Rhie","8":"SK","9":"17"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Manakongtreecheep","8":"K","9":"18"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Zhou","8":"H","9":"19"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Nathan","8":"A","9":"20"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Peters","8":"M","9":"21"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Mattei","8":"E","9":"22"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Fitzgerald","8":"D","9":"23"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Brunetti","8":"T","9":"24"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Moore","8":"J","9":"25"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Jiang","8":"Y","9":"26"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Girdhar","8":"K","9":"27"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Hoffman","8":"GE","9":"28"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Kalayci","8":"S","9":"29"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Gümüs","8":"ZH","9":"30"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Crawford","8":"GE","9":"31"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Roussos","8":"P","9":"32"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Akbarian","8":"S","9":"33"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Jaffe","8":"AE","9":"34"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"White","8":"KP","9":"35"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Weng","8":"Z","9":"36"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Sestan","8":"N","9":"37"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Geschwind","8":"DH","9":"38"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Knowles","8":"JA","9":"39"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks","7":"Gerstein","8":"MB","9":"40"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Wang","8":"D","9":"1"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Liu","8":"S","9":"2"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Warrell","8":"J","9":"3"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Won","8":"H","9":"4"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Shi","8":"X","9":"5"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Navarro","8":"FCP","9":"6"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Clarke","8":"D","9":"7"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Gu","8":"M","9":"8"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Emani","8":"P","9":"9"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Yang","8":"YT","9":"10"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Xu","8":"M","9":"11"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Gandal","8":"MJ","9":"12"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Lou","8":"S","9":"13"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Zhang","8":"J","9":"14"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Park","8":"JJ","9":"15"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Yan","8":"C","9":"16"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Rhie","8":"SK","9":"17"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Manakongtreecheep","8":"K","9":"18"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Zhou","8":"H","9":"19"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Nathan","8":"A","9":"20"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Peters","8":"M","9":"21"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Mattei","8":"E","9":"22"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Fitzgerald","8":"D","9":"23"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Brunetti","8":"T","9":"24"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Moore","8":"J","9":"25"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Jiang","8":"Y","9":"26"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Girdhar","8":"K","9":"27"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Hoffman","8":"GE","9":"28"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Kalayci","8":"S","9":"29"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Gümüs","8":"ZH","9":"30"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Crawford","8":"GE","9":"31"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Roussos","8":"P","9":"32"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Akbarian","8":"S","9":"33"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Jaffe","8":"AE","9":"34"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"White","8":"KP","9":"35"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Weng","8":"Z","9":"36"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Sestan","8":"N","9":"37"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Geschwind","8":"DH","9":"38"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Knowles","8":"JA","9":"39"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study","7":"Gerstein","8":"MB","9":"40"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Wang","8":"D","9":"1"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Liu","8":"S","9":"2"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Warrell","8":"J","9":"3"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Won","8":"H","9":"4"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Shi","8":"X","9":"5"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Navarro","8":"FCP","9":"6"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Clarke","8":"D","9":"7"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Gu","8":"M","9":"8"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Emani","8":"P","9":"9"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Yang","8":"YT","9":"10"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Xu","8":"M","9":"11"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Gandal","8":"MJ","9":"12"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Lou","8":"S","9":"13"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Zhang","8":"J","9":"14"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Park","8":"JJ","9":"15"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Yan","8":"C","9":"16"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Rhie","8":"SK","9":"17"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Manakongtreecheep","8":"K","9":"18"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Zhou","8":"H","9":"19"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Nathan","8":"A","9":"20"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Peters","8":"M","9":"21"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Mattei","8":"E","9":"22"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Fitzgerald","8":"D","9":"23"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Brunetti","8":"T","9":"24"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Moore","8":"J","9":"25"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Jiang","8":"Y","9":"26"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Girdhar","8":"K","9":"27"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Hoffman","8":"GE","9":"28"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Kalayci","8":"S","9":"29"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Gümüs","8":"ZH","9":"30"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Crawford","8":"GE","9":"31"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Roussos","8":"P","9":"32"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Akbarian","8":"S","9":"33"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Jaffe","8":"AE","9":"34"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"White","8":"KP","9":"35"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Weng","8":"Z","9":"36"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Sestan","8":"N","9":"37"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Geschwind","8":"DH","9":"38"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Knowles","8":"JA","9":"39"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans","7":"Gerstein","8":"MB","9":"40"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Wang","8":"D","9":"1"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Liu","8":"S","9":"2"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Warrell","8":"J","9":"3"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Won","8":"H","9":"4"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Shi","8":"X","9":"5"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Navarro","8":"FCP","9":"6"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Clarke","8":"D","9":"7"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Gu","8":"M","9":"8"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Emani","8":"P","9":"9"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Yang","8":"YT","9":"10"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Xu","8":"M","9":"11"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Gandal","8":"MJ","9":"12"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Lou","8":"S","9":"13"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Zhang","8":"J","9":"14"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Park","8":"JJ","9":"15"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Yan","8":"C","9":"16"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Rhie","8":"SK","9":"17"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Manakongtreecheep","8":"K","9":"18"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Zhou","8":"H","9":"19"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Nathan","8":"A","9":"20"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Peters","8":"M","9":"21"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Mattei","8":"E","9":"22"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Fitzgerald","8":"D","9":"23"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Brunetti","8":"T","9":"24"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Moore","8":"J","9":"25"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Jiang","8":"Y","9":"26"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Girdhar","8":"K","9":"27"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Hoffman","8":"GE","9":"28"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Kalayci","8":"S","9":"29"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Gümüs","8":"ZH","9":"30"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Crawford","8":"GE","9":"31"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Roussos","8":"P","9":"32"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Akbarian","8":"S","9":"33"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Jaffe","8":"AE","9":"34"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"White","8":"KP","9":"35"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Weng","8":"Z","9":"36"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Sestan","8":"N","9":"37"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Geschwind","8":"DH","9":"38"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Knowles","8":"JA","9":"39"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders","7":"Gerstein","8":"MB","9":"40"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Wang","8":"D","9":"1"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Liu","8":"S","9":"2"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Warrell","8":"J","9":"3"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Won","8":"H","9":"4"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Shi","8":"X","9":"5"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Navarro","8":"FCP","9":"6"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Clarke","8":"D","9":"7"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Gu","8":"M","9":"8"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Emani","8":"P","9":"9"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Yang","8":"YT","9":"10"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Xu","8":"M","9":"11"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Gandal","8":"MJ","9":"12"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Lou","8":"S","9":"13"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Zhang","8":"J","9":"14"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Park","8":"JJ","9":"15"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Yan","8":"C","9":"16"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Rhie","8":"SK","9":"17"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Manakongtreecheep","8":"K","9":"18"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Zhou","8":"H","9":"19"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Nathan","8":"A","9":"20"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Peters","8":"M","9":"21"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Mattei","8":"E","9":"22"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Fitzgerald","8":"D","9":"23"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Brunetti","8":"T","9":"24"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Moore","8":"J","9":"25"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Jiang","8":"Y","9":"26"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Girdhar","8":"K","9":"27"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Hoffman","8":"GE","9":"28"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Kalayci","8":"S","9":"29"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Gümüs","8":"ZH","9":"30"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Crawford","8":"GE","9":"31"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Roussos","8":"P","9":"32"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Akbarian","8":"S","9":"33"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Jaffe","8":"AE","9":"34"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"White","8":"KP","9":"35"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Weng","8":"Z","9":"36"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Sestan","8":"N","9":"37"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Geschwind","8":"DH","9":"38"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Knowles","8":"JA","9":"39"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics","7":"Gerstein","8":"MB","9":"40"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Wang","8":"D","9":"1"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Liu","8":"S","9":"2"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Warrell","8":"J","9":"3"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Won","8":"H","9":"4"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Shi","8":"X","9":"5"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Navarro","8":"FCP","9":"6"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Clarke","8":"D","9":"7"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Gu","8":"M","9":"8"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Emani","8":"P","9":"9"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Yang","8":"YT","9":"10"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Xu","8":"M","9":"11"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Gandal","8":"MJ","9":"12"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Lou","8":"S","9":"13"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Zhang","8":"J","9":"14"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Park","8":"JJ","9":"15"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Yan","8":"C","9":"16"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Rhie","8":"SK","9":"17"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Manakongtreecheep","8":"K","9":"18"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Zhou","8":"H","9":"19"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Nathan","8":"A","9":"20"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Peters","8":"M","9":"21"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Mattei","8":"E","9":"22"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Fitzgerald","8":"D","9":"23"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Brunetti","8":"T","9":"24"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Moore","8":"J","9":"25"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Jiang","8":"Y","9":"26"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Girdhar","8":"K","9":"27"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Hoffman","8":"GE","9":"28"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Kalayci","8":"S","9":"29"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Gümüs","8":"ZH","9":"30"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Crawford","8":"GE","9":"31"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Roussos","8":"P","9":"32"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Akbarian","8":"S","9":"33"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Jaffe","8":"AE","9":"34"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"White","8":"KP","9":"35"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Weng","8":"Z","9":"36"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Sestan","8":"N","9":"37"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Geschwind","8":"DH","9":"38"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Knowles","8":"JA","9":"39"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci","7":"Gerstein","8":"MB","9":"40"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Wang","8":"D","9":"1"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Liu","8":"S","9":"2"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Warrell","8":"J","9":"3"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Won","8":"H","9":"4"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Shi","8":"X","9":"5"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Navarro","8":"FCP","9":"6"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Clarke","8":"D","9":"7"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Gu","8":"M","9":"8"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Emani","8":"P","9":"9"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Yang","8":"YT","9":"10"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Xu","8":"M","9":"11"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Gandal","8":"MJ","9":"12"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Lou","8":"S","9":"13"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Zhang","8":"J","9":"14"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Park","8":"JJ","9":"15"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Yan","8":"C","9":"16"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Rhie","8":"SK","9":"17"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Manakongtreecheep","8":"K","9":"18"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Zhou","8":"H","9":"19"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Nathan","8":"A","9":"20"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Peters","8":"M","9":"21"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Mattei","8":"E","9":"22"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Fitzgerald","8":"D","9":"23"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Brunetti","8":"T","9":"24"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Moore","8":"J","9":"25"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Jiang","8":"Y","9":"26"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Girdhar","8":"K","9":"27"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Hoffman","8":"GE","9":"28"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Kalayci","8":"S","9":"29"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Gümüs","8":"ZH","9":"30"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Crawford","8":"GE","9":"31"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Roussos","8":"P","9":"32"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Akbarian","8":"S","9":"33"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Jaffe","8":"AE","9":"34"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"White","8":"KP","9":"35"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Weng","8":"Z","9":"36"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Sestan","8":"N","9":"37"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Geschwind","8":"DH","9":"38"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Knowles","8":"JA","9":"39"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis","7":"Gerstein","8":"MB","9":"40"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Wang","8":"D","9":"1"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Liu","8":"S","9":"2"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Warrell","8":"J","9":"3"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Won","8":"H","9":"4"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Shi","8":"X","9":"5"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Navarro","8":"FCP","9":"6"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Clarke","8":"D","9":"7"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Gu","8":"M","9":"8"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Emani","8":"P","9":"9"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Yang","8":"YT","9":"10"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Xu","8":"M","9":"11"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Gandal","8":"MJ","9":"12"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Lou","8":"S","9":"13"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Zhang","8":"J","9":"14"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Park","8":"JJ","9":"15"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Yan","8":"C","9":"16"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Rhie","8":"SK","9":"17"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Manakongtreecheep","8":"K","9":"18"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Zhou","8":"H","9":"19"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Nathan","8":"A","9":"20"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Peters","8":"M","9":"21"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Mattei","8":"E","9":"22"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Fitzgerald","8":"D","9":"23"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Brunetti","8":"T","9":"24"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Moore","8":"J","9":"25"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Jiang","8":"Y","9":"26"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Girdhar","8":"K","9":"27"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Hoffman","8":"GE","9":"28"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Kalayci","8":"S","9":"29"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Gümüs","8":"ZH","9":"30"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Crawford","8":"GE","9":"31"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Roussos","8":"P","9":"32"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Akbarian","8":"S","9":"33"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Jaffe","8":"AE","9":"34"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"White","8":"KP","9":"35"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Weng","8":"Z","9":"36"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Sestan","8":"N","9":"37"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Geschwind","8":"DH","9":"38"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Knowles","8":"JA","9":"39"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome","7":"Gerstein","8":"MB","9":"40"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Amino Acid Sequence","7":"Tallorin","8":"L","9":"1"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Amino Acid Sequence","7":"Wang","8":"J","9":"2"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Amino Acid Sequence","7":"Kim","8":"WE","9":"3"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Amino Acid Sequence","7":"Sahu","8":"S","9":"4"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Amino Acid Sequence","7":"Kosa","8":"NM","9":"5"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Amino Acid Sequence","7":"Yang","8":"P","9":"6"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Amino Acid Sequence","7":"Thompson","8":"M","9":"7"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Amino Acid Sequence","7":"Gilson","8":"MK","9":"8"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Amino Acid Sequence","7":"Frazier","8":"PI","9":"9"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Amino Acid Sequence","7":"Burkart","8":"MD","9":"10"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Amino Acid Sequence","7":"Gianneschi","8":"NC","9":"11"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bacterial Proteins","7":"Tallorin","8":"L","9":"1"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bacterial Proteins","7":"Wang","8":"J","9":"2"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bacterial Proteins","7":"Kim","8":"WE","9":"3"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bacterial Proteins","7":"Sahu","8":"S","9":"4"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bacterial Proteins","7":"Kosa","8":"NM","9":"5"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bacterial Proteins","7":"Yang","8":"P","9":"6"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bacterial Proteins","7":"Thompson","8":"M","9":"7"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bacterial Proteins","7":"Gilson","8":"MK","9":"8"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bacterial Proteins","7":"Frazier","8":"PI","9":"9"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bacterial Proteins","7":"Burkart","8":"MD","9":"10"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bacterial Proteins","7":"Gianneschi","8":"NC","9":"11"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics","7":"Tallorin","8":"L","9":"1"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics","7":"Wang","8":"J","9":"2"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics","7":"Kim","8":"WE","9":"3"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics","7":"Sahu","8":"S","9":"4"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics","7":"Kosa","8":"NM","9":"5"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics","7":"Yang","8":"P","9":"6"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics","7":"Thompson","8":"M","9":"7"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics","7":"Gilson","8":"MK","9":"8"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics","7":"Frazier","8":"PI","9":"9"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics","7":"Burkart","8":"MD","9":"10"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics","7":"Gianneschi","8":"NC","9":"11"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism","7":"Tallorin","8":"L","9":"1"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism","7":"Wang","8":"J","9":"2"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism","7":"Kim","8":"WE","9":"3"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism","7":"Sahu","8":"S","9":"4"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism","7":"Kosa","8":"NM","9":"5"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism","7":"Yang","8":"P","9":"6"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism","7":"Thompson","8":"M","9":"7"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism","7":"Gilson","8":"MK","9":"8"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism","7":"Frazier","8":"PI","9":"9"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism","7":"Burkart","8":"MD","9":"10"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism","7":"Gianneschi","8":"NC","9":"11"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bayes Theorem","7":"Tallorin","8":"L","9":"1"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bayes Theorem","7":"Wang","8":"J","9":"2"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bayes Theorem","7":"Kim","8":"WE","9":"3"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bayes Theorem","7":"Sahu","8":"S","9":"4"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bayes Theorem","7":"Kosa","8":"NM","9":"5"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bayes Theorem","7":"Yang","8":"P","9":"6"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bayes Theorem","7":"Thompson","8":"M","9":"7"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bayes Theorem","7":"Gilson","8":"MK","9":"8"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bayes Theorem","7":"Frazier","8":"PI","9":"9"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bayes Theorem","7":"Burkart","8":"MD","9":"10"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bayes Theorem","7":"Gianneschi","8":"NC","9":"11"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Machine Learning","7":"Tallorin","8":"L","9":"1"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Machine Learning","7":"Wang","8":"J","9":"2"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Machine Learning","7":"Kim","8":"WE","9":"3"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Machine Learning","7":"Sahu","8":"S","9":"4"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Machine Learning","7":"Kosa","8":"NM","9":"5"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Machine Learning","7":"Yang","8":"P","9":"6"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Machine Learning","7":"Thompson","8":"M","9":"7"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Machine Learning","7":"Gilson","8":"MK","9":"8"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Machine Learning","7":"Frazier","8":"PI","9":"9"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Machine Learning","7":"Burkart","8":"MD","9":"10"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Machine Learning","7":"Gianneschi","8":"NC","9":"11"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Peptides","7":"Tallorin","8":"L","9":"1"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Peptides","7":"Wang","8":"J","9":"2"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Peptides","7":"Kim","8":"WE","9":"3"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Peptides","7":"Sahu","8":"S","9":"4"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Peptides","7":"Kosa","8":"NM","9":"5"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Peptides","7":"Yang","8":"P","9":"6"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Peptides","7":"Thompson","8":"M","9":"7"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Peptides","7":"Gilson","8":"MK","9":"8"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Peptides","7":"Frazier","8":"PI","9":"9"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Peptides","7":"Burkart","8":"MD","9":"10"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Peptides","7":"Gianneschi","8":"NC","9":"11"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics","7":"Tallorin","8":"L","9":"1"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics","7":"Wang","8":"J","9":"2"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics","7":"Kim","8":"WE","9":"3"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics","7":"Sahu","8":"S","9":"4"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics","7":"Kosa","8":"NM","9":"5"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics","7":"Yang","8":"P","9":"6"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics","7":"Thompson","8":"M","9":"7"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics","7":"Gilson","8":"MK","9":"8"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics","7":"Frazier","8":"PI","9":"9"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics","7":"Burkart","8":"MD","9":"10"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics","7":"Gianneschi","8":"NC","9":"11"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism","7":"Tallorin","8":"L","9":"1"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism","7":"Wang","8":"J","9":"2"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism","7":"Kim","8":"WE","9":"3"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism","7":"Sahu","8":"S","9":"4"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism","7":"Kosa","8":"NM","9":"5"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism","7":"Yang","8":"P","9":"6"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism","7":"Thompson","8":"M","9":"7"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism","7":"Gilson","8":"MK","9":"8"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism","7":"Frazier","8":"PI","9":"9"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism","7":"Burkart","8":"MD","9":"10"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism","7":"Gianneschi","8":"NC","9":"11"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Protein Binding","7":"Tallorin","8":"L","9":"1"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Protein Binding","7":"Wang","8":"J","9":"2"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Protein Binding","7":"Kim","8":"WE","9":"3"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Protein Binding","7":"Sahu","8":"S","9":"4"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Protein Binding","7":"Kosa","8":"NM","9":"5"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Protein Binding","7":"Yang","8":"P","9":"6"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Protein Binding","7":"Thompson","8":"M","9":"7"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Protein Binding","7":"Gilson","8":"MK","9":"8"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Protein Binding","7":"Frazier","8":"PI","9":"9"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Protein Binding","7":"Burkart","8":"MD","9":"10"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Protein Binding","7":"Gianneschi","8":"NC","9":"11"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Recombinant Proteins","7":"Tallorin","8":"L","9":"1"}],"options":{"columns":{"min":{},"max":[10],"total":[9]},"rows":{"min":[10],"max":[10],"total":[1106]},"pages":{}}}
  </script>
</div>
<!-- rnb-frame-end -->
<!-- rnb-chunk-end -->
<!-- rnb-text-begin -->
<p>or the most recent 3000 with keywords</p>
<!-- rnb-text-end -->
<!-- rnb-chunk-begin -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuc2VhcmNoIDwtIFwibWFjaGluZSBsZWFybmluZ1tNZVNIXSBhbmQgcHVibGljIGhlYWx0aFtNZVNIXVwiXG5zdGFydCA8LSAyMDA4XG5lbmQgPC0gMjAxOVxubiA8LSAzMDAwXG4gIFxuICBcbmFic3RyYWN0c19rdyA8LSBwdWJtZWRBYnN0cmFjdFIoc2VhcmNoID0gc2VhcmNoLCBzdGFydCA9IHN0YXJ0LCBlbmQgPSBlbmQsIG4gPSBuLCBhdXRob3JzID0gRkFMU0UsIGtleXdvcmQgPSBUUlVFKVxuYGBgIn0= -->
<pre class="r"><code>search &lt;- &quot;machine learning[MeSH] and public health[MeSH]&quot;
start &lt;- 2008
end &lt;- 2019
n &lt;- 3000
  
  
abstracts_kw &lt;- pubmedAbstractR(search = search, start = start, end = end, n = n, authors = FALSE, keyword = TRUE)</code></pre>
<!-- rnb-source-end -->
<!-- rnb-output-begin eyJkYXRhIjoiUGxlYXNlIHdhaXQuLi5Zb3VyIHF1ZXJ5IGlzIFwibWFjaGluZSBsZWFybmluZ1wiW01lU0ggVGVybXNdIEFORCBcInB1YmxpYyBoZWFsdGhcIltNZVNIIFRlcm1zXSBBTkQgMjAwOFtQREFUXSA6IDIwMTlbUERBVF0uIFRoaXMgcmV0dXJucyA1NDk5IGFic3RyYWN0cy4gQnkgZGVmYXVsdCAxMDAwIGFic3RyYWN0cyBhcmUgZG93bmxvYWRlZC4gWW91IGRvd25sb2FkZWQgMzAwMCBhYnN0cmFjdHMuIFRvIHJldHJpZXZlIG1vcmUgc2V0ICduID0nIGFyZ3VtZW50IHRvIHRoZSBkZXNpcmVkIHZhbHVlXG4ifQ== -->
<pre><code>Please wait...Your query is &quot;machine learning&quot;[MeSH Terms] AND &quot;public health&quot;[MeSH Terms] AND 2008[PDAT] : 2019[PDAT]. This returns 5499 abstracts. By default 1000 abstracts are downloaded. You downloaded 3000 abstracts. To retrieve more set 'n =' argument to the desired value</code></pre>
<!-- rnb-output-end -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuYWJzdHJhY3RzX2t3XG5gYGAifQ== -->
<pre class="r"><code>abstracts_kw</code></pre>
<!-- rnb-source-end -->
<!-- rnb-frame-begin {"metadata":{"classes":["tbl_df","tbl","data.frame"],"ncol":6,"nrow":46975},"rdf":"H4sIAAAAAAAABuz9S48kSZoliuWdruqeHnBxAS4JErrJLnfAzCoi8hWRNTO8Hh6PjK7wiLjuHpk9vHceYqpiZlKuqqKpomoelotBDWbD5gsgCXBBgkADBO+CJEAMNwR474KoLcH7C7ggezUgwC3B3fB8n4iqqbl7RGbP9KOq8iSqwt3NVEU++R7nHDVT/eT8yZ89+Ad/9g8++uijv/fRH/z0P/ro7/0Bfv3J38M//9FHP/noj+Xnu48++oP/Jn75Q/z/P8bv/za98Z9fbmx2aevgfJ09tt21tfjp1tkT05nM1EWGA3y7y1yddTj0T77tffeL15XLQ/w1e9qazK9wjq9s4XJTZuc2WNPmmwXn4Bycg3P8js1xflqaENwKb3YyDY7uWteUdl7bNV7a2mzZWhO6LDd1btuQLU2wRYZDX1RVX/u1rT1mzJrWr1zp6jVH5si/jyNvzmy38YUv/XqXdT4r7NaWvskqk29cbbMSdVXj+MyUa9+6blMFOcxVGAmzNrZd+baSSaVe1zCh9a7ubOhcjcK0deFD7psd5+N8nI/z/b7N9/bi67PsddO5yn0XsRnnZ49bg7Mv+wq/vyhs3e2h+22Q2V/Uq9a0QOiLxuaYQsYEPF+YCqAeOPjv6eD/7I1vO7Msbfak9dc40YaQPbEdTpGhuk3r+/UGQ1qheJO9ae2q9XWHzLvALOD7042pa1tmT0udxiJRm41Btrem4iychbNwlt/9WT766I//Hf77G/8ZV3N56kH/diOfSUADrPpalwFjh8um1gbft9AE8vGEyAGYqVddlS+wCGEI+ahi00M54EoMXLHg2BybY3Nsjv03PvafPnGQ21vbihAvbFb7rceVHDQ8/gj9EtdwBldwOoStv9tV+L1X1X7zqpAjckSOyBF/+Ij/c4zY4e/ehY0cl7e7AJmrQrbZANage6ts6eQDKf2qSpCtXZkcI7taPo/vLH7mXj4neGfDl1nrS1XNemCFP/K+NC2OgHzOu6DwaGvbrm3n8mhqfvDtAE2jaTSNpv2+mpafZBcWIhCHzR/r15zPTcguonh86WHM8Mnttes2mcnO/NJh7nO/9F0GHbp0+g3A105vQZB5Tze20lVciD7dozun4lR3TPWfx+8HZI6gH/fjEFzczJH1yH/VC5K+BcRGi+Pq8Ut71Muq7F0Rsq0z2cnl+fzZ5YvzNMjhF0ucg3NwDs7BOTgH5/ibnePdE2fWtQ8uyIm1Cb7ZmHZXry0my02bu9pXJkreYNse/8bv9dOHA5tdY9vROleZtUpmlRSwO+mNHGrCV7ZroZ4rvUuF83N+zs/5Of/f7fz/5Im1zeTWwDbfOLmXoW/TZ8EgnMLlA7PUfV5aHzBW1sBoeVlpKJr3bS83M4SsMJ3hBJyAE/w+TfDPLr4+m58/e/ol3i/T7U7yUdHWhX7/CZM8n7GRb65Dl7U4bmvqLltZE+0Ybo+qfT0vgVCmza5sW9sycBbOwlk4C2f5sc5yJU/HDiR144EUjB02vu2GUyvfudV+8PS87CHD5aasfNHjjDnEcCHslr6b45ScklNySk75+znl9sw0jbxxZuq1Ptz4zGO8Tj9jeeLr9Xcb49Z4L3ulM2kThXarzz2eblxt0pNtL0FywXTZQ2W7c1OYFn/OH2RvfGlalz5QuTg51wYOnJ2z/1hn/9evt7Y1ZZmFvt26bfyiaihaeZq4dH5ZmtDJh5lVX6LMgQEobUhHW8NI/dxh68s+TjADLpgm3hDf2Xdq8AgLH74tlabQFJpCU2gKTaEpNOW33ZT1SXYBI+xu+ADt0uab2n3bp69t5PLpRt8NvUH3Vlusr/TxwBNdQzLwa/2A7kCpcTpO9wOn++++HL5MHJ5pGC64zWrlatftUmo3rdu60q6tPL2qF/cyMIfhMBzmb2aYf32jzFHTm34pD5QDCvSmnyLeV9ThYh301qdnk0ydt6AlvBi7JWbLndwtOs6Qy8NIptwFG59KCn1jQZByC+p4Z0G8gSjQFJpCU2gKTaEpNIWm0BSa8vtmyr9IpuzkvWettfOXUOX4/c1mF/TxaLmG3rrOYczh+7Nlegb7TJo3JYu/wQTaNPAkz21pW7kZ37ach/NwHs7zez/P/+gkG9qmzrJvnNwdGgIm8Z1vSkDuLvgqtlfZacMJ3+rnmSchpOdcv7KmxDSggpMWAzu/tbXvQ/bMha4vh3sX9IPO+TfWrTed9KPumwazZl/bvMNoZ/EDeNpEm2gTbaJNtIk20aabNn3xxpW+yy66vtjJLlLPjetufoUah129enF+kV24Na4qA0/n6Tydp/8VT29f7L/cTddVj31fF6bdZU+/7V3plq3rq+y59Ic0+gDFSbHFpZVpHS7PXtnu2rdX6SrshfSXbFob96c4t/g14PouGjF88cyZOfPv+8zbN5OHjIyqhQoHi04wrX60LBPUtm/1R5onfSis2mAbtUFr161IDcxRxY87RH+ErrWmylalv57cNxg4O2fn7Jz9xzT7/1g/BRZ5UxhX7rJrA5jOOls1Aul6G7QM7QTWv9Se2AD3gCmWaftrU5hGoV8s9PNV/913sv/1yrbSgSYLu4DBor0fWE40mEbRKBpFo2gUjfpbMGr7QrdOFqvkYYwLm/et3MAtg/yn/qnclJIa7T+xWyft1IYmOKbW65mydGuhajnhZDDw1Nedq3v5FPOkx7jS1T9e5VyokZyds3P2v4vZ/9dnN3dSX+qHGiKY5RHBOUDHDF1WzbqW3Vwy2duvjpuqp+assjW7WynydA449t6HDfW5rKbFee0uy3H8MoJRuxVTI2Rl5a5qNjiRRtJIGkkjaSSNpJE0kkbSSBpJI2kkjfwdNzJ/k753wkytdi30rs02PnTjB3a4ym98kb7JSh1NrLTnkct4mSvIbTdjV9HzVyfZ1rWYcm1rX9nAqTgVp+JUnIpTcaof0VT9SS8aRWRNYTs7dhn3oktkrsl2bPg1xOHCtewHfy32xW5Nh9u1Z6Zc+9Z1m/SNogqgfGPq2pbZ07PnnJyTc3JOzsk5OSfn5H8tk3+7n1xu2e30JuCmxHEHH+tAOVk7Lxzellt9YUnhg5VNxLvWLVU+Dff54gTVVcXBxpLd0HOWE3NiTsyJf3cn/p+cNE05aTNW+dLmfWlajJxfySkCuG8uXs8vvj4HVE/uH2ua1pt8ExHc1J2rTBkfWzOxY87uxrZVtpajcOkpH6Xnu7z0697UrtSeZPh9f0lKq2gVraJVtIpW0SpaRatoFa2iVbTqb86qjz7643+H/37rfkZvdZPvQwtnlukuLPztG9Nt4vNPbtLK1R00S1nK4gtt5/o9e5JNPmtccG7Ozbk5N+fm3Jybc/97zP3sRDZTXbUmdG2fj20aMHjuYp8hGVoG2T+mLRt0ON20fumk28N+O0qOxtH+Nkf74snBt0cunY5KGB57kNJpDapKLzW6jW1Ns+PpP+7Tf30iSBnc0pVyLRqGxrAG/4vfc9oi7TMkz82sY/PLcWvpeWiQrSu5heTmt5uxIZtM7NOcCYoPvuakHbSDdtCO3xs7vnIg6m97o2YMEKy3d4TGtMGWMM5UTQlzpPFXL3Z1+30DhNLTtnEHuC4gfm22trRd1rWmDvKEoqD91rROnkYssEa373RJO2gH7aAdv+t2/MUv7S57UVV97Uu/Vl37rK9jV9/sRb315dbKnvPaYe1N68emwLhEetpgflvKly2vZXhwwYVtZZJT0+LCSp72fuJC7re2xSDLnQ4i/d2z13Un8+1SI/howCpN7CubnaRLMdpJO2kn7aSdPw47N28Ovq1fOm+2xpUmXXcIvXX+ncvlD7wv1Fjad1m+sZUuqnLv4sfSw2d6tz6YPuzay/k4H+fjfJyP83E+zve7Nt//ILVsm+v7kFgBl/7j9E3Y5ZtR8H3b2yDv1Ma1NnO6xYFssro1dScf2opqK+zWlr4Z9gxqbAtx1ukjeEbusFzJTgvL1prQZbl0fWuz0Ldr2+5oES2iRbSIFtEiWkSLaBEtokW0iBZNLVo9LVzn9QG1Uz9uOHdudevVz4adrWu9l1A+b8eV31fWlHgDh+uH8rPswoQr03lfz7JTU5vCzLIHD+YPPsv+tMfhD+7df8jZOBtn42ycjbP90zeyhWle2uzi2rRV9rrpXOW+09HT17IXaevvr+PW3+f7rb/l1sxL37dgueykbd3WlCF75lubg+Imt2VyEk7yOz7J8kxaaVa+QMmdnb+Yx05zN7pvSnMCt24h9uyXd92mnOW+HvuO39wxmDNxJs7EmTjT78NMH/1aZvqfnaWnAV9UZm2z08MpHg/dSvUhwmfDI9NP33Wt0b6ky118Sze012+HLzqcGuSx7HR49qxXHtObvXVdpdnZNntj29w2Xevrfxj65h//5a//D//w5/ILLaNltIyW0TJaRstoGS2jZbSMlv02WRav0vzJ2Dkg2LV8qTpemNk6W5ncZvnGt97JZZw8IgvD/LKTCza1yzedLiz3G/kMvZs+H4u3b945y2k5LafltJyW03JaTvt7Ne2vn4ZOH8nebzWIo3Nfd67u5fXKmgCtJgZpf8OtdBzBPJ2tGmnVJDpO1B1OKfo8tU5XRQfJZtutE51462EkV2cQkl1paQftoB20g3bQDtrx47Pju0t/bdoiQORs5MZ3bQZplr70lTR9lG5l0+7KlQkhk56QMB4HtrEFmv0yfnykTWY6m5327VZujAzpW3g1NN3Sn728oYBoAS2gBbRgsOB/d2mllQKgrnCrdJN1yJa2u7a4EMOfcpFlS/wzNrEK/bLbNTZ8OQ46AF66g+jbXjaPkis62HFXW8ZO57T7tSmSurqwja1lW4UMB8i93SWAuMQ1oCyDFtNiWkyLaTEtpsW0mBbTYlpMi2kxLabF/34Wu6ewM+/iZws3OyjqNjVB7npr9tshvro4fXmaSQ9rg4WEvt3Ko6JZ5yqbLYe75M5lm5rK5WG0ihNyQk7ICTkhJ+SEnPBvcMJfPInf8cqDym2/nrdWuo9pe7J+adu8L73IJPludmNDF/fUUzHFITgEh/jdGuLi5Fy/3/xP5ZfY9F2gJt/lpffvdmtcdAU7v58dnb7+s/n9Ywy2cUvpK8UhOMQHh/j61Nfj9quZCcGGMLS0rOT79sa0BgxmW70beei0lBU25K1rZChJ3dNXFxmuxG3XHlx5c3SO/mMa/dYNKHLs0K/PtJbH/W4ft3k9PJFxq31QbX1TGn0UNveltJTrcFzjy10Tsnlmho8127mcGeTzTdM0rcfE2ZH0Ez59fXL6VdxM+5jzcT7Ox/k4H+fjfJzvd3W+S2kX8sp1rf8yO9wM703rOwuRJW+a8f5tPTTsyvjKhevkm+XUdOTmPd0cm2NzbI791zV29/RdA9yTi7/Q4ARTzlet/ba3db6bB/1FXpR9YHS4sHFARukoXnlpM64PqbS7m9CqN6oATftWn+C/u0ct5+bcnJtzc+7fj7n/k4ve5a6IT1MPv5908px1B/bZf5QMMortyfUegewkKWqOw3E4DsfhOByH43z00f/ymTXBLV0pDUlwtWdq08l9cWDeVeo723gnXU2Ev+XTKNm/sxo/3MJooZOuAaWPNK5f4spxj83OBmfkC97S1TaesZKvgIXP43jj2WkbT71DBye3ptnRQlpIC2khLaSFtJAW0sK/CwtfXuSttXrjlnyV2Xetk6FM3KRgLTfquRy/28qZkPZ3s+nbztKtN10WpIWdbSffB3BMjskxfzvH/M/ObbCmzTdfZm+DlXGftLvsaak94+SB9GZjSnmIokpXngcbAguqvF7+Sh7K2NrsjQEYnYw3AnMKTsEpOMV/8BT/4rmtfWXnQK/SZmcub/35q5OsM+3aduOToF6EUOv79SbLyz5EmItfMj1xrcs3pR7sc4yeVS52wdAnfTgP5+E8nIfzcB7O89c3z5tbz4IJ3e9b6kMrbJ3c8xHvIZHmV+D/TV+ZWvtar8XM1Nc62C5wXI7LcX9/xv1n43idz2Jvh+zUr2unFwMvqsa4Vp8oHnDoiVs7eZbiualsyO5qU59d2nxTO5jBWTgLZ/mtnSU8geKQe1TSIwWpfaXspTwRIPEzTNnGAnOXu0xaCpSlHZFGW8HEXS+K1HQAiuZ23yjt58GpOTWn5tScmlNzak7NqTk1p+bUf7tT/2+euND2jXZ9CLsqbsvnV5mrpSOEDoVfWzPf2MqFZmNbl2ervs7TrR65r2v9ulRuIXN1Jg/k6S6k+sms9sWsDeydZSvXhm5uGxdgQBZg1Xe+2bS2dtHibmNdm/W10Ya7sCe4ZQmDaSpNpak0labSVJpKU2kqTaWpNPW32dSPPvrjf4f//sZ/Rpe8ONHGfXr95/M+fhvWOrl8lG/G4zffV7Jjm83yPnXR2mIVN68NFxyQA/4WDfgvDvq5adG9ruV5suxrV1j/ZXZSbM1wg8dla+rYdwDDzrKTvvOVkbJ8URf2Hc6fpS+Da9f08XMWzsN5OM9/+Dz/i9ONaU0u92R+Nz4cKu23GvnIct6CiTuFhfFTyZCXttXtcUb+jR9vhvRAxjY+kDEgw2GvLt0LZcLpYpfsWYohMPfZ+Qv9HJTW0TpaR+toHa2jdbSO1v3Vrfvoo//4o4/+4N8mKz/62/n5R//vxyenv3x+/vrtqyfQqMu+LmRXRbuFaIVazcLGX4es2xi9vIQz5rVdG70feNlaE7qho8jR5avHp8cZfLSRjb+89CTwfYhCFheju8yucGUK122MnCz73Bd26+Me9ZlM17nVTrwqI43b3Wc+djlZGvE/PDk8UtC0fuXkM6BF9pW/tlvbzrKVvdbNE5xN01htX2v1A6Q79muIMzU211fLcrffNdZVVY9QBreutTtLckJldtnK5NLGRdqpyLC6xZk8AqFN028NP6YMxmiQDeI6WbCMP7ZgOXt6+dXrJxfyILV4YOX7Nmv6Zely2GS2xpVmiUTUAZMDwvhQxSy73i8O1utRN90mf8Q5bzlQ3n7w6PaKF9nbGhlu263TWyQQyMmf792i99q2FvUR44rDEfXqDv8vzp9evH15iTV/Y4fwO41Ua+2NHFDXY5G1qeQiSQyVjxS/cutNdjT8+c+/Op7t3zuzheurybtnxzEXxyNe+uvJ2y+PY2HaCjGSSKopkvYbOPBm/2Ij4SydBkVOS7eO6N9LREw2Gv7uAEOk4q12Ox6fhcn2luuI+R6XMDmGWaPCZBO9FJncliWuHhG0aXt+lKubd33lx+NM/MgVRYAVSzxwGn4urTQA2e+SjPiva0U12ZXEtDFgmtGSlqP3F9ljGxCgsM+haZbMsqAfMikMyL4mPnfqPST+5trsUkJsMFSrlumbuAjer36GP/MSZSsXzg3qSayaYcgylxjqXKVeFZ+dvPnl9O83Lz755fzkqpu+Jk45P7nYvwRH1/JZNLwWun2K/POXEraAkFiJu/wuSXu78OPn3LnAnZRBXEMqcY2JbBVqZ0hHsMHUErnVqLVNmdJmllUu4Do/l97X8izFLJ5uio1VLqh8afNeUsjVhY4Q5GTrxcMzPQ4ZFLJfJTIZWWWWNbvWVa6QgpTnrpa+xFSzbF3uctm7odn40CCbXbGDaXBv58vs6PmbF8dzxG2D3Fk6HFd3YkkCbXkwVLauqRC3YMdwLrJnfSsJgoyzCj2T4jXaiwbOngN5xaFiJRIptfbGeuWrAzmw9aCabKVoOP00RNBVuPTo8tmxDhZk49Xz1/dPZtnF5cnlp7Ps8enL+/cfz7L/3qtnDz+5H419+vrs6cXxIZZLJPQPFF3qlTWpuJTesYY+ZCNezS6fDba8OH/2MLazePPi/vGkZoP02klAO0mxNM3i9PWr05dvL168fgXEu9zsvXaTjQbM+wATbVDNDZgz9l7PEVHtI+aqMdVi1y8dsBMQmfTUIOOT8cn4ZHwyPhmfjE/GJ+OT8cn4ZHwyPhmfjE/GJ+OT8cn4ZHwyPhmfjE/GJ+OT8cn4ZHwyPhmfjE/GJ+OT8cn4ZHwyPhmfjE/GJ+OT8cn4ZHwyPhmfjE/GJ+OT8cn4ZHwyPhmfjE/GJ+OT8cn4ZHwyPhmfjH+b8X/6/4utXCXpnUkIENsLmVYNkkGl5XJZurWKgI2iBwjbZBskBHAJhCQurQT1cLSUkWmR1yvtSgSy3+HvlEetzRX2QNGlbyrlQlcr6PQCSPBgcW0EIpSxawHRSNi1aVtQewvDrBEP3eIcAJb9tndNcoJDIsVmz6N7YC64aNWXONaX0S/j1Oa2J45OT54gj3Z4uQoTaYEkdWOnTZwnuS1/jYP9DECxFF2wE6vSgDDVXVnxmzbIlVXK8aV9l4EErpKHQp/L1uZipO87HIAYA5BsrfHfmtZBSaXCgE3fJFetfK40K2JBMxcHrwFxrZfoSbNeI0X+4hhOLXzIfQN9Y3ODkzLXiVQT69vatqHzdWzku3eEGDbmjji/AO0jJ0c18fyFOCXvFpCNMDt7sHgIgEPSwIyyr3R2HHNkgwf0rK0pgWfSeDTfAPi86DIwZnmcqCOod+JWz1jUuvRLjZ64P+ZTdJYpITNkM1hUSuhMrIFOd31NRdD6rR3TbFi6nQrPyhRgOQysCylFxt6/N7//2Zi2OOJX8EYJTO3G+hyGQp3bd0YWGEuttRVyA34RhhPskohFjYNKhysV4ErwnliE5DAHtsfu5n4ZoKzs5OQBs/a7X+9Tb4hJ1QPeMUapBKKcmUoZMmadiBwKpl5LQKEkYaHsPIUqboSNwlyUjgrAex8PE0ps4mTdpo+sL/bqTlQHdSznmazuqyVmwe+ND91cz07Zto/yEORFhvoaygsWrDe42BA311FOw1t7B4gJKHXVJcI24F7tLW3H8grK7XoaoAi+d5Jl17JCJ/YhLVWdpJTF2SrBgNplaet17I4bnXywKlyrAE300FTead+uIu1AHJEDEYz1uHZ6sWGktLVAkITwhkoqQZ0YlKGSu3GP4tl44XOHbTHfdejQr9dS0QOy3zT5dmaseuGKqbeJ/8R/4j/xn/hP/Cf+E/+J/8R/4j/xn/hP/Cf+E/+J/8R/4j/xn/hP/Cf+E/+J/8R/4j/xn/hP/Cf+E/+J/8R/4j/xn/hP/Cf+E/+J/8R/4j/xn/hP/Cf+E/+J/8R/4j/xn/hP/Cf+E/+J/8R/4j/xn/hP/Cf+E/+J/3/X+P/Rr4H/f+//JN2HFC/27a9ccmJjGuk3FvbYEt0jkIFBpb0S4CUGd9K1T4/RbkriaKRVr79F0FsKcmYh+cbih9c2f6FvGt922dZqw6cB28dGdpIsl9d+0jktTV9Jg8EbfeZMDhrA365etdrKbGIq6nXSPCkF/Bq1kDIX1bkWYOiuBRvuP7h37y//1X/5yWf37mV59Q9h5T+e3/+HP5efQDoAyjswi3bx0y5vApXSvC01uovWrFwdGWzoDZj7euXWfWrbJhE0379+japUf1vJGzJehQqTznN2K02tWrvWjEjZHZdsUoJoNEHoeV8aDNWMvaEW2n4KrujLLkwb3mWp392YWtIDq1yjqLpNJUnR+mWP+W2t+It1Jltj/N/jeml3dzMZUorobNLtb9Icz0knsAFbUf0whJnLzGXmMnOZucxcZi4zl5nLzGXmMnOZub9FmaufLeO/36ufP/lvP7GhcXC8NEuXftaSnIVdxY+CpSW0dH1uXbjSmDZhhxQxXStedcG3hZWPE+F71w7dvRHqyuYbU7tQDZ8dZrbsJWGRvkXRpo+WJUH03OyNDPv01enrJ0+zU+QCclL6osvH8mJCbFYfP4lu7Sblvq9LyUmM5vs2t+PHRqZAVqUomxxJELL7Dz//PJOW41tX9KYMMf+ms46jSBt1/bDzX37xaHYPBagDzbUpunx4v4kf880y6XAvSfWVm59msOTKjJ9odb7xpV+nLt1Dx3hZcuH1k9RfZOKA0s61Pfqkk3jcssCG/fcMeoQ2zP7F9MBve/lwtdONKuby0X2XlZglO/pPL1+G41+oGavYxjyTl0Yr4Ej9/iDfAMXEqNSDfewsLxPOFUj1I75WP5OTTyE7u07gMdkzY2taRdI7z8qQC2srLshz36O0hhBpVOaNb5AtOuLBZ8KTZR6prX+y7n7x8OHH8kWLAkWfPi3WD0vz3TGs6wATARhclmLasndlkTZ+SB3bAVQymW93WeqDPtOopTQHos+vwSX7aMk6u77YRdvkw3agTeqRbhfrxSz75MF9XVFASXznG8BI7cyxflxqgepFRMCh63r8YLyOn4ZjgXEvhcLaZr7fYcIXVj7e3bh8M3zQH4bvJYY9GMSy5S77l5/PV74sgN1t6IN+4g3rhmIF8o2d/Yfu9SG7sru0BHlj3L8APr+zsBcECYIEQYIgQZAgSBAkCBIECYIEQYIgQZAgSBAkCBIECYIEQYIgQZAgSBAkCBIECYIEQYIgQZAgSBAkCBIECYIEQYIgQZAgSBAkCBIECYIEQYIgQZAgSBAkCBIECYIEQYIgQZAgSBAkCBIECYIEQYIgQZD4XQWJ/5ZUi3TQ8NrVVhqF2qYTb2lH2FZ7xIonbP3dTtoAa9TsuzwWvdRKaWMBaR25ToyJnXxhW2vKbO21pyzS0lbaEXfppIR2+06p2kJGu6SmLiLSn3i3bF2Rup1qzKTJKZaGs8eRKtttvLZPaU3jCqSjdk9x39lhGdF4aS8ijaRnGdJ349c62HSgVV/nqRrEIWlcbTqcAUJbLcbb3Z4RRemTLDGLgUV+29ZJy1MMqm1MnHZO9sHFnjnabBfFiYkxpky9b5eiVRf9Gfb9ou8KCEZZ2kxaKmPQ6ZwlvPpaOmTH9yIE72fopVuyvHTbTvGhcIMdGrWmwCafSJTSYqWri22s4g0q35XamMbFpAd0amtmm9V+6++yXZsqp4SzRSopafAzVJU2o9UMiX2r46HTyL0nRT/92bzZ+ID/NyhqK8xV78rY7HiFGAYrMJgyOTaiiT7HBKaEL5A/KNNYT1hth/Mn/XyB2XVKU23cPGmDU8RxbuVHLu1rrLakkTbHmqnrXkwflpDydd/kZ0jVu9MTXu2AHtLmHNNG+BU8FdcjCWNl6Skhb62NLcknzX1DjySV1kPS/1p825RmF5ui4x9fZRWKTWHEESIIEYQIQgQhghBBiCBEECIIEYQIQgQhghBBiCBEECIIEYQIQgQhghBBiCBEECIIEYQIQgQhghBBiCBEECIIEYQIQgQhghBBiCBEECIIEYQIQgQhghBBiCBEECIIEYQIQgQh4m8FIv74f/r45PSXz89fv3315MvsQh9/RYQreYx6/3Q3fGmrZZmKH/YWJmUXloy/bBu6+PzxsBJBBFvKc9d/Nm9hRN7ugmSwX6OWNzsZpht2oQcKwNf7lcigwZdbm54y/+RJFh8BlsRFIEznK3nq1eKgXqbTKJphjlm28dcSk1m29ICzvdvK3Xzc8V4fyl2ZPD0ZW/t6PgZn8l6rm9uLo1dwyI1l4NDG5PpAseS9XwbbbiXrn8RF6IPPgLjSvnOd+lVemYRx4te8b9uYpB2GLKW6NYfdahefnPfBTgybZW5hFxJjMa53YSNHTYaempuVpgMc3Tg/plvXAtYT+PoVUElqo1bzbdv6dlIi8qC8fddJmZly9100C8m+2QWX+/mYz/nGtKALQBCMy/WR+b1hPx9smjhZCmljy0a8jeLCQG0YHmLeAStTCayASn1rU1lPli5mVLqCtbYAQFV2GHySmenJcDE3YHpbhcX504u3Ly8vvhyXF58QR/1LLOVBbKen1fYatga33nQhQnynpLoC6NhazMds16jGg8DKY/U3cyWlglVGWfm8154IyPw/+bb33S8a49q5PEtvW6HZ+KJYPfGUrlzxSWK3AxwvZeZVL20HXL0FL7i1QJYi7/SFbD9yxAkddV/i8KsrejtPP2NXBKGqI1O21gAWcJagUZzLNA3SthiyfPKgukY7etyspKuETHkcn0uXKU08TJo8rMWYI2WiFkAglDnLvjbSjqLNvjGmjLVZSKFvFUSPF9njXdaHIff+DA4+k6YJctxj5/X30V/KfdK1QcMqPQyiA4cDJO9vrncsO1mdEaUzgFpKIADSrYzf+3amyTzNzR+aHfsoR5WiDtJeHBKnoObPJFtMpBvAHHISjgK79Ykjb9fWTHhfqV7iAa4CK4ZI5hM3Rbgazh4wTfIVtaBBnlg/NXQMhtGmCbYb2OOQKZEtrceLNkZCulfU2t8jFtdgx+D5PBJmSiqsa4koFrL2MSvvTCf11oASkEp9OxkDSSwGiEYY2kgoS01AdrLIbbjDmbK2e4tHD2YHrrm3ePhQvf/0zZsXp9mRoGfCGm2EIolt5341xytz03b7BGtVa0nrDEweQKkQDi1GqqTjiCTfmxcXJ8eL09evTl++vXjx+tUhWI1aZR3deRulanXFiCH7aj/w4+i7kFLth7HK3akrTl/F+oeoEnuijQBlpIAUtkJHbpauFFJUB0Vy3188zOJFyTsjgDn2EBnaWqT0wKpqJJgsUuQ7aMLGXjZe0zcioAwgUkXSB5bdyLAhL8dWHdaE3bzzc0jp2FDFQJ8E8OI1og2roLoE/LbGlVpDyc8hd8k0FTN9LStTX226rvny5z9fQ6D3ywXe/PnGFMnCn49+m+9TIqMwozCjMKMwozCjMKMwozCjMKMwozCjMKMwozCjMKMwozCjMKMwozCjMKMwozCjMKMwozCjMKMwozCjMKMwozCjMKMwozCjMKMwozCjMKMwozCjMKMwozCjMKMwozCjMKMwozCjMKMwozCjMKMwozCjMKMwozCjMKMwozCjMKMwozCjMKMwozCjMKMwozCjMKMwozCjMKMw+/cUZn/4X1yOTaAznIKMDjaKptIjFEN3XHjBIAFCBijCEHglYKFIH2lJrWSIxC/nyJeyyDZ9pa1+tw4cL26JjasNdBjCYbPWQzHFGO5dE/blJycD03W1EcX8RliwS6wa4XWlDZUHhpTmzXVACCtfwGwloCMRL7Ns69RgHWiAUjkYvjlWAfKuKb3rZmMGrBzoPOtcZWMPZ6gnaDnVgqW6AwnbIKkhJyM/FBaqUoIPDyWlJy/75a+0nTQM6EUW4vzcr2v3nVaRHjJxUur0XPutLfd+kQK4jgFRt4nBSurJMtEx6rNMSXBsAr1vYS1RS8HKRaMU2rP5qNjVpopyNeubQsnbTCcSrpFDj2fSX7uUHuO5l57TolKTp0TP1nZdurVKJ1AY+AkwERuR1xMvDGvvhlCIWTfqBCx6JadtRZWPLkqtr5N7pgkDbERUBGnKRMc2jOaNWl4GKrx2UR99HVUmDJWjK5HeggBQ1oCrMkUwRW+G81CEgxRwdRJkA/iOOTFS8BB2bZh+x2uaJIvsRFa2VIASAZs9NjuIBOT+qgVGK/LGxt8COUoBG5wtcShLmTnc9LeMfTtVZxORicF9W0jr70wmlSVMUiI1Npe00nRJHh+PiOfglSFdDlMIARSeHcoQGAfnR2cL6sXk0dAMzhBxCebcOt8HDIGQQCTZdh/6lN6TDLBDtY6wpCpz9KQ6ovNraUDeRthBxITr9PihBfeAbzFwKZJjwFNyCwBgSbaI3ocAim643sTRAYhghHriILncbHstdIgSVSwa7FnsRF/aqJG1D31jYFtTmjpKl7FN/IiCZ6a98luclkf8Sl6IgaqQutpqf+ImsTf6KMHktaw09ql3iqpeUNXOS3clZIK8bp1Pl6/qquBQCxEJpCs5EH3SrB6rELCsIyOla06MEGIc9kB8uLLYpH09JOjUkQ45MAA9ZJJeR015BAlRuNgFn2xFtiJbka3IVmQrshXZimxFtiJbka3IVmQrshXZimxFtiJbka3IVmQrshXZimxFtiJbka3IVmQrshXZimz1g9jqo1+DrX76f3zT2nlyhAzu9HZW8UrEOqy1GZJHb9IPTsMrTzZ0cn+l3BC9yM5cMX9xnl71IffN7vAmfbkZtSnj0x7xoYDQRxiD/a4WbEnPf2jRxds0x8cn5E5go3fGAzgRmMrs0ihYUS5elVuW1Y8HtxWPebrIvgHiBq2O6XLzyIxyN/PWapoVfS7BkKKsr43e5jnMHrkLhnUb35rICelBgsmQ4rEAZBme9Ei5kpUmv1J8gPdR0f0I5ytny2KW1oMqryMyymMpo8P7rukF7Np4m35MFFkvUC/cXBROGD033E4aHRoTYn8TPzwzy0QJyI2/jTwrIfogZbvcPL9nB4GZwq5cPeC2b1AefXVzcvza+dyXegKCsSp7V2Qnl+fzZ5c3MmSRvU13endwcDlH5Of6hEgq2T1l13Jndw7KSNg4PnOTbseXG/rz1i3jPeY1Joh5tJTbwiXIQHWpIpeqTlBPo665fHMFtq36bkAyTdRgv+3FNTdv9h0wBnlpJ4/rzORxDHkSJw54ZXcoZrOuvdLS9I5siWIFrdMKotV52SurqJZCRso9v1oOKZr4e5G96BSGVgD/IqbJEIn3zJH7VrkLHlVMktXL3chyW72Ant4knUBTfAaHlnKvvZ6XxxzRE5E7bhtvjZ48llUpG+Lk90yvD2QFB6UifpPnkbAGAEjlfbdJ6drCv64Vx5nsAqN1313t5s99aXb7JLhOLINoARaF02TdiIJLN7AfpPUi+8qa7W6/sqaxw+31qchvBPO2nbCmhCAVCsXswAckWu1dsHEEPeto5Up5MKi09Rou+ss//99+fjybPOOVahySE7a9x0WahKJBPpSIkXYI24RtwjZhm7BN2CZsE7YJ24RtwjZhm7BN2CZsE7YJ24RtwjZhm7BN2CZsE7YJ24RtwjZhm7BN2CZsE7YJ24RtwjZhm7BN2CZsE7YJ24RtwjZhm7BN2CZsE7YJ24RtwjZhm7BN2CZsE7YJ24RtwjZhm7BN2CZsE7YJ24RtwjZhm7BN2CZsE7YJ24RtwjZhm7BN2CZsE7YJ24RtwjZhm7BN2CZsE7YJ24RtwjZhm7BN2CZsE7YJ24RtwjZhm7BN2CZsE7YJ24RtwvbvPGzrzsc//R8+iSPJYbUJvtmYdlevBQlz0+au9pXJjl69OT1WRJ+uK8s3mAvmAittblImiJEbt97oVqaCFe8GTAN0Kr7FnVyBl2NE4Mq0IJthKqQtQBypFWsaw8D50beYYLPDckbWQNath4S7tpi3m8eab1qUgWtkHTDD13EX5QiDi+wikYhWG7zVaEhRbIJdOu8SBQnUyp2gLgxsLNbaBUUjWaoZ9h4GgEth6wafaeNRvDbDtDhB90Netb7K7t+7B4A0ZbfZZVtf9iAELEPt/vyernoPK5KhReuQabIH6oC8fbsy+ejjcU616E6nRGsQpdbAjjZusDsetMTUyQGo02jpuO2qzKBsJZwU/QpQkk12h/XIqpvGt122xbmy1y0iKdV+dPH12bFsQG3LWYrhh2KRHb05PTmeVJNMXcheq2GsSdnvttNFFNHsRfZ6MCZWCIhq468jiqnCyPMeJwDg4aHZFAdnN4Fw3J1YzkvZZ/SgMb5DWqfwJWIQtMGaYYNYZyuhfcl8lDBKXGvx0aPF/c8+nmWPHi6+ePRxnBqvffL5x1razSAXFtmztN2u+u1nujMznNPplrBWNUnCTzsFbDnjlyijaC9y2CRmljfgAQDs0clb1K4ftmnOLSZs07bWynKH6XF0/hqHx1M1N+4tHj3S0fHLw5tWX+oGzGMI+vVawGk0rRBH+GbKwLnvS9mgWcY3Aii1B6xuTRAymKCaBilvEReVCT7pgIQsMbyd1cNGV3VpC/IEFIilgLfqrR+IIkdfXbw4TiohZv33IEl29I2k7xw5H0MHZyT5I4trgNbtqo8aAh6oXDhYjqRbWrQLhGRCMiGZkExIJiQTkgnJhGRCMiGZkExIJiQTkgnJhGRCMiGZkExIJiQTkgnJhGRCMiGZkExIJiQTkgnJhGRCMiGZkExIJiQTkgnJhGRCMiGZkExIJiQTkgnJhGRCMiGZkExIJiQTkgnJhGRCMiGZkPx7D8n/6PHJ6S+fn79+++rJl9mrPi+tD76ysQvOk1cn8w1W67VRieLrLLPaJ6SFkxUKl77vsvuf3QOiuFbzsPA9CnkugIH0KGQUDZ5rx44mAu/4vTCpHZGYJ5OkzIETKjDDpAEK3jjdYEmSRplbAPsak1+51CUHM0TclD9qWUQfhrGe9lcYyiN8OUBV0Bh5opA0aZvU9YWz0k8IeSG1Xe/Tqh59Io2InJjjtOXIquyt9hWJub7uyzHeMlPWIejzsUXQ2tYCFAoLmGqRnfnWelgyU8+mDiR322K3rpCptCWUNsnJ7QGoaH+mtp66Y9WatTg3RsomXtkvBsCPX02L/NYiLhXfwEkygG/XpnbfjesBYaFMsMBWx45sgNmCNkZSJNEWQNJ0KZoX2/+I2d2++QtGmhggyG/EL0hUMAXiYLWh09Jq36pcWBzZDANTF5do36G3KmkTBWYZ6Ht0z8qarkdt7Eskdqw5f3rx9uXlxZfZi9TQ5tq3V7PYmUnFAgYprG0ycY56NFaaZOgkFQ5XBobo23Rg6JCYCqlCvMnM0uwG/n3pMebFBlw2Bw5W2ZmtQP6SRj4zfacpHvsvJRraL0WpMOipOpT0zZmjyNYCfo2tJUlkJO2ENXhi6P+ki40mYrFS3Uq3MuvWu8g/aaZhZu2+JNCojC1/xbZb1xuHM/c9iRT/D/v8TBvvLE5fvzp9+fbixetX8Pt5wu8YxygApNEUgi59pjBZ7Be1ihi9WoEXkMYxJUOFvFU3/BNrgrY1+6rHLLOBkUWqYG4nHaN2ezhJMjBmS+yzlLhl7N3VCcKnE5Duyl7SnyhL6aMlpO+WrhM+g6MIogRRgihBlCBKECWIEkQJogRRgihBlCBKECWIEkQJogRRgihBlCBKECWIEkQJogRRgihBlCBKECWIEkQJogRRgihBlCBKECWIEkQJogRRgihBlCBKECWIEkQJogRRgihB9K8dRP/44RREL+58tjqkh6vV8fuHS/VxUomBPJT6nY0uUPsM0q1ayvO+KzGhcDJaiE/jvgM8dvLMMmKM7MIsKM21Pjts6oRaw7l+KU/salRQrl9hYgUdOGjtasmzmYxZTmpUHoidmAScrGR6TBStQ42WrnL6RHdqHiCnyOu1lwd5pdGA1W3r0+PPmizwiUkgNq5nfFAdpp22Nj7WvH9X0zXsH233dRkBSje+byVtpJnBOIjQClBDSlOeDK6ntksUTZtvMFHfthraWUQyEw8XINgDUCF0JF4oSyQWchvjKp7C/PHp+smqMNn4IDGG6Ls9uuigK5/3aRVynBMyrWJaabgFfwGvV4BxKyx1KXkrWTJERJ+4Tq6RQMVSlsYOIfjcmXEkLWQwtVu6UopAmKfVt4GeqdND7ev5zRn3hCTTjY4AFlilcTgjIVzfbt1W8q7vckFysRaGNAaVl46PrHBu877Vx8OfJWR5KpmTHuU+On/2FAVRrqVYN1Vs4SCVGjGltXZ89jzCI6DuahLsMS0mq1FPAbLkp0D2aOvYP2IkgMspMoxWhBjxkG1dQG1NSFB1j2aFrOzZ0yzCgNRV7A6wicR3m/RuZ+ykoP3weH9ohD7H9Q24HVw1KItBGuxbPbjKzjs/F/TsxnCkBgjiv9amqhVUVZYbK1ImjQclDp3tx22C7Qs/D6nThowX0+SDD9TP0iP9lXTkkPGrfUIOcCOBmYvz9mFXZr0jHy9HAyfBuZ7EbC8LYooLZy5t101xcO2lZQFKtDBtoVG7ezr4BuFLxg+c1rU9hnwf1oxrG+FA8jOIfdIMQ8tNc2a/VIDE7XAusueD+bMht+Y3IoDQ7ler/sQ/7c34KYnqOiZWSiMIQERfxRJeipIH/pUmMZoRqWqD/BXAeDjR32Dsw0LZV2QOHy/tbSgbG3hguigdJvZogwZFU5B7ayciowMor3E6CmKANJX+YuPQsgHv3aSjqPyGekfRWfF2HmnxsECGGhOy8TWCpHQzhm8vc8Qe6GXbok71mB9o6tCOZMrXOH4szDFl7nDnbKKykXXjoXdkw74jx/dFQJMhErk2xjn03dAE5MCImGa3CinqOzlTiggLf97v4A7xuYBMalAzJFC6LIzCqoWjBftvB4/6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifqJ+on6ifrpd1I//dGfT/VTTLeR53AWDgfz9KjY+dLVhazk6NScDX8cizs76xCApjQ74UnQ2G5kZwTel8rQSo3OlsWQSaVf7zRE+B3rr7CMFlU4yBpd+Dj5ME0m88bItnYt1SwxyVDXnUNJJ4UTD+1El3V4e7WyeUol/Cr6I8ttWUq05eBcZIvmZdX0naYTfJQqW6LQabBjYFX6JZrZZRNP7B0hxk3fKHxl5PVr3wMQMQxyXQYaZZG4B0vNXV9lot8QUpymgL53wKqvNSiL7GID1w4YWnkYIgL3pTsLxzNlphGjkEDFDP9CBEQ9ET2xlTWoIhJxFNVB0HTap2tazXxwppakyRPlwjX9WmvEqQuRuZ2wo04lQlSn6zuooO8i1HW3Musu3+0VwjdjoYoat9cpHmrlDxtrT6lLn+q5853KESwcWWrWqBAAstWMvKr9dYQYmU3dmU3yLkDui8YICfSiUXK6/JWMQ7hKwfLSqSXXsMjvDzq6+Obi+JbLbyxGww0BcjJIB7Ht/qNPcS1T90qzMQsheXq89P4MvP/okwwXCigtwG0rInt8e58QftkhNSURcIZmhJoEShp4eERL1Z9RGWjODdpWjJYrqVl2JkUINMyeRj4408Oeln3uiqQ6z56ePT2e7QWuTgmqinbEOMeEXrW+SrIvijTRppK6KURro38M+ioTF2xdEV10JCdcnI3geqwn6ZAKK75a6qrHYeTtcYJxTB3mdDLMVKjLe9ct3kKd5a3oUVmhUgC0CGpefABHqitSxCc0d/QMuTD6Qa8C1fsigKN+iag/atmYdnsEmwiz0IvSCdnVXCBB5qytW2+WwoFHV/NXr47lausDV8azrDay8sdmJy+9ehwddrgOXDIcH4qT1307yY9YAmGjAl44YO3x9yS1MQoyJGZnYSsASdcqfuMUxE+oLy4193VKS7myi5WIo7AkxHZUg27kenHMnWiSPetbAcJZUmuSX9MDU67t6yGfUgAmi/FK9RE5SwgU70DKS1YP4Ab7RFLuog6/3ri9QhjL6vusJSGTkEnIJGQSMgmZhExCJiGTkEnIJGQSMgmZhExCJiGTkEnIJGQSMgmZhExCJiGTkEnIJGQSMgmZhExCJiGTkEnIJGQSMgmZhExCJiGTkEnIJGQSMgmZhExCJiGTkEnIJGQSMgmZhExCJiGTkEnIJGQSMgmZhExCJiGTkEnIJGQSMgmZhExCJiGTkEnIJGQSMgmZhExCJiGTkEnIJGQSMgmZhExCJiGTkEnIJGQSMgmZhExCJiH/1hPyT8/PTL1ukWTJ8UE3xSyEHt2yTzMqHHewQHZuXAsoR6ICQsetEP/k2953v6gl7XDM0rSts218UQouloEJnVb0LrrA1giB70Nm82GlM/m99pXL48p0N69SVt/byXaZWgy+LYufBQGqO8y3OQhLltvXBSrGVZWV7fzgkxCkMrQ4EdaN5BOgxeWx0NMCZPl9u5S9JBHWk0TFB1kDP5g2hvWmBQf7XibQjcTVTfYtk2N9RLSEc4JJfvmryJkRiIZA636ecGQBB5S+EQ0SCwCvQfzo9OrkwyrGGLesi5V9Ol+KEd/2ppg3vswudnCGlW3DToRdxUfnpgDjH12cnB/Hzd2O9JVguvmDWLG+6fZbvx29xEt4M3t4HIM32bVUTAsNFtYmQlya/CrASMGxeh1lSCSpO0xeCD1HAfEeYEnbud5Y/d5F6Y24XWmZ2EcS+yv4HHXzxNfr7zbGrTFz9mrQZK8iip5b2bMVc3z15NWr8+MYrAFdBICEVKQaVAltdfPA/aZv0d26V+rgrmkaSVwffrL47GMIwkPr99vG4ZAU4+hU2SRvJ6Pq7p6doLdMbYrCDVHfA3erURw3mFNcE3y9ZahM8+izxb2P90rGJO4akwm5cCvwcVhUnbkjdoMWa5MPr3Xz1b4edj+8/+jh/cUXwIOZ4EhhkQ+VQvHInhitb/Yb8A3m53c7S2X1Mpb+QXbqAGK+/pWrNv5A4Yxe0WS1mqD6bh0Z9uYyc9nJMG3sS2QlshJZiaxEViIrkZXISmQlshJZiaxEViIrkZXISmQlshJZiaxEViIrkZXISmQlshJZiaxEViIrkfXHgaz/9Hnp/BLjdr5K9xNL3JFIzx8jWQWnzHotiCTlvmyl/Lu+8m2Ypdu9SmvUUY3HlEPAgF9bB0TMjl5fHOvNyZgVkUaZvL64cRMrJhrfFvzZukJvN7Wr/jANZU0YWEE4Fi/i2VWSQA3qRfy5EEBwgs1hf5uxVHDVCOp205vRgJ/WKN76de2D0/t7+8EEOWJpawt/OnPbDuBPkPrT+3z3dkTIltx3ttvJ6lxl1jLWePMr6kFuKB7SpxruHj0712MFy18c3lo3vIPUa53WF8ZQgkhjzmJIUOemiTd1bn3ZA1laQOX+IL3bMzo6k+GuUXz7W2FlVfc//+QwUjGxJ/GS2sDaNUfiOXqX8YO55mZ2FOQmbZ2p9HKbvPz2ycGbM0BeIbd87w8as0Wnw8wXdwPojfyPENBaVIFm53C3qS1dNeBBglcxe7jpNpl/++bUCBLpbaHV4R7cm5AttwTrkEbuoJdhI4B+Nl95lGze+hDm6U7JcdzBRVOP3OXhsarHyGicHj1cfPGxnvzw4eLRZx9LejfDXe1xhhj+MdF0vcNdmlAiV9M74kWt6G2cEsIPl+Rwt/bKtQCRzlU2Tnf75l5NsP1AQR5vsIJgpZXquHnTaLaT5yLklm7g5X7dt5LqezwWxJwDDbJP0BgXnICKl7v/Tf5t73Dmvtp0uul6EwpU5mq4Fxz1Wody5Je9P6E4helUxgkmBdvBMsDsFmINYxFkCbIEWYIsQZYgS5AlyBJkCbIEWYIsQZYgS5AlyBJkCbIEWYIsQZYgS5AlyBJkCbIEWYIsQZYgS5AlyBJkCbIEWYIsQZYgS5AlyBJkCbIEWYIsQZYgS5AlyBJkCbIEWYIsQZYgS5AlyBJkCbIEWYIsQZYgS5AlyBJkCbIEWYIsQZYgS5AlyBJkCbIEWYIsQZYgS5AlyBJkCbIEWYIsQfZ3CmR/8uzc5sCYsZH6pkd6yT4HYn2mySig5wMiFGKA0vvbfRP0Ec6WNjfaab7Tw03TlCkzg/hXsEc2QCi89P4Ph53lMU6yPC5jJRFQlB+yRQ3RirSuLKUKABy9sIP08Y/vlmaJGoN3JDK6mHnuq6bvZFcE2dUhLg0nVl56psOJrWx5UCMAxVbGrDSzbluBEMR29PGwMLR611FbW8aUlcN1LXFjA4GAwb2zLEgg/TwTzPeyNUC0WXcNAMirzcHCZllPsGsxJZXpiXjcAbcnA8rGCwjxBqxma0XyzoSrDHmVawhWRszEcDshjiUyHZnYC+vAwjwvkYFi1dbZa1Ak1qEBMtFW2bFA0hkmDc31ZTQxEWfKRgb6OwLRj4g2ni44mUuaCTJlApF2O3WsTX7dV30NTmglN2TQ1jSuECvlyIMkkkCsTAsvKO6uJ4QkaQFGupadN0D1WWqmf41qTVgZ5xw77SNlSyfN7AMYSYcX3SCAtoEReWtWGtEBsxTqJBVnkgUS7hasZxtRGa024IelrYddNu0WIpVQwUFqeeLb5MJUUzKQnL2fZcxnBBXY+XgXVwdBkPchxus65lyt2Sj4VOL/cTeGyvxKEAreuZKtPvr1Jk4n7xUAl1TW6oxeEXIs3SoOYq6siKfSJoWhcmR0WUA62rlfzfHH3IAFI4cFognRhGhCNCGaEE2IJkQTognRhGhCNCGaEE2IJkQTognRhGhCNCGa/C2gyR89eHxy+svn56/fvnryZfYk7TErI+iOzK6ep5/TUhwtdLDc1fods1mtcB6yXeLtpFg62Q8WJ+ou0zAjHpdbpF9p5MRhY2uZKpfvHxFN8ZrkQtxctrCyt6wEosaLpUyJRLMIfY5jB8u0kqxulhy/HK76DmGrbUjfpjn5MvpJb4fdtuW7Pz3Qrlby9Wxr07dpGOzadoJImX3XYMQqfpMW8UgTWs2dfsd4ywHq+oAhrX712sKEts81dAoYE+/cRGPU4HDsPH4rnKIlX+ZJbmSVlzsZhj23kbP1OFU6o7P5pnZ4Sb4px8HyJfL4laVELFXn0pVibRHdMhxltsaVw3tyv0Py8X4Nuq3x+dOLty8vL768+RX/td6G0HiUkUkxG770HmsufZWtdx/s72K45cahHsNowydPJmbI16Mt8LW0a13c/rYG2Wxa7u9QdJVIx+KQgMapdL/pcWFDoKZDFL3uvN0BahSx3obhO9Ro/HDPCBY+7getFdqayiolwnXjguOXt++x9ujl2zcvjtVzCq0JeccNmIvDL/IFJnPfypfmPjrsRvhv+XGSrSmZomsLjwB1w6RSf3pTwd1WDg5Jfl1kr/t2WiK61Xccd9yNOiVCMfFK9JoGdR9JDceNCWZChvAuBggONKgsHj1z8y6GqXukTk1r0gnRnCFQ420IMRzhRqENcL7InsZ7CrS8VTrBo7YBeMv9Jp2yDzBCFhw+ECTxwJs3J/M3cP+DIeeNcFJZLk5fvzp9+fbixetXKKHLqa/Sgb7v0ojwlNWbkTTTyrGSAKkKYeY2wr8vBVBwEnH1NzL/5u0dEBA9IKkMPq172DNdVM94lNY/HACottBjcKPphuIALg+4IX9KZk+CHws+iZoYG91pPLFWxM0bwf2+WInvxvsyxjsbdOICbit9k24NmdzsEBIURG24tPtbtKK2VFQOEdr9WAR5GKNH5iRzkjnJnGROMieZk8xJ5iRzkjnJnGROMieZk8xJ5iRzkjnJnGROMieZk8xJ5iRzkjnJnGROMieZk8xJ5iRzkjnJnGROMieZk8xJ5iRzkjnJnGROMieZk8xJ5iRzkjnJnGROMieZk8xJ5iRzkjnJnGROMieZk8xJ5iRzkjnJnGROMieZk8xJ5iRzkjnJnGROMieZk8xJ5iRzkjnJnGROMudt5vzDfzNlzjeIvOz67fIslyRoNeXqccvoyiNvSgQXzoz7pcdC0V3Sm/2O4xLS0uRXOj/oycbtJmBJZdorCTrMLJyJx0ceHnYbj+4wroqTOjl2KxC2jp6RrZCxYlfo7gS7bNMvM6VJGbO5uYAB42KQgm23EXQBmzhd8nFvk3g4LfuGbUrYu0Q+qfP+4uzp5VevnyD1T321HHZQEJuvvcRGd5eXym79Clikrnh+8fT+55/d/0xHxR8PHnzx8F5MmedYQvZ0f9rrqnbLPmRHz5++PtZ0lazR1esq4vYKA0MglaEN0jYPsi4UR7IBR0b3HD15+jwcJ2TzTfbgs4/jhg9S7Stflv5akHf3Ic2UHb0Bzme17SISypYK+32pERbUaiFOLKTQbJxZI4rC3EdKz1v1rSZqQMRsHace90zXbSr8u7S1Rgyu5MVpjA+85cGJJx0KLTu6PH1+svfRInuGaMADt2ZM9R9lhMTis0+/uD9AQQrD09fRDqxq68R5Nxg/ZFfzGi8JgtbWrTdLZM3R1atXx2nni7rAMHCIHGDKtW/h7yrstcbJSjae+LY3CjK5r7vWx/UuTYdMjeVysN27JNUk0rPs/sP7mUQTdW8i49yMp6431YiLyfKeqEi6jn6aZWdnb75Qa15cPj95MIs0XUZ01NQ5LI2x6FVm3YIPNWMMMIzYRwRs7dsiGp+ZJehmLuWP9Sr/H2DWsEvFeyO7R/GYhqFXLQBAFFbWuoiAlQUjQBtitGuZAVDmQujtgGVJaWwHhZpDeMf9SuLYjz5ZfPZIF//w/uKT+x9LvkSERxZ8MAlm2cH29gf8eVLqhcHNhYFHfO50WaMkae26n2zcrsuqHIjQ1lvX+lrcOGq7Km6+kqSzHouYlQ4eSXwpIUyoM5NdRIbX9RrEojbwPxeiWBr2+hG9gOwa5TH+1oUphr4H2O/MkMHOyuySiBtxYbJvjBJ92o+exEXiInGRuEhcJC4SF4mLxEXiInGRuEhcJC4SF4mLxEXiInGRuEhcJC4SF4mLxEXiInGRuEhcJC4SF4mLxEXiInGRuEhcJC4SF4mLxEXiInGRuEhcJC4SF4mLxEXiInGRuEhcJC4SF4mLxEXiInGRuEhcJC4SF4mLxEXiInGRuEhcJC4SF4mLxEXiInGRuEhcJC4SF4mLxEXiInGRuEhcJC4SF4mLxEXiInGRuEhcJC4SF4mLxEXiInGRuEhcJC4SF4mLxEXiInGRuEhcJC4SF4mLxEXiInGRuEhcJC4SF4mLxEXiInGRuEhcJC4SF4mLxEXiInGRuEhcf5vE9dGvQVw//e8LHDR92/hgR6oIXV/sBorIAQ4BFJGW4gsYKgXiAavNZhdktExwbes6ifEeyBBRg2VswQqoltb3TTS+heEOa+gUj8wBTJjlXNBHS6LzearpvnOl+84m9hQLptx104pdHHaFepmXeCHWu9TeIvumdaGbA3ZryUtbWiSwFSgR/IrJgklLBAE2aHYfZa+yf5Td/+xBBmwqELeDFfwiM2sLJPnLf/Vffv5ptgOQJOKG/XnkDTFaR5/avPdlX7tve/v9rpRhbvou4V5pi2GFEZCy56ZH0EyNTHwnNJvmOnp+dnY8kHG2cQXMyc5A3H47HPGVHjEWW3RJH2LRJt9v7jY3lpYDo8gMcD/WVee7FNBDd6+QvrAL5p6g/pAiAKQ0fMKLnSTLoweLLz7W4R59Kr/Fas43zm6jRUN2Zg8+vdOmCClYtg6Cxd1AD/WWCrI4bTe4SrMf0D6u/b3pditSD+4dBGqWCephWkFqySoUt9DFYX4qcij+o2Jb/84BtGFgFty7bON7CCsZJdo7PXOS8xBjIUVC3CRqr9pj3sN7H+9dK84IG5Uqmp5eWFIYD/MDqQQtTBsPK8HO3Tj6brpqZOAnn2e+V1D69N5+icNyxFzgiaocLEpAJoxoN1oup61r1yWdJ2Vz4PC+niDEHWvfx3kPHykvBuTTmMKcFzXQpoJUBZxNoE7rCEKxszqzuKSPeHiNijbLEvSL5YtS/75MEJcNns/AQO1aNaSFatBChM/uAKZAPCYeE4+Jx8Rj4jHxmHhMPCYeE4+Jx8Rj4jHxmHhMPCYeE4+Jx8Rj4jHxmHhMPCYeE4+Jx8Rj4jHxmHhMPCYeE4+Jx8Rj4jHxmHhMPCYeE4+Jx8Rj4jHxmHhMPCYeE4+Jx8Rj4jHxmHhMPCYeE4+Jx8Rj4jHxmHhMPCYe/4fhsTbC+6k/yRrfdjLlDHFrUTJBcBZg2EjLu13wlV+3BlNLF7Tnx8kwzSosWRwvnmlRZA5urgWmV8C8vjTZ0cnXz473jaLUR/NraR8mWQIny9TZFsUhvZykzLRj28XXgASpB+nkhqXb2MVpdN8ie+WvTWF2SHW8sfGhcZ0pZxmmgyU22RWLAwDamuB7uOmJb7Cm/UxDFyY5ZdmXV4iRei6gVKUF2NhEat75uW+kdZSNYCugM0cQEVtF+RdT82ZZba8z+GqMYWwYF/Ox0AEK4EmJIYvDnl0I9tBjaoiKHg5rB8Oy4Mu+09qVEOiSdbnSbEoKwA+Da1pFE2B1h6i0oZuJT3Jt3Sch0WLEYmopHw193VdLaUOlHej2nQAz33Saeo8t3n1p5KDuZwEVcD3DyFtJtAaFOeDs0KCsddsBgjAIIjtWim2T3yz89a6D72wz03TXZlkhsm9wa1gyrz2KMdMeXciPV+fHUivqYn0/zPRg8GfdzZH60risEJzIXZv3DrW2t0jOiAgbfd6nmYpdbSqXSxuztZaiuMCv54VbS3ZJzYI2hEuOTp6cHkc/RjocPDmdbW1EFCTn3cQ0jB5fspXrJL8LB8DIjl4+fXIsHQ3jjHFtA0Rpmd3gyTGn1INCTxubX0U6BI6nAUztK1M6O+0kp+Ye1uNhcID/yH+/k+hJeIuhzWJ2ZdsacLrq6zzmoXSy0xTUbEw9/lJDyzE1xyZqg+GS5RqGwkv9h7GJmt93USvA3VXMVHiul5+yZGlrN/RXSwJE6qOVRBbHDVONjIPsVxExuGtanAcFOFK9qQ90wcNHi/v3P1adN2LexpoSPId3tQjrxHvQXbvGZi9eZLZtsSS8j9LaZY8Wnz36mLBL2CXsEnYJu4Rdwi5hl7BL2CXsEnYJu4Rdwi5hl7BL2CXsEnYJu4Rdwi5hl7BL2CXsEnYJu4Rdwi5hl7BL2CXsEnYJu4Rdwi5hl7BL2CXsEnYJu4Rdwi5hl7BL2CXsEnYJu4Rdwi5hl7BL2CXsEnYJu4Rdwi5hl7BL2CXsEnYJu4Rdwi5hl7BL2CXs/hhh91+f241ZOjgqdqwERsVlYuECXXXnsA7xSOUFHItdGPydNTjFaqfRIb3Gs7tN6/v1Rl50LVa2/FVsfSqjyKmagfJbhDfT6kkAHYn6dj/QTOyovLbHrYs+1/c8/Do1OrX7jD01J/0+K9CGP2yienN6cco+oa5NeSWGSCtSae5ZFzbCRe1bJC5Cv3WobAnubM8mWvDJJziotqadu3rVAs2BqtLztfUh9w14a/XqxfnFcdbZfFN71LQk5zVG282lM2uM425wV8rQ1uYtajmmqFiYGt5uWjstBpQ5zjgCZpV9oYuAxeVcwCyeUPrrOayxxezWW5Ur0jvy2+0zjmNqXxvAuZVGxPkVfhRWQudD7KAqNDn0rF055IOgnrimEvzJNwYZLNQcgN7yZ43S1Vau+yWk4ETvj0kFVBwPj2a5+iqkhqax1a8eGmCWHVopC62korawRup/YIRE89ICOJe+sSnz9magfqs+ZlYs/jhcekHwuCxvDgZrYdeyle61UizvlRQ4aFQVg7tSrau3ljZ0B51ptYXsDbwcAUEbB2v7bKvkISlxI4lloi8eLr5AyU/LxAFTbRU1zQjB+8a1B2URR/rZ7eI5LAHJ7YPUftGBlV0hPbFF9iSA8dJpuNwdzGqL76nMtBiRO+oEKZayAXRurXaZfh80DcwIG5Jf5jJjUCyCPHFIGYlXezcKolSEUsb5YHMloN55balbWGmwO0WOOMjQkBcA0OcxrogoyA+pv+xbnIE8QqL73FkQFKGYUEwoJhQTignFhGJCMaGYUEwoJhQTignFhGJCMaGYUEwoJhQTignFhGJCMaGYUEwoJhQTignFhGJCMaGYUEwoJhQTignFhGJCMaGYUEwoJhQTignFhGJCMaGYUEwoJhQTignFhGJCMaGYUEwoJhQTignFhGJCMaGYUEwoJhQTignFhGJCMaGYUEwoJhQTignFhGJCMaGYUEwoJhQTignFhGJCMaGYUEwoJhQTin9boPgnGp7GyIYkhQ1565YKY7L/j6vM2mZrW9s2Wjju3ZItjaQRXhrexcpMAb8EoKriEbClvVpk3+h+IuLilcCZDDOHaViKlKR918V9e2SxmmR951FcSL92HuconBhVSSnIJkC6R5EYt7dFNlqRXYYwRAkYjOFsG8ygL7c27cGUamnV+krnirv96CJRl6/7NqY9cLeL251MFoS/ZBOXyn0nCYGTv5FNVFrAloIJMqXObbK49LK/SqqQQ/s1QMll+GuJ+U2JaFfm3WRsAEEPH05chgrtrq2tI4gKVgdgYZqhNJK92VYMxYIn+x3hqHab2OobG6fSLANODqtVdFP+ahOXDNmrYdINna6sjVsxAfqcII7rq9Gkuxcpr04WakpxUBHx1UiCxQ1uZmrJh5Moy5E/FRJ8LcCjFaz7GOGsXDfEwaIrwZmR/Sdb6WjOt1bcqYGeAazhqtIVimKYfNxRJzL3sKOWTmpq1/TlMG0yE4fGsWQhshmTUO4dWymluEgyazbEfBvDpFtHmaJwUZHIGVsXJPBx+yEXz4J5Us/7OQECFgilykbSEuHsjBDPXhHFyMoKgtTAbnTYUGaTOC6yr/y1INpskhQbDZEgocsRpZ0Qn9aWrA3Blmqq17rSlYlbHy1tbmQfqv0ghYe5UkytXcOJLfI71d0AYbk9yKLDuk0DqwpoLUrB6lZpUfgIDWoorx3qYdgtzEwzKRqhGyeJJyI03Gk7sZBYSCwkFhILiYXEQmIhsZBYSCwkFhILiYXEQmIhsZBYSCwkFhILiYXEQmIhsZBYSCwkFhILiYWHWPjRr4GFf/SffIOIye09AYvIYXyDrI139qQZ4s184makBsIhfyNNrdy9U7poNgzNTeg0eC0MabNV6a9juBu8ka2AXgWOKeJ9a3J3FWrPYKRCUlbhUAKwFL84yamUAHHxcFDh8uGuJ3llsytauYsKgNpsbO0xiCBqqgeDukYYnSJKZ5GfWjgJrNRLWKKa141cEPMRvygESaB0LrllbDJebft2UqdHJ69eHat3VpIFN25rQxbAs7q6o4uvz4/j1PGeM4f0DLHA9Sa3tEakL0q3Uv8Ny3/bCFW9qIs+ZOfi3kV2rlCSkB02DCMPt5sd3vvom06wNt27JXeguW97CUVt5H6x7HHrd8jN+bPSdjlSb/7cl8XKtMv5hdxZKLV66utf9YpGz1tTuDEpHpv8KnsDPDHrG4SpuBNvNmz0Vk+FXS/3GqJCNrKKE6R1K78ON7mGdKNkhUyZ1gmKDIsMe0d3uyZiBdw6elVBTOccuRpxRhHMssaXO7m/zJSzTOxHCHEMQj/cERdXE9y68q4A+rdyP+UieyPZ+8m93/zFDsPoLX51t4HHAKVGb4xD2HLXpPvikEK2aqQatVZ1xDGc4KYIWjFob8yVcmh20bcruTMzVuJXKbF32RMLj3Rabi/NRm6o06XpTZEyc8zcvhUkVypAyEe3ROA9uDFT3Y90lBtuB1DUe09vgHR2dLCIGwvcr0lrPOa+3mYIl/6Vpkfhgy/WcVUdasEW8TZavcUzjiDrlOyWSaaRlvqJtyzLrZEx6XPfApFiEubeCo5LmuJcU+4k1IMQERU2Zmmc8lbV2/dNa0GkvdYs6K+yiN/SycttK1LtlQmb+UXf5aXUXjYYke+QdR60oCcEkJ0wWjwl3kB7p+nRtv0gg2nfW67zERHUZr27VHy+FKGFGkFldXrntqkjW2BgLcm0UhUEZaSucf37orqzgFLNDDhmD9IkhT9WuUk0vnFrmXK8WTeZY5MpYw2Ot/aWvl7PYXg1IQRNt0mRbczWRhqJGBLvo9WUGp2id95OHCMemBgrI96C3EEf2BzHRZAFtBbkUfIoeZQ8Sh4lj5JHyaPkUfIoeZQ8Sh4lj5JHyaPkUfIoeZQ8Sh4lj5JHyaPkUfIoeZQ8Sh4lj5JHyaPkUfIoeZQ8Sh4lj5JHyaPkUfIoeZQ8Sh4lj5JHyaPkUfIoeZQ8Sh4lj5JHyaPkUfIoeZQ8Sh4lj5JHyaPkUfIoeZQ8Sh4lj5JHyaP/4TyqPVLx39/oz5/+X4C/nat7D3tMjyXhr7S1atihdKqQ9lReStziRqTyUt5rd8thv2Kxu5empOL1/V61ne6qvLRwntN+l0byQ4p2E/F3FxsvGpRu3OD3YB4AOXBxnTxd25XsHNy0fotpixQCIHgyVHsySuzBypu4pa+tN1J6inUpx+PBQBYkh+sQfLENc8hmuqbGgdJ8de8IG7ta6tp+oTUlf0JmwIqDcfWIn6X+mVpRsRGo6INZauA6bkGrzSpXNx2ODFB3GknOJ0A019nDtfvVzSWrD7W5qiaob6zuYVyWtpaOnUGq0sTWrjdmG8tjWJQpTNPFfWG186p0uk2rGiMIw74/YcLG9+Ug65LBE5sk0D5i8Bp4oRCLUGCUEqY2uqE0Fnoj5YaVLDWFtK1o6KsmkofUf9oJGYOUcPV0W2QhB/xulRpSW2BZ8NrjYCEVjWaKTVBVKIsNE6Nne1bTVqtu2e9V49jE2EVHS1/Wda1Tj7sXm+FwU0+kY6cHqeOlbWj+Pa69oxQTzQx9ZNNxto6MK9ZIA9q5kmIK5o2hY/fYgJJqh92Yde/rG12AVVvIhsjpPLgkQGBL+1VZw1ncODp7OXRq3avBPb5Dn1VGRI7trILsIrtIDD/tmltYVD1wc6y+IVVnBzk6G4KbrjAmGaG8I7LZl32cZ8R6KSO8pkmOeA3teItR4/+QCPpa9B8WVl9NfSL5iVDI5CsxJ7dNN/T0xexCVxEkRZZHZTAR0ybxzh0IeiNkpVxBLYjgRHAiOBGcCE4EJ4ITwYngRHAiOBGcCE4EJ4ITwYngRHAiOBGcCE4EJ4ITwYngRHAiOBGcCE4EJ4ITwYngRHAiOBGcCE4EJ4L/6BFcn9v6w//izdvzN68vnn6ZXfrxmQRdxY1HGQzyNwapHIJUWZRisQ9QZ9/Jox7ZyuojH/rYUdWXnZvLzfo4unU5RlnHJyfE9bWO7vCajHd0dv7iWMweV+XEGJOtS+eXpQkdEiCOKJbZ7Oj547PjlFtwHcaR0saZy/hoVbuVYkhZXe6qZiMDHL05fXXx8nhxdnL59PzFycuL7OTVk+zs6eVXr59cfJl9A4PqvOyFJL64J6TjNK+uNz7ra+T5tbhb61ie6UkkATe0Ut9YQma67JO//PWfX0ZSiq93fSXJXjgsX2sNwYb12VGNI/8R/v/pZ/ERGDVu//IDvOzS02UtPOgV4qTcQ9cXOxTwtS23wlzwzhpejgU1hCI5XrJGH48xIdiQwnX5YH5thezk+TiEQJ7YuXzwzYtwPJO0NJpWEopeHzybPgpTmQYVHB81EeQZXL4sPRJii7qR6LSnj78+lmOHh1Oiy+ajyy7v37bg9On88r4YIU91TZ7X2z+Fkp4nHJ/XeX9mHvW108eRkEXyjF+IeTc+S6cPI0o6DQfZP+talGu2To+mZUvvg3DM/M+eP5Zfj/d8B2SM+ZBwMrf6eIfXJ56UljZGpAmASecFCG3tCPn75QAq875UENk6k92/N1958F+OUI8AoyD0AgYXhYucdUeFRo652xM60cHzc3L0r/piHUFTTr/2WK5pCwlneiBK3OCj58Li/OnF25eXUiHD+d/jXl1jNFUeUCtkbCGeEQslQfBTaj06VZ/kkSds3p5mR/cWDz9HKsIbwL7Jc1ICUnY8XQ77BIeFK3tdY2J5I+WQvPfFQ7x3eNrp08v741vxedR3twf94ovjyI5iS/JuSgL1pkC8PMtpVPOlR5DGJ4/EmVPnyYiPHmZbMC7s/fQXWYPa/pOy+wV+3Fvcu692TA754tGtQ2bDQ2/60NPx4vT1q9OXby9evH715V2Pnt3KhBGmR6g4QIoPgragmi66F56VZwaFW+LzXijrrUC1iqe87+YI6JB2Q7F8KK/uAnxBxgTriodkK7IV2YpsRbYiW5GtyFZkK7IV2YpsRbYiW5GtyFZkK7IV2YpsRbYiW5GtyFZkK7IV2YpsRbYiW5GtyFZkK7IV2YpsRbYiW5GtyFZkK7IV2YpsRbYiW5GtyFZkK7IV2YpsRbYiW5GtyFZkK7IV2YpsRbYiW5GtyFZkK7IV2YpsRbYiW5GtyFZkK7IV2YpsRbYiW5GtyFZkK7IV2YpsRbYiW5GtyFZkK7IV2YpsRbYiW5GtyFZkK7IV2YpsRbYiW5GtyFZkK7IV2YpsRbYiW5GtyFZkK7IV2YpsRbYiW5GtyFZkK7IV2YpsRbYiW5GtyFZkK7IV2YpsRbYiW5GtyFZkK7IV2YpsRbYiW5GtyFZkK7IV2YpsRbYiW5GtyFZ/F2z1k4/AVn/w33lRyEGrnSxIq7AGbpSZbx0YRGN//uoEddT2wDk47NveyZp2cIK+i9nLaFZplh6F6sEYgqQOR+mKkKllqa72tYwB64AIrRKUq1fifyGVwgULhyJYbxWEStOugRu29hX8JRPYXFeI8s5QwTi2A2ReW1RAhZGBhMqzmDGtAVMKYbk2jG6z7+AgKwGVV5yuvdspG7fdpvWNgC0sEmZBImZLOyAmfFxg5bnkpjoSLsEcah+qEX6RYYMizs1MWSgFlmU/Gon5l65MU+PPYGNtq3fSjNHgBkZWGlo9thBIxNFDQExEtUqKaNMjV+fJpUDGlakwh9UwiUtLOxcDauHhSVBniZ3F6Z8/GkdWTIMpW4kOFm1hvoyKXK3BFy0m2gJZ3FqBduJrHJBcuMjO4qJCn2+En3WliNnG4e/cNA6p4b6zKnWk4FpfupWifYQzwNQ8l6UNaZD8DFNnGp/atK2/jgDhEIfSoCxtd21tHRciaZV7mLuLOSBJNdhr2nwDmBMWQXCkzAf0qsGcAuOsElYJq4RVwiphlbBKWCWsElYJq4RVwiphlbBKWCWsElYJq4RVwiphlbBKWCWsElYJq4RVwiphlbBKWCWsElYJq4RVwiphlbBKWCWsElYJq4RVwiphlbBKWCWsElYJq4RVwiphlbBKWCWsElYJq+RvoUr+8P92cW2kC4KmLJyuvRxK+04szqXpgaYdHOJL+CRZ2Tnkh/TiqDuTptcj0t9VH/LSpq4c2mND/GXKVV/rXzKXBG4/s/b7sEU6UxpK9Cg9JFmhz/DvQrMxa2cW2Vf+WiKkrR9aGy0uTX6l46VOEHB7LNvaS85sjQY39g0YCrdvGt920fIKS93G1E1NVFwsK1MtpX2GlH1uWitNG/BOYxrbSvoE7W8Bj5UmBG3YoMEN+UYaffjY92KySKxBsu/IS3XJ+Hih3dVra8rjfQ8F6f5gypjZfbsyKGhbIulQmDvprdBsdtlReHr2/HiRPZUOJygUIFfQ7h3SGaSuJS9Rz74tUvMLHJ1JILapLD/9Ittg1g5DhX75K4wuTWhcqU7YDTZLPw9EBc7GxH3yVkBabxGIp5p40Vht4JDyxRbIO6u9P+wInlhA6g2yRKzWre/Fu8mgWaYOQW3t/RF9Koj5StBGC6DwlbS7kSFXvm8BVbFidsM7Y58J7Udj32nyYWLFNHFDsguwMDarcTVgxxU9FrwboLTe9zPBqGJtI2gk/lQq8VolbexRo71eTLlDzkhbmSGxIkyMcHl08fXZcfSANKiQfjZGsmyoiOzKtghbzDosxBYr315LZwujjS1yp12H+th8CHnVXmVHJ69epTF9LQ1OCmA+vL1DdqoH+tQMaMhPK7D1ZOiHkW12yONJF58I1xksjcXTV0tpOrMaRpbpfT0eh9lvNP5Z+XbAukYbEcVKiL1OJB/XdUxS+BIryTUVZbqjRw9m9z75+FjzaNrvBHP8DAXz6N7swecfS9OUSR4cRnulKYXQbAxKGTiJJQkMT7iotalmY9SGhirujkwC/CB9xTkdMlAABwcCl5A59l0D7wySIhmRhcZotylFklhzd7TQOQjE03fS8ETyMfJ5X6IIw0YhHwi1dyKKdx7RIbU+EXbQ/FPGLpy2EQICbEZ+uANh7gAiOSApgX6IXwymWCVGC4K7utdWV/vToU+uwgEYotZsXYSRU8XXqAIZ06mzlPxDJWppgHhNXIyYMGTe+XntIZQy5Ug1TlIhdiuCj64izqWq1D4yCexSG65ASiOlkdJIaaQ0UhopjZRGSiOlkdJIaaQ0UhopjZRGSiOlkdJIaaQ0UhopjZRGSiOlkdJIaaQ0UhopjZRGSiOlkdJIaaQ0UhopjZRGSiOlkdJIaaQ0UhopjZRGSiOlkdJIaaQ0UhopjZRGSiOlkdJIaaQ0UhopjZRGSiOlkdJIaaQ0UhopjZRGSiOlkdJIaaQ0UhopjZRGSiOlkdJIaaQ0UhopjZRGSiOlkdJIaaQ0UhopjZRGSiOlkdJIaaQ0UhopjZRGSiOlkdJIaaQ0UhopjZRGSiOlkdJ+CKX99J+9eXv+5vXF0y+zS3AHolf6BuNlpu8QXrGqaxE3XWRTYghZVNzCfL1TL8h6WgG2pTUVpsPqgK+7eeWLPhKVVnHKIwtQBia/ODu/PJ5uOm4wuW3G3dJTELtNa+28kMgHnI9Jjj55cozMC+Oe7BFUBAn0VYlw65a9vJ4GEbNl8/BhT3FTrn0Lh1aLs6eXX71+coHSeZKdnVw+PX9x8vLiSyATUkxx7gaMpAEPLI17tgu5wimAr2K6e/sdRu3Jq4E5cOs8NDYX2IKNHlmbNILUX966Rs+RUQQxOy8FgGR78MU9YaVijkPntQWn51I8UsZhBPW69WUZU6CT/AtdX+ymTr//6LN0goubr+sS5J3CIHFtN8se3DhiC0oroh/HY8Tcz+7dGMlqpQ0HwXikc1pxsk8Ta+A6SYj4m8EcrbNd2up+QOADf2AgSboQ4TJFoG76TqoQXNEp8p5eAmXMeqhe1CeoMCB8JeJkugGXfLs2gGrgSOsCqOL1yXk4jjEYEj5uGa8qrhJV8uby63AcJx+zKfN9JxbcnQkqmG7lQiyJ0dAslC63aVV+2cVRJok+5ppi0GT4W0MHrc3aXo9O11FriVbm4cXKfRfD6FXTiOobCXZMURi3rzTJ/NvTwJg8BVIxMeIGsvlG2S1OX786ffn24sXrV19GONR0HDBH2FfN3QOPwIYfEOMuFFIk2xv7yZM7gWF4+Q5kmPphkb3ookQGm1SQiAJKDX6HKtGVwYDSfacvfwgbU/6veuE6oixRlihLlCXKEmWJskRZoixRlihLlCXKEmWJskRZoixRlihLlCXKEmWJskRZoixRlihLlCXKEmWJskRZoixRlihLlCXKEmWJskRZoixRlihLlCXKEmWJskRZoixRlihLlCXK/taiLP7jz7/enx/9Gj///v/q8cnpL5+fv3776smX8al5qeCVkV4CIeKHWVrJxhb/1h61IN0gnpwfRwhy9VZwaq3B1IeypfVFuRui2JjQaZ46G2bZUqobKGHlmXfUYH1V++taGkEgRQ5m1sErHx/297nb45yM+uQ804fpNblRly9WOEGfLC9sZxNY4KChycfB0HFUbQjQwdLZcGonfRjsO9vm8kw4yAmrkMfLpfkIKiFRNtahyXynX9KiK49Fy6Pkc5248U1fphIRFzd9Kw/ax2f0xzJ2+sT6sndloSV0A7KGVgdYlcyya2z2IBkBiypblq7rBdYGzsiqSETwx6Z23/bKLANvyUh3N45AlAqwaVCxAe0grSve1xAiROYq/Vo6Aogr1uAYOTUszp9evH15CS1wZ9eBwlY4SD0qGkW7D4wLnvYxWO7eZ+dwGAZIzReG/goxLcZOGKPOGIkm9VrB21Z6J3zxaPHZx/rSvcXDTx6Jf8d+EXogMAq5WtgYgdbmFjneAvwUmTFyvjHa+aONfsC5W5tCgWNyWbtwU4MYZUduYRezGCLweqbdQFRjIPwP730s/TOU/qLNmP9BehGFBsUHFzaRbsqdNEUxZa9ehKei2Ls2uzS6zpeaw3xw2s8n02LW2TDlXqvMppY4+KKx+AewnayS9iipWcRIu+Di9UYaRkhnl/YgrGO7E2HgGx6aJTwI/RrKY0yQOxendJPCL29hOJs8kmKFpJtOnIThVttNIIgCXlWqzTMAg9dWP9cCbLlHmcYMHWjMhn2XDGRJMzSfSAB3ML14ZPS2TCsvvCfLRfiM2bzP4FvjSxsKwZY0iaKDNUGakqTuGKV2xRhKBvbIrIDQvmrS9QNcqctpWgHVD1YJorTUSCrwgv4hH4EqRrVODg3ocrh3bIsiIGqhNlNyDlh8F1JOtAwg4vU+eZwklTQsUYUmEAmi6MvUhafo0xXISEwiTUNWI2ylXjm18FlnlqXdmyXdc4JI2riM0e4B5tStad7dAI53off7gV8ZaGrckzNJIGSfCHpU5v3f/MUODp7F4BYIUew5MrSPeXJ2Lrk8nKPV/GjxycdJyN5xwu3jP1l89vl9bVwUDd1fK2y8OnPw5EHxTQ8qPDzZTY9daGwG1J62bsG5IFRpdSNZlDTo2MXlpo/HjEyNU9TA8ahGe3ZJO5tD6UeJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJQolCiUKJ8jsnUX7yESTKH/8/pxLllb82hdmF6Mm0fk3brXGlWYpBOzHBVy4PWoAAvd4qt/okH0yxlbKrdOFpTpN/28PUIYCVL22OuLfZ0nkQ3G50guQhzhkWMrwdXJXSJDKuvKqaB6UmSBt0lqUmhEanHVxTCSSgzBbZRZ/n4M8ELTfeziLmQpQNBuuxkhAAuW6TmzbCGyzSc8T9WD5SyEedgbOj2wq3xkK/G7PVlOU+GPadSQQ5jAJTfIuJMcQSv1bqbmASjjGtOmPjQ4NEKEPM14PxZeIQpLowFKzNfQnXAuUDSNNGXjFrCAfRkBk8Dh7Y+rKXNIZtG9R469e2tgKECqgYZAQ4nS3kAtsa9o0rUMmS1jgNFTtKRuMqObGwK/HlgMNbG+VVjMnEc0mjYUFvUoX8LKE5rBYHKPMAD7uUwV6iARyoVWfOVOYaJ9EGsMkxWLDoWPwssdQyLnyfKjKKA05rogCjqx6AtbTKN1akqCkKEVe22EurF3UMrGgxJS0sSzyNoRGVVQvt3fa51JIUqEtlWwgnjn4R0Fzvget7/B+zfZpbOsTBVNcAZDBM6eJ0GiLxXAp81GvXFlF6cO/+vTn++VxyyNdJEQsn/SoC7br2KqhMbcpdEHozS6FkEFRkwxdIOqDvExl/1foqqgScChpqxRMNalJ4NV1R7G1IemgccBcTfyapsxkXiYk7X43vYflNSH8d37n4jZEisXIhEty6ji5AfflrXRmukBTrfH2Q98n5ClB9PY5W6EHBVm4+eS06XpcsJT8mCNR6lNMQIXXQoEf5ATkqoBilj9tC1gJqoCGRjO47mWTP+MotqGMfF+GqplSYTGQRszzW01CyAgAqZHQVN+stisF4QaPXVchXCV9yboxqCvsIQeKhLSorZqAmRhsv2wa6moq1GPLHZgePI/HzUtgeCqJNy0nhUIJK8ZCJv7MaR5Uzwu2tFUQRdwAMZMQOwVrcffkSNhpP0yW79zPadxu3RO2bbO19sb+OuJaLy4E4h/mlVi2IKIwXqqleghHHQzfnSXwD46KWiBWehCwgWK75kvtcWdYCEOFQXN2RpJqP4a7yB4d1TqaW4Q9LP0BJ5jEipvb1rtLcKSaVN627PbcPBbjIHv/g9B4SO1fA+xvNo1hHkzocnOMHhS5cZ9s0iLhcL/JkeHF2iCqitZAP7RDeINc7IrNK+y6TS++YYpoxUxGlK9qCUGwULcihsgDOhB7XPyZMaSpduNzSDC+E7HCBrmJlFj9LGETs6IjoLJ1iFHxqjBbIvjYgYpxonhEDk6rf2LKJAKD2iBtxDShXkH28hmivJPlVd494J1cD+iFKAvIYILBqcHLcPl2p86jzqPOo86jzqPOo86jzqPOo86jzqPOo86jzqPOo86jzqPOo86jzqPOo86jzqPOo86jzqPOo86jzqPOo86jzqPOo86jzqPOo86jzqPOo86jzqPOo86jzqPOo86jzqPOo86jzqPOo86jzqPOo86jzqPOo86jzqPOo86jzqPOo86jzqPOo86jzqPOo86jzqPOo86jzqPOo86jzqPN+d3Te3/u/SqauPdAnBtKJV7fOXsOcRtrVSxXbZt/p++jJy2Nx4cDZrjLroed8azBr6hhuW9PsNKVg25E5hnsrmIz8RVmqExJmjx31hSWxsF9kR8vjsbW2BLRKwN3rjgTSNx98Uq9t2klgsseCuleK1bT5ZsSizlxhHnFRZHOxLkzH+YWOc5RPpg0QJUNqoyYql/SurfukJeWd2HM6UohIWiucJ7UqTJwnjDNCg2UZu/HLtgrqtrr223jAIvtGIaH1RZ/HDvRS/q0qHIhtgQYd9clLtTP3tUgFOdfcsblCkH0Edsjq7cDpshXBTbPSeD80kLNbAelkg4CgIJn3IaRW7KnbOcpbGtjbdw3K0g0bAcBw2Uoi7c8Qs0FmxPKCOEpzzBayW0EV9xS4Fevk8AJVn0fnMY+Zx8xj5jHzmHnMPGYeM4+Zx8xj5jHzmHnMPGYeM4+Zx8xj5jHzmHl8Zx7rltZ/9G/fvD1/8/ri6Zdy40b6biYzwwaj6d4R/VoIo/pG9n8ts0I2ZMYCutYt1Z+YZQ2/pV2sSxO34xXPpO8O7Tp9sZu+457JWsSt+vXRYaVM9mCW3FOvyK0s+oVO2uS13EVj4lfKddp0VqrhRa3bane7eYW8SDta36ov/fq6St/ZwxtnTy+/ev1ENmCWXXgRLP3+ExPql0rzoBvu1ib4ZmPaHfwKL+RyW0+bHb16czru761xKobbfPT7sUV2oTvoDoPGWwM2cGENw+rCV3K/RfyCdNhTeNwGV17cR3U4yso24bYb7glo+i4Nq1+yitfTvSjjN50IkL5ggRqo63Y9bLPbro2UWhd3/T56fXIejnUHWL2dwAzYUZqlLdP+qn23n1AzoTINxt/vl51704bJe2P1Wf3KW++J2b959OzJ2XH8VndSoZjr2uvO3RoGXeR7lhYtGb7i1Fs6dBNw3R0c9iyy15hQNwHfjzREauKxIx13soP6fopjnRMrh8m1O9ygPFiYXdwaHwuRdIQpk41yY0WsW7OLHo1Lmd7SoH7Y5+vSmgqoBlDtWmTSuQ2vbHf/3n297yUlUcqKwyJKuBbvNALMRlvHOwRiKUldy5fgt8pZh7fjbtlmLTvQp/sPfCubamPJWrlyqgkH3o9fBC+yk2xd+qXch6WbURdyX0OI4Ls2QLH9V+m6GFPmqVwHlthv3Ly/C+ky8krcVTrGWYvGTja8x8onNwegUG6nUOK/IYNy35dFpKPhW+f01fVc9g+XDd3v8lJ0Z6d7iz9LRiNJ5n411y/X7wTKfYKOe3+PtzREG3Uh+xwYwn97D/ejNH5catwS+ONZ9unii9/8xW/+zW/+4vPF/Y+zbcg+W3wWX/hi8Qjvv/nNX/xJ2f3iN39xb3Hvs3RnUWVNnT3XsDQoAdlAOVbeHcveZ45aGu90PKzUdP+TbJ0c95fWeyGQQgIw2ZFYsB4tmIHwctt0Y+CXThJB6FlAPkcyg5rDCIjxRcgfE6rbt5+M2RFvmnyvNyFq9vfApOQIes/HoFoSCeKQqCs6+4OyQlYh8/lENovsxXgjxuRWtXSTiZbu7UECBIedL0E98ksk4oFXv+2N3ngqO5W340btcsi6d1qWpgfJai0NJ5Hvyffke/I9+Z58T74n35Pvyffke/I9+Z58T74n35Pvyffke/I9+Z58T74n35Pvyffke/I9+Z58T74n35Pvyffke/I9+Z58T74n35Pvyffke/I9+Z58T74n35Pvyffke/I9+Z58T74n35Pvyffke/I9+Z58T74n35Pvyffke/I9+Z58/+Pge+0T+ff/XyPfXzSC0uCeuN9WoeHq4z5clQdGNZtddnR6eTxp8djFDdxkBiRgrQ6VDe/2nJ2N2zwhSYY2iBuQ6iQEulykilKCDoJIn17qdk6pY6JsISgel+aHsgNj2jdLKXwvD/Y7nE38Gm6u6/RSXgbhy4Zv0ZbBgxENtAKEjjTew9ZPaVOreEL0jSy88bK9VdpUc6xlVUexy2RKuyFZ4bFf2XzYgGrvBHBAnLi1iJyNuJA2XhxbeKqAUHjcJ8zBAm5D69EnT46nLhNcntDmIUv0dYHFRI9Ff0X+BrhrGu510TeJYc2NERLVGnlPkiFb9WW5u9XbMpKRCjUsByoT+gOeqYMA2nRzrbvD46fZFKQI4350aYqs9CEcclo8VfeFbC2KIE9c33ivayzNDiuPjH/bIgnM4VaKkGnCgRHY9sw4jxa5WgqmSkfNJlw/vDKkw2a3bF2RXpbT/ShkYcj7Un3v4APvx91NW90bDuPv5fsdMZopOJ5Gzfoi9Qg9aYGiqKGjy9MXJ8djv8/rxOh72r0QwYwAtp2THT7FsRsHKZnKVeS4cOH3JtQsORBu1Z3dStlatlLhriR4YPg8rvpWQd+V3YvsKxSmbokYHZ9DqMNS2+qGdZodKjwnrK97zxVpa1mt4LS57GF71TuuThJGROrsY8G+9yJmuBg4TJJx3eGGa7XJLK6PwEfavDYup/ay71+8FEBgspfuyl7jpVncXPFDl1Jxi96B6A6zMluWfatbusaQxDC2MsMBlx6m7Ycioqr1zmyNe6OmXfLg/072IkzYpBd6Q9kPG/HhxYgmwzQTuB7jCCBIx8upRxcXL86kr3Fh32VSpVGU3MUJP8zmiQc1c+8tHn4mOwAKTtkWIrfySdunzVcTTghyO5u2HD703iQ19j2TE0vKlZ0s4XAFR/cWj4bdG48nikdheYzReNX+wxas9WaAzdciLEXQKNvOUcMlkuu9BKw0DfGkBa0Au99CEbQ/fkbw3kre48L74W43iv/xc4QhO+6gsYOapNCh0KHQodCh0KHQodCh0KHQodCh0KHQodCh0KHQodCh0KHQodCh0KHQodCh0KHQodCh0KHQodCh0KHQodCh0KHQodCh0KHQodCh0KHQodCh0KHQodCh0KHQodCh0KHQodCh0KHQodCh0KHQodCh0KHQodCh0KHQodCh0KHQodCh0KHQodCh0KHQodCh0KHQodCh0KHQodCh0KHQodD5rRU6P/3/XtjW99KIvM1ReZVBbpweS0/oSNpwNEi98hE6gf4byaR+OTR+tw3mAbFL12oBCixtHOoXMKnq66EjdGo07VURSYP0cTcCaeJ8cTrLNgM2ydypjXocQozO8deqr9UJmq4Xp6KqBAdSN3jXCp7VUrm9VmsXi3ONMgoJpnCS6iGYFTWRg7oC9q2VqJwkNvQDrHMYtvbXC0keQeYIo0awHHgzv3aFNNDu7DqFf+zrjnqcjJngRBYxGI/TR/tl8SCErkfSZrrhQpCwIopw0rSF/t1eKOxKe6kvd3rYc/BM9rruYiUK62gj+EX25NVJVrm89aaVNvz6jn3XDH6Bj1aujFbdv3/vHkyLjcfvf/I5nNBWk/B2LoReXdK1vhx3RLiuS28KO2nrrsY83U/yuqrdEqk27mxxuEFCQt6JkxTB6vc5UOc95Diph3ej9pbz/GoVGk2F0azJIGPrdY0BwiEBkIPXqIkmIeiV3b3X/Wm2YdV3WRmlUwDB2sSuJRBDdPMWUlsxzXSTNUK1bXYpO2Rt4GWrWGWiVZFDW7setg0YjRl3AsiFMSpbLWWe/QYVj7NcS0UALLK2qqFBu0XBPcvS0KlcSttf+XzXiVIAE3fmnQs/l3F6oR5d/9aEdKrk7Fo2+LDS2F6Q2BZpUwm3RnnohQHWd2120FkZcAOQuj9IHaAt3mFXZZCtzUb3Uhkt/sUoEE3/zgF1cLkASSogMqzUFhObbw19c3muXpXS/l8vPOIODyIWLqOrbvkGOOjrPhdEjUdUTstf37NrcwWD4sy3TpVLo2jpzQjgeH8lmgtVWAzkES+1poF+Xw7GRIqBx3Cu0D0MpJrihiduWkEJion+RH+iP9Gf6E/0J/oT/Yn+RH+iP9Gf6E/0J/oT/Yn+RH+iP9Gf6E/0J/oT/Yn+RH+iP9Gf6E/0J/oT/Yn+RH+iP9Gf6E/0J/oT/Yn+RH+iP9Gf6E/0J/oT/Yn+RH+iP9Gf6P9bhP5/+H9+WjWu1QGlKodHmz+fY6FIJiSwz32oJNERKafWa91pSwt59jwEVHeMyNKVQ/BwsHSDkJ4J2pLj2ks8N7LI8dnjo7OXx7HDQphNslQf53e50+4X+pT60ATj6NWrYx29xT+wU7p/gJ6Ozp8dz6adMDpbNV5OXDqP5HTlYFnkBq3CGI13mtS6/Mq9i70N4C6BNlO5OmaudwA5g6VLammNyclCjEhwTCH9EhbZswFe9p00bk4vHhZD32F13T7bFIRaZPEW5ZMBz4YQD1UUYh8TgUJZcm5Cgkus3ixLFzaZrbeu9bXER0504QrxHnsxhNTkArhTSQhMLgNrQwGsat540Jh0SLCpxUrEvaGnBdAkmlqE2H8gjpueRofHYHFpdcUeUJ7df3gP5+7ipJEUBaYEab1YJy/vXQMbGitEYvsq2+yK1kM+LAebN9Zsd/J0vinDz/VH6V0RNEJYK9zet5LSkTxckMYMrQoAxBiTDK50qIvcqC/3mbaMXS4MRuvrbqaR1qi4saSFMZeSiqKBIjaBb9e2FU6RU6yFNWv1azoH6Q2AQ/L/LCS5pLCTVl32EoGQSyGN899ojaL6IbZ32di7QhuLrlIHvDEtclMZJfT5RoSQrkP02SymrVbtUcrURLqawMdSd66L66vFpnYCjIXbuqKPa2/goSLEVcCB/TIe1wERJnhgxLtN32mFie1nL1OBx4xCkkep5KRAuxEdBJ3kPO0rIikRMx4x9/sEgleWtsNCY6sUpH5igqLFkG2cc6j8odJRzDerUE9LNbjIXnRZENU50PBQnMMA0o9pmeaoRV9Ufdk5pH0mLUckn47gnqVqsNgIJBwPLV4qCK2oMqXiJMdSHQjElAiipiZIUdgEOD/opFFIHmnpRbI6PmiZMjpWcrcUbgB3wLG+n7on9VZCUO28dJWLbZhQYVYSKDOxl0xSSqvWStuLfVmuVEfBnqNptR5H9EwAGWlXM05Fe2zJFLUhtF4cHNjvkhbei39J5JCCMaS7aaQlRyuMvUdHBXygImK8S306AumL9EX6In2RvkhfpC/SF+mL9EX6In2RvkhfpC/SF+mL9EX6In2RvkhfpC/SF+mL9EX6In2RvkhfpC/SF+mL9EX6In2RvkhfpC/SF+mL9EX6In2RvkhfpC/SF+mL9EX6In2RvkhfpC/SF+mL9EX6In2RvkhfpC/SF+mL9EX6In2RvkhfpC/SF+mL9EX6In2RvkhfpC/SF+mL9EX6In2RvkhfpC/SF+mL9EX6In2RvkhfpC/SF+mL9EX6In2RvkhfpC/SF+mL9EX6In2RvkhfpC/SF+mL9EX6In2RvkhfpC/SF+mL9EX6In2RvkhfpC/SF+mL9EX6In2Rvn489PXm8cnpL5+fv3776smX2ZvWbmXwmL9gILhQZssaAxPNSlJn2Vqgp0Q1x1+hb1G6KM4tihBBwPJdIUOsEnDqQPjNyjqRHhu33qjlKBy8gCiifnKlKFugFsMu34yYMySIgUMM+DS6uRLigH+ScZhS1uwlwxNzSIE0+6pW4JQ0x+pK32gx317fIvsKWQwfzQSgreJIypVSpm4OTPu2B3VgfbVxifIEPCOqvus0cZG09t3G9EHtESPM4IoBBXwNf+sLGEDm3gH29z5pNH9yuzh7evnV6ycXX2YXPazeOlnrLTUgBT+IiryVBWBClGbbZZobWMgNq7VgrzX9JfkROfUTWMkeuPJQimgyjM7Da5Fas1Vf3uUXIQc1Aqfev3fvHiaslIdBRIIafaO++STbtR9KsUV2Fhc81wXvg63sLgC6cqjZDACsUKIyYzBr7oBrmVAxjHhs8yswyxPbDHDxQsKAgXbZ0eMnL4A+F42z5dLKxDjyopPyv8TAXXZSv3MW6DY55eLyRM4ZwPTwaIyQPX1310w47c9ezB8AlS76ZbBwnOTyLFshciqjdFHBJmGwGtTRzRiOwZ74Y2O2KgSRyUWfiwSLSxc3hMX504u3Ly+RTSfZiLxBKv/ATffvfTxQi2/dGlBVvqcGQjRO/KBegA9nQ0IV35tRk0L9QCL9gBoGLEiuxMrRgha4nyxMOC5C0kpni8VhI6GjEkpNO6HNPO8F8u/Aspi8SOvrDZZ8qxQAAX1duivhgSNTKlQ9+uxjoNs68vbECaJW7PHi9PWr05dvL168foWIvA0xbqIc54kyq2ne69sC8nhxNtY3FKy6QxcboxxjglDo6jQ2MG5ESlkl5JNwZEKmvWGd9+Xo8OnqhuL/UJmSV8gr5BXyCnmFvEJeIa+QV8gr5BXyCnmFvEJeIa+QV8gr5BXyCnmFvEJeIa+QV8gr5BXyCnmFvEJeIa+QV8gr5BXyCnmFvEJeIa+QV8gr5BXyCnmFvEJeIa+QV8gr5BXyCnmFvEJeIa+QV8gr5BXyCnmFvEJeIa+QV8gr5BXyCnmFvEJeIa+QV8gr5BXyCnmFvEJeIa+QV8gr5BXyCnmFvEJeIa+QV8gr5BXyCnmFvEJeIa+QV8gr5BXyCnmFvEJeIa+QV8gr5BXyCnmFvEJeIa+QV8gr5BXyCnmFvEJeIa+QV8gr5BXyCnmFvEJeIa+QV8gr5BXyCnmFvEJeIa+QV8gr5BXyCnmFvEJeIa/8fvEK/vs7+fkH/1Zi3vkeFFMhTAXQF8W2wXKXFsmONdR2SGuNjqsaeNAggfB+7SuXw4uxisQFa4+sqSulr2vflsU1cmKRnaQMQZhxlM3hCInMMHFhK0V4EELb5w4JidmNsAlAIVWGgjVSHVZqLWiGoZpbWyr3JOMdDpSxJobMMlubZSkThs5cWVRkIQmNk03xK5yUNaWp42mNL12OMVAMfigeRPvQ6Em4b7puFnktdH0x8qykDip244vIIAlEwgBdCbRkPUfPLo7VjtA34mfUoPgWi1wPkHh08fX5cYRrQAHorsQA10YIq+lc5b6Lnjl6c/EaKFsDK4rs2cUcf+JEXZatg8yq0mJYWKrhHAt4dhELPMMpmSnXQLNuU6mosFVT+p1SprB+aKxWgMBwXINEw8HXCFzd9DDftPpndC4cnhBiF3FSDDYSUdc5RaER2pBy0VwpqaEIkxOFuDugnQqOff0PQAzh022QaDE0WFkLXDClxvvSuGtTx1r/U1P3Bsn+4N69z+W9Jza3FUgML9z/PM6MJfYlMll0HuzT6Inhtm0l4f2yi+QZzRi9rL5ClGU90T9ZwDpLKzljRPp4EUqHZ3sM3KYlImWRUAqjKuIw7X5w0YFQPwDlCD/JK5KR76+tBeud9c56Z72z3lnvrHfWO+ud9c56Z72z3lnvrHfWO+ud9c56Z72z3lnvrHfWO+ud9c56/5uu97//z6b3k51jxfGmlsLaZn+nUmfzTa23kVi9VwWOMI0rsAz7rsFgWm3wWCW3JEj8KrO2MMqUu+DU9rzsCxlpiVVlhQvWBLk3pEtpLsmQlwYJPdy7AYhAPZhWbny4ttlV7a9nWeXWerdQvBUNw6Qq1tN9hUBnte3b8YYXHOHbQu4Q63aNvAKL842Ru7Rs676D2ctd1tdOAKM1pdRq65fLYcimL0P0+MaawuQbgYG3gjZdXyt4yR0dpWmx2LrXVJF0S0b2SIjCZ7WXIsit3qiBVBnvVSmcWddebui43tg6Bb1rTeFk/Wq9HoCKBgo6sVjvAIHVAnQYat2jekpFjoTIL2ocVps0wFfJ6uzC53ITlPo09HIjiuSWujH0yyDo7bTscLYNenNbgjp1Rd/5SiE1JaMCZZC7TOJ9dNO1TBywvwsOGCNHLW286wWJqAEtbbG2gCSv8DjmlpUbbXQ+vZ/Fy91CYh7O/EBaym0uapPeWjfcTHaYVFPrxrscF/BTCzOQZXo33uEcw5IxfITpOFCaoLVy91OdJ4dXSGu9FexIIw1wdFhYuiXxer5q9a6xHJxX9nnX61BBgHMdz9/4yq9tbV230wQc35jMkftWGU6sAMHYet1tjvd50Yb56uz8RQRAxKmIHuld2Ggq+rqUOx27ayt3Kk1SVeZDmpfdZqd3RaKKYNoSmA2o9OMpynHXXvIGNWUPA559M6GEB/dv+1r95mVM1MAsu//ZgQnq1PiOWPPg4S2D9rfCnSqaTu8bnJbODbYcbr0cskEQ4Xrj8o0KG4DnQHaymoefLD7/4uOZZumLOreNurryRV/aefSz3Afqyz5NJsbrD/ilvRrv9pJbveR+SfCQW9eag7XKJcgXW6V7SG/mZ98JSx6JVskefr64//Dj40X2GpZoPDUSiQjsnn3eY+Xpq1fDjXui3rpuTzc2Oyntu1e2mxx69IFhWis4Utx01aNHiwefiYXP5G5DgUMUkRq58n2d1M0PTeLs6PzZKdROrve3LoVs16Yt4r1vozroq6QkJIsS6sU6VL9I7Z28fPZsBi77CppEhzy8Ze/1VrC+jAGOukwiFaZazKVbl99f4Zh6KDXNwEPUuBFWpasG2dCKXh2k32Fxfl9NyvIge3u492ZGiHAr8f8uLuHAlBTElQgpSc+w9+9w7/GgaiufVEqp+VVIGljIJBRQ2AW9R1GA3xUxcdM9z4XNnerQylzJ0hMjrHpRslQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBlUGVQZVBm/gyrjj96eHSiDu9xzZXcR0B0wUtwrFd4jZ+cnTpLgyUgxR6cnT44HkxbZ5aTuB7RuZdv7Cm7Ej0SWYWMaoHwOvmgVX36OdXX2nZiZrazpNKyqNsoypZxrp6APOKx8ZLAIHsCfDNW8LG01Dw38gBXFmAmNSVLV4rFl8qoWvWkllIdKKQxohKAldk3LiwEtTX4VS8AsXSnkIFrLXEmJNLBahlUDxTRJhnkpIR1sgwoRVwhqSYHHtNKBBf0aLwApkc6EelAa7rsYljTZIsnC9xCjwBkCJNBgVyvRc1j7tVEbMSOqG1Sn79bFvPNz/EjTxXozSqwS6WzlFBsOk6M0S0nCEeZbc5017p0m5uqGH0HlKLKtwHuBJOqi7BCPwFMhIfaAGoenJqcgbBXAQYsr2A7Q/Z29qYZTWYQey21RWb6KU8RlmBHiQnJ16So3BChVR3RAaXY2VTlUaV1bKW1oJVgaxWIY80tFNF5C+jfI41aRFu81HseYuwyM7hVJtxa5GVBPqsBfJZpSh571ZefUjOyNbSU7Wjjo6PTV2ZvjISljBYg422fWWC86idQBCklldREdkkz6MFFi3cFXcLktrZ46pfBhCnhEdNyQSZMApuUP6RQvMmwslJUvobhkvSijJghDtaFTr3UCrz/MQMGlPLpteE1Phbyw7dbp3BK3CCgxPW2ATwXSov+HDC/s92ZvvIZK607SJQwcmup8GoSxnsHwt66eLizeLnTBKTRit1X0+qC/91JyCdhZt0rko1q/q+am5A//Q+wkMHC5iL6DdJwMf+hshb0VKCldT0htycmDO8SQBk5bdkKOxUgzEtaYSbpgDXfUoekq4jBVRnEmrHAt2Fznm8ogsIfXrqn+w5fZVy8uHjyEFJU5Xly8OH1w7/4XOoFoSsRB1uqjpLgJXQdS6d7i/sc6CH578LGIfqEMQUt13UgoEuCpUMMQ6ghct0HdhL2ACCRXkivJleRKciW5klxJriRXkivJleRKciW5klxJriRXkivJleRKciW5klxJriRXkivJleRKciW5klxJriRXkivJleRKciW5klxJriRXkivJleRKciW5klxJriRXkivJleRKciW5klxJriRXkivJleRKciW5klxJriRXkivJleRKciW5klxJriRXkivJleRKciW5klxJriRXkivJleRKciW5klxJriRXkivJleRKciW5klxJriRXkivJleRKciW5klxJriRXkivJleRKciW5klxJriRXkivJleRKciW5klxJriRXkivJleRKciW5klxJriRXkivJleRKciW5klxJriRXkivJleRKciW5klxJriRXkivJleRKciW5klxJriTXv3Vy/ejXINc/zN+8PX/z+uLpl4IdhaSGb8Qq03cAfolzPEE8HOxaWCiOvPGtd4UZgQhm2jpbmRxhbjr1Ru43MQ4YygNIms0uO3p9enk85OxSeBaeqO2IP4uLy7dP/kn25OnFi+evvsxOsrz1IcyDzWOqzSQcw+IRsL5QDz344vPM7qyacf/h/WxjTdlhutAvf4Vjw+Ls6eVXr59cfJlh/tHQZEaChLQkZCI8OeaKMMIue7D4/Dd/8V//V1UEqFirnTJO46JTbANMtKXrq+zo/M3T44FAZFTnQ15KlLOlbwvbRlgauCM6NIDdu6kpzuemcWVpWgcAH9++MF2HsX4WouMjeIzvfoVM2r8ZlwKCrTskli32SBMTte6rpcRuXBQMB+MgHHpiB5VQJzUDtYNIYUhJbpStb7vd3Nej+sm+7Q1m6Vz0pxycJtGhRoRfIKRAwAbnJ5QaU+Do4uuz41Tw15g1b60ZOUEHHOEN1WkHXykkC8qKZXGFArx7CMFxhYUWrJIUi4ObMu/LOD5s0OGjz25kA3LUACm2FqxQxGyU+ZH6EStfYWmzGEFTjcgxTAOox/CVgMcKJsQ1ibEmw2qHxQqbjri6F0K3Xbs4f3rx9uUl0vhSRYiywwdW2gedq5wgtFh1b/Ho4Wef/OWv//w3/wb/3Fvcu3f/AVYiQfjQ7NkRpLHRNwfvQFTkV+B3kbew5udXfduJzv75Fmlr6lyjtGwBS1086tmzy3+ehSt7Hf+8uvfPt/hFnVB0G7xw/+dXD35+9enwMlDNHMccGjy0z2J1wBCvD/hhrwDDwXpeJFW0zznxzOefTT1z736s1lgrmtttK9yaSGRaSbdqeZJWMvr9xb37+7G/eKSpd3e931/cHwOE3x/ooXfW/ieLL74YjnyweHRPjzzEgcXp61enL99evHgtkDoiO0SR6faMcyPxXX0TJ0WM4HqkkLJXh6pyHYmq24Bm8cItSCfVkGpINaQaUg2phlRDqiHVkGpINaQaUg2phlRDqiHVkGpINaQaUg2phlRDqiHVkGpINaQaUg2phlRDqiHVkGpINaQaUg2phlRDqiHVkGpINaQaUg2phlRDqiHVkGpINaQaUg2phlRDqiHVkGpINaQaUg2phlRDqiHVkGpINaQaUg2phlRDqiHVkGpINaQaUg2phlRDqiHVkGpINaQaUg2phlRDqiHVkGpINaQaUg2phlRDqiHVkGpINaQaUg2phlRDqiHVkGpINaQaUg2phlRDqiHVkGpINaQaUg2phlRDqiHV/OQjUA3++zv9+Uf/4qVpESpT+b7uFKUEMSTDsrWtBZ7LnbBL0ecD6lQG1a5sg79sByIQV0hNHZ1dvDgGrKHAneC/5kMkDXlbs9MjX4ExbYToBl4GA7haAGH0+NL50q+VLoEfTYkazy5bU7hId+Vulp1djFTRSp7XiFuvUBHLuzJ1r7aPECIpH5PDdRnyWyks30hO1Go9uCn3VdPaja0D6hknG8y2+85ithfgttCXWFIBlI005lpkknhPXRbcd2INxpcMwMkyWGnfpXfVPAGbhYgKj9nxvk3ltzRt60A6s2SbX5ZubcADO5lqVCDFVtCjSCES24AqmWkQH+GhIAdvYEFpYxXWgqziDlgTLZWFRLJ6ESsVaapqREXDDJiCSsn7gEl8neBElU6yoUpIEp18Boc4BbXOZqd9Cww8t8GXvQby6Oz0/FgdcpaS/2VKfrz18nhi9yL7BinohBGwghFtYXWiSLVEsK++lS6Il7w8IE9cpkw6uH9Ysr5o640CcFqZWSLRKpff8OhhCnYuhF6M/OBy5yclwLWORIaFhi67AKoKu4gj5icvL7Dkcg1M6zaVIp+6GQuOFYKU/RVAChUh46gRQ3kUDunjltGtsow1QKWJMlSW4Dq7R/NIuXeeOoyt0TdFrKcZ9JdQLQZst05Mkhn6evLC2cuUBiEJF2A5MjRsov1DlcjktxLscJgh5rPsHLMATKCZMNqQZeKVOxhtZCKVNWON6/BDecukwaI+l2aSvXctfy9jFc5ScFL0bRgtv+mCve3qsCePL05PXmVHTwQtoPvivBfJ76dlHzCZmIlAnjRNmRglBeqVx7CxOk5fnpyfZEeTMyImT09KbG/kpej0PB5+4HRZP8xXCLmGmNxkte+ip0DCwVVOgPd7M0ynwiu5oJTMljhsUkmpUBIMRA/ODmM9uyuPFtnrvhU+6XzuywnfDCMmOp0sFAfnKP0YTj02/7Z37RTpcbXTiQzvdk1U2mJpZ/NN7b5F5aZM8gdoIms70IATIJnCvbpOOMbVejIS3w75t6ek90LygjxLniXPkmfJs+RZ8ix5ljxLniXPkmfJs+RZ8ix5ljxLniXPkmfJs+RZ8ix5ljxLniXPkmfJs+RZ8ix5ljxLniXPkmfJs+RZ8ix5ljxLniXPkmfJs+RZ8ix5ljxLniXPkmfJs+RZ8ix5ljxLnv294lltyfQPwuvHf/r09PLF14dNmWCRgIYQVeo/I4nf2si4DnNF4xMXu+90ei2IoD1BJHCwpUcxxkC31iYkCf1ydAgwXno3WSw4N23uag8Wz47OT0+RWoMfDzt8pIROnVVShxhgat9pXPbNn6T3U4eFSF+Z0QNH355ezi9PjhdnJ5dPz19IgZ28epKNHZsu3DvUjJUeMplYkboa1UjrwhYRzTFMC31xszOULDtCwpSUlNjr6M2DXj4ndUyOB5/fNZFCQNMDzSIJyKJh/SUy5FSYos2e21qI+qQrTZhfnj4/OVYLXF3YxtaFtol6d8e8z3xZ+mvxbOwmg/xqTBtJC5XbaOedUbgoECPnRO7gnBkqFwwnAY9vyfKkJKVDVXzteJY9+OKz0fP7XkAHrZniAvs6EV+RqLHtnMiPopfWNBB4Gyw7O71MmgrGpz5BEV5dany0cm3okKr7ZjH7THVgod0+/stdykWpEaXS0MVC/IWUH1ak55vsGlkEgEjZlsPJQdpatXOJuvSx2ZOmtJmqwRY2tWya7919oy+TBGh1awmy9Jg40sysSn5cZI9l8fuZkwsFJEyrrXQEIWvbt/qjA7JeZUcnr15F+P5Q46v3jW3KoGJzqTSUmFu8NZAyZhqXrbLOQZgCsqZAED2eFi3BXYB14kQj1SiSj9GSJa3GtFQREb7MjtyxpFs9z6X0I0igUrIjfS2f4/djUcuhBzzfOGR4Wxxx5GSg+MpwfJO6H+0m5zQ3hgS7VL7ZeMD+ZOBNPAqqS7TRZJWiFVqkhcRY8EhaK+laU0+zM9Dbxl4HyfLY2sofNtSCHMO4Y9OtV2MPKDl7Cr37mkJCh0q7L43dnSYllS5Ejh59kvm+i53rPjtOxkUSU6l9d9UNZz/45MH0dDBlYqjbax+7270PsxV7AY8tUDNBwIdn10RZ2i4qCiPo64P2+bq1zkX2VvnigwPOgPavUokXplH0XnofYpu0UQXvK3YpKjARWo6rx6HZGSzYp2Fqajf8IYH8y1//+T+KjbcePDxOE9Z3AfLY0goyRRWb26J8Uqe9BDVST5jw4aeLzz+eZZ8/Wjz4OB5w/969jxWem+HKBOGJKjGSi1x1xYZx02j9oCgJyxkdpPG+/aGkHvuXSbs5XfPSrNf/Hq6NpRi9Ghcif47C4cDBD+99+tfl4OTZL+4vPn2/g/ftzVCkZx90oYjGic/enzGJcwIMDqudOOwAPv8KIY3XKz9UgR3GGDj9PQQsonfrCozT5xtwVmqPqOJvIHwRE5U0xAuxYm8XKqUnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSelJ6UnpSel5++b9PzJ//3xyekvn5+/fvvqiWpPV2+REW4NralrATLC6bKym4malgm4qUW+FC7v4hLtCE4Xfbt1sC07en0RhZE4X8EyonnZC1ZEKRWDhsFUFFQCZCPEDsphMUrEEwBnh5Fh2CefPBrP+bDSEduCXYskFOTt4bts68u+ijq4EUGJ81UyvlfNDkCHEgv2jomjJl7tdLY4RwNN4xFsHJZvjFrUSmLk6ryYMvAflpMiHEV3PDlsTGNjobjvbEw60bJSRTuIRUlXHUoO0TljDiQUuJGfn90hfYZAygAP3x/npI3H/IgZ/vpijL7IJZ0y/o0DppMLBVtN1G6QNRC4IIpC3xbJ/E5Y5traejKErqrtrUw00OsHsqiBOxC+tPgwJCDAZzsmxWjEMgbpl6YpTT0/s9BgE5CMYjjRdDoUWnXemvoKToZk3esEmWwtuSCpM3IZxLooonRFNib4qX/3M1E/KHOYVrorW7qNB2Ik4EjRV1Vw00Hvi17ml51RwSjnKapPnX90OhnphYz0ZXZv8fnDWfbos49hUL0CoMT3kJtwkL794F9G9vz0+BBwU5BLpQsAFJKtL7sATVHpJYs6F7iDKrKtmHU7qcS5+0IfrwzSYnLfl8WQBBL5xPTvCfpALgQ1ghpBjaBGUCOoEdQIagQ1ghpBjaBGUCOoEdQIagQ1ghpBjaBGUCOoEdQIagQ1ghpBjaBGUCOoEdQIagQ1ghpBjaBGUCOoEdQIagQ1ghpBjaBGUCOoEdQIagQ1ghpBjaBGUCOoEdQIagQ1ghpBjaBGUCOoEdQIagQ1ghpBjaBGUCOoEdQIagQ1ghpBjaBGUCOoEdQIagQ1ghpBjaBGUCOoEdQIagQ1ghpB7QOg9pOPAGo//Vdv3p6/eX0hm2P1S9vmfellcPzPpL0U1qVfwvcba8q0W44YWxpZETLelaXueINpSyeJY2F/toPxi+ybjSsjNkYEqvc7vkwny3Xrpw2SfikJXdgcc2hg/dbGNC4NoiSDhljVwASt0aLtkWUWo3SAksNhZUC4pc9TpPPNUNnIla71ZTnkToHRYEMqyb5tZAsWN2z/U9q4z1XWucrKJkzOrGud4cMGzLLrjYMvcKANAUNICmNIU8BzOB7AJtEt7Le9UsiIp61dY6Y6okzofNMMhq76tpPNLJA3dahcCGk7kQ9YMeWBSvKr875M+2fEdSh8HsY+FdRWjNY9kfKNlMmfoaB3CKvszzTFt8E8+C0MG1KJVZNtT2SlPfgBv+a669oAXzdMlyXrS8NWJvaGcfXUFt3uqrIm5l/c7mssEBnqfQi9h6NnN/ZnwTEHpu3tGE17b7hxDKazeqy4yGQ98CNmcGtz6ySdPcAmznNIcBF4s6OTt6fHuv9PI8nyuWyIE1FOx3zftljiF93WKu3KlfZbsapH9rx4c9MyDWbhCkAGjlwG26rxIEu3rnU/K6yycFA2rY3ImhYTUewabJ22dBML4xZXc1ieoiNppniQuGaCjV9mr/t2HCj067VEVZHQTEOsxYq8ldArRuv6zFJ2bFJk2HMCVmo+iAgYITLBUJqyf81StE9TeidIHKWMiVlfxlyXirMr2QpmtNLD8EZwUHXfO0RUCrbTLPRYVuNK+DPumifWAr/aNWKf4jHNYAIxgZhATCAmEBOICcQEYgIxgZhATCAmEBOICcQEYgIxgZhATCAmEBOICcQEYgIxgZhATCAmEBOICcQEYgIxgZhATCAmEBOICcQEYgIxgZhATCAmEBOICcQEYgIxgZhATCAmEBOICcQEYgIxgZhATCAmEBOICcQEYgIxgZhATCAmEBOICcQEYgIxgZhATCD+UQEx/vux/NRexn/0fN/LODuR/784QzWeApO1t25hOnOYFeJqIOUALr7p4oERxWJT4NyXiFMuXNP4cteElLsBQNBe2QK4YyqPTLV14UPuGxeG7rPgMyWmDfIkBk564CLSBeq59I1kZewyjPC20mS4inbJYWYpPOfHSgHUA9Fr6xshLmk4LB2NpSnq5LVkYSzuvgZ4ScUhCUfjcIzLY52OKP6kV9qQldZ61E7MAcdpP2MdM2s2vottkN3QRzf1l7XThrXTOTduvZkXdgX3RwDZoB5QXOtNxOTatK2/zpbye8RZaZS7yE5KhMB2NnYQjis6qv/y13/+j/D/B198dhynh2127BAsXCjeAihssIw1yuwrJzyX/r4RVwUlnBlpad36PnYZ7jaL7Owmvks0emndC6TyrYKvz9a2Fsy1kxjOTRCIkB6/KZGWzjdB2kafvH58nJkGXsXgi+xFhLxOu/RCU9gxKMmzsrbYo9pncvLB1LHT7+1sFc8hRlbp/IuHD28MarbGlZpVR5/fexB7KbcYaAjd7Ra9B52Q7z/8XM9Rc8RyHHIcgxXXcThZGfzhMsApEdY6ZdzB+phde9r6zkz7SCMt2p0kb+Nd3cVistNakipLzX/lXTVuH2Z30897jp70D79/796YZnEGBOSzBx9Pii2l3JAFMujohzSyWiy6Qdt0q6n6ZhxYjP0U6VtVcNnE4HGkITn0yC8eLu59vMgukk4QeNKCsSKMtmODbflVelnbaN2jB4tPPtYDHz5cPADHw/2N1cOEdvbTDp2ipaf1GJUD/FIrHn4KK3S8L75Qe84xf6usPPX5bdTUBe2bgodRDUQsmwqBcrdvsd3tE+SoSeW++OTeF2rC8ML9xb179w6XdqM5tc4eNv4aQ66Fw/fGxsgtTRLa3weQ2ZvD3ul/tXUpPqcF/UyuQJxI60QN0tjbNpG5BwqI8KGTSaHdJJ5bRYJ8sIXyid36UlStv0Z85DILOrGcy7WF5FUJi/R41JPXS6WlVX5I2WyyJVKviFoCSmtBOiWdkk5Jp6RT0inplHRKOiWdkk5Jp6RT0inplHRKOiWdkk5Jp6RT0inplHRKOiWdkk5Jp6RT0inplHRKOiWdkk5Jp6RT0inplHRKOiWdkk5Jp6RT0inplHRKOiWdkk5Jp6RT0inplHRKOiWdkk5Jp6RT0inplHRKOiWdkk5Jp6RT0inplHRKOiWdkk5Jp6RT0inplHRKOiWdkk5Jp6RT0inplHRKOiWdkk5Jp6RT0inplHRKOiWdkk5Jp6RT0inplHRKOiWdkk5Jp6RT0inplHRKOiWdkk5Jp6RT0inplHRKOiWdkk5Jp6RT0inplHRKOiWdkk5Jp6RT0inplHRKOiWdkk5Jp6RT0inplHRKOp3Q6U8+Ejr94zet73BkBvxu4wiahfjLh12ZXkHi2RCUn8TQ0M1xcB3i23gJmK4+iR47enN5Fo4xq1qs08O9cBYA2FQYBWfktiz70rSRhIIi27nNBeGl8oV/NmYrBLDFMiVxhDPtOzlWSqIUdtUAf8hwzBw8HJQD4iISxdUGXRI0w1VMybqvLPghwP2th5BAsIM1ahQC2VqEys40r1whXhjWKvOHfhnEAhuijVikbdcer6PQDx2jcUC127kktrwhjgHHZMhVgIqrGt8iOTrlPdNigE6zNcERsqjq6wEprl2pC9rCpgz5iERVKxT0TQuOULeBwZpdoqNBo8wAJqJc4upvKpUhqp33pY42lAPy6UPelpXpIgcvL7JvkOauBUSiFuClXrl85XtYuGui9rJ17hVvVtZoSc4wRF72+hpyzSVrTOVqjzpHOSI6XeuWvXp1hoz+trdSUZiks++6XoDKNqh2vOpkwGazCy73+cZWQxpIyep7Cjxpmn1cABPtoVFwVGsT20Uu1dhiPXjNFb0ky2Mj5RYhCPxyx9KupZI6MLQLGxEng28FC0wpif7E2uaV+DUprgJ/7/m6AvP7ItwMS/P9VbzI3up49XzlywIl4UOYg1kka/D2LJOoWKGaFE2ga4BsgunZydvTSEJx4tHEWXZv8flnMeN2GFCkxWiCvPnwXtIguwaZvDH19G0x8d7ii3hIvguyAnto9CEJzOCMShPJdIOiaf2yD10NWNDxWls6s3Sj2pdMQxqLhgkw93pja+XsPce7esiVTq8egI+zSRCkZKTCjYIfID/0SB3BWFFpKsOCq5xAmUwEVoWaQly/+Hj+KeQFShoVagX1hgn35DKoa6EDII25EuOSuItwM0V2LOeuXIiRxhzlPt+CZLqkmzov2q1Tf1+ez2LAcXgy/Lb8+j4EmK5PjqgMkB9li5CIlL7hAYmROhGcEQFkceh82FGq+2LE/vTk6xMd9s1Xb/QnDlm11soV2qh9JZ9MDrZDte+hFHm86brmy5//XNyohi9wzYVTFr5dkxBJiCREEiIJkYRIQiQhkhBJiCREEiIJkYRIQiQhkhBJiCREEiIJkYRIQiQhkhBJiCREEiIJkYRIQiQhkhBJiCREEiIJkYRIQiQhkhBJiCREEiIJkYRIQiQhkhBJiCREEiIJkYRIQiQhkhBJiCREEiIJkYRIQiQhkhBJiCREEiIJkYRIQiQhkhBJiCREEiIJkYRIQiQhkhBJiCREEuJfgRB/+v/Z75XxZXbq663gfSS5VHowufJSsLo3Q7vLlrJbwL5duYOtLVYM3x2dvZg/Pn0BMgy9dkLX3ufighI5I0sC8yyt9h4PRlYaszjIqiO47KEj+CzukoHAFH0u0RQQ2KdQyr3QGEnVOdyiuLgbx4hjb5AO/jrLS+mrjjnayY4XJyVsr81QbsoYjWmkCbtkogwRk7C1yAjZfSOrLVKjxI/u2rdX2dH5q1fHQxEEoItk1zWKTKYE7Daan0qY6112dPHN6cWxLEp6xIsuSFbtcz65MLaH/9Da2oFrQAHaDz428t/Iy7Is2VDjSjlUMjUOJPtiyIqzo2eP56cXb473mztEfFIWP5hDF7EfWxYgIfeZtpXHinNlgt1ghq73ptnzyFlqAiAr6oONa0Is+2GOyZA6dyfwtdJKwITwdITOA58p1e/3xNjaNhcJpIwF9ES+Kn2aPLHnICx8jRrS1vdr0ymrDREWyZEdPT9/e6wuKX29noMdWtCgbath1KOXF5dnx/FgsTUmTNziAlOIsVKGTvYvUaSRsXQbAJc0ITzcl11cqRqi2kTmEF643jiEQodHUmJKeKZ33VjwSUiKu58+fZ7yKew3tnh611S+HhICOZYtEZqN7F4zEEFQFszGPXF+eBzBPF0qTaRUmUBOMMLenREDvGj4GgNxkos+niXA9IBueARBmN/0ZCb7k9gBqlHasr1G5cKNUooSVUAZ5ty92sl+EV9KBiPLFGr+aikci3+s9X0ODxB3Y02JxtZuq/ASqewarIHwj7IxUokv8JZsn7NnJCX9vQZIaCF7WUQlNgAtBKOJFwzT7CDoE/QJ+gR9gj5Bn6BP0CfoE/QJ+gR9gj5Bn6BP0CfoE/QJ+gR9gj5Bn6BP0CfoE/QJ+gR9gj5Bn6BP0CfoE/QJ+gR9gj5Bn6BP0CfoE/QJ+gR9gj5Bn6BP0CfoE/QJ+gR9gj5Bn6BP0CfoE/QJ+gR9gj5Bn6BP0CfoE/QJ+gR9gj5B/8cJ+n//301B/6J3ubSzlH6YGrHSvsvM2Cou6NsTPtDmjUitRtpcltJnDuQwYLG1SN61tr6TpnZWm+bJoL6G78K+naO8jjOlb2RukP2xZ+HG7udLFYsE0Qo4aKsHR86k4owUrNRxve/jORikWbxvH4m1wbESvcohKB0MGroDDliO1UqyyEuavzNZZxAynGXIzk6Af5atLY53ufph6fYNLtO8M1lJNbRKTMGWkaNHJcIxkWB2gRUpYSxhgbUSvZXVgQs4b7O4ePv4T5+eXl5kJ6+eZCNpTTteZud2DXiLlJoiGYZ1ndumXyIT9b0SeVY7k13ZphvA/G2NJGyDNG58E3YoK4O0ybPT0klD1pe/wtm/MrXRFpqKUJogS1ePbAU60a6gmHRr2l0kP9CodF3FC07hSj2VVji8KD0Heys5P2Tsjb6L0v6xMG0hv3RYovp4moMwrNyFuFqlrVy6x+5tlQWeCVbU9mb/xll2hnC6FJzNbtk6nb/1OH6WoFdlQ0gLlnOlGaQTWaPplI62KlGqm/McSWiDLKVrrVg1Zs3At0md9E3qtQjvZVurKXQcyX/sohh7s2JJn33+xf0HKSmD+N5WTYTXVMMy5IP7j+5/Mh4kcO+66UHaITaXEkKMFLAljvshYp5qOS9RBtLAMjgJYyKRL4eJbXEw7zD8yEAHeRqj5aKcvOEtjVlhV3itmGYUDtVTo0WtXSMdUmG5FmejwsvMIiJ59z1GJTeIn5OwSq+3Q/loWQwYBCbpsk/vZTsYGFJX1o2p1wpakXcqrx12pzriBlLO4qtLobrkT+WBvhUekMUJ8O0Dox10UfXCXEKenbRuNRM8jAtcZK/rPUSJWXEmdaz0+NR2z0Egc99s+RBY40CJYkI32L8UdVkZqc09MapIPrgYuAnQ0ge59t3QYfTGaoT8+qA9eN9JO2FbTIro1qgKCOraSHidNBkdBo7XEdC0A5ZMAFbbkmLVMRsUAKGjDkYelo0Yj5Vw+X6MEKSGvq4Skhym5TDmsAC9HqprO6mdmKT7tUIgiTBVYa+tp1EPU1CTgCEMq75M7ZwHdVdKX2nVLELySEcnfZchC22tQJoJkw2w+rOg12O1Yjp8aaI/Yq6M2Hvgn1jWMRusEQ9Ev9xuuz3mfQQ3aRXuwtVIuKvRs1jU0m7M1kkvYKQHdEGLo43qFJc6KZdIGy2oOkVNBmyk+XgdG9vGiyZtGC1YLQ1yD01SFijApkZb4HqMEkK8eN3YshkSXwWUWppAkTKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDKIMogyiDLoRyiDPvo1ZNAf/YFGInR9scuMq2KpuHoLdeDWMqacvbIweelKcagAJbjPJ8JHfvctZvZOCm4ADzm7Gn0Gs4TAkF4+Wj2y82Ozs8Fh9YVFVtt4xqpF+YoYSU4azoYTc0SwNYXTWJpmN5BEGYfduCYcVEZrNfOQKzm81noXC20cUqBPzDk6fXMejrOj25YeDzz7nhVfY3yUdVN6VOhMDx5TJLpNyf+DpwdbIvSCPlO2CIAhEWmjLVOv2raVdMNaxPJxWq0TnPLE5VIGAbICL0nYco8EQ15KGR49uTg9fo+fZCT7DmmnBg3+CIOjh8N0VjUei4IuNKpe8twndvKTY/cB9HWHagiItlSeAiEAVwKacqXOfemFjTDhM6mF7/FcZepe5fBkRCmKcc5ZtixNUYiOlZW18HNfZSrNgllDFGBgqUIbBcBYkCLX+06rofJrpNoGlVeZddTo1iSpFd2yd0aKEM6LrCZXAPa2MhJFA72Xy3pC9p+ZVgtadHltRWAPanwG39SFr2RSDD0b5RJkfhJK4+BHF1+fHf/TQbjpVAm2f0h5jFn0XoffXKpKVcyQcCzXde1jjV+WRiAjqOLrICfwr86ae80SSatpuskAtwozutF8D1BE2wx0vETodpkIGYF7dDYlJvjqIEKHSx2c6GqREl1y41IKC+gpclGQaBb98Nni87/89Z//5t/gn08WX/zmL6pKp7m/eDi8fH9xT16eCcs0EeORsUcHNa6GCgDh+D8pu1/gx73FvXv3jw+XhsL9ntXYO1cUTb23+PzRYNS9BQSyjHBv8fDB/sV7n312l51CH4orAhzvNfK9tVqZHdy3x8MfShNDIIQ+l/uUS5wmlxNSLP/BJEIqJBWSCkmFpEJSIamQVEgqJBWSCkmFpEJSIamQVEgqJBWSCkmFpEJSIamQVEgqJBWSCkmFpEJSIamQVEgqJBWSCkmFpEJSIamQVEgqJBWSCkmFpEJSIamQVEgqJBWSCkmFpEJSIamQVEgqJBWSCkmFpEJSIamQVEgqJBWSCkmFpEJSIamQVEgqJBWSCkmFpEJSIamQVEgqJBWSCkmFpEJSIamQVEgqJBWSCkmFpEJSIamQVEgqJBWSCkmFpEJSIamQVPh7TIU//a9Pals5kzZ1hNUouky3Cf3NfzXsz4gRywLI2vimj1U1Gzb5BLopyWjCAGFKfz2HJwF4Aqst1h7rNzdt62SjSds634dsY03ZxR0UUWT/xHZZ3re6p2XIEcnJnplBhsHQ46aMRdzit9O9MPF6omi8FGxjxJLMtb7WzV8F+nNwfFzj0YsnJ8dwErBlv+GyvBPiZr+6DatB0QY9HKty4I3Ly+O04WiTNpKUnBPOiRvDjpvtDiH1Eh8xYZF9JRl4LcCQNoyux01Ix91+xXJwwbrW3XNTNBSUohW7xqZEr+BOBU/JG1uknZVBwSB62U/Vt81GqOSAGVAZvl9v7sDjfWL5Ju4aWiLjJQKyrWk7mVF3f11kJ1kjqC0HWtnNNiAgYk7lkYRpS1vdIVu26Ay70NlKs3iy72qCPd0VNFq99WVf2dl+GcF9h9qTBXiJEmIbU2h/ysaCnkq/jDukpvwT5ysw6Naccco8aiX4Ndftp4X3jNQIBof+SQXZmmvdClU2e7Xl6niovNAvZZvj6KLb7ttvujwkD9xRiCU54ok0hg6pjSCB7mF6F3/pPs+5JJxb7YRIcLKkCfDDpxLB4pG1Mxnj8lJCMK4Ewce/cEDRq2zB+h98/jA71YFlN2ZXFqiomWRLRJRPH2UbU8h46tAHn+qfl5ezFLs/WXe/ePTwY9SR7PXqtlJWSr6yS7oUE/4WXEnZql7QJJ1Fzz+8f/vch59/fMf5g3e0lgZ7ZH0CqZX5lW+T6lZZ6cJQHxEM5ITkqkgMMS9FkbXIsYAqbe1oWtprGpILAOI0rTc+NE5UEGApyhmIAgDfLImkEYIkWwq3ruDAOORONsbtBMLlXa9LjdB+eSm77WqVD3vEDrPI22tfFvMw7D8+eDAM4KjEipW/g1uQ/kMiLFEAK4AQ4leKI2p5W6ZOmzOjVAVoB8QNRHWiOlGdqE5UJ6oT1YnqRHWiOlGdqE5UJ6oT1YnqRHWiOlGdqE5UJ6oT1YnqRHWiOlGdqE5UJ6oT1YnqRHWiOlGdqE5UJ6oT1YnqRHWiOlGdqE5UJ6oT1YnqRHWiOlGdqE5UJ6oT1YnqRHWiOlGdqE5UJ6oT1X83Uf0nHwHV/97/I/UUc2bf8qyWpj8lkK+cxyZd2rKrRe0Ov0kbpQYAKN2iquzo6dPnx2p7RIHoDzhoY6QFk62zrSldIcgPF3opIawCiSTun2Uri6ryeS/YISUk2QrcN1tBM7xQtLsMM8TWNjIsqqfWJlJayzEVGqSJwYFrD8s1HcZOb9dGq8cvfzX2+Ukj7OJ4ETOHaSJW/Kqv8z1SmA82olpIU6JksS4XcA343wO4WD4U7+gclK5WQOrrZnpwWCv+AtZubYRHsSf31VLxOVpSawek3Pel0GguxBn71knLH21AJdgF37YK/jKT0FQI4t5FdhrJswRaRHxwpg7Je05TH/9g2YjMEgMduYVdzATgkvOOcYQ4InYaiiMPS/qF2DHUR2y5Fay0/wLLSB0vsQitjmi9h5DAEIm9b4ao8rXrUsRnyLuIAsjlJZQBrItdpCLgS++qrSt6ZBlKooNPOl0tc5w5zhxnjjPHmePMceY4c5w5zhxnjjPHmePMceY4c5w5zhxnjjPHmePMceY4c5w5zhxnjjPHmePM8d/GHP/D+vHJ6S+fn79+++rJl9mZy1t//upEdtBK9xvKrTWrvi6M3mhXqhdC4+v9XkwrBGDe9XrXjt6zuPFl3F9p2IlM0mbTV3I/GgwaE99VTZm2yMIBuulds9kFp7u4SaTk6MZ0m/EFueXK6eZOSCvJX5kz2epb2WStkVvcENtqWImEy8Q7H+UONrlRScctXNDsQDrmViKldmFtfZkMqlF0rZ6n27mpN+TmL+/LdLPddKfDYcJ5JbNK/uq2ZLIN2XAfYKelaAuXD/cralrm2VJihJUg4eNuWbonXWPrQu5EwqHBftvH3fCM3ka1yL4aAOJaDEG5Fba1RZpCJhZ3DbcqyU1y8bbJ6fwu6OFqalPqJltxczdZr+3iPWaFbLjWWLm3brtf5GixukGOj4EMkwSYhCX5OLPvgIzRjeVucf704u3Ly4svs28sVou8xjwFUr4G5KW0l/RCTAUxiv3kt5cybn34BO7JNyXefZPmfG76oPt7nbl3uqvYmd4yefTkzfOzs+Nxizjd+xArKQXDU3QqLEPvbBt2JAtS0x6o0A2IM9g0yyr916StFCfx16giX8+QWK6BYxLea2qMhn8gfSKmxJxsrdxzGa2dB8TYDrkRw2XKXUgb401vppPb5oadIeU2Wrgh1mPXAuGAPk3nK6v3Iu5vI433lvq+S9vWyS23knNILN0Nbe5Xcww4N22XikL25bRtNeySWbmIfilOWztAb32Q8WG8S1Fv3xstQoJ6mTfdaIhR+hw2rECAdn8D4D4LFtlLI9scXsP9KPSQbo2WNadCSMfKi5pCIfEZDu3jFoIjwGCR+5DoDb84SzFtAo0J3sIe3+IGcYvT169OX769ePH61ZeJgNN+ht0uqYaDkp9ksuS6AyNAZ0jESrk3Fdav+gg86SbOle682Ll4F+eNwgiHW2lqzMedJYd5G9/pAGW2lM0Ay+AxUW6aQekkFELxIfegB+LOlbpTqeqBXW0qvQN6dEa8T3MYP2HIADRASl+iiMk6ZB2yDlmHrEPWIeuQdcg6ZB2yDlmHrEPWIeuQdcg6ZB2yDlmHrEPWIeuQdcg6ZB2yDlmHrEPWIeuQdcg6ZB2yDlmHrEPWIeuQdcg6ZB2yDlmHrEPWIeuQdcg6ZB2yDlmHrEPWIeuQdcg6ZB2yDlmHrEPWIeuQdcg6ZB2yDlmHrEPWIeuQdcg6ZB2yDlmHrEPWIeuQdcg6ZB2yDlmHrEPWIeuQdcg6ZB2yDlmHrEPWIeuQdcg6ZB2yDlmHrEPWIeuQdcg6ZB2yDlmHrEPWIeuQdcg6ZB2yzt8q6/xkNmWdJ7bbF90Af4gtFiPw12Y71HNfX9X+GmDu2l5SfIX8EpgwOAiZlodpIaC84GWJb5D9uM2vMMjSeVdLPgnkAtQ3ACFbr+0i+2Zjh/gFAyiTAmrHwrLFbMQHREf8kUyVzcIrsKBgJHy5jqelfdGdYFnI/uTb3ne/SMbHP2byOs7YSgBipinaBWHSAoFHUlQOE0ocEMC47sEaIAnw8tqFjdUtxmNMBHQxiN1v5F5a02rtm3KNmHUb1FEEu3NbRjS/2NW+3lVCcae+wJreBngTno1T7bKj84vTt8dZ2ps94rDmUzGNGCIikDDYp1y+j8vNsBzAPkpUd4I/B2AhnM+wEACVoNcJvLySzdzL7JXtW/0RtURcxB0zCPuYd15fU6EyiQQA1cfU0dGx7nn8S48Rp0qZTlwlXrTCOnHP+9xh9GvoB5DkzgsrbqTS4WXw1iztZN9a1KoQcXb++jTDafDWvcUXjzD4tYcXC0Hzo8vT52rD6fPTYwzZiojqa43lxuAMA5LH4pV4sAhgkxfXOQFF3TJeQieVmiM/DpBGopXg5VYWIF6b2sFPWFoDto7J84E4CZRlG1s2mRMV4la7sQogjJYC4wBUlUWw52YOqHKLUJaJ7Csiqsqcd2c+CnQM3hi4XJGFmEHMIGYQM4gZxAxiBjGDmEHMIGYQM4gZxAxiBjGDmEHMIGYQM4gZxAxiBjGDmEHMIGYQM4gZxAxiBjGDmEHMIGYQM4gZxAxiBjGDmEHMIGYQM4gZPxrM+G/8/ZPyu411lW1/FsZH/45OnhxLlftanw6S5IwPIbZ2a0rBj3QkbKp8errRFH2JQ3yTnnuJ0bfq74PUPnNI/FO/ruNzSi8qeXZPHqLMjs5OXxzLk3su38DbKNTWrdfwysmTmdgjjyPGZ3Ow5FD666yQKpbZ83G8wualRCk9W7f4hz8/WcojT3l3ad91//jL7Pd+xZcbnNmYBsPAfhlAADv0Th8ADTY+9Lk2lU2PaxonxdkNRmN5J08022BdBnhqc2RQWnSJeunSQ3riqdaMz4XJw3RBgRgH7hS3O/h5Lg+S9TIA3lutrD5nttxJzmqRysgrhMe3yRy4Gn90Ol187lSN6UOvCGQKjIVD9LnOa6GZsKvkOb1IFXartaWnuE4f5vQeRdbFh3IlouJSeWgTAZWHF2PclqbDkLtZVht5ou+NqX1rKvduppSkD8JqWgBcU4z3EahMe2Vh/pFb2MUMA1deRrLvbN7rAau+jg8tYrSui5WqFq5rH5wJxwswyNrEZ9Mc4rV/FnImqxgfDRYfD89YAk78RhwV5Ilficb9zxHe2sGTOKvOy76IwZxpJPUZY2vKbrPL5Gk0OAoevaNCmEBMoL9KAmm+rFwrgOlKvx9vpS52skiENzoWBG+WvsehYZdvPMiqBTupueDe+KRwJeJrePg1xkxPGR9JnWUg7k4SMXoBeWtbSaFhnEV2ssJLypP68K8blNoHWHymYhGvhfjEr5k8rHv/3r2PM3lwNj04rs9Qy1OyB7SaxcdERdgMD1CHfgnVHFmltTaVjYsgnnJGEqjH9DFZUxrWkIitWesoeAkyafA9hvwVqiBEpZP7tsVfqu9HPSPPA4uYhxIIosEgowo5UUKS6hO5jKC+p/oZzd/NaAoQBQ+vTR5khrGFWwN0yxvYrcG56UBVjXfrmMJWOuSkNwQCgVc1kGLmIruQngpTV6eH5FXZD16QS82+1Usr4RfTSh8GXHYJsEaMxrVF6+W5dtgiCDxEdTRPJI/2ciicUQxUNtkjqhtF1l0ZTifddBKvB35vV0w5RznH6wEmEK8HqCB5PfDjiialLq8HeD3A6wFeD1DO8XqACcTrASpIXg/8eKNJqcvrAV4P8HqA1wOUc7weYALxeoAKktcDP95oUuryeoDXA7we4PUA5RyvB5hAvB6gguT1wI83mpS6vB7g9QCvB3g9QDnH6wEmEK8HqCB5PfDjjSalLq8HeD3A6wFeD1DO8XqACcTrASpIXg/8eKNJqcvrAV4P8HqA1wOUc7weYALxeoAKktcDP95oUuryeoDXA7we4PUA5RyvB5hAvB6gguT1wI83mpS6vB7g9QCvB3g9QDnH6wEmEK8HqCB5PfDjjSalLq8H/v2uBz76Na4H/vB/L75ZOQvBiiOfvDqRSWxZurXW+srnunE5ltpKqQMEhG+GLcnxsuapnDfig1LyuBFzbdp2kLFxJ+Z16/smxEIUlEAlwPzCrsTjnRzSTY4Rc2SD7UX2jVAYakW4eomKuEJF+n69Ues0OAHqwQxxWVu/bk2zUX+IoxGNnUa32QBQ9NWmgZvlvdkdA+QYvvalX8dj11KrqoBkO2jZcb1Lcchdm5c2Gjs6RvhZTRU0FUTRfbLTttSyk7XsIr2LFxJZABqOqBI3ddcdrgdnCkaoIIkbayMVIp+vrS5InL20wCzBjZQKhWzy7Ru96oBlOHQ+Wd7/v70v647juNJk21zAfRNFLZadsi2bPAYg7It05pzBRgotAoRRENV+zMoKVIWZlZHOBUDxpf0482v6zNO8zNP8i3n1U/+IOd19b0TuVVlVICkRBD+dAzGjMiIy4sa99/si4kZm/tHwaWvbM93Qbn/Smp2dIZKkqENNV6lW9nV5PdAFFsBVtij31Oq81SMxJv7M+GvRyjwo60axr3+LbS2C1OWGIU2DzAfAKdmU5ENp0CKWtkdMMkxBosuemvrU40+NkzmI7NPd/JxH267LlNGmyVdD/O2xJjdz1ob/1Ah32vohNIyUjdOObOroMpmJBjk9StQckg8PdVe12AK49T6ZLPkCkTlrMiAGxay9gSLAJF5IY0gdY8dP6h5Yj/Z3GluPdbttsn7fZ9b1QjBntXYS56KH0Fduj78fTo9NKZ/1qPFix39smmEdE3qEwjUkmAc39RFM7KiN0/wBej3iWS5TUDfhH3//n/+N/hamV80YPTaUlNtL6shOJ23wztrW43Qq3KTOt/QDrEdeUsX8/GPdFhIQf+Wdn0OauTA9aypOPie/OPdVWkmqN8SfW9JMEnQWl6GX1NqzFhK9oQKmESyulaWvqvmWTT7qqek684vJpMteyJ6NKEM2jdcfZ9dNTWg4jZai+ti6qKx+3DB9dBxyxk7iKZK2F39PrNQQppx1m+eTcr0k2ZkJQkswoDcTW6dGkQulyQBzKmYJaYVmhq+Io5CYSUrajxjOZfyxT9yJpPOP//F/5kyOgpHsbeybHCQd0n5CiUlrfoGE78ojOxuDsmVyzw6V66pjHhRSZWJwHvstV4bJDEKDSZ//S0Tcop/Z3O1scNMJxpCxZdVdnOnTDm7L4OEuF12e+QqQBcgCZAGyAFmALEAWIAuQBcgCZAGyAFmALEAWIAuQBcgCZAGyAFmALEAWIAuQBcgCZAGyAFmALEAWIAuQBcgCZAGyAFmALEAWIAuQBcgCZAGyAFmALEAWIAuQBcgCZAGyAFmALEAWIAuQBcgCZAGyAFmALEAWIAuQBcgCZAGyAFmALEAWIAuQBcgCZAGyAFmALEAWIAuQBcgCZAGyAFmALEAWIAuQBcgCZAGyAFmALEAWIAuQBcgCZAGyAFmALEAWIAuQBcgCZAGyAFmALEAWIAuQBcgCZAGyAFmALEAWIAuQBcgCZAGyAFmALEAWIAuQBcgCZAGyAFmALEAWIAuQBcgCZAGyAFmALEAWIAuQBcgCZAGyAFmALEAWIAuQBcgCZAGyAFmALEAWIAuQBcgCZAGyAFmALEAWIAuQBcgCZAGyzjdk/b/1tY3vn+4//2F38xvrme285Jym/TTkvS4JO8iGqRmQxMn3huQgBYMYWyKPgEduJJJk+qF5fkhG+Ur5HfIG0p62vlPH5ECDSRoqKtSlSkKL7NOllpF3FNoCWzIMYl9bQvZY8qptGocod5ikdFMd0ZWhT2VI0qmZU2vJw3lkskZ/Hz3Z0A7ja+otlQrsUqknG6ZHpGBJu8l1+LHR4emdrYPvnm82vmFfEPWmDlUcVLrXCuL2lGeTA500qjslfBmSoyh3fNJamKN+2uQW9aiGkn1Bm8ybB2phgTDddsl2uOkERS4LpSWCY25PYBzSFLtSUexm1257glwr56AfmCMQDrW12z7c2d9+TG2wPWMz7NtJkiRdBq1MrI/21hrGnYaJMz0yzrSbOFP2mY+NnmsYJHvS+v5KGJUljz9t7WUi4XwRcYhMc5Vre69sn6tidVv5x9//7ViIl+H0k+3dze3dpyTbjdT56wJVQUzmAg87pDwti+yLukENp+6Rx8rw3RWHBBmy1SKIjUSXekMyaveCOCQvfPD08dfEImjM2atX7m7T3UlT3ldhZDIx/GmHzDQhEickq42Nx1+TZTqxJ2JjYrqMrTMGpjYzoh3Z7tQ30jdsK2vB1/zU0i8Eq/3KQuwiVGNJgbr7NXUqbyI1vdByTXpIZXk0q/LO0GDSoqFPnJvMhK95k82A3WRzzBy06G9KSPUfE6dzYxZpWHINVAlDvavxmiGl6erWJH6PCpGrZvdI1fnKo6rsQ1beTH/4qQXd0jqnOZlWouXl6bnlr4owNmktz00vz9NvxIwZlfRvLJ/lxekZ8p8pbExv7x5s7e/tbx2sHWw/3/3GWA81I+WcPTKVdptsMhzsqBJqPaUrr3M4Y7qNbzmv3WpJgx42iaMVO4OfN8irjacOXSKKoQhIH3gkPEt4LWoA8eSo5xuzrfgyQxt7hnpnQxVH0mWHWxjGbPTot0GjRcqm0YZlvGsnbu170bP2/0A49u2mtRfwZKPLvdzoMAvlR0fF3HQRs9k0HKlnSU8Uec5MMXUhABwADgAHgAPAAeAAcAA4ABwADgAHgAPAAeAAcAA4ABwADgAHgAPAAeAAcAA4ABwADgAHgAPAAeAAcAA4ABwADgAHgAPAAeAAcAA4ABwADgAHgAPAAeAAcAA4ABwADgAHgAPAAeAAcAA4ABwADgAHgAPAAeAAcAA4ABwADgAHgAPAAeAAcAA4ABwADgAHgAPAAeAAcAA4ABwADgAHgAPAAeAAcAA4ABwADgAHgAPAAeAAcAA4ABwADgAHgAPAAeAAcAA4ABwADgAHgAPAAeAAcAA4ABwADgAHgAPAAeAAcAA4ABwADgAHgAPAAeAAcAA4ANx7CHAXLxDA0X8/y7+XD7aN7EVgcxvYR1rixHdVqEeRb0nPIRmE7KoPA/G3mJquh9KPydTDDo9wQJ7dJWNKdI8RgfxQR7XUieV0bNcVHmkhS/Ywdg+l62aqbbEmawlw1ZJgVpfngWxKNUWDRC0jqRn3zXZIVr8vHNX25CtukjHeFsGz1yKHdszXoSSwoWZZLeXE2tKiQNptUtgemXfX2J0dR6prMySRclJTQ+MvCIUImfxAkbqIQzY+3V9qekA6LMWRAZMueUH2TeLIpuozAZAmZx06VsHLQ3J9xvsaa9A/uspuZV3U2VVAvWpI1gmufF2qDVY7dnsvtq1HczOzy49137QWU/NcLSf2ceKEAZewxON/qN2OCPVYUVOYAiRdZgKkfKF9EXdOtjhP4vqF9t70NI/K6oaZTlCOrGfaDxtQ7cQkbOslaWvI7kZFgpjRtPUjQ1moQYBpkwZ9A8zMmHTzMkmrtqFPhnYxWZhSh1P00xQ9kP27I/yIFJE8kmYQVML4e2rbodAKYQY7yUIPJV/SoZJTip1joO1L+xCGRhnyOBOmMkNM6qMhbAlXyzsbskR8LKSsk6orcik0e7qAJ/4lInOPMqWcttYM7HipM1Nad0gIpCFunBi5uVWqOnt2ZIcvuXB58CeLg8i6mY2V28s1cnF6Tnd2aXoxHZesyVrE/NhMWwkKBGd5tLmdECrSQ1e1tWdMRfBofe9xUWKT2kGmjya/2lXG+kiUvjU7M8OtiQO2O8oYuxGNlmFL2kqVltnaYqk/ZLXkcWkAmSqz0bJH4BYmBmh8AWMxsxwCFm3xRnBTqUJmHbVZdV02uG+KD2EdJBmF1sz0wuKK7u7M9OzMqtZzbj9JwbJPiDYQp2dHl43w2uIfecpAgJdNGbqChsBm7W5rpHUk+0nibGt7jxOoOZHduFu4p5oar7ihgtswmzRhZmHael5oJvMlFUe+CFjmxVawBJKh5v6v7yXN5YGlrqwu6q5QEzLEyVqfNZyV0NAXKjGreXYo0pFKWYLxgAXZMXA2RcZ4bPIslCvT/oL7MqPExuqIaWALsAXYAmwBtgBbgC3AFmALsAXYAmwBtgBbgC3AFmALsAXYAmwBtgBbgC3AFmALsAXYAmwBtgBbgC3AFmALsAXYAmwBtgBbgC3AFmALsAXYAmwBtgBbgC3AFmALsOXdY8svX25zu/kstNUjDxAaOCHFiekXMjFyQkLpw8qcxUmOmnMfYp99pPE2XGabT8V6ItIvKWgHbGYEUsqjcmRibm/aelGqi7PFniSs4rPA7BCb5jxrDkbfUItb4oQESs0KbC90AsrEKX2CntrLvqudNJIrtN1ju5e8I4E0oGe5dtO8h4CPJvPp30T8NM768LynUpDhA/Fcljpdqdm42xwNTQemrV1xbIXqMDpmrdHOzwxOrMFO+P0+lTOmmEY/h+xczHFu46VZDOw0u/bLvF+pwLqKEVaGjmLd5uHWwxAKwmutLFw5/7GWkvfqkRIcJ+3iDhRwx1iBJ82LF7InSc+cbTYvQNDi4IpJjx3lxl2CS6YFTVLyQ/Js3JQ4NEZAxQ03KXVbn8xXx5VfTYvYTzbzlxxkwyuSoWbHMZmMhBk1chBe3mqRjM20tR2ZdqUGokdRD4QrmwH5NqpNP47HxYg6GSw+je/6/JtkHaFeRzH7UVagiI+/09PYiZTGQT9Qy5i4gBu32KvRk8LcXDK3V1YOmBxMDiYHk4PJweRgcjA5mBxMDiYHk4PJweRgcjA5mBxMDiYHk4PJweRgcjA5mBxMDib3c5icfh//xJ92YjeSPo1fw3FFoML8HfXhH/PXLoe9rk+aElotRVrKgTCBqdcKo0B5bRqBJGImiB3zrmSbtSfUQU4txW/g1uEegW3eM13/ZnmOoyq8wJ9fgE0ZdcOM4POoFfNO8CRq5I8c5aXaAWsV3eSecgBMi4NbBrxLnKpL32OfvX6cMuUBTLq9mQDEid1NyifqTVpMOqF0tFBTkhUFL/kF5PxcT7Bu24GOzkpGT79qP4zSQIik0TR+2YcBfO7wsSDt8GVku/KV4Kb3hSpFwuloT6V1xnE59uGwp8OgfLYnGvCujEzsVTq2Yd/YGnNIXst+RAZFfebmZyIb8tzEbyk2NPKn5uEmgsd8scHW0SqcqfSRhC79yvFRJpCrY+v4qMDEzqTtIuEqIxDhtbQ4bEeH37WGfYlARwfqTza8iRjCuPlXaixHcyXRXazGngwV6bhP7aeaJ0sqToXrvgihHXoeBKYbxwPPX0ugJ2yReBMF7ha+fEBiCwV/RiHi8EY/jrKgMj3YOiiJnl73IYVEG6TgsL01iz8lQUpcqkiH2qTQ2ewlhqEBYKyOVT/E0JLsZvQ3OfhF/IS1sR8yiKqglQRYGZfWEmSbGmFI9+0EXm0e5HLQnY57M98JMLUxC+CSOkEjJ4Pk0RyOxKJlbTIBXaG2zmPhHolcjgWhmHLNWLpRPiL9nxkIhRZddQSM7VaaYr580feMNDKpJTV8xTLssCc4Zi4wVPk4nM02eJ9+LYBs8Ei4Oo6M4yL535XVr/7x93/7v/+L/jf3lXYiWmR2GBnOlARraSPhASefLR1Bjeol33Q47ggvlVoaLpcPH8di2qUvkMjDQ+oWWXjSltIwFtqc3G4Keoy1NJ+1cvErIyjjIALR1shmAlu55bIZ6yDONII14XGpXJ0kclV/+oNDBkkOhHGOI7WvTL6rQUPqUcpSQdP8SurBkY7p7/yNDRJDmMdf5p/C4Ma1uPHKp3YUxzNziTv728bT1I7waT0NuyvJozJt7RCcKI15JiSS499YoBUJ6NjQMPW8km24KNHJqulqbpobdmrJLPzMaeuA3ypK8bPLAAvKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMoAygDKAMpQpAwX7ly48Mt/v3DxAlGHC7/fo6y+9gskUmoDoaCr2tqoteQdcknIi7wD8n77z+RfWT9JxcQJeSvJrIvSf7C7/rc57XLYgwVsDkRDCDG/sTb2UQWqGFLFlz+qwG1Zf80rats8SWFWH2iFRMbzkvFXDeGFijD60ToBFAF+g9jKKxG45HIeIw/yIA/y/IR5Pmk4RO5pjvVoVxxbf1HBy0lrd/ov07j/Ydx/sGvWVGgi3Y29ZI4W4ua7vXlvfWeDJx/S02sgNOU/r3fOmj98W3mu82rMml6Wj/DTz/vTrec+axhPv3gv5YP99d1bN+7gDu6c/TtnDT1/zjx3G3HQ1ktyynOKSzO4cbZunDXFeVt53r35n7c7v+1bfQ1rdAo5kRM53zznWfOpyIM8yPPT5fnThur6cWQnMTrSi4TryrZeaeZgCU/EgQrN0jOKoAiKoMg5KfLHLe9IBspLwnq6ypORCkwUfqtwZgDZz3H2b8rZEw3ReX3lurGOdM1iu1itAi9RMtSAGs5tDWeNp561PF9sEZ74wvaKk2o+UVacTCMTMiHTW830rsOscP/Dvv+vxVMBrnCiQHV7qh3YfsecLnkpPREmp02+oVyH0uFzXwWV5nNM20XItRqKHhr1+OaWqZNqM5XoNdrv8zrRDDQDzUAz0Aw0A81AMz6sZtze4bO7dEtnzMJEPoyf/9BY29ey/jNfSM8SpUWedDkHuZEbuZF7ZO6vy4vE+cLwo3U7IH/enrS2wlCckD+fXV1ZfoxiKIZi57zYu4/5xR3ced07Z4es42f8XPr5T+W5b2Fi3FU0+Y1dO0j36VHk3BW5vtERXRX6/LZW/PTOf/r1eiAjfktiYexszxYhv3FT2siFXMj1M+b6TWF5uZvAZ1c6gWqWln+RDdmGZzuzweYfeJEv1qVKh014bekJoWOylefmb2JFJmQ6wzqMIiiCIuegyJf/bPu2x59WKJBS5Xeiju12i2wCGZERGXXGW/yhIanIrvDrT/Hrx/rNhxFRI8vpyC7/azuR/YHePYsnT5AJmd7jTL/fpx80S8pe+WM9eqa8lvImrS2vXTzciLzIi7xvlve/124SOnrCIgJ+GYEM+VNjma3qGQu/mksEPdSDelDPB1fP2YkPRm7kfr9yr+2m5rceB8KO9ckiR3mK5pfWfvq6k2bsuiKSnv4aczt9M5D5HiYqQkWoaJyKHjUcmz/Nah/J8sSz5vt4yI/8yP/+5n/8VGgnEU5afqAioa+Tb6EOjMVHARR4WwXe/cmS83bno72w53SkHQXStjZtL26SK8A93HvP7/1uP1lbKR7B0ew1Ek6ntOWKrMj6zrPefGY39SyLt8H9D+vHPxXCQaVHrDPWyzp6f8WQgT5xoQiKnKrIDWZA7YRu4ref9bd3z3Lfzzu/3RFRR7VCno1nd0nFpWeOvuSx8sj5rnI+eqIC4RGuZy9XL71FfdqiKa4ojCnyIz/yI/95zX9ji7jZTtlH4rd399uvd8yrKMTQr1gg1/nI9e2mHdlNum19o9+zWtjOaeYLEa0kk1mKcOJAGzOqQBVDqvh9+jqjQByKQCNBKIIj6VD2v8V2QKDg9pD3Z8n70S4fZtzu2m0xbW240uOCuPce3Ltw4c6FC7/89yTPxPzM0uz8zPzs+Ukvri7MzS6dofTSyvzK/PucXp5fXfpp0wvL5yk9t7q4eo7SC4sri8sfcHp+dmVp7vymF1aX55dWzlB6ZXlhduGnTC8sry4j/drp5ZmZ+dX3OL04v1LEn/chvbL4YaeXl851emlm5WdML6wulOz5g08vrszM/pTpuZmVpXOUnltZWV1F+u2lFxZn585Ten51ZeUDSs8uLc7NID0sPbv6M6ZnllYWF96r9OLK3PucnplfXn536fnVpaWFFaTfWXplcbHIZ5E+bXphbm4W6fr0/PzMzPuUnl1dmkf6naWX+Q/psdNLy4srq0gPSy/Pnql0af3iTKTnznJ6bnZ2+QynF5dm5ubPcHphmX5C+q2l55dK+4tI/8zpuZWVmQ8qvby0tPQO07MLCyW+cc7Tc6srM8X1QaTfdnp+bm4J6ddPz60szXzQ6bnVxbOVrrYP6Z8yPbOysIr0a6dXFmYX5z+g9PLC4vxZS8+dpfTcyvJ7nZ5ZKu4nIf2G6aWV1WI8/jlIzxTXA9//9PLi3ALSZzg9Nzv7IacXVubf6zQHSLzH6cXF5WJ8B9Ij0gurs8X9/PcvvbI8s3qW0/OzxXgTpM96enZ1Fuk3Sc+tzJ6j9PxqeX7w7tOleJ13n15ZLZ4X/kDS5XPoF+dmshjes3i9gmtc4xrXuMY1rnGNa1zjGte4xjWucY1rXOMa17jGNa5xjWtc4xrXuMY1rnGNa1zjGte4xjWucY1rXOMa17g+59flOPdra25bBTLqdNPP1d5fl6qbfHhvX4TCDpxOcutK13wDPElejgLhZakHG6rrx1HyFVxrXX9EsTdOyev8KUZrR3rSayc/fbrlCicKlCcd6zthu1GH2uKoICvzxVPhUTOnfpQtYa2FoXKk+R55I4pb6VMvfxd3bS8tcmfHdjrSE9Yz6lPhWfd3VEu44aR10BEq4C/3Zl+su7MhXNd6RoXobtxVQVrxE9G1XTHwMbe2u93YU+3yR4ArAqhtS0O2WXoHAVXYip3C1ybvNuLgSB7RzTXK0QtlWhdllr4rrF3RJhEcCWs9EHYYUVr5rh1mA/vRBo1IQGKlKqr37rWk3fZUSC22ZNdu5y361aa5I0lAZoRFMEUCl2EkWoM79/mW11Kho/zepPWUWhIo/kAy1e1lgq3qQ0mCv9OfCLT2AuUIepDXHvvJdWL9jL88qLsdHavgZWg9Sit8nArgeZO/LSkC64UdyOJXPm+vB7b0+iR2tZXKZWAfPm/wJ6JpOGTU098ObfjCkYfSoXSWxdc67ndURKocBSSube8wsIOsex83Yt9XQWS9oJwqsJLuJXcvrbViN0oNObGYlkib8HHyC3840+/YZI2B7Xd6Y6jwxZ38zt29QBySIbLWbFBTxEn6QKorLBn5dRqxpt2Ubt7Hq/vPN6wNUtyszQ1XCL+2iuEdnlhzI0n2naavrZGWdXuOiuxUW2WoXOMI/mB3/W8tPw5Y6sUBvblu90SYWHs3tVoaZVItx7Y824+zT3d3pUN9KjXxDplRyzoQXV8EdhQH4vRae2PPtb2IlfRIDHvUp/uiqyJhaV3y2vRQp+MNcasj1EUrcio6Kmk3lSvDVAJ32QuHIgotm4SjfOmk8tqkEeuzqC2vY5NiBRZpWVd4EbmH5LvnqSvb8iU7Qe05yreum1uqm/vHzziHtXXiByw8Gr590Y7d4rB9onMkP6uglxnzmyCC0Hq9SVoTtESQ/j5Rcd4P/xzTeMnIuFfyzZIGj+pPHWuD5OKKKQ0WFed8U3tyhzw023gqmrWu9JS15kjyC+JvMVto6ofWbYc0RlKrSJMiIb26RvWP4EDFrnOJE3vCj2TuLUZXfztpEEG718or+oiBudsk504qXWlzfyUPGnGTEMFmre7ziLNaWIdkV/zF5UfPow7ply5AVk/mY+11VEiujAo/DVTsh6n37mcxH28EvZDGNvV6k9a/TO3b6YPupR9/JtVMmpxawZYngnbP2qk2vF6O5S5fdTqiS8YepM/6bF/45JZjRxrPyF+YJl5FnjsD3wZrlmMZf10USH+/Hq4FkRYaKcg2oarrsiVl6nMqFfj1nh2RrnmaWrU9ydYyaa3FpKl27qwm9lVTFRVjraVcETpkOoNw6OJaOyt6l68nrZUZjYCK0LW+X+uuUi1rg4Xn9HOc34QsIqYnYeLYvbhLZpJ+o3s4Vl9qcuV1wF3r+IZBZJ1Mi9B5fUe2WkTMChIZgxY8SmhBQqCeKEIwMgNjGiroVjlCBQOu/0XFBBXFIbnLjN4OXpKDK9PYklzK/ftk1w6JmdhBz2sLhn6aBpDP6tpjifRXe4H0HOlrztD1lUfKUh3SPmrwdijTqSDxyppHbNfNnPU6fw++4pEfFnzFbuy4giyVPfcwdCzLcjT7vK4rViH1qd519glstGf5pGE7Dg0ikyRyCwTX4kiG0s4JVNUOa3Wlig930z6QKyYHm9+o6NEzyaR6QwZBx0wi1qmtduYdq9VepSeS286H/NYzVueqRY8s9ptnvS5pSdeetJ7ZAfGydQ3Pk4T1h4dxKMatZ7j+3MzmZPvkMTOvl6P7DnnOw2xmXQ/7A/32lQ3bdWTcrdWIzylDlxTAld5UAspVBO6Do1NN00tDOYDef5FSgkYU0GSVyPCkRVyJQcU+BQAOF/KXG8rjuZlhc1R4l2m3WZ0g5+hkJvPJlnckaarSNaxuRxGkkXZnVlnp3SkI+6V9u2UHY7V24kcREbtv5XBZNbG6CWVV9a76NjW3ODphTJqcyfU+0VbBDot60E5oc3LrxlNXqibVHuUe+9T1jwd4n+2Q62cT0sPh8ZzA2i6tIGTrK40Uw7NlgKvc9CJw9Pm4gRY20Ofe0c0l69IIIkWNP2r4rEdTPH9TQT/R+IyfJ3qhBqA/x7xqoTzPlkFW390XMoyZngtSPb8wQRmwlFZv8KcxwyvPZLugUXUjUcPPRxLUt4I0w41ibFQZKpZaojbEEj6tzispyyH1oQaqJ/ZIgXn5rM5GPkoysMKPXBIaiS591fcZxCfpoDLZD2y9IEjC9ese8TmNA/lKkkfLqtGT2oXEBwcyDGPiq0Fg96o3P9bDZu3wKoXI/WxqkWuOI1wRGFKWGcTQmcLE1gmZkMyw+E3p9s0d0jB1RHMIO9f2ARz8YQ4MNPtLV6AyZfr8R3qE3aQyhTXoTeJNOdAM4Nj9xv+AZmo0Q6FZj6fi0HpCJhe7qTOuX299QDofFtd7JPmNDDqoY4S0GuAKnufqdzQtllFOZMvCs57HEU3R9aoIWQGXth4lq+rE60XKQj/aY1rtu+R8emG3vFxY8+TfJ+vV44DoA5N36kBN7SoadvboUo3lP27/4EYBTUi8cqPu/0h+mTQs7F8Ze6h3MYj7enqOuNfRi0NeNlHcICrcDKprmvXD0u8ky+p68ykvClVsZiidusoW7RVkWdTl8abmlfpv7UlX6TWYv5IQc49Qmk/uknZPvcmc6c6P9hEJva+zA4zi4hM7A7wr35EV1Lnd11/xv0ddoUmx4YaaPmfrtDUu49RrKqeklVe/67WCIWg+ejZIIPSSumyninF5n+dQ443O7R+ZfVMjj8yqbG2n72y4cchZK8M4qrfXn8SvXvWsZwWPWSfpOynxS1d1xpZAucd9jOV6/+r7Jd3v1BiNEGgm4g5bS7uzRkBu/eC1eIJaYDvX9EIuOcOcv2ST3YZw4iCv9GG6ZmftqWO9WOn7bh33HD5yNw4kuWiyGLqVLVzVrayV1vL7WETdDKOa72Fhb4/nxeQTySFl41T2cAPnFNUayx2+a8w62Soo0IWKSdxmbdJO12hMagfpHL6OX/U9/vUnKZUWjVjG6yPID/YFu1j2tLxFwFsOuRZUVpnukrvpBMpXrUQR6rjcDcKwljaEwroGaWI3ZlBjhpLwXhq+ra4ICt35hPjukUGXZL3UUR61MB3aCbbxguDupQyad/yDIyXzRlVyfrblyxaZo+FMgzzER1tHyo0NYu0QAXSI9mSWaTZpJq0XMsj0bOJpZS+I6Ew0tcdjSxIpMt/BdlU36h/t767xg4h9EUqIUg2nFdD1rC4x0jhrl72vb4o2S6Y4aezbAr2T0M5ur0x2qjDDANGy84iIcTd0B6jzpR0VR53aFl3Z0+vA9Ru/b8Ds+r3ytYTlFDZsB033HxKBbWkB7wrnZZ+vuxHYLal4A8n2axY09imH4Q2bKiQ/lZLK/ULJ8q1HpVu8ieudhqt8WSw+qfWaF7x7Uzu8hlfgdf1CublGqkrDy7EJbi0u3t3yXvUIRLa9Dk3UC56lL+fHT4jKmnVsIgCR3SYjDqPa7HUW9qvMvklQzkueszRkt7xvez/Pk60Spnqzx0NGPi7uWoe81unbQb7cKbgzfZPjmBi9W9fOfpZ+g/cwurZTgsfBCyWTpV3erK1TyYpSj3yj6VjYkWkEw+iFkdsNUgxBVqF4v2q8fdBfHxCa2B3mkYcczkCOXugUuUM7my8PWLc5IPV4ReOUzQjWZEDMxCWnY+dkcMIuU75LGzS2Kche3CRaWJPxlEz4YTm7aUeuGNXaJ7a9VlwYzKspaGdGwJuyzCfJ9I96NbXc27OJzTvansjXRDkrrOYcFIXRbyjDQyoOAvEGeNBv57/dJF3Q61Tpcxs9cihdJtGu9Aok+lPibk0RidDa4QlLFPPKWs8XVvom+Js05ScuakJf0vo/MqU0EYqkp5hAZfLuW76iLCVy9/b3Q0dPBfqo1o19Gb6s8OQBDnPQhsrEumxbm/l28WUiWH6YrSbkJL/qw27qCMXKTGk8AdzbC9Ih3eGoylx5ruppp53P1Afi3L3NfEliKGV97Rn1jf1+qKzUPRTgxwTs+0+IYKZuskyQT7tdeoahe4zt4Ndf7LjIe6GpXtQuVd1O5r1Ua5HR1gntswPVLQfJpM1JW1G34vNFFhQwaT0/YmriWTQ7ICm5+SSyL65I6vDYIqz3rbFvEMhNJa2vqkrJB/2hPmpsMqWEedjZeAZ7N+1KlVI+XM8nPWtHtnTLe6ETG8Q0HFWIHWb/K06sHXnCPCJ7bspIiC4VBTMRqZMiCTglet7Qy06OHTRzbz/uo+pEMRbgjuHC93hy7IqM2lWff1u79Hx1OlX3hqqnenf5ptmOKAdN3tY3+khPCZ0vrXntDIVpen4iRb5ORIjglFcVagKqK/ulNzY6ZrNgrxBm2VfZrQ3V0bheUutrm8Ivb1z1l3wd+L22Qw1n5tLNJrL9IHyHG0zoZFN/hqzS9LfoPhecJFmHkdLrcTJfQ+vL/CkBIeGfJtcvbDcWzJUPRD7rsPa4CLkoXk7jvWKatzPO8KSCbC6T1egt2sqCywOePE0lSwBHuuu5Xtxz0pCzsOeR6yoEMY0RS/xpyAt+vSRDixVUNotm+qmeuBkttdmZiWOes+cziMsbZE+tlJHc2gziNi/rOEwTszUX/es+ty3itavJVO/zJdWRqzI3n7qqSTfMvk/68NI5jDFV6jn9Vqrl+hM+VsCedjxucu+ZkKxq/Xv198l/p668uv84lIhfPrDlcb5gfhAwYmX8ZOg25DC0GYzmQ+zw9bF99BLlCCp9b0e2edlX9IUz11OFezskB0kzcN75KN0ZFEZIMvISEzI7xXUA/hpnRq6lxCEDiRFry68v6Qffs6syrWuIpgqCjsg4wthLyhM07bK9IUvhV3bi0Mm9Vt/9G7t83mSEJEeD66VdcRTXPuR+I4+brQRNnH66emWDkEtlkY8PyXExsCTOr0OPKW0ubAQqDKcaZt3VHk7k7hmH0rNeKDcmcp0rb2VukGgpH9aiqffUpuwyEVf5yaLXnIje36tdvh+9xvOZnkwzSZNtvbvep8wTTq8knC+KpPu5r2OiSH87vAOTb5mOjOytAN2dddXqDTia0r9iS6gTRe6Q+1u82x/W3y+N3kfPlNfmgzmyf5xHRFvUxBVUvcOR4FiKUwUVPmyIE47TWhcd+0iqYNIywkpujxEo07+qUJH35e9lyxPZHkqtm62dahA7C61kf74YOXMjOX5Q3BW5SJifLZxqv63nKZGoIuXbWId6UJja7QseVd4THdnRN9thrPAPI9xTHFUc23eP8AVfaum2RGSYRjobtnKbrYHwkc56tNYO3UgcI0J+OE36dWFYd5U31SDpu+bc0lhLC6MD2CpnYQcGb79J/XVD2hc4dwbWgirlBoayjl59qdRyw8ThrcfE8FJv+SZW9lOt2w4ORhrniOgDLd9UJgfEOWwnw4uqyZ1WfF8exE0ROLFrpGUsnWZXU+nsKnWcdzZ6jqvUSc/suVjpBwT7d10+reQcvft2k0+U20E52uFuGi1T3TN/nX2p34yXbbi3uK/PZE2ZYJJ1O+BzSLWM4LqZuZIU295rdfNOvk/4o5DtTjoQ93c5vksf0qxOrl9HMqfdjn6wwcEI68ITh/0Bfvl2zY79cqgP+bxvY6cvuPPhJjFGnvUzKhTCM09lt1eFo0rBFA92erwq2DLBbYfk/4uBo9Utn0GbKx//wNM+mmQR+zLzrVZhObNIMMr7KdXoRH79gF4eU24vi1++5bh87rqyrNLXruu6sIlhPBVzHPbSg37wKjnKK08FKZ6XBTlkQbaT1g9eJSznteemrztd2SVzVMdklcQCyjP3ketsQ04lXM9vZdS7/5jx6C2OCR2z44nUhsc5ASeZ9xRH8jUOLozmVxMNdRgd51bVb/Cfan83lW0G6q4c2nn0d/HwcPlce+0BheGvYhhsA8PPYpkxL+bvd8mjpX6a8O1RjnPoItutDTsOtSZuCjtffnz7xOTqToVBDp0qXdsXbQ0r2eCOedB4kJ+8ThPOyk8TDZfj/2Va7E4jbjIdYvfOkScZKDZiIvF6Fa4lSkpgbmShyCOi1vpX3cfsz73kOTRJjiLR9fNh/8keOWA5Y+Cm/dj7xuNoDPsUbl627jT+ZPJukO2fisPDAqe9n9Q54ETQKaofFLD2hhOV0eT44ZpHLpUmg9sBzQY3BU8lyUfVR4RUNnM5csjNoEwn+IUK5Ac6KtOQTzZ7nk2MxHrGrI73ciK9mDPOevplpiw5Jx9jhG+ZNRUnEKKQo+KMBm3BDffRVW88ZrDlmFtrb88Pj3U0aaCd3UxPEDdklAll6Hm80+2+j3p/SxYarIV5OtKrt8P2d9fq9PTqqPPjA2LpqgZ6i+qnWQt1VRQ2j8d4K8ugN8AMHJP+dw8MFX89DxlPanqRsfoantPHY32ctjkD10lrc3dtsKJfKYdQFycPA6de+ugTEdnNXngYe0OnLm9KJkZvK19/QQiprKd24S0Nb+FlKJfWCrjQ9+qh4e9FKTng6xv+U2s7LJ4+r1Z3m0aG323T6ZXi2776jlzz1EEnUHG7Q8NtXnSheBE0Vck6qj9qolJ/+Pt3mpnpEBmeEnb1a3/M6U1yE3ZxsN/GyurlBtHCo2y7rjqZuNRg/1x3d7iSTzRi97DgNV/DRQ9Vo9JpnyGBX2YGcJpwqmvJnm7umd7S7vbptrNvNkhAr5TfCQpkeWQ8ak1/PylW5piokuL9iYZsugXyferRur4dqkPXPlJefdzwOMEjQ2zjlolN3jqJgkKAaP9BOJNtX6n6PBN7MVlWIGs1vyZe8LVjMQa8zvPmpnL6VmrGc9FZsP73kldX63HWLBcUILYvx5DN8C/XdDS+o6ON9JqK1xInOlHOWF3TP/1ayO2d7OWqxReaflX5uRD4nZiYfJXvUKmgbXvyVVHB7FZX8iGOoPTySgNZps7izubb8Df95w4HG+RNs4K8Y/t+bYTQ7817ecxS6gjP8dME4IwAsj+maEVzC37RgYYAXl/2+SlT+2RTkQ6AunDxF5T9n1IZBep42tOMgQRBf7/4O/3vP//z/39SyXhJLwJd0G/nzX68xvPl6cOAylezp3Vy9svpj5HMN/Un7ESl0+7+VcVBHifxy83n22nPeyJbhb/yUvQIYlt0+R+VR15RvjlKcOEX97ln3D592/wV2/1PQeHmhcrN27HHjW9NOZ3Yezk1W8lad33TXP/vf82vqeO6iRf/M3nE1UyY5EwyBSG+XjiyIYIgfwGaazdF4Z20YWGX8Mpxyahv0UBqmU/7NHfNgJt+DacjFWVyveYoN/1Fy/DCf/wXC6kDyh5jGAA="} -->
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["title"],"name":[1],"type":["chr"],"align":["left"]},{"label":["abstract"],"name":[2],"type":["chr"],"align":["left"]},{"label":["journal"],"name":[3],"type":["chr"],"align":["left"]},{"label":["DOI"],"name":[4],"type":["chr"],"align":["left"]},{"label":["year"],"name":[5],"type":["chr"],"align":["left"]},{"label":["keyword"],"name":[6],"type":["chr"],"align":["left"]}],"data":[{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"Algorithms"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"Biomedical Research"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"methods"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"trends"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"Computational Biology"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"methods"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"trends"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"Data Mining"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"Electronic Health Records"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"Genome-Wide Association Study"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"Humans"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"Machine Learning"},{"1":"The Tension Between Big Data and Theory in the &quot;Omics&quot; Era of Biomedical Research.","2":"","3":"Perspectives in biology and medicine","4":"30613031","5":"2019","6":"Models, Theoretical"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Cell Line, Tumor"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Female"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Humans"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Immunogenetics"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"methods"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Machine Learning"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Signal Transduction"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Survival Analysis"},{"1":"Classification of triple-negative breast cancers based on Immunogenomic profiling.","2":"BACKGROUND: Abundant evidence shows that triple-negative breast cancer (TNBC) is heterogeneous, and many efforts have been devoted to identifying TNBC subtypes on the basis of genomic profiling. However, few studies have explored the classification of TNBC specifically based on immune signatures that may facilitate the optimal stratification of TNBC patients responsive to immunotherapy.METHODS: Using four publicly available TNBC genomics datasets, we classified TNBC on the basis of the immunogenomic profiling of 29 immune signatures. Unsupervised and supervised machine learning methods were used to perform the classification.RESULTS: We identified three TNBC subtypes that we named Immunity High (Immunity_H), Immunity Medium (Immunity_M), and Immunity Low (Immunity_L) and demonstrated that this classification was reliable and predictable by analyzing multiple different datasets. Immunity_H was characterized by greater immune cell infiltration and anti-tumor immune activities, as well as better survival prognosis compared to the other subtypes. Besides the immune signatures, some cancer-associated pathways were hyperactivated in Immunity_H, including apoptosis, calcium signaling, MAPK signaling, PI3K-Akt signaling, and RAS signaling. In contrast, Immunity_L presented depressed immune signatures and increased activation of cell cycle, Hippo signaling, DNA replication, mismatch repair, cell adhesion molecule binding, spliceosome, adherens junction function, pyrimidine metabolism, glycosylphosphatidylinositol (GPI)-anchor biosynthesis, and RNA polymerase pathways. Furthermore, we identified a gene co-expression subnetwork centered around five transcription factor (TF) genes (CORO1A, STAT4, BCL11B, ZNF831, and EOMES) specifically significant in the Immunity_H subtype and a subnetwork centered around two TF genes (IRF8 and SPI1) characteristic of the Immunity_L subtype.CONCLUSIONS: The identification of TNBC subtypes based on immune signatures has potential clinical implications for TNBC treatment.","3":"Journal of experimental &amp; clinical cancer research : CR","4":"30594216","5":"2018","6":"Triple Negative Breast Neoplasms"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Colorectal Neoplasms"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"diagnostic imaging"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Diagnosis, Computer-Assisted"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"methods"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Endoscopy, Gastrointestinal"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"methods"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Humans"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Image Processing, Computer-Assisted"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"methods"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Machine Learning"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Neural Networks (Computer)"},{"1":"Methodology to develop machine learning algorithms to improve performance in gastrointestinal endoscopy.","2":"Assisted diagnosis using artificial intelligence has been a holy grail in medical research for many years, and recent developments in computer hardware have enabled the narrower area of machine learning to equip clinicians with potentially useful tools for computer assisted diagnosis (CAD) systems. However, training and assessing a computer's ability to diagnose like a human are complex tasks, and successful outcomes depend on various factors. We have focused our work on gastrointestinal (GI) endoscopy because it is a cornerstone for diagnosis and treatment of diseases of the GI tract. About 2.8 million luminal GI (esophageal, stomach, colorectal) cancers are detected globally every year, and although substantial technical improvements in endoscopes have been made over the last 10-15 years, a major limitation of endoscopic examinations remains operator variation. This translates into a substantial inter-observer variation in the detection and assessment of mucosal lesions, causing among other things an average polyp miss-rate of 20% in the colon and thus the subsequent development of a number of post-colonoscopy colorectal cancers. CAD systems might eliminate this variation and lead to more accurate diagnoses. In this editorial, we point out some of the current challenges in the development of efficient computer-based digital assistants. We give examples of proposed tools using various techniques, identify current challenges, and give suggestions for the development and assessment of future CAD systems.","3":"World journal of gastroenterology","4":"30568383","5":"2018","6":"Observer Variation"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Brain Neoplasms"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"diagnosis"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Humans"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Sensitivity and Specificity"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Spectrophotometry, Infrared"},{"1":"SVM Optimization for Brain Tumor Identification Using Infrared Spectroscopic Samples.","2":"The work presented in this paper is focused on the use of spectroscopy to identify the type of tissue of human brain samples employing support vector machine classifiers. Two different spectrometers were used to acquire infrared spectroscopic signatures in the wavenumber range between 1200<U+207B>3500 cm<sup>-1<\/sup>. An extensive analysis was performed to find the optimal configuration for a support vector machine classifier and determine the most relevant regions of the spectra for this particular application. The results demonstrate that the developed algorithm is robust enough to classify the infrared spectroscopic data of human brain tissue at three different discrimination levels.","3":"Sensors (Basel, Switzerland)","4":"30567396","5":"2018","6":"Support Vector Machine"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Adult"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Electrodes"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Electroencephalography"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Female"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Humans"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Male"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Prefrontal Cortex"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"physiology"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Probability"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"ROC Curve"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Sleep"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"physiology"},{"1":"Portable Drowsiness Detection through Use of a Prefrontal Single-Channel Electroencephalogram.","2":"","3":"Sensors (Basel, Switzerland)","4":"30567347","5":"2018","6":"Support Vector Machine"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Altitude"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Ascomycota"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"isolation &amp; purification"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Bayes Theorem"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Brassica napus"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"microbiology"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Cold Temperature"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Image Processing, Computer-Assisted"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Plant Leaves"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"microbiology"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Remote Sensing Technology"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"methods"},{"1":"NA","2":"","3":"Sensors (Basel, Switzerland)","4":"30562959","5":"2018","6":"Support Vector Machine"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Brain"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"metabolism"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Datasets as Topic"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Deep Learning"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Enhancer Elements, Genetic"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenesis, Genetic"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Epigenomics"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Expression Regulation"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Gene Regulatory Networks"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Genome-Wide Association Study"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Humans"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Mental Disorders"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"genetics"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Quantitative Trait Loci"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Single-Cell Analysis"},{"1":"Comprehensive functional genomic resource and integrative model for the human brain.","2":"Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains ~79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with &gt;88% reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by ~6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.","3":"Science (New York, N.Y.)","4":"30545857","5":"2018","6":"Transcriptome"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Amino Acid Sequence"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bacterial Proteins"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Bayes Theorem"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Machine Learning"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Peptides"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"genetics"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Protein Binding"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Recombinant Proteins"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"metabolism"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Substrate Specificity"},{"1":"Discovering de novo peptide substrates for enzymes using machine learning.","2":"The discovery of peptide substrates for enzymes with exclusive, selective activities is a central goal in chemical biology. In this paper, we develop a hybrid computational and biochemical method to rapidly optimize peptides for specific, orthogonal biochemical functions. The method is an iterative machine learning process by which experimental data is deposited into a mathematical algorithm that selects potential peptide substrates to be tested experimentally. Once tested, the algorithm uses the experimental data to refine future selections. This process is repeated until a suitable set of de novo peptide substrates are discovered. We employed this technology to discover orthogonal peptide substrates for 4'-phosphopantetheinyl transferase, an enzyme class that covalently modifies proteins. In this manner, we have demonstrated that machine learning can be leveraged to guide peptide optimization for specific biochemical functions not immediately accessible by biological screening techniques, such as phage display and random mutagenesis.","3":"Nature communications","4":"30531862","5":"2018","6":"Transferases (Other Substituted Phosphate Groups)"},{"1":"Distinguishing crystallographic from biological interfaces in protein complexes: role of intermolecular contacts and energetics for classification.","2":"BACKGROUND: Study of macromolecular assemblies is fundamental to understand functions in cells. X-ray crystallography is the most common technique to solve their 3D structure at atomic resolution. In a crystal, however, both biologically-relevant interfaces and non-specific interfaces resulting from crystallographic packing are observed. Due to the complexity of the biological assemblies currently tackled, classifying those interfaces, i.e. distinguishing biological from crystal lattice interfaces, is not trivial and often prone to errors. In this context, analyzing the physico-chemical characteristics of biological/crystal interfaces can help researchers identify possible features that distinguish them and gain a better understanding of the systems.RESULTS: In this work, we are providing new insights into the differences between biological and crystallographic complexes by focusing on &quot;pair-properties&quot; of interfaces that have not yet been fully investigated. We investigated properties such intermolecular residue-residue contacts (already successfully applied to the prediction of binding affinities) and interaction energies (electrostatic, Van der Waals and desolvation). By using the XtalMany and BioMany interface datasets, we show that interfacial residue contacts, classified as a function of their physico-chemical properties, can distinguish between biological and crystallographic interfaces. The energetic terms show, on average, higher values for crystal interfaces, reflecting a less stable interface due to crystal packing compared to biological interfaces. By using a variety of machine learning approaches, we trained a new interface classification predictor based on contacts and interaction energetic features. Our predictor reaches an accuracy in classifying biological vs crystal interfaces of 0.92, compared to 0.88 for EPPIC (one of the main state-of-the-art classifiers reporting same performance as PISA).CONCLUSION: In this work we have gained insights into the nature of intermolecular contacts and energetics terms distinguishing biological from crystallographic interfaces. Our findings might have a broader applicability in structural biology, for example for the identification of near native poses in docking. We implemented our classification approach into an easy-to-use and fast software, freely available to the scientific community from http://github.com/haddocking/interface-classifier .","3":"BMC bioinformatics","4":"30497368","5":"2018","6":"Algorithms"},{"1":"Distinguishing crystallographic from biological interfaces in protein complexes: role of intermolecular contacts and energetics for classification.","2":"BACKGROUND: Study of macromolecular assemblies is fundamental to understand functions in cells. X-ray crystallography is the most common technique to solve their 3D structure at atomic resolution. In a crystal, however, both biologically-relevant interfaces and non-specific interfaces resulting from crystallographic packing are observed. Due to the complexity of the biological assemblies currently tackled, classifying those interfaces, i.e. distinguishing biological from crystal lattice interfaces, is not trivial and often prone to errors. In this context, analyzing the physico-chemical characteristics of biological/crystal interfaces can help researchers identify possible features that distinguish them and gain a better understanding of the systems.RESULTS: In this work, we are providing new insights into the differences between biological and crystallographic complexes by focusing on &quot;pair-properties&quot; of interfaces that have not yet been fully investigated. We investigated properties such intermolecular residue-residue contacts (already successfully applied to the prediction of binding affinities) and interaction energies (electrostatic, Van der Waals and desolvation). By using the XtalMany and BioMany interface datasets, we show that interfacial residue contacts, classified as a function of their physico-chemical properties, can distinguish between biological and crystallographic interfaces. The energetic terms show, on average, higher values for crystal interfaces, reflecting a less stable interface due to crystal packing compared to biological interfaces. By using a variety of machine learning approaches, we trained a new interface classification predictor based on contacts and interaction energetic features. Our predictor reaches an accuracy in classifying biological vs crystal interfaces of 0.92, compared to 0.88 for EPPIC (one of the main state-of-the-art classifiers reporting same performance as PISA).CONCLUSION: In this work we have gained insights into the nature of intermolecular contacts and energetics terms distinguishing biological from crystallographic interfaces. Our findings might have a broader applicability in structural biology, for example for the identification of near native poses in docking. We implemented our classification approach into an easy-to-use and fast software, freely available to the scientific community from http://github.com/haddocking/interface-classifier .","3":"BMC bioinformatics","4":"30497368","5":"2018","6":"Crystallography, X-Ray"},{"1":"Distinguishing crystallographic from biological interfaces in protein complexes: role of intermolecular contacts and energetics for classification.","2":"BACKGROUND: Study of macromolecular assemblies is fundamental to understand functions in cells. X-ray crystallography is the most common technique to solve their 3D structure at atomic resolution. In a crystal, however, both biologically-relevant interfaces and non-specific interfaces resulting from crystallographic packing are observed. Due to the complexity of the biological assemblies currently tackled, classifying those interfaces, i.e. distinguishing biological from crystal lattice interfaces, is not trivial and often prone to errors. In this context, analyzing the physico-chemical characteristics of biological/crystal interfaces can help researchers identify possible features that distinguish them and gain a better understanding of the systems.RESULTS: In this work, we are providing new insights into the differences between biological and crystallographic complexes by focusing on &quot;pair-properties&quot; of interfaces that have not yet been fully investigated. We investigated properties such intermolecular residue-residue contacts (already successfully applied to the prediction of binding affinities) and interaction energies (electrostatic, Van der Waals and desolvation). By using the XtalMany and BioMany interface datasets, we show that interfacial residue contacts, classified as a function of their physico-chemical properties, can distinguish between biological and crystallographic interfaces. The energetic terms show, on average, higher values for crystal interfaces, reflecting a less stable interface due to crystal packing compared to biological interfaces. By using a variety of machine learning approaches, we trained a new interface classification predictor based on contacts and interaction energetic features. Our predictor reaches an accuracy in classifying biological vs crystal interfaces of 0.92, compared to 0.88 for EPPIC (one of the main state-of-the-art classifiers reporting same performance as PISA).CONCLUSION: In this work we have gained insights into the nature of intermolecular contacts and energetics terms distinguishing biological from crystallographic interfaces. Our findings might have a broader applicability in structural biology, for example for the identification of near native poses in docking. We implemented our classification approach into an easy-to-use and fast software, freely available to the scientific community from http://github.com/haddocking/interface-classifier .","3":"BMC bioinformatics","4":"30497368","5":"2018","6":"Databases, Protein"},{"1":"Distinguishing crystallographic from biological interfaces in protein complexes: role of intermolecular contacts and energetics for classification.","2":"BACKGROUND: Study of macromolecular assemblies is fundamental to understand functions in cells. X-ray crystallography is the most common technique to solve their 3D structure at atomic resolution. In a crystal, however, both biologically-relevant interfaces and non-specific interfaces resulting from crystallographic packing are observed. Due to the complexity of the biological assemblies currently tackled, classifying those interfaces, i.e. distinguishing biological from crystal lattice interfaces, is not trivial and often prone to errors. In this context, analyzing the physico-chemical characteristics of biological/crystal interfaces can help researchers identify possible features that distinguish them and gain a better understanding of the systems.RESULTS: In this work, we are providing new insights into the differences between biological and crystallographic complexes by focusing on &quot;pair-properties&quot; of interfaces that have not yet been fully investigated. We investigated properties such intermolecular residue-residue contacts (already successfully applied to the prediction of binding affinities) and interaction energies (electrostatic, Van der Waals and desolvation). By using the XtalMany and BioMany interface datasets, we show that interfacial residue contacts, classified as a function of their physico-chemical properties, can distinguish between biological and crystallographic interfaces. The energetic terms show, on average, higher values for crystal interfaces, reflecting a less stable interface due to crystal packing compared to biological interfaces. By using a variety of machine learning approaches, we trained a new interface classification predictor based on contacts and interaction energetic features. Our predictor reaches an accuracy in classifying biological vs crystal interfaces of 0.92, compared to 0.88 for EPPIC (one of the main state-of-the-art classifiers reporting same performance as PISA).CONCLUSION: In this work we have gained insights into the nature of intermolecular contacts and energetics terms distinguishing biological from crystallographic interfaces. Our findings might have a broader applicability in structural biology, for example for the identification of near native poses in docking. We implemented our classification approach into an easy-to-use and fast software, freely available to the scientific community from http://github.com/haddocking/interface-classifier .","3":"BMC bioinformatics","4":"30497368","5":"2018","6":"Energy Metabolism"},{"1":"Distinguishing crystallographic from biological interfaces in protein complexes: role of intermolecular contacts and energetics for classification.","2":"BACKGROUND: Study of macromolecular assemblies is fundamental to understand functions in cells. X-ray crystallography is the most common technique to solve their 3D structure at atomic resolution. In a crystal, however, both biologically-relevant interfaces and non-specific interfaces resulting from crystallographic packing are observed. Due to the complexity of the biological assemblies currently tackled, classifying those interfaces, i.e. distinguishing biological from crystal lattice interfaces, is not trivial and often prone to errors. In this context, analyzing the physico-chemical characteristics of biological/crystal interfaces can help researchers identify possible features that distinguish them and gain a better understanding of the systems.RESULTS: In this work, we are providing new insights into the differences between biological and crystallographic complexes by focusing on &quot;pair-properties&quot; of interfaces that have not yet been fully investigated. We investigated properties such intermolecular residue-residue contacts (already successfully applied to the prediction of binding affinities) and interaction energies (electrostatic, Van der Waals and desolvation). By using the XtalMany and BioMany interface datasets, we show that interfacial residue contacts, classified as a function of their physico-chemical properties, can distinguish between biological and crystallographic interfaces. The energetic terms show, on average, higher values for crystal interfaces, reflecting a less stable interface due to crystal packing compared to biological interfaces. By using a variety of machine learning approaches, we trained a new interface classification predictor based on contacts and interaction energetic features. Our predictor reaches an accuracy in classifying biological vs crystal interfaces of 0.92, compared to 0.88 for EPPIC (one of the main state-of-the-art classifiers reporting same performance as PISA).CONCLUSION: In this work we have gained insights into the nature of intermolecular contacts and energetics terms distinguishing biological from crystallographic interfaces. Our findings might have a broader applicability in structural biology, for example for the identification of near native poses in docking. We implemented our classification approach into an easy-to-use and fast software, freely available to the scientific community from http://github.com/haddocking/interface-classifier .","3":"BMC bioinformatics","4":"30497368","5":"2018","6":"Machine Learning"},{"1":"Distinguishing crystallographic from biological interfaces in protein complexes: role of intermolecular contacts and energetics for classification.","2":"BACKGROUND: Study of macromolecular assemblies is fundamental to understand functions in cells. X-ray crystallography is the most common technique to solve their 3D structure at atomic resolution. In a crystal, however, both biologically-relevant interfaces and non-specific interfaces resulting from crystallographic packing are observed. Due to the complexity of the biological assemblies currently tackled, classifying those interfaces, i.e. distinguishing biological from crystal lattice interfaces, is not trivial and often prone to errors. In this context, analyzing the physico-chemical characteristics of biological/crystal interfaces can help researchers identify possible features that distinguish them and gain a better understanding of the systems.RESULTS: In this work, we are providing new insights into the differences between biological and crystallographic complexes by focusing on &quot;pair-properties&quot; of interfaces that have not yet been fully investigated. We investigated properties such intermolecular residue-residue contacts (already successfully applied to the prediction of binding affinities) and interaction energies (electrostatic, Van der Waals and desolvation). By using the XtalMany and BioMany interface datasets, we show that interfacial residue contacts, classified as a function of their physico-chemical properties, can distinguish between biological and crystallographic interfaces. The energetic terms show, on average, higher values for crystal interfaces, reflecting a less stable interface due to crystal packing compared to biological interfaces. By using a variety of machine learning approaches, we trained a new interface classification predictor based on contacts and interaction energetic features. Our predictor reaches an accuracy in classifying biological vs crystal interfaces of 0.92, compared to 0.88 for EPPIC (one of the main state-of-the-art classifiers reporting same performance as PISA).CONCLUSION: In this work we have gained insights into the nature of intermolecular contacts and energetics terms distinguishing biological from crystallographic interfaces. Our findings might have a broader applicability in structural biology, for example for the identification of near native poses in docking. We implemented our classification approach into an easy-to-use and fast software, freely available to the scientific community from http://github.com/haddocking/interface-classifier .","3":"BMC bioinformatics","4":"30497368","5":"2018","6":"Proteins"},{"1":"Distinguishing crystallographic from biological interfaces in protein complexes: role of intermolecular contacts and energetics for classification.","2":"BACKGROUND: Study of macromolecular assemblies is fundamental to understand functions in cells. X-ray crystallography is the most common technique to solve their 3D structure at atomic resolution. In a crystal, however, both biologically-relevant interfaces and non-specific interfaces resulting from crystallographic packing are observed. Due to the complexity of the biological assemblies currently tackled, classifying those interfaces, i.e. distinguishing biological from crystal lattice interfaces, is not trivial and often prone to errors. In this context, analyzing the physico-chemical characteristics of biological/crystal interfaces can help researchers identify possible features that distinguish them and gain a better understanding of the systems.RESULTS: In this work, we are providing new insights into the differences between biological and crystallographic complexes by focusing on &quot;pair-properties&quot; of interfaces that have not yet been fully investigated. We investigated properties such intermolecular residue-residue contacts (already successfully applied to the prediction of binding affinities) and interaction energies (electrostatic, Van der Waals and desolvation). By using the XtalMany and BioMany interface datasets, we show that interfacial residue contacts, classified as a function of their physico-chemical properties, can distinguish between biological and crystallographic interfaces. The energetic terms show, on average, higher values for crystal interfaces, reflecting a less stable interface due to crystal packing compared to biological interfaces. By using a variety of machine learning approaches, we trained a new interface classification predictor based on contacts and interaction energetic features. Our predictor reaches an accuracy in classifying biological vs crystal interfaces of 0.92, compared to 0.88 for EPPIC (one of the main state-of-the-art classifiers reporting same performance as PISA).CONCLUSION: In this work we have gained insights into the nature of intermolecular contacts and energetics terms distinguishing biological from crystallographic interfaces. Our findings might have a broader applicability in structural biology, for example for the identification of near native poses in docking. We implemented our classification approach into an easy-to-use and fast software, freely available to the scientific community from http://github.com/haddocking/interface-classifier .","3":"BMC bioinformatics","4":"30497368","5":"2018","6":"chemistry"},{"1":"Distinguishing crystallographic from biological interfaces in protein complexes: role of intermolecular contacts and energetics for classification.","2":"BACKGROUND: Study of macromolecular assemblies is fundamental to understand functions in cells. X-ray crystallography is the most common technique to solve their 3D structure at atomic resolution. In a crystal, however, both biologically-relevant interfaces and non-specific interfaces resulting from crystallographic packing are observed. Due to the complexity of the biological assemblies currently tackled, classifying those interfaces, i.e. distinguishing biological from crystal lattice interfaces, is not trivial and often prone to errors. In this context, analyzing the physico-chemical characteristics of biological/crystal interfaces can help researchers identify possible features that distinguish them and gain a better understanding of the systems.RESULTS: In this work, we are providing new insights into the differences between biological and crystallographic complexes by focusing on &quot;pair-properties&quot; of interfaces that have not yet been fully investigated. We investigated properties such intermolecular residue-residue contacts (already successfully applied to the prediction of binding affinities) and interaction energies (electrostatic, Van der Waals and desolvation). By using the XtalMany and BioMany interface datasets, we show that interfacial residue contacts, classified as a function of their physico-chemical properties, can distinguish between biological and crystallographic interfaces. The energetic terms show, on average, higher values for crystal interfaces, reflecting a less stable interface due to crystal packing compared to biological interfaces. By using a variety of machine learning approaches, we trained a new interface classification predictor based on contacts and interaction energetic features. Our predictor reaches an accuracy in classifying biological vs crystal interfaces of 0.92, compared to 0.88 for EPPIC (one of the main state-of-the-art classifiers reporting same performance as PISA).CONCLUSION: In this work we have gained insights into the nature of intermolecular contacts and energetics terms distinguishing biological from crystallographic interfaces. Our findings might have a broader applicability in structural biology, for example for the identification of near native poses in docking. We implemented our classification approach into an easy-to-use and fast software, freely available to the scientific community from http://github.com/haddocking/interface-classifier .","3":"BMC bioinformatics","4":"30497368","5":"2018","6":"Reproducibility of Results"},{"1":"Distinguishing crystallographic from biological interfaces in protein complexes: role of intermolecular contacts and energetics for classification.","2":"BACKGROUND: Study of macromolecular assemblies is fundamental to understand functions in cells. X-ray crystallography is the most common technique to solve their 3D structure at atomic resolution. In a crystal, however, both biologically-relevant interfaces and non-specific interfaces resulting from crystallographic packing are observed. Due to the complexity of the biological assemblies currently tackled, classifying those interfaces, i.e. distinguishing biological from crystal lattice interfaces, is not trivial and often prone to errors. In this context, analyzing the physico-chemical characteristics of biological/crystal interfaces can help researchers identify possible features that distinguish them and gain a better understanding of the systems.RESULTS: In this work, we are providing new insights into the differences between biological and crystallographic complexes by focusing on &quot;pair-properties&quot; of interfaces that have not yet been fully investigated. We investigated properties such intermolecular residue-residue contacts (already successfully applied to the prediction of binding affinities) and interaction energies (electrostatic, Van der Waals and desolvation). By using the XtalMany and BioMany interface datasets, we show that interfacial residue contacts, classified as a function of their physico-chemical properties, can distinguish between biological and crystallographic interfaces. The energetic terms show, on average, higher values for crystal interfaces, reflecting a less stable interface due to crystal packing compared to biological interfaces. By using a variety of machine learning approaches, we trained a new interface classification predictor based on contacts and interaction energetic features. Our predictor reaches an accuracy in classifying biological vs crystal interfaces of 0.92, compared to 0.88 for EPPIC (one of the main state-of-the-art classifiers reporting same performance as PISA).CONCLUSION: In this work we have gained insights into the nature of intermolecular contacts and energetics terms distinguishing biological from crystallographic interfaces. Our findings might have a broader applicability in structural biology, for example for the identification of near native poses in docking. We implemented our classification approach into an easy-to-use and fast software, freely available to the scientific community from http://github.com/haddocking/interface-classifier .","3":"BMC bioinformatics","4":"30497368","5":"2018","6":"Static Electricity"},{"1":"A Semantic-Based Gas Source Localization with a Mobile Robot Combining Vision and Chemical Sensing.","2":"This paper addresses the localization of a gas emission source within a real-world human environment with a mobile robot. Our approach is based on an efficient and coherent system that fuses different sensor modalities (i.e., vision and chemical sensing) to exploit, for the first time, the semantic relationships among the detected gases and the objects visually recognized in the environment. This novel approach allows the robot to focus the search on a finite set of potential gas source candidates (dynamically updated as the robot operates), while accounting for the non-negligible uncertainties in the object recognition and gas classification tasks involved in the process. This approach is particularly interesting for structured indoor environments containing multiple obstacles and objects, enabling the inference of the relations between objects and between objects and gases. A probabilistic Bayesian framework is proposed to handle all these uncertainties and semantic relations, providing an ordered list of candidates to be the source. This candidate list is updated dynamically upon new sensor measurements to account for objects not previously considered in the search process. The exploitation of such probabilities together with information such as the locations of the objects, or the time needed to validate whether a given candidate is truly releasing gases, is delegated to a path planning algorithm based on Markov decision processes to minimize the search time. The system was tested in an office-like scenario, both with simulated and real experiments, to enable the comparison of different path planning strategies and to validate its efficiency under real-world conditions.","3":"Sensors (Basel, Switzerland)","4":"30487414","5":"2018","6":"Algorithms"},{"1":"A Semantic-Based Gas Source Localization with a Mobile Robot Combining Vision and Chemical Sensing.","2":"This paper addresses the localization of a gas emission source within a real-world human environment with a mobile robot. Our approach is based on an efficient and coherent system that fuses different sensor modalities (i.e., vision and chemical sensing) to exploit, for the first time, the semantic relationships among the detected gases and the objects visually recognized in the environment. This novel approach allows the robot to focus the search on a finite set of potential gas source candidates (dynamically updated as the robot operates), while accounting for the non-negligible uncertainties in the object recognition and gas classification tasks involved in the process. This approach is particularly interesting for structured indoor environments containing multiple obstacles and objects, enabling the inference of the relations between objects and between objects and gases. A probabilistic Bayesian framework is proposed to handle all these uncertainties and semantic relations, providing an ordered list of candidates to be the source. This candidate list is updated dynamically upon new sensor measurements to account for objects not previously considered in the search process. The exploitation of such probabilities together with information such as the locations of the objects, or the time needed to validate whether a given candidate is truly releasing gases, is delegated to a path planning algorithm based on Markov decision processes to minimize the search time. The system was tested in an office-like scenario, both with simulated and real experiments, to enable the comparison of different path planning strategies and to validate its efficiency under real-world conditions.","3":"Sensors (Basel, Switzerland)","4":"30487414","5":"2018","6":"Artificial Intelligence"},{"1":"A Semantic-Based Gas Source Localization with a Mobile Robot Combining Vision and Chemical Sensing.","2":"This paper addresses the localization of a gas emission source within a real-world human environment with a mobile robot. Our approach is based on an efficient and coherent system that fuses different sensor modalities (i.e., vision and chemical sensing) to exploit, for the first time, the semantic relationships among the detected gases and the objects visually recognized in the environment. This novel approach allows the robot to focus the search on a finite set of potential gas source candidates (dynamically updated as the robot operates), while accounting for the non-negligible uncertainties in the object recognition and gas classification tasks involved in the process. This approach is particularly interesting for structured indoor environments containing multiple obstacles and objects, enabling the inference of the relations between objects and between objects and gases. A probabilistic Bayesian framework is proposed to handle all these uncertainties and semantic relations, providing an ordered list of candidates to be the source. This candidate list is updated dynamically upon new sensor measurements to account for objects not previously considered in the search process. The exploitation of such probabilities together with information such as the locations of the objects, or the time needed to validate whether a given candidate is truly releasing gases, is delegated to a path planning algorithm based on Markov decision processes to minimize the search time. The system was tested in an office-like scenario, both with simulated and real experiments, to enable the comparison of different path planning strategies and to validate its efficiency under real-world conditions.","3":"Sensors (Basel, Switzerland)","4":"30487414","5":"2018","6":"Bayes Theorem"},{"1":"A Semantic-Based Gas Source Localization with a Mobile Robot Combining Vision and Chemical Sensing.","2":"This paper addresses the localization of a gas emission source within a real-world human environment with a mobile robot. Our approach is based on an efficient and coherent system that fuses different sensor modalities (i.e., vision and chemical sensing) to exploit, for the first time, the semantic relationships among the detected gases and the objects visually recognized in the environment. This novel approach allows the robot to focus the search on a finite set of potential gas source candidates (dynamically updated as the robot operates), while accounting for the non-negligible uncertainties in the object recognition and gas classification tasks involved in the process. This approach is particularly interesting for structured indoor environments containing multiple obstacles and objects, enabling the inference of the relations between objects and between objects and gases. A probabilistic Bayesian framework is proposed to handle all these uncertainties and semantic relations, providing an ordered list of candidates to be the source. This candidate list is updated dynamically upon new sensor measurements to account for objects not previously considered in the search process. The exploitation of such probabilities together with information such as the locations of the objects, or the time needed to validate whether a given candidate is truly releasing gases, is delegated to a path planning algorithm based on Markov decision processes to minimize the search time. The system was tested in an office-like scenario, both with simulated and real experiments, to enable the comparison of different path planning strategies and to validate its efficiency under real-world conditions.","3":"Sensors (Basel, Switzerland)","4":"30487414","5":"2018","6":"Machine Learning"},{"1":"A Semantic-Based Gas Source Localization with a Mobile Robot Combining Vision and Chemical Sensing.","2":"This paper addresses the localization of a gas emission source within a real-world human environment with a mobile robot. Our approach is based on an efficient and coherent system that fuses different sensor modalities (i.e., vision and chemical sensing) to exploit, for the first time, the semantic relationships among the detected gases and the objects visually recognized in the environment. This novel approach allows the robot to focus the search on a finite set of potential gas source candidates (dynamically updated as the robot operates), while accounting for the non-negligible uncertainties in the object recognition and gas classification tasks involved in the process. This approach is particularly interesting for structured indoor environments containing multiple obstacles and objects, enabling the inference of the relations between objects and between objects and gases. A probabilistic Bayesian framework is proposed to handle all these uncertainties and semantic relations, providing an ordered list of candidates to be the source. This candidate list is updated dynamically upon new sensor measurements to account for objects not previously considered in the search process. The exploitation of such probabilities together with information such as the locations of the objects, or the time needed to validate whether a given candidate is truly releasing gases, is delegated to a path planning algorithm based on Markov decision processes to minimize the search time. The system was tested in an office-like scenario, both with simulated and real experiments, to enable the comparison of different path planning strategies and to validate its efficiency under real-world conditions.","3":"Sensors (Basel, Switzerland)","4":"30487414","5":"2018","6":"Pattern Recognition, Automated"},{"1":"A Semantic-Based Gas Source Localization with a Mobile Robot Combining Vision and Chemical Sensing.","2":"This paper addresses the localization of a gas emission source within a real-world human environment with a mobile robot. Our approach is based on an efficient and coherent system that fuses different sensor modalities (i.e., vision and chemical sensing) to exploit, for the first time, the semantic relationships among the detected gases and the objects visually recognized in the environment. This novel approach allows the robot to focus the search on a finite set of potential gas source candidates (dynamically updated as the robot operates), while accounting for the non-negligible uncertainties in the object recognition and gas classification tasks involved in the process. This approach is particularly interesting for structured indoor environments containing multiple obstacles and objects, enabling the inference of the relations between objects and between objects and gases. A probabilistic Bayesian framework is proposed to handle all these uncertainties and semantic relations, providing an ordered list of candidates to be the source. This candidate list is updated dynamically upon new sensor measurements to account for objects not previously considered in the search process. The exploitation of such probabilities together with information such as the locations of the objects, or the time needed to validate whether a given candidate is truly releasing gases, is delegated to a path planning algorithm based on Markov decision processes to minimize the search time. The system was tested in an office-like scenario, both with simulated and real experiments, to enable the comparison of different path planning strategies and to validate its efficiency under real-world conditions.","3":"Sensors (Basel, Switzerland)","4":"30487414","5":"2018","6":"Robotics"},{"1":"Optimised spectral pre-processing for discrimination of biofluids via ATR-FTIR spectroscopy.","2":"Pre-processing is an essential step in the analysis of spectral data. Mid-IR spectroscopy of biological samples is often subject to instrumental and sample specific variances which may often conceal valuable biological information. Whilst pre-processing can effectively reduce this unwanted variance, the plethora of possible processing steps has resulted in a lack of consensus in the field, often meaning that analysis outputs are not comparable. As pre-processing is specific to the sample under investigation, here we present a systematic approach for defining the optimum pre-processing protocol for biofluid ATR-FTIR spectroscopy. Using a trial-and-error based approach and a clinically relevant dataset describing control and brain cancer patients, the effects of pre-processing permutations on subsequent classification algorithms were observed, by assessing key diagnostic performance parameters, including sensitivity and specificity. It was found that optimum diagnostic performance correlated with the use of minimal binning and baseline correction, with derivative functions improving diagnostic performance most significantly. If smoothing is required, a Sovitzky-Golay approach was the preferred option in this investigation. Heavy binning appeared to reduce classification most significantly, alongside wavelet noise reduction (filter length =6), resulting in the lowest diagnostic performances of all pre-processing permutations tested.","3":"The Analyst","4":"30484797","5":"2018","6":"Adolescent"},{"1":"Optimised spectral pre-processing for discrimination of biofluids via ATR-FTIR spectroscopy.","2":"Pre-processing is an essential step in the analysis of spectral data. Mid-IR spectroscopy of biological samples is often subject to instrumental and sample specific variances which may often conceal valuable biological information. Whilst pre-processing can effectively reduce this unwanted variance, the plethora of possible processing steps has resulted in a lack of consensus in the field, often meaning that analysis outputs are not comparable. As pre-processing is specific to the sample under investigation, here we present a systematic approach for defining the optimum pre-processing protocol for biofluid ATR-FTIR spectroscopy. Using a trial-and-error based approach and a clinically relevant dataset describing control and brain cancer patients, the effects of pre-processing permutations on subsequent classification algorithms were observed, by assessing key diagnostic performance parameters, including sensitivity and specificity. It was found that optimum diagnostic performance correlated with the use of minimal binning and baseline correction, with derivative functions improving diagnostic performance most significantly. If smoothing is required, a Sovitzky-Golay approach was the preferred option in this investigation. Heavy binning appeared to reduce classification most significantly, alongside wavelet noise reduction (filter length =6), resulting in the lowest diagnostic performances of all pre-processing permutations tested.","3":"The Analyst","4":"30484797","5":"2018","6":"Adult"},{"1":"Optimised spectral pre-processing for discrimination of biofluids via ATR-FTIR spectroscopy.","2":"Pre-processing is an essential step in the analysis of spectral data. Mid-IR spectroscopy of biological samples is often subject to instrumental and sample specific variances which may often conceal valuable biological information. Whilst pre-processing can effectively reduce this unwanted variance, the plethora of possible processing steps has resulted in a lack of consensus in the field, often meaning that analysis outputs are not comparable. As pre-processing is specific to the sample under investigation, here we present a systematic approach for defining the optimum pre-processing protocol for biofluid ATR-FTIR spectroscopy. Using a trial-and-error based approach and a clinically relevant dataset describing control and brain cancer patients, the effects of pre-processing permutations on subsequent classification algorithms were observed, by assessing key diagnostic performance parameters, including sensitivity and specificity. It was found that optimum diagnostic performance correlated with the use of minimal binning and baseline correction, with derivative functions improving diagnostic performance most significantly. If smoothing is required, a Sovitzky-Golay approach was the preferred option in this investigation. Heavy binning appeared to reduce classification most significantly, alongside wavelet noise reduction (filter length =6), resulting in the lowest diagnostic performances of all pre-processing permutations tested.","3":"The Analyst","4":"30484797","5":"2018","6":"Aged"},{"1":"Optimised spectral pre-processing for discrimination of biofluids via ATR-FTIR spectroscopy.","2":"Pre-processing is an essential step in the analysis of spectral data. Mid-IR spectroscopy of biological samples is often subject to instrumental and sample specific variances which may often conceal valuable biological information. Whilst pre-processing can effectively reduce this unwanted variance, the plethora of possible processing steps has resulted in a lack of consensus in the field, often meaning that analysis outputs are not comparable. As pre-processing is specific to the sample under investigation, here we present a systematic approach for defining the optimum pre-processing protocol for biofluid ATR-FTIR spectroscopy. Using a trial-and-error based approach and a clinically relevant dataset describing control and brain cancer patients, the effects of pre-processing permutations on subsequent classification algorithms were observed, by assessing key diagnostic performance parameters, including sensitivity and specificity. It was found that optimum diagnostic performance correlated with the use of minimal binning and baseline correction, with derivative functions improving diagnostic performance most significantly. If smoothing is required, a Sovitzky-Golay approach was the preferred option in this investigation. Heavy binning appeared to reduce classification most significantly, alongside wavelet noise reduction (filter length =6), resulting in the lowest diagnostic performances of all pre-processing permutations tested.","3":"The Analyst","4":"30484797","5":"2018","6":"Aged, 80 and over"},{"1":"Optimised spectral pre-processing for discrimination of biofluids via ATR-FTIR spectroscopy.","2":"Pre-processing is an essential step in the analysis of spectral data. Mid-IR spectroscopy of biological samples is often subject to instrumental and sample specific variances which may often conceal valuable biological information. Whilst pre-processing can effectively reduce this unwanted variance, the plethora of possible processing steps has resulted in a lack of consensus in the field, often meaning that analysis outputs are not comparable. As pre-processing is specific to the sample under investigation, here we present a systematic approach for defining the optimum pre-processing protocol for biofluid ATR-FTIR spectroscopy. Using a trial-and-error based approach and a clinically relevant dataset describing control and brain cancer patients, the effects of pre-processing permutations on subsequent classification algorithms were observed, by assessing key diagnostic performance parameters, including sensitivity and specificity. It was found that optimum diagnostic performance correlated with the use of minimal binning and baseline correction, with derivative functions improving diagnostic performance most significantly. If smoothing is required, a Sovitzky-Golay approach was the preferred option in this investigation. Heavy binning appeared to reduce classification most significantly, alongside wavelet noise reduction (filter length =6), resulting in the lowest diagnostic performances of all pre-processing permutations tested.","3":"The Analyst","4":"30484797","5":"2018","6":"Algorithms"},{"1":"Optimised spectral pre-processing for discrimination of biofluids via ATR-FTIR spectroscopy.","2":"Pre-processing is an essential step in the analysis of spectral data. Mid-IR spectroscopy of biological samples is often subject to instrumental and sample specific variances which may often conceal valuable biological information. Whilst pre-processing can effectively reduce this unwanted variance, the plethora of possible processing steps has resulted in a lack of consensus in the field, often meaning that analysis outputs are not comparable. As pre-processing is specific to the sample under investigation, here we present a systematic approach for defining the optimum pre-processing protocol for biofluid ATR-FTIR spectroscopy. Using a trial-and-error based approach and a clinically relevant dataset describing control and brain cancer patients, the effects of pre-processing permutations on subsequent classification algorithms were observed, by assessing key diagnostic performance parameters, including sensitivity and specificity. It was found that optimum diagnostic performance correlated with the use of minimal binning and baseline correction, with derivative functions improving diagnostic performance most significantly. If smoothing is required, a Sovitzky-Golay approach was the preferred option in this investigation. Heavy binning appeared to reduce classification most significantly, alongside wavelet noise reduction (filter length =6), resulting in the lowest diagnostic performances of all pre-processing permutations tested.","3":"The Analyst","4":"30484797","5":"2018","6":"Blood Chemical Analysis"},{"1":"Optimised spectral pre-processing for discrimination of biofluids via ATR-FTIR spectroscopy.","2":"Pre-processing is an essential step in the analysis of spectral data. Mid-IR spectroscopy of biological samples is often subject to instrumental and sample specific variances which may often conceal valuable biological information. Whilst pre-processing can effectively reduce this unwanted variance, the plethora of possible processing steps has resulted in a lack of consensus in the field, often meaning that analysis outputs are not comparable. As pre-processing is specific to the sample under investigation, here we present a systematic approach for defining the optimum pre-processing protocol for biofluid ATR-FTIR spectroscopy. Using a trial-and-error based approach and a clinically relevant dataset describing control and brain cancer patients, the effects of pre-processing permutations on subsequent classification algorithms were observed, by assessing key diagnostic performance parameters, including sensitivity and specificity. It was found that optimum diagnostic performance correlated with the use of minimal binning and baseline correction, with derivative functions improving diagnostic performance most significantly. If smoothing is required, a Sovitzky-Golay approach was the preferred option in this investigation. Heavy binning appeared to reduce classification most significantly, alongside wavelet noise reduction (filter length =6), resulting in the lowest diagnostic performances of all pre-processing permutations tested.","3":"The Analyst","4":"30484797","5":"2018","6":"statistics &amp; numerical data"},{"1":"Optimised spectral pre-processing for discrimination of biofluids via ATR-FTIR spectroscopy.","2":"Pre-processing is an essential step in the analysis of spectral data. Mid-IR spectroscopy of biological samples is often subject to instrumental and sample specific variances which may often conceal valuable biological information. Whilst pre-processing can effectively reduce this unwanted variance, the plethora of possible processing steps has resulted in a lack of consensus in the field, often meaning that analysis outputs are not comparable. As pre-processing is specific to the sample under investigation, here we present a systematic approach for defining the optimum pre-processing protocol for biofluid ATR-FTIR spectroscopy. Using a trial-and-error based approach and a clinically relevant dataset describing control and brain cancer patients, the effects of pre-processing permutations on subsequent classification algorithms were observed, by assessing key diagnostic performance parameters, including sensitivity and specificity. It was found that optimum diagnostic performance correlated with the use of minimal binning and baseline correction, with derivative functions improving diagnostic performance most significantly. If smoothing is required, a Sovitzky-Golay approach was the preferred option in this investigation. Heavy binning appeared to reduce classification most significantly, alongside wavelet noise reduction (filter length =6), resulting in the lowest diagnostic performances of all pre-processing permutations tested.","3":"The Analyst","4":"30484797","5":"2018","6":"Brain Neoplasms"},{"1":"Optimised spectral pre-processing for discrimination of biofluids via ATR-FTIR spectroscopy.","2":"Pre-processing is an essential step in the analysis of spectral data. Mid-IR spectroscopy of biological samples is often subject to instrumental and sample specific variances which may often conceal valuable biological information. Whilst pre-processing can effectively reduce this unwanted variance, the plethora of possible processing steps has resulted in a lack of consensus in the field, often meaning that analysis outputs are not comparable. As pre-processing is specific to the sample under investigation, here we present a systematic approach for defining the optimum pre-processing protocol for biofluid ATR-FTIR spectroscopy. Using a trial-and-error based approach and a clinically relevant dataset describing control and brain cancer patients, the effects of pre-processing permutations on subsequent classification algorithms were observed, by assessing key diagnostic performance parameters, including sensitivity and specificity. It was found that optimum diagnostic performance correlated with the use of minimal binning and baseline correction, with derivative functions improving diagnostic performance most significantly. If smoothing is required, a Sovitzky-Golay approach was the preferred option in this investigation. Heavy binning appeared to reduce classification most significantly, alongside wavelet noise reduction (filter length =6), resulting in the lowest diagnostic performances of all pre-processing permutations tested.","3":"The Analyst","4":"30484797","5":"2018","6":"blood"},{"1":"Optimised spectral pre-processing for discrimination of biofluids via ATR-FTIR spectroscopy.","2":"Pre-processing is an essential step in the analysis of spectral data. Mid-IR spectroscopy of biological samples is often subject to instrumental and sample specific variances which may often conceal valuable biological information. Whilst pre-processing can effectively reduce this unwanted variance, the plethora of possible processing steps has resulted in a lack of consensus in the field, often meaning that analysis outputs are not comparable. As pre-processing is specific to the sample under investigation, here we present a systematic approach for defining the optimum pre-processing protocol for biofluid ATR-FTIR spectroscopy. Using a trial-and-error based approach and a clinically relevant dataset describing control and brain cancer patients, the effects of pre-processing permutations on subsequent classification algorithms were observed, by assessing key diagnostic performance parameters, including sensitivity and specificity. It was found that optimum diagnostic performance correlated with the use of minimal binning and baseline correction, with derivative functions improving diagnostic performance most significantly. If smoothing is required, a Sovitzky-Golay approach was the preferred option in this investigation. Heavy binning appeared to reduce classification most significantly, alongside wavelet noise reduction (filter length =6), resulting in the lowest diagnostic performances of all pre-processing permutations tested.","3":"The Analyst","4":"30484797","5":"2018","6":"diagnosis"},{"1":"Optimised spectral pre-processing for discrimination of biofluids via ATR-FTIR spectroscopy.","2":"Pre-processing is an essential step in the analysis of spectral data. Mid-IR spectroscopy of biological samples is often subject to instrumental and sample specific variances which may often conceal valuable biological information. Whilst pre-processing can effectively reduce this unwanted variance, the plethora of possible processing steps has resulted in a lack of consensus in the field, often meaning that analysis outputs are not comparable. As pre-processing is specific to the sample under investigation, here we present a systematic approach for defining the optimum pre-processing protocol for biofluid ATR-FTIR spectroscopy. Using a trial-and-error based approach and a clinically relevant dataset describing control and brain cancer patients, the effects of pre-processing permutations on subsequent classification algorithms were observed, by assessing key diagnostic performance parameters, including sensitivity and specificity. It was found that optimum diagnostic performance correlated with the use of minimal binning and baseline correction, with derivative functions improving diagnostic performance most significantly. If smoothing is required, a Sovitzky-Golay approach was the preferred option in this investigation. Heavy binning appeared to reduce classification most significantly, alongside wavelet noise reduction (filter length =6), resulting in the lowest diagnostic performances of all pre-processing permutations tested.","3":"The Analyst","4":"30484797","5":"2018","6":"Datasets as Topic"},{"1":"Optimised spectral pre-processing for discrimination of biofluids via ATR-FTIR spectroscopy.","2":"Pre-processing is an essential step in the analysis of spectral data. Mid-IR spectroscopy of biological samples is often subject to instrumental and sample specific variances which may often conceal valuable biological information. Whilst pre-processing can effectively reduce this unwanted variance, the plethora of possible processing steps has resulted in a lack of consensus in the field, often meaning that analysis outputs are not comparable. As pre-processing is specific to the sample under investigation, here we present a systematic approach for defining the optimum pre-processing protocol for biofluid ATR-FTIR spectroscopy. Using a trial-and-error based approach and a clinically relevant dataset describing control and brain cancer patients, the effects of pre-processing permutations on subsequent classification algorithms were observed, by assessing key diagnostic performance parameters, including sensitivity and specificity. It was found that optimum diagnostic performance correlated with the use of minimal binning and baseline correction, with derivative functions improving diagnostic performance most significantly. If smoothing is required, a Sovitzky-Golay approach was the preferred option in this investigation. Heavy binning appeared to reduce classification most significantly, alongside wavelet noise reduction (filter length =6), resulting in the lowest diagnostic performances of all pre-processing permutations tested.","3":"The Analyst","4":"30484797","5":"2018","6":"Female"},{"1":"Optimised spectral pre-processing for discrimination of biofluids via ATR-FTIR spectroscopy.","2":"Pre-processing is an essential step in the analysis of spectral data. Mid-IR spectroscopy of biological samples is often subject to instrumental and sample specific variances which may often conceal valuable biological information. Whilst pre-processing can effectively reduce this unwanted variance, the plethora of possible processing steps has resulted in a lack of consensus in the field, often meaning that analysis outputs are not comparable. As pre-processing is specific to the sample under investigation, here we present a systematic approach for defining the optimum pre-processing protocol for biofluid ATR-FTIR spectroscopy. Using a trial-and-error based approach and a clinically relevant dataset describing control and brain cancer patients, the effects of pre-processing permutations on subsequent classification algorithms were observed, by assessing key diagnostic performance parameters, including sensitivity and specificity. It was found that optimum diagnostic performance correlated with the use of minimal binning and baseline correction, with derivative functions improving diagnostic performance most significantly. If smoothing is required, a Sovitzky-Golay approach was the preferred option in this investigation. Heavy binning appeared to reduce classification most significantly, alongside wavelet noise reduction (filter length =6), resulting in the lowest diagnostic performances of all pre-processing permutations tested.","3":"The Analyst","4":"30484797","5":"2018","6":"Humans"},{"1":"Optimised spectral pre-processing for discrimination of biofluids via ATR-FTIR spectroscopy.","2":"Pre-processing is an essential step in the analysis of spectral data. Mid-IR spectroscopy of biological samples is often subject to instrumental and sample specific variances which may often conceal valuable biological information. Whilst pre-processing can effectively reduce this unwanted variance, the plethora of possible processing steps has resulted in a lack of consensus in the field, often meaning that analysis outputs are not comparable. As pre-processing is specific to the sample under investigation, here we present a systematic approach for defining the optimum pre-processing protocol for biofluid ATR-FTIR spectroscopy. Using a trial-and-error based approach and a clinically relevant dataset describing control and brain cancer patients, the effects of pre-processing permutations on subsequent classification algorithms were observed, by assessing key diagnostic performance parameters, including sensitivity and specificity. It was found that optimum diagnostic performance correlated with the use of minimal binning and baseline correction, with derivative functions improving diagnostic performance most significantly. If smoothing is required, a Sovitzky-Golay approach was the preferred option in this investigation. Heavy binning appeared to reduce classification most significantly, alongside wavelet noise reduction (filter length =6), resulting in the lowest diagnostic performances of all pre-processing permutations tested.","3":"The Analyst","4":"30484797","5":"2018","6":"Machine Learning"},{"1":"Optimised spectral pre-processing for discrimination of biofluids via ATR-FTIR spectroscopy.","2":"Pre-processing is an essential step in the analysis of spectral data. Mid-IR spectroscopy of biological samples is often subject to instrumental and sample specific variances which may often conceal valuable biological information. Whilst pre-processing can effectively reduce this unwanted variance, the plethora of possible processing steps has resulted in a lack of consensus in the field, often meaning that analysis outputs are not comparable. As pre-processing is specific to the sample under investigation, here we present a systematic approach for defining the optimum pre-processing protocol for biofluid ATR-FTIR spectroscopy. Using a trial-and-error based approach and a clinically relevant dataset describing control and brain cancer patients, the effects of pre-processing permutations on subsequent classification algorithms were observed, by assessing key diagnostic performance parameters, including sensitivity and specificity. It was found that optimum diagnostic performance correlated with the use of minimal binning and baseline correction, with derivative functions improving diagnostic performance most significantly. If smoothing is required, a Sovitzky-Golay approach was the preferred option in this investigation. Heavy binning appeared to reduce classification most significantly, alongside wavelet noise reduction (filter length =6), resulting in the lowest diagnostic performances of all pre-processing permutations tested.","3":"The Analyst","4":"30484797","5":"2018","6":"Male"},{"1":"Optimised spectral pre-processing for discrimination of biofluids via ATR-FTIR spectroscopy.","2":"Pre-processing is an essential step in the analysis of spectral data. Mid-IR spectroscopy of biological samples is often subject to instrumental and sample specific variances which may often conceal valuable biological information. Whilst pre-processing can effectively reduce this unwanted variance, the plethora of possible processing steps has resulted in a lack of consensus in the field, often meaning that analysis outputs are not comparable. As pre-processing is specific to the sample under investigation, here we present a systematic approach for defining the optimum pre-processing protocol for biofluid ATR-FTIR spectroscopy. Using a trial-and-error based approach and a clinically relevant dataset describing control and brain cancer patients, the effects of pre-processing permutations on subsequent classification algorithms were observed, by assessing key diagnostic performance parameters, including sensitivity and specificity. It was found that optimum diagnostic performance correlated with the use of minimal binning and baseline correction, with derivative functions improving diagnostic performance most significantly. If smoothing is required, a Sovitzky-Golay approach was the preferred option in this investigation. Heavy binning appeared to reduce classification most significantly, alongside wavelet noise reduction (filter length =6), resulting in the lowest diagnostic performances of all pre-processing permutations tested.","3":"The Analyst","4":"30484797","5":"2018","6":"Middle Aged"},{"1":"Optimised spectral pre-processing for discrimination of biofluids via ATR-FTIR spectroscopy.","2":"Pre-processing is an essential step in the analysis of spectral data. Mid-IR spectroscopy of biological samples is often subject to instrumental and sample specific variances which may often conceal valuable biological information. Whilst pre-processing can effectively reduce this unwanted variance, the plethora of possible processing steps has resulted in a lack of consensus in the field, often meaning that analysis outputs are not comparable. As pre-processing is specific to the sample under investigation, here we present a systematic approach for defining the optimum pre-processing protocol for biofluid ATR-FTIR spectroscopy. Using a trial-and-error based approach and a clinically relevant dataset describing control and brain cancer patients, the effects of pre-processing permutations on subsequent classification algorithms were observed, by assessing key diagnostic performance parameters, including sensitivity and specificity. It was found that optimum diagnostic performance correlated with the use of minimal binning and baseline correction, with derivative functions improving diagnostic performance most significantly. If smoothing is required, a Sovitzky-Golay approach was the preferred option in this investigation. Heavy binning appeared to reduce classification most significantly, alongside wavelet noise reduction (filter length =6), resulting in the lowest diagnostic performances of all pre-processing permutations tested.","3":"The Analyst","4":"30484797","5":"2018","6":"Sensitivity and Specificity"},{"1":"Optimised spectral pre-processing for discrimination of biofluids via ATR-FTIR spectroscopy.","2":"Pre-processing is an essential step in the analysis of spectral data. Mid-IR spectroscopy of biological samples is often subject to instrumental and sample specific variances which may often conceal valuable biological information. Whilst pre-processing can effectively reduce this unwanted variance, the plethora of possible processing steps has resulted in a lack of consensus in the field, often meaning that analysis outputs are not comparable. As pre-processing is specific to the sample under investigation, here we present a systematic approach for defining the optimum pre-processing protocol for biofluid ATR-FTIR spectroscopy. Using a trial-and-error based approach and a clinically relevant dataset describing control and brain cancer patients, the effects of pre-processing permutations on subsequent classification algorithms were observed, by assessing key diagnostic performance parameters, including sensitivity and specificity. It was found that optimum diagnostic performance correlated with the use of minimal binning and baseline correction, with derivative functions improving diagnostic performance most significantly. If smoothing is required, a Sovitzky-Golay approach was the preferred option in this investigation. Heavy binning appeared to reduce classification most significantly, alongside wavelet noise reduction (filter length =6), resulting in the lowest diagnostic performances of all pre-processing permutations tested.","3":"The Analyst","4":"30484797","5":"2018","6":"Spectroscopy, Fourier Transform Infrared"},{"1":"Optimised spectral pre-processing for discrimination of biofluids via ATR-FTIR spectroscopy.","2":"Pre-processing is an essential step in the analysis of spectral data. Mid-IR spectroscopy of biological samples is often subject to instrumental and sample specific variances which may often conceal valuable biological information. Whilst pre-processing can effectively reduce this unwanted variance, the plethora of possible processing steps has resulted in a lack of consensus in the field, often meaning that analysis outputs are not comparable. As pre-processing is specific to the sample under investigation, here we present a systematic approach for defining the optimum pre-processing protocol for biofluid ATR-FTIR spectroscopy. Using a trial-and-error based approach and a clinically relevant dataset describing control and brain cancer patients, the effects of pre-processing permutations on subsequent classification algorithms were observed, by assessing key diagnostic performance parameters, including sensitivity and specificity. It was found that optimum diagnostic performance correlated with the use of minimal binning and baseline correction, with derivative functions improving diagnostic performance most significantly. If smoothing is required, a Sovitzky-Golay approach was the preferred option in this investigation. Heavy binning appeared to reduce classification most significantly, alongside wavelet noise reduction (filter length =6), resulting in the lowest diagnostic performances of all pre-processing permutations tested.","3":"The Analyst","4":"30484797","5":"2018","6":"methods"},{"1":"Optimised spectral pre-processing for discrimination of biofluids via ATR-FTIR spectroscopy.","2":"Pre-processing is an essential step in the analysis of spectral data. Mid-IR spectroscopy of biological samples is often subject to instrumental and sample specific variances which may often conceal valuable biological information. Whilst pre-processing can effectively reduce this unwanted variance, the plethora of possible processing steps has resulted in a lack of consensus in the field, often meaning that analysis outputs are not comparable. As pre-processing is specific to the sample under investigation, here we present a systematic approach for defining the optimum pre-processing protocol for biofluid ATR-FTIR spectroscopy. Using a trial-and-error based approach and a clinically relevant dataset describing control and brain cancer patients, the effects of pre-processing permutations on subsequent classification algorithms were observed, by assessing key diagnostic performance parameters, including sensitivity and specificity. It was found that optimum diagnostic performance correlated with the use of minimal binning and baseline correction, with derivative functions improving diagnostic performance most significantly. If smoothing is required, a Sovitzky-Golay approach was the preferred option in this investigation. Heavy binning appeared to reduce classification most significantly, alongside wavelet noise reduction (filter length =6), resulting in the lowest diagnostic performances of all pre-processing permutations tested.","3":"The Analyst","4":"30484797","5":"2018","6":"Young Adult"},{"1":"Diagnosis of nasopharyngeal carcinoma from serum samples using hyperspectral imaging combined with a chemometric method.","2":"Diagnosing nasopharyngeal carcinoma (NPC) is a significant challenge because of the highly complex process. We proposed an approach to diagnose NPC serum using a combination of hyperspectral imaging and weight-based principal component analysis. Samples were prepared by pressing boric acid into pellets for use as the sera substrate. The sera, collected from 100 healthy volunteers and 60 NPC patients, was dripped onto the surface of the substrate for hyperspectral imaging. The characteristic spectral bands were selected based on the variable weight obtained from a support vector machine (SVM) model, using principal component analysis (PCA) to reduce the dimension in the extracted bands. Obtained results show that the accuracy rate, sensitivity, and specificity between the NPC sera and the sera of the healthy controls reached extremely high levels of 99.15%, 98.79%, and 99.36%, respectively. For the model's consistency evaluation, we found that the Kappa and area under the curve (AUC) of the receiver operating characteristic (ROC) curve were 0.99 and 0.98, respectively. These results suggest that the developed approach could serve as a noninvasive diagnostic and screening tool for highly accurate and consistent detection of NPC. Hence, a combination of hyperspectral imaging (HSI) and a weighted principal component analysis (WPCA)-SVM model represents a powerful and promising tool for NPC diagnosis.","3":"Optics express","4":"30470039","5":"2018","6":"Biomarkers, Tumor"},{"1":"Diagnosis of nasopharyngeal carcinoma from serum samples using hyperspectral imaging combined with a chemometric method.","2":"Diagnosing nasopharyngeal carcinoma (NPC) is a significant challenge because of the highly complex process. We proposed an approach to diagnose NPC serum using a combination of hyperspectral imaging and weight-based principal component analysis. Samples were prepared by pressing boric acid into pellets for use as the sera substrate. The sera, collected from 100 healthy volunteers and 60 NPC patients, was dripped onto the surface of the substrate for hyperspectral imaging. The characteristic spectral bands were selected based on the variable weight obtained from a support vector machine (SVM) model, using principal component analysis (PCA) to reduce the dimension in the extracted bands. Obtained results show that the accuracy rate, sensitivity, and specificity between the NPC sera and the sera of the healthy controls reached extremely high levels of 99.15%, 98.79%, and 99.36%, respectively. For the model's consistency evaluation, we found that the Kappa and area under the curve (AUC) of the receiver operating characteristic (ROC) curve were 0.99 and 0.98, respectively. These results suggest that the developed approach could serve as a noninvasive diagnostic and screening tool for highly accurate and consistent detection of NPC. Hence, a combination of hyperspectral imaging (HSI) and a weighted principal component analysis (WPCA)-SVM model represents a powerful and promising tool for NPC diagnosis.","3":"Optics express","4":"30470039","5":"2018","6":"blood"},{"1":"Diagnosis of nasopharyngeal carcinoma from serum samples using hyperspectral imaging combined with a chemometric method.","2":"Diagnosing nasopharyngeal carcinoma (NPC) is a significant challenge because of the highly complex process. We proposed an approach to diagnose NPC serum using a combination of hyperspectral imaging and weight-based principal component analysis. Samples were prepared by pressing boric acid into pellets for use as the sera substrate. The sera, collected from 100 healthy volunteers and 60 NPC patients, was dripped onto the surface of the substrate for hyperspectral imaging. The characteristic spectral bands were selected based on the variable weight obtained from a support vector machine (SVM) model, using principal component analysis (PCA) to reduce the dimension in the extracted bands. Obtained results show that the accuracy rate, sensitivity, and specificity between the NPC sera and the sera of the healthy controls reached extremely high levels of 99.15%, 98.79%, and 99.36%, respectively. For the model's consistency evaluation, we found that the Kappa and area under the curve (AUC) of the receiver operating characteristic (ROC) curve were 0.99 and 0.98, respectively. These results suggest that the developed approach could serve as a noninvasive diagnostic and screening tool for highly accurate and consistent detection of NPC. Hence, a combination of hyperspectral imaging (HSI) and a weighted principal component analysis (WPCA)-SVM model represents a powerful and promising tool for NPC diagnosis.","3":"Optics express","4":"30470039","5":"2018","6":"Humans"},{"1":"Diagnosis of nasopharyngeal carcinoma from serum samples using hyperspectral imaging combined with a chemometric method.","2":"Diagnosing nasopharyngeal carcinoma (NPC) is a significant challenge because of the highly complex process. We proposed an approach to diagnose NPC serum using a combination of hyperspectral imaging and weight-based principal component analysis. Samples were prepared by pressing boric acid into pellets for use as the sera substrate. The sera, collected from 100 healthy volunteers and 60 NPC patients, was dripped onto the surface of the substrate for hyperspectral imaging. The characteristic spectral bands were selected based on the variable weight obtained from a support vector machine (SVM) model, using principal component analysis (PCA) to reduce the dimension in the extracted bands. Obtained results show that the accuracy rate, sensitivity, and specificity between the NPC sera and the sera of the healthy controls reached extremely high levels of 99.15%, 98.79%, and 99.36%, respectively. For the model's consistency evaluation, we found that the Kappa and area under the curve (AUC) of the receiver operating characteristic (ROC) curve were 0.99 and 0.98, respectively. These results suggest that the developed approach could serve as a noninvasive diagnostic and screening tool for highly accurate and consistent detection of NPC. Hence, a combination of hyperspectral imaging (HSI) and a weighted principal component analysis (WPCA)-SVM model represents a powerful and promising tool for NPC diagnosis.","3":"Optics express","4":"30470039","5":"2018","6":"Nasopharyngeal Carcinoma"},{"1":"Diagnosis of nasopharyngeal carcinoma from serum samples using hyperspectral imaging combined with a chemometric method.","2":"Diagnosing nasopharyngeal carcinoma (NPC) is a significant challenge because of the highly complex process. We proposed an approach to diagnose NPC serum using a combination of hyperspectral imaging and weight-based principal component analysis. Samples were prepared by pressing boric acid into pellets for use as the sera substrate. The sera, collected from 100 healthy volunteers and 60 NPC patients, was dripped onto the surface of the substrate for hyperspectral imaging. The characteristic spectral bands were selected based on the variable weight obtained from a support vector machine (SVM) model, using principal component analysis (PCA) to reduce the dimension in the extracted bands. Obtained results show that the accuracy rate, sensitivity, and specificity between the NPC sera and the sera of the healthy controls reached extremely high levels of 99.15%, 98.79%, and 99.36%, respectively. For the model's consistency evaluation, we found that the Kappa and area under the curve (AUC) of the receiver operating characteristic (ROC) curve were 0.99 and 0.98, respectively. These results suggest that the developed approach could serve as a noninvasive diagnostic and screening tool for highly accurate and consistent detection of NPC. Hence, a combination of hyperspectral imaging (HSI) and a weighted principal component analysis (WPCA)-SVM model represents a powerful and promising tool for NPC diagnosis.","3":"Optics express","4":"30470039","5":"2018","6":"blood"},{"1":"Diagnosis of nasopharyngeal carcinoma from serum samples using hyperspectral imaging combined with a chemometric method.","2":"Diagnosing nasopharyngeal carcinoma (NPC) is a significant challenge because of the highly complex process. We proposed an approach to diagnose NPC serum using a combination of hyperspectral imaging and weight-based principal component analysis. Samples were prepared by pressing boric acid into pellets for use as the sera substrate. The sera, collected from 100 healthy volunteers and 60 NPC patients, was dripped onto the surface of the substrate for hyperspectral imaging. The characteristic spectral bands were selected based on the variable weight obtained from a support vector machine (SVM) model, using principal component analysis (PCA) to reduce the dimension in the extracted bands. Obtained results show that the accuracy rate, sensitivity, and specificity between the NPC sera and the sera of the healthy controls reached extremely high levels of 99.15%, 98.79%, and 99.36%, respectively. For the model's consistency evaluation, we found that the Kappa and area under the curve (AUC) of the receiver operating characteristic (ROC) curve were 0.99 and 0.98, respectively. These results suggest that the developed approach could serve as a noninvasive diagnostic and screening tool for highly accurate and consistent detection of NPC. Hence, a combination of hyperspectral imaging (HSI) and a weighted principal component analysis (WPCA)-SVM model represents a powerful and promising tool for NPC diagnosis.","3":"Optics express","4":"30470039","5":"2018","6":"diagnosis"},{"1":"Diagnosis of nasopharyngeal carcinoma from serum samples using hyperspectral imaging combined with a chemometric method.","2":"Diagnosing nasopharyngeal carcinoma (NPC) is a significant challenge because of the highly complex process. We proposed an approach to diagnose NPC serum using a combination of hyperspectral imaging and weight-based principal component analysis. Samples were prepared by pressing boric acid into pellets for use as the sera substrate. The sera, collected from 100 healthy volunteers and 60 NPC patients, was dripped onto the surface of the substrate for hyperspectral imaging. The characteristic spectral bands were selected based on the variable weight obtained from a support vector machine (SVM) model, using principal component analysis (PCA) to reduce the dimension in the extracted bands. Obtained results show that the accuracy rate, sensitivity, and specificity between the NPC sera and the sera of the healthy controls reached extremely high levels of 99.15%, 98.79%, and 99.36%, respectively. For the model's consistency evaluation, we found that the Kappa and area under the curve (AUC) of the receiver operating characteristic (ROC) curve were 0.99 and 0.98, respectively. These results suggest that the developed approach could serve as a noninvasive diagnostic and screening tool for highly accurate and consistent detection of NPC. Hence, a combination of hyperspectral imaging (HSI) and a weighted principal component analysis (WPCA)-SVM model represents a powerful and promising tool for NPC diagnosis.","3":"Optics express","4":"30470039","5":"2018","6":"Principal Component Analysis"},{"1":"Diagnosis of nasopharyngeal carcinoma from serum samples using hyperspectral imaging combined with a chemometric method.","2":"Diagnosing nasopharyngeal carcinoma (NPC) is a significant challenge because of the highly complex process. We proposed an approach to diagnose NPC serum using a combination of hyperspectral imaging and weight-based principal component analysis. Samples were prepared by pressing boric acid into pellets for use as the sera substrate. The sera, collected from 100 healthy volunteers and 60 NPC patients, was dripped onto the surface of the substrate for hyperspectral imaging. The characteristic spectral bands were selected based on the variable weight obtained from a support vector machine (SVM) model, using principal component analysis (PCA) to reduce the dimension in the extracted bands. Obtained results show that the accuracy rate, sensitivity, and specificity between the NPC sera and the sera of the healthy controls reached extremely high levels of 99.15%, 98.79%, and 99.36%, respectively. For the model's consistency evaluation, we found that the Kappa and area under the curve (AUC) of the receiver operating characteristic (ROC) curve were 0.99 and 0.98, respectively. These results suggest that the developed approach could serve as a noninvasive diagnostic and screening tool for highly accurate and consistent detection of NPC. Hence, a combination of hyperspectral imaging (HSI) and a weighted principal component analysis (WPCA)-SVM model represents a powerful and promising tool for NPC diagnosis.","3":"Optics express","4":"30470039","5":"2018","6":"ROC Curve"},{"1":"Diagnosis of nasopharyngeal carcinoma from serum samples using hyperspectral imaging combined with a chemometric method.","2":"Diagnosing nasopharyngeal carcinoma (NPC) is a significant challenge because of the highly complex process. We proposed an approach to diagnose NPC serum using a combination of hyperspectral imaging and weight-based principal component analysis. Samples were prepared by pressing boric acid into pellets for use as the sera substrate. The sera, collected from 100 healthy volunteers and 60 NPC patients, was dripped onto the surface of the substrate for hyperspectral imaging. The characteristic spectral bands were selected based on the variable weight obtained from a support vector machine (SVM) model, using principal component analysis (PCA) to reduce the dimension in the extracted bands. Obtained results show that the accuracy rate, sensitivity, and specificity between the NPC sera and the sera of the healthy controls reached extremely high levels of 99.15%, 98.79%, and 99.36%, respectively. For the model's consistency evaluation, we found that the Kappa and area under the curve (AUC) of the receiver operating characteristic (ROC) curve were 0.99 and 0.98, respectively. These results suggest that the developed approach could serve as a noninvasive diagnostic and screening tool for highly accurate and consistent detection of NPC. Hence, a combination of hyperspectral imaging (HSI) and a weighted principal component analysis (WPCA)-SVM model represents a powerful and promising tool for NPC diagnosis.","3":"Optics express","4":"30470039","5":"2018","6":"Sensitivity and Specificity"},{"1":"Diagnosis of nasopharyngeal carcinoma from serum samples using hyperspectral imaging combined with a chemometric method.","2":"Diagnosing nasopharyngeal carcinoma (NPC) is a significant challenge because of the highly complex process. We proposed an approach to diagnose NPC serum using a combination of hyperspectral imaging and weight-based principal component analysis. Samples were prepared by pressing boric acid into pellets for use as the sera substrate. The sera, collected from 100 healthy volunteers and 60 NPC patients, was dripped onto the surface of the substrate for hyperspectral imaging. The characteristic spectral bands were selected based on the variable weight obtained from a support vector machine (SVM) model, using principal component analysis (PCA) to reduce the dimension in the extracted bands. Obtained results show that the accuracy rate, sensitivity, and specificity between the NPC sera and the sera of the healthy controls reached extremely high levels of 99.15%, 98.79%, and 99.36%, respectively. For the model's consistency evaluation, we found that the Kappa and area under the curve (AUC) of the receiver operating characteristic (ROC) curve were 0.99 and 0.98, respectively. These results suggest that the developed approach could serve as a noninvasive diagnostic and screening tool for highly accurate and consistent detection of NPC. Hence, a combination of hyperspectral imaging (HSI) and a weighted principal component analysis (WPCA)-SVM model represents a powerful and promising tool for NPC diagnosis.","3":"Optics express","4":"30470039","5":"2018","6":"Spectrophotometry, Infrared"},{"1":"Diagnosis of nasopharyngeal carcinoma from serum samples using hyperspectral imaging combined with a chemometric method.","2":"Diagnosing nasopharyngeal carcinoma (NPC) is a significant challenge because of the highly complex process. We proposed an approach to diagnose NPC serum using a combination of hyperspectral imaging and weight-based principal component analysis. Samples were prepared by pressing boric acid into pellets for use as the sera substrate. The sera, collected from 100 healthy volunteers and 60 NPC patients, was dripped onto the surface of the substrate for hyperspectral imaging. The characteristic spectral bands were selected based on the variable weight obtained from a support vector machine (SVM) model, using principal component analysis (PCA) to reduce the dimension in the extracted bands. Obtained results show that the accuracy rate, sensitivity, and specificity between the NPC sera and the sera of the healthy controls reached extremely high levels of 99.15%, 98.79%, and 99.36%, respectively. For the model's consistency evaluation, we found that the Kappa and area under the curve (AUC) of the receiver operating characteristic (ROC) curve were 0.99 and 0.98, respectively. These results suggest that the developed approach could serve as a noninvasive diagnostic and screening tool for highly accurate and consistent detection of NPC. Hence, a combination of hyperspectral imaging (HSI) and a weighted principal component analysis (WPCA)-SVM model represents a powerful and promising tool for NPC diagnosis.","3":"Optics express","4":"30470039","5":"2018","6":"methods"},{"1":"Diagnosis of nasopharyngeal carcinoma from serum samples using hyperspectral imaging combined with a chemometric method.","2":"Diagnosing nasopharyngeal carcinoma (NPC) is a significant challenge because of the highly complex process. We proposed an approach to diagnose NPC serum using a combination of hyperspectral imaging and weight-based principal component analysis. Samples were prepared by pressing boric acid into pellets for use as the sera substrate. The sera, collected from 100 healthy volunteers and 60 NPC patients, was dripped onto the surface of the substrate for hyperspectral imaging. The characteristic spectral bands were selected based on the variable weight obtained from a support vector machine (SVM) model, using principal component analysis (PCA) to reduce the dimension in the extracted bands. Obtained results show that the accuracy rate, sensitivity, and specificity between the NPC sera and the sera of the healthy controls reached extremely high levels of 99.15%, 98.79%, and 99.36%, respectively. For the model's consistency evaluation, we found that the Kappa and area under the curve (AUC) of the receiver operating characteristic (ROC) curve were 0.99 and 0.98, respectively. These results suggest that the developed approach could serve as a noninvasive diagnostic and screening tool for highly accurate and consistent detection of NPC. Hence, a combination of hyperspectral imaging (HSI) and a weighted principal component analysis (WPCA)-SVM model represents a powerful and promising tool for NPC diagnosis.","3":"Optics express","4":"30470039","5":"2018","6":"Support Vector Machine"},{"1":"Deep learning architectures for prediction of nucleosome positioning from sequences data.","2":"BACKGROUND: Nucleosomes are DNA-histone complex, each wrapping about 150 pairs of double-stranded DNA. Their function is fundamental for one of the primary functions of Chromatin i.e. packing the DNA into the nucleus of the Eukaryote cells. Several biological studies have shown that the nucleosome positioning influences the regulation of cell type-specific gene activities. Moreover, computational studies have shown evidence of sequence specificity concerning the DNA fragment wrapped into nucleosomes, clearly underlined by the organization of particular DNA substrings. As the main consequence, the identification of nucleosomes on a genomic scale has been successfully performed by computational methods using a sequence features representation.RESULTS: In this work, we propose a deep learning model for nucleosome identification. Our model stacks convolutional layers and Long Short-term Memories to automatically extract features from short- and long-range dependencies in a sequence. Using this model we are able to avoid the feature extraction and selection steps while improving the classification performances.CONCLUSIONS: Results computed on eleven data sets of five different organisms, from Yeast to Human, show the superiority of the proposed method with respect to the state of the art recently presented in the literature.","3":"BMC bioinformatics","4":"30453896","5":"2018","6":"Animals"},{"1":"Deep learning architectures for prediction of nucleosome positioning from sequences data.","2":"BACKGROUND: Nucleosomes are DNA-histone complex, each wrapping about 150 pairs of double-stranded DNA. Their function is fundamental for one of the primary functions of Chromatin i.e. packing the DNA into the nucleus of the Eukaryote cells. Several biological studies have shown that the nucleosome positioning influences the regulation of cell type-specific gene activities. Moreover, computational studies have shown evidence of sequence specificity concerning the DNA fragment wrapped into nucleosomes, clearly underlined by the organization of particular DNA substrings. As the main consequence, the identification of nucleosomes on a genomic scale has been successfully performed by computational methods using a sequence features representation.RESULTS: In this work, we propose a deep learning model for nucleosome identification. Our model stacks convolutional layers and Long Short-term Memories to automatically extract features from short- and long-range dependencies in a sequence. Using this model we are able to avoid the feature extraction and selection steps while improving the classification performances.CONCLUSIONS: Results computed on eleven data sets of five different organisms, from Yeast to Human, show the superiority of the proposed method with respect to the state of the art recently presented in the literature.","3":"BMC bioinformatics","4":"30453896","5":"2018","6":"Base Sequence"},{"1":"Deep learning architectures for prediction of nucleosome positioning from sequences data.","2":"BACKGROUND: Nucleosomes are DNA-histone complex, each wrapping about 150 pairs of double-stranded DNA. Their function is fundamental for one of the primary functions of Chromatin i.e. packing the DNA into the nucleus of the Eukaryote cells. Several biological studies have shown that the nucleosome positioning influences the regulation of cell type-specific gene activities. Moreover, computational studies have shown evidence of sequence specificity concerning the DNA fragment wrapped into nucleosomes, clearly underlined by the organization of particular DNA substrings. As the main consequence, the identification of nucleosomes on a genomic scale has been successfully performed by computational methods using a sequence features representation.RESULTS: In this work, we propose a deep learning model for nucleosome identification. Our model stacks convolutional layers and Long Short-term Memories to automatically extract features from short- and long-range dependencies in a sequence. Using this model we are able to avoid the feature extraction and selection steps while improving the classification performances.CONCLUSIONS: Results computed on eleven data sets of five different organisms, from Yeast to Human, show the superiority of the proposed method with respect to the state of the art recently presented in the literature.","3":"BMC bioinformatics","4":"30453896","5":"2018","6":"Databases, Nucleic Acid"},{"1":"Deep learning architectures for prediction of nucleosome positioning from sequences data.","2":"BACKGROUND: Nucleosomes are DNA-histone complex, each wrapping about 150 pairs of double-stranded DNA. Their function is fundamental for one of the primary functions of Chromatin i.e. packing the DNA into the nucleus of the Eukaryote cells. Several biological studies have shown that the nucleosome positioning influences the regulation of cell type-specific gene activities. Moreover, computational studies have shown evidence of sequence specificity concerning the DNA fragment wrapped into nucleosomes, clearly underlined by the organization of particular DNA substrings. As the main consequence, the identification of nucleosomes on a genomic scale has been successfully performed by computational methods using a sequence features representation.RESULTS: In this work, we propose a deep learning model for nucleosome identification. Our model stacks convolutional layers and Long Short-term Memories to automatically extract features from short- and long-range dependencies in a sequence. Using this model we are able to avoid the feature extraction and selection steps while improving the classification performances.CONCLUSIONS: Results computed on eleven data sets of five different organisms, from Yeast to Human, show the superiority of the proposed method with respect to the state of the art recently presented in the literature.","3":"BMC bioinformatics","4":"30453896","5":"2018","6":"Deep Learning"},{"1":"Deep learning architectures for prediction of nucleosome positioning from sequences data.","2":"BACKGROUND: Nucleosomes are DNA-histone complex, each wrapping about 150 pairs of double-stranded DNA. Their function is fundamental for one of the primary functions of Chromatin i.e. packing the DNA into the nucleus of the Eukaryote cells. Several biological studies have shown that the nucleosome positioning influences the regulation of cell type-specific gene activities. Moreover, computational studies have shown evidence of sequence specificity concerning the DNA fragment wrapped into nucleosomes, clearly underlined by the organization of particular DNA substrings. As the main consequence, the identification of nucleosomes on a genomic scale has been successfully performed by computational methods using a sequence features representation.RESULTS: In this work, we propose a deep learning model for nucleosome identification. Our model stacks convolutional layers and Long Short-term Memories to automatically extract features from short- and long-range dependencies in a sequence. Using this model we are able to avoid the feature extraction and selection steps while improving the classification performances.CONCLUSIONS: Results computed on eleven data sets of five different organisms, from Yeast to Human, show the superiority of the proposed method with respect to the state of the art recently presented in the literature.","3":"BMC bioinformatics","4":"30453896","5":"2018","6":"Humans"},{"1":"Deep learning architectures for prediction of nucleosome positioning from sequences data.","2":"BACKGROUND: Nucleosomes are DNA-histone complex, each wrapping about 150 pairs of double-stranded DNA. Their function is fundamental for one of the primary functions of Chromatin i.e. packing the DNA into the nucleus of the Eukaryote cells. Several biological studies have shown that the nucleosome positioning influences the regulation of cell type-specific gene activities. Moreover, computational studies have shown evidence of sequence specificity concerning the DNA fragment wrapped into nucleosomes, clearly underlined by the organization of particular DNA substrings. As the main consequence, the identification of nucleosomes on a genomic scale has been successfully performed by computational methods using a sequence features representation.RESULTS: In this work, we propose a deep learning model for nucleosome identification. Our model stacks convolutional layers and Long Short-term Memories to automatically extract features from short- and long-range dependencies in a sequence. Using this model we are able to avoid the feature extraction and selection steps while improving the classification performances.CONCLUSIONS: Results computed on eleven data sets of five different organisms, from Yeast to Human, show the superiority of the proposed method with respect to the state of the art recently presented in the literature.","3":"BMC bioinformatics","4":"30453896","5":"2018","6":"Neural Networks (Computer)"},{"1":"Deep learning architectures for prediction of nucleosome positioning from sequences data.","2":"BACKGROUND: Nucleosomes are DNA-histone complex, each wrapping about 150 pairs of double-stranded DNA. Their function is fundamental for one of the primary functions of Chromatin i.e. packing the DNA into the nucleus of the Eukaryote cells. Several biological studies have shown that the nucleosome positioning influences the regulation of cell type-specific gene activities. Moreover, computational studies have shown evidence of sequence specificity concerning the DNA fragment wrapped into nucleosomes, clearly underlined by the organization of particular DNA substrings. As the main consequence, the identification of nucleosomes on a genomic scale has been successfully performed by computational methods using a sequence features representation.RESULTS: In this work, we propose a deep learning model for nucleosome identification. Our model stacks convolutional layers and Long Short-term Memories to automatically extract features from short- and long-range dependencies in a sequence. Using this model we are able to avoid the feature extraction and selection steps while improving the classification performances.CONCLUSIONS: Results computed on eleven data sets of five different organisms, from Yeast to Human, show the superiority of the proposed method with respect to the state of the art recently presented in the literature.","3":"BMC bioinformatics","4":"30453896","5":"2018","6":"Nucleosomes"},{"1":"Deep learning architectures for prediction of nucleosome positioning from sequences data.","2":"BACKGROUND: Nucleosomes are DNA-histone complex, each wrapping about 150 pairs of double-stranded DNA. Their function is fundamental for one of the primary functions of Chromatin i.e. packing the DNA into the nucleus of the Eukaryote cells. Several biological studies have shown that the nucleosome positioning influences the regulation of cell type-specific gene activities. Moreover, computational studies have shown evidence of sequence specificity concerning the DNA fragment wrapped into nucleosomes, clearly underlined by the organization of particular DNA substrings. As the main consequence, the identification of nucleosomes on a genomic scale has been successfully performed by computational methods using a sequence features representation.RESULTS: In this work, we propose a deep learning model for nucleosome identification. Our model stacks convolutional layers and Long Short-term Memories to automatically extract features from short- and long-range dependencies in a sequence. Using this model we are able to avoid the feature extraction and selection steps while improving the classification performances.CONCLUSIONS: Results computed on eleven data sets of five different organisms, from Yeast to Human, show the superiority of the proposed method with respect to the state of the art recently presented in the literature.","3":"BMC bioinformatics","4":"30453896","5":"2018","6":"metabolism"},{"1":"Deep learning architectures for prediction of nucleosome positioning from sequences data.","2":"BACKGROUND: Nucleosomes are DNA-histone complex, each wrapping about 150 pairs of double-stranded DNA. Their function is fundamental for one of the primary functions of Chromatin i.e. packing the DNA into the nucleus of the Eukaryote cells. Several biological studies have shown that the nucleosome positioning influences the regulation of cell type-specific gene activities. Moreover, computational studies have shown evidence of sequence specificity concerning the DNA fragment wrapped into nucleosomes, clearly underlined by the organization of particular DNA substrings. As the main consequence, the identification of nucleosomes on a genomic scale has been successfully performed by computational methods using a sequence features representation.RESULTS: In this work, we propose a deep learning model for nucleosome identification. Our model stacks convolutional layers and Long Short-term Memories to automatically extract features from short- and long-range dependencies in a sequence. Using this model we are able to avoid the feature extraction and selection steps while improving the classification performances.CONCLUSIONS: Results computed on eleven data sets of five different organisms, from Yeast to Human, show the superiority of the proposed method with respect to the state of the art recently presented in the literature.","3":"BMC bioinformatics","4":"30453896","5":"2018","6":"ROC Curve"},{"1":"Deep learning architectures for prediction of nucleosome positioning from sequences data.","2":"BACKGROUND: Nucleosomes are DNA-histone complex, each wrapping about 150 pairs of double-stranded DNA. Their function is fundamental for one of the primary functions of Chromatin i.e. packing the DNA into the nucleus of the Eukaryote cells. Several biological studies have shown that the nucleosome positioning influences the regulation of cell type-specific gene activities. Moreover, computational studies have shown evidence of sequence specificity concerning the DNA fragment wrapped into nucleosomes, clearly underlined by the organization of particular DNA substrings. As the main consequence, the identification of nucleosomes on a genomic scale has been successfully performed by computational methods using a sequence features representation.RESULTS: In this work, we propose a deep learning model for nucleosome identification. Our model stacks convolutional layers and Long Short-term Memories to automatically extract features from short- and long-range dependencies in a sequence. Using this model we are able to avoid the feature extraction and selection steps while improving the classification performances.CONCLUSIONS: Results computed on eleven data sets of five different organisms, from Yeast to Human, show the superiority of the proposed method with respect to the state of the art recently presented in the literature.","3":"BMC bioinformatics","4":"30453896","5":"2018","6":"Reproducibility of Results"},{"1":"Deep learning architectures for prediction of nucleosome positioning from sequences data.","2":"BACKGROUND: Nucleosomes are DNA-histone complex, each wrapping about 150 pairs of double-stranded DNA. Their function is fundamental for one of the primary functions of Chromatin i.e. packing the DNA into the nucleus of the Eukaryote cells. Several biological studies have shown that the nucleosome positioning influences the regulation of cell type-specific gene activities. Moreover, computational studies have shown evidence of sequence specificity concerning the DNA fragment wrapped into nucleosomes, clearly underlined by the organization of particular DNA substrings. As the main consequence, the identification of nucleosomes on a genomic scale has been successfully performed by computational methods using a sequence features representation.RESULTS: In this work, we propose a deep learning model for nucleosome identification. Our model stacks convolutional layers and Long Short-term Memories to automatically extract features from short- and long-range dependencies in a sequence. Using this model we are able to avoid the feature extraction and selection steps while improving the classification performances.CONCLUSIONS: Results computed on eleven data sets of five different organisms, from Yeast to Human, show the superiority of the proposed method with respect to the state of the art recently presented in the literature.","3":"BMC bioinformatics","4":"30453896","5":"2018","6":"Saccharomyces cerevisiae"},{"1":"SVM-RFE: selection and visualization of the most relevant features through non-linear kernels.","2":"BACKGROUND: Support vector machines (SVM) are a powerful tool to analyze data with a number of predictors approximately equal or larger than the number of observations. However, originally, application of SVM to analyze biomedical data was limited because SVM was not designed to evaluate importance of predictor variables. Creating predictor models based on only the most relevant variables is essential in biomedical research. Currently, substantial work has been done to allow assessment of variable importance in SVM models but this work has focused on SVM implemented with linear kernels. The power of SVM as a prediction model is associated with the flexibility generated by use of non-linear kernels. Moreover, SVM has been extended to model survival outcomes. This paper extends the Recursive Feature Elimination (RFE) algorithm by proposing three approaches to rank variables based on non-linear SVM and SVM for survival analysis.RESULTS: The proposed algorithms allows visualization of each one the RFE iterations, and hence, identification of the most relevant predictors of the response variable. Using simulation studies based on time-to-event outcomes and three real datasets, we evaluate the three methods, based on pseudo-samples and kernel principal component analysis, and compare them with the original SVM-RFE algorithm for non-linear kernels. The three algorithms we proposed performed generally better than the gold standard RFE for non-linear kernels, when comparing the truly most relevant variables with the variable ranks produced by each algorithm in simulation studies. Generally, the RFE-pseudo-samples outperformed the other three methods, even when variables were assumed to be correlated in all tested scenarios.CONCLUSIONS: The proposed approaches can be implemented with accuracy to select variables and assess direction and strength of associations in analysis of biomedical data using SVM for categorical or time-to-event responses. Conducting variable selection and interpreting direction and strength of associations between predictors and outcomes with the proposed approaches, particularly with the RFE-pseudo-samples approach can be implemented with accuracy when analyzing biomedical data. These approaches, perform better than the classical RFE of Guyon for realistic scenarios about the structure of biomedical data.","3":"BMC bioinformatics","4":"30453885","5":"2018","6":"Algorithms"},{"1":"SVM-RFE: selection and visualization of the most relevant features through non-linear kernels.","2":"BACKGROUND: Support vector machines (SVM) are a powerful tool to analyze data with a number of predictors approximately equal or larger than the number of observations. However, originally, application of SVM to analyze biomedical data was limited because SVM was not designed to evaluate importance of predictor variables. Creating predictor models based on only the most relevant variables is essential in biomedical research. Currently, substantial work has been done to allow assessment of variable importance in SVM models but this work has focused on SVM implemented with linear kernels. The power of SVM as a prediction model is associated with the flexibility generated by use of non-linear kernels. Moreover, SVM has been extended to model survival outcomes. This paper extends the Recursive Feature Elimination (RFE) algorithm by proposing three approaches to rank variables based on non-linear SVM and SVM for survival analysis.RESULTS: The proposed algorithms allows visualization of each one the RFE iterations, and hence, identification of the most relevant predictors of the response variable. Using simulation studies based on time-to-event outcomes and three real datasets, we evaluate the three methods, based on pseudo-samples and kernel principal component analysis, and compare them with the original SVM-RFE algorithm for non-linear kernels. The three algorithms we proposed performed generally better than the gold standard RFE for non-linear kernels, when comparing the truly most relevant variables with the variable ranks produced by each algorithm in simulation studies. Generally, the RFE-pseudo-samples outperformed the other three methods, even when variables were assumed to be correlated in all tested scenarios.CONCLUSIONS: The proposed approaches can be implemented with accuracy to select variables and assess direction and strength of associations in analysis of biomedical data using SVM for categorical or time-to-event responses. Conducting variable selection and interpreting direction and strength of associations between predictors and outcomes with the proposed approaches, particularly with the RFE-pseudo-samples approach can be implemented with accuracy when analyzing biomedical data. These approaches, perform better than the classical RFE of Guyon for realistic scenarios about the structure of biomedical data.","3":"BMC bioinformatics","4":"30453885","5":"2018","6":"Biomarkers, Tumor"},{"1":"SVM-RFE: selection and visualization of the most relevant features through non-linear kernels.","2":"BACKGROUND: Support vector machines (SVM) are a powerful tool to analyze data with a number of predictors approximately equal or larger than the number of observations. However, originally, application of SVM to analyze biomedical data was limited because SVM was not designed to evaluate importance of predictor variables. Creating predictor models based on only the most relevant variables is essential in biomedical research. Currently, substantial work has been done to allow assessment of variable importance in SVM models but this work has focused on SVM implemented with linear kernels. The power of SVM as a prediction model is associated with the flexibility generated by use of non-linear kernels. Moreover, SVM has been extended to model survival outcomes. This paper extends the Recursive Feature Elimination (RFE) algorithm by proposing three approaches to rank variables based on non-linear SVM and SVM for survival analysis.RESULTS: The proposed algorithms allows visualization of each one the RFE iterations, and hence, identification of the most relevant predictors of the response variable. Using simulation studies based on time-to-event outcomes and three real datasets, we evaluate the three methods, based on pseudo-samples and kernel principal component analysis, and compare them with the original SVM-RFE algorithm for non-linear kernels. The three algorithms we proposed performed generally better than the gold standard RFE for non-linear kernels, when comparing the truly most relevant variables with the variable ranks produced by each algorithm in simulation studies. Generally, the RFE-pseudo-samples outperformed the other three methods, even when variables were assumed to be correlated in all tested scenarios.CONCLUSIONS: The proposed approaches can be implemented with accuracy to select variables and assess direction and strength of associations in analysis of biomedical data using SVM for categorical or time-to-event responses. Conducting variable selection and interpreting direction and strength of associations between predictors and outcomes with the proposed approaches, particularly with the RFE-pseudo-samples approach can be implemented with accuracy when analyzing biomedical data. These approaches, perform better than the classical RFE of Guyon for realistic scenarios about the structure of biomedical data.","3":"BMC bioinformatics","4":"30453885","5":"2018","6":"genetics"},{"1":"SVM-RFE: selection and visualization of the most relevant features through non-linear kernels.","2":"BACKGROUND: Support vector machines (SVM) are a powerful tool to analyze data with a number of predictors approximately equal or larger than the number of observations. However, originally, application of SVM to analyze biomedical data was limited because SVM was not designed to evaluate importance of predictor variables. Creating predictor models based on only the most relevant variables is essential in biomedical research. Currently, substantial work has been done to allow assessment of variable importance in SVM models but this work has focused on SVM implemented with linear kernels. The power of SVM as a prediction model is associated with the flexibility generated by use of non-linear kernels. Moreover, SVM has been extended to model survival outcomes. This paper extends the Recursive Feature Elimination (RFE) algorithm by proposing three approaches to rank variables based on non-linear SVM and SVM for survival analysis.RESULTS: The proposed algorithms allows visualization of each one the RFE iterations, and hence, identification of the most relevant predictors of the response variable. Using simulation studies based on time-to-event outcomes and three real datasets, we evaluate the three methods, based on pseudo-samples and kernel principal component analysis, and compare them with the original SVM-RFE algorithm for non-linear kernels. The three algorithms we proposed performed generally better than the gold standard RFE for non-linear kernels, when comparing the truly most relevant variables with the variable ranks produced by each algorithm in simulation studies. Generally, the RFE-pseudo-samples outperformed the other three methods, even when variables were assumed to be correlated in all tested scenarios.CONCLUSIONS: The proposed approaches can be implemented with accuracy to select variables and assess direction and strength of associations in analysis of biomedical data using SVM for categorical or time-to-event responses. Conducting variable selection and interpreting direction and strength of associations between predictors and outcomes with the proposed approaches, particularly with the RFE-pseudo-samples approach can be implemented with accuracy when analyzing biomedical data. These approaches, perform better than the classical RFE of Guyon for realistic scenarios about the structure of biomedical data.","3":"BMC bioinformatics","4":"30453885","5":"2018","6":"Computer Graphics"},{"1":"SVM-RFE: selection and visualization of the most relevant features through non-linear kernels.","2":"BACKGROUND: Support vector machines (SVM) are a powerful tool to analyze data with a number of predictors approximately equal or larger than the number of observations. However, originally, application of SVM to analyze biomedical data was limited because SVM was not designed to evaluate importance of predictor variables. Creating predictor models based on only the most relevant variables is essential in biomedical research. Currently, substantial work has been done to allow assessment of variable importance in SVM models but this work has focused on SVM implemented with linear kernels. The power of SVM as a prediction model is associated with the flexibility generated by use of non-linear kernels. Moreover, SVM has been extended to model survival outcomes. This paper extends the Recursive Feature Elimination (RFE) algorithm by proposing three approaches to rank variables based on non-linear SVM and SVM for survival analysis.RESULTS: The proposed algorithms allows visualization of each one the RFE iterations, and hence, identification of the most relevant predictors of the response variable. Using simulation studies based on time-to-event outcomes and three real datasets, we evaluate the three methods, based on pseudo-samples and kernel principal component analysis, and compare them with the original SVM-RFE algorithm for non-linear kernels. The three algorithms we proposed performed generally better than the gold standard RFE for non-linear kernels, when comparing the truly most relevant variables with the variable ranks produced by each algorithm in simulation studies. Generally, the RFE-pseudo-samples outperformed the other three methods, even when variables were assumed to be correlated in all tested scenarios.CONCLUSIONS: The proposed approaches can be implemented with accuracy to select variables and assess direction and strength of associations in analysis of biomedical data using SVM for categorical or time-to-event responses. Conducting variable selection and interpreting direction and strength of associations between predictors and outcomes with the proposed approaches, particularly with the RFE-pseudo-samples approach can be implemented with accuracy when analyzing biomedical data. These approaches, perform better than the classical RFE of Guyon for realistic scenarios about the structure of biomedical data.","3":"BMC bioinformatics","4":"30453885","5":"2018","6":"Humans"},{"1":"SVM-RFE: selection and visualization of the most relevant features through non-linear kernels.","2":"BACKGROUND: Support vector machines (SVM) are a powerful tool to analyze data with a number of predictors approximately equal or larger than the number of observations. However, originally, application of SVM to analyze biomedical data was limited because SVM was not designed to evaluate importance of predictor variables. Creating predictor models based on only the most relevant variables is essential in biomedical research. Currently, substantial work has been done to allow assessment of variable importance in SVM models but this work has focused on SVM implemented with linear kernels. The power of SVM as a prediction model is associated with the flexibility generated by use of non-linear kernels. Moreover, SVM has been extended to model survival outcomes. This paper extends the Recursive Feature Elimination (RFE) algorithm by proposing three approaches to rank variables based on non-linear SVM and SVM for survival analysis.RESULTS: The proposed algorithms allows visualization of each one the RFE iterations, and hence, identification of the most relevant predictors of the response variable. Using simulation studies based on time-to-event outcomes and three real datasets, we evaluate the three methods, based on pseudo-samples and kernel principal component analysis, and compare them with the original SVM-RFE algorithm for non-linear kernels. The three algorithms we proposed performed generally better than the gold standard RFE for non-linear kernels, when comparing the truly most relevant variables with the variable ranks produced by each algorithm in simulation studies. Generally, the RFE-pseudo-samples outperformed the other three methods, even when variables were assumed to be correlated in all tested scenarios.CONCLUSIONS: The proposed approaches can be implemented with accuracy to select variables and assess direction and strength of associations in analysis of biomedical data using SVM for categorical or time-to-event responses. Conducting variable selection and interpreting direction and strength of associations between predictors and outcomes with the proposed approaches, particularly with the RFE-pseudo-samples approach can be implemented with accuracy when analyzing biomedical data. These approaches, perform better than the classical RFE of Guyon for realistic scenarios about the structure of biomedical data.","3":"BMC bioinformatics","4":"30453885","5":"2018","6":"Liver Cirrhosis, Biliary"},{"1":"SVM-RFE: selection and visualization of the most relevant features through non-linear kernels.","2":"BACKGROUND: Support vector machines (SVM) are a powerful tool to analyze data with a number of predictors approximately equal or larger than the number of observations. However, originally, application of SVM to analyze biomedical data was limited because SVM was not designed to evaluate importance of predictor variables. Creating predictor models based on only the most relevant variables is essential in biomedical research. Currently, substantial work has been done to allow assessment of variable importance in SVM models but this work has focused on SVM implemented with linear kernels. The power of SVM as a prediction model is associated with the flexibility generated by use of non-linear kernels. Moreover, SVM has been extended to model survival outcomes. This paper extends the Recursive Feature Elimination (RFE) algorithm by proposing three approaches to rank variables based on non-linear SVM and SVM for survival analysis.RESULTS: The proposed algorithms allows visualization of each one the RFE iterations, and hence, identification of the most relevant predictors of the response variable. Using simulation studies based on time-to-event outcomes and three real datasets, we evaluate the three methods, based on pseudo-samples and kernel principal component analysis, and compare them with the original SVM-RFE algorithm for non-linear kernels. The three algorithms we proposed performed generally better than the gold standard RFE for non-linear kernels, when comparing the truly most relevant variables with the variable ranks produced by each algorithm in simulation studies. Generally, the RFE-pseudo-samples outperformed the other three methods, even when variables were assumed to be correlated in all tested scenarios.CONCLUSIONS: The proposed approaches can be implemented with accuracy to select variables and assess direction and strength of associations in analysis of biomedical data using SVM for categorical or time-to-event responses. Conducting variable selection and interpreting direction and strength of associations between predictors and outcomes with the proposed approaches, particularly with the RFE-pseudo-samples approach can be implemented with accuracy when analyzing biomedical data. These approaches, perform better than the classical RFE of Guyon for realistic scenarios about the structure of biomedical data.","3":"BMC bioinformatics","4":"30453885","5":"2018","6":"genetics"},{"1":"SVM-RFE: selection and visualization of the most relevant features through non-linear kernels.","2":"BACKGROUND: Support vector machines (SVM) are a powerful tool to analyze data with a number of predictors approximately equal or larger than the number of observations. However, originally, application of SVM to analyze biomedical data was limited because SVM was not designed to evaluate importance of predictor variables. Creating predictor models based on only the most relevant variables is essential in biomedical research. Currently, substantial work has been done to allow assessment of variable importance in SVM models but this work has focused on SVM implemented with linear kernels. The power of SVM as a prediction model is associated with the flexibility generated by use of non-linear kernels. Moreover, SVM has been extended to model survival outcomes. This paper extends the Recursive Feature Elimination (RFE) algorithm by proposing three approaches to rank variables based on non-linear SVM and SVM for survival analysis.RESULTS: The proposed algorithms allows visualization of each one the RFE iterations, and hence, identification of the most relevant predictors of the response variable. Using simulation studies based on time-to-event outcomes and three real datasets, we evaluate the three methods, based on pseudo-samples and kernel principal component analysis, and compare them with the original SVM-RFE algorithm for non-linear kernels. The three algorithms we proposed performed generally better than the gold standard RFE for non-linear kernels, when comparing the truly most relevant variables with the variable ranks produced by each algorithm in simulation studies. Generally, the RFE-pseudo-samples outperformed the other three methods, even when variables were assumed to be correlated in all tested scenarios.CONCLUSIONS: The proposed approaches can be implemented with accuracy to select variables and assess direction and strength of associations in analysis of biomedical data using SVM for categorical or time-to-event responses. Conducting variable selection and interpreting direction and strength of associations between predictors and outcomes with the proposed approaches, particularly with the RFE-pseudo-samples approach can be implemented with accuracy when analyzing biomedical data. These approaches, perform better than the classical RFE of Guyon for realistic scenarios about the structure of biomedical data.","3":"BMC bioinformatics","4":"30453885","5":"2018","6":"mortality"},{"1":"SVM-RFE: selection and visualization of the most relevant features through non-linear kernels.","2":"BACKGROUND: Support vector machines (SVM) are a powerful tool to analyze data with a number of predictors approximately equal or larger than the number of observations. However, originally, application of SVM to analyze biomedical data was limited because SVM was not designed to evaluate importance of predictor variables. Creating predictor models based on only the most relevant variables is essential in biomedical research. Currently, substantial work has been done to allow assessment of variable importance in SVM models but this work has focused on SVM implemented with linear kernels. The power of SVM as a prediction model is associated with the flexibility generated by use of non-linear kernels. Moreover, SVM has been extended to model survival outcomes. This paper extends the Recursive Feature Elimination (RFE) algorithm by proposing three approaches to rank variables based on non-linear SVM and SVM for survival analysis.RESULTS: The proposed algorithms allows visualization of each one the RFE iterations, and hence, identification of the most relevant predictors of the response variable. Using simulation studies based on time-to-event outcomes and three real datasets, we evaluate the three methods, based on pseudo-samples and kernel principal component analysis, and compare them with the original SVM-RFE algorithm for non-linear kernels. The three algorithms we proposed performed generally better than the gold standard RFE for non-linear kernels, when comparing the truly most relevant variables with the variable ranks produced by each algorithm in simulation studies. Generally, the RFE-pseudo-samples outperformed the other three methods, even when variables were assumed to be correlated in all tested scenarios.CONCLUSIONS: The proposed approaches can be implemented with accuracy to select variables and assess direction and strength of associations in analysis of biomedical data using SVM for categorical or time-to-event responses. Conducting variable selection and interpreting direction and strength of associations between predictors and outcomes with the proposed approaches, particularly with the RFE-pseudo-samples approach can be implemented with accuracy when analyzing biomedical data. These approaches, perform better than the classical RFE of Guyon for realistic scenarios about the structure of biomedical data.","3":"BMC bioinformatics","4":"30453885","5":"2018","6":"Lung Neoplasms"},{"1":"SVM-RFE: selection and visualization of the most relevant features through non-linear kernels.","2":"BACKGROUND: Support vector machines (SVM) are a powerful tool to analyze data with a number of predictors approximately equal or larger than the number of observations. However, originally, application of SVM to analyze biomedical data was limited because SVM was not designed to evaluate importance of predictor variables. Creating predictor models based on only the most relevant variables is essential in biomedical research. Currently, substantial work has been done to allow assessment of variable importance in SVM models but this work has focused on SVM implemented with linear kernels. The power of SVM as a prediction model is associated with the flexibility generated by use of non-linear kernels. Moreover, SVM has been extended to model survival outcomes. This paper extends the Recursive Feature Elimination (RFE) algorithm by proposing three approaches to rank variables based on non-linear SVM and SVM for survival analysis.RESULTS: The proposed algorithms allows visualization of each one the RFE iterations, and hence, identification of the most relevant predictors of the response variable. Using simulation studies based on time-to-event outcomes and three real datasets, we evaluate the three methods, based on pseudo-samples and kernel principal component analysis, and compare them with the original SVM-RFE algorithm for non-linear kernels. The three algorithms we proposed performed generally better than the gold standard RFE for non-linear kernels, when comparing the truly most relevant variables with the variable ranks produced by each algorithm in simulation studies. Generally, the RFE-pseudo-samples outperformed the other three methods, even when variables were assumed to be correlated in all tested scenarios.CONCLUSIONS: The proposed approaches can be implemented with accuracy to select variables and assess direction and strength of associations in analysis of biomedical data using SVM for categorical or time-to-event responses. Conducting variable selection and interpreting direction and strength of associations between predictors and outcomes with the proposed approaches, particularly with the RFE-pseudo-samples approach can be implemented with accuracy when analyzing biomedical data. These approaches, perform better than the classical RFE of Guyon for realistic scenarios about the structure of biomedical data.","3":"BMC bioinformatics","4":"30453885","5":"2018","6":"genetics"},{"1":"SVM-RFE: selection and visualization of the most relevant features through non-linear kernels.","2":"BACKGROUND: Support vector machines (SVM) are a powerful tool to analyze data with a number of predictors approximately equal or larger than the number of observations. However, originally, application of SVM to analyze biomedical data was limited because SVM was not designed to evaluate importance of predictor variables. Creating predictor models based on only the most relevant variables is essential in biomedical research. Currently, substantial work has been done to allow assessment of variable importance in SVM models but this work has focused on SVM implemented with linear kernels. The power of SVM as a prediction model is associated with the flexibility generated by use of non-linear kernels. Moreover, SVM has been extended to model survival outcomes. This paper extends the Recursive Feature Elimination (RFE) algorithm by proposing three approaches to rank variables based on non-linear SVM and SVM for survival analysis.RESULTS: The proposed algorithms allows visualization of each one the RFE iterations, and hence, identification of the most relevant predictors of the response variable. Using simulation studies based on time-to-event outcomes and three real datasets, we evaluate the three methods, based on pseudo-samples and kernel principal component analysis, and compare them with the original SVM-RFE algorithm for non-linear kernels. The three algorithms we proposed performed generally better than the gold standard RFE for non-linear kernels, when comparing the truly most relevant variables with the variable ranks produced by each algorithm in simulation studies. Generally, the RFE-pseudo-samples outperformed the other three methods, even when variables were assumed to be correlated in all tested scenarios.CONCLUSIONS: The proposed approaches can be implemented with accuracy to select variables and assess direction and strength of associations in analysis of biomedical data using SVM for categorical or time-to-event responses. Conducting variable selection and interpreting direction and strength of associations between predictors and outcomes with the proposed approaches, particularly with the RFE-pseudo-samples approach can be implemented with accuracy when analyzing biomedical data. These approaches, perform better than the classical RFE of Guyon for realistic scenarios about the structure of biomedical data.","3":"BMC bioinformatics","4":"30453885","5":"2018","6":"mortality"},{"1":"SVM-RFE: selection and visualization of the most relevant features through non-linear kernels.","2":"BACKGROUND: Support vector machines (SVM) are a powerful tool to analyze data with a number of predictors approximately equal or larger than the number of observations. However, originally, application of SVM to analyze biomedical data was limited because SVM was not designed to evaluate importance of predictor variables. Creating predictor models based on only the most relevant variables is essential in biomedical research. Currently, substantial work has been done to allow assessment of variable importance in SVM models but this work has focused on SVM implemented with linear kernels. The power of SVM as a prediction model is associated with the flexibility generated by use of non-linear kernels. Moreover, SVM has been extended to model survival outcomes. This paper extends the Recursive Feature Elimination (RFE) algorithm by proposing three approaches to rank variables based on non-linear SVM and SVM for survival analysis.RESULTS: The proposed algorithms allows visualization of each one the RFE iterations, and hence, identification of the most relevant predictors of the response variable. Using simulation studies based on time-to-event outcomes and three real datasets, we evaluate the three methods, based on pseudo-samples and kernel principal component analysis, and compare them with the original SVM-RFE algorithm for non-linear kernels. The three algorithms we proposed performed generally better than the gold standard RFE for non-linear kernels, when comparing the truly most relevant variables with the variable ranks produced by each algorithm in simulation studies. Generally, the RFE-pseudo-samples outperformed the other three methods, even when variables were assumed to be correlated in all tested scenarios.CONCLUSIONS: The proposed approaches can be implemented with accuracy to select variables and assess direction and strength of associations in analysis of biomedical data using SVM for categorical or time-to-event responses. Conducting variable selection and interpreting direction and strength of associations between predictors and outcomes with the proposed approaches, particularly with the RFE-pseudo-samples approach can be implemented with accuracy when analyzing biomedical data. These approaches, perform better than the classical RFE of Guyon for realistic scenarios about the structure of biomedical data.","3":"BMC bioinformatics","4":"30453885","5":"2018","6":"Lymphoma, Large B-Cell, Diffuse"},{"1":"SVM-RFE: selection and visualization of the most relevant features through non-linear kernels.","2":"BACKGROUND: Support vector machines (SVM) are a powerful tool to analyze data with a number of predictors approximately equal or larger than the number of observations. However, originally, application of SVM to analyze biomedical data was limited because SVM was not designed to evaluate importance of predictor variables. Creating predictor models based on only the most relevant variables is essential in biomedical research. Currently, substantial work has been done to allow assessment of variable importance in SVM models but this work has focused on SVM implemented with linear kernels. The power of SVM as a prediction model is associated with the flexibility generated by use of non-linear kernels. Moreover, SVM has been extended to model survival outcomes. This paper extends the Recursive Feature Elimination (RFE) algorithm by proposing three approaches to rank variables based on non-linear SVM and SVM for survival analysis.RESULTS: The proposed algorithms allows visualization of each one the RFE iterations, and hence, identification of the most relevant predictors of the response variable. Using simulation studies based on time-to-event outcomes and three real datasets, we evaluate the three methods, based on pseudo-samples and kernel principal component analysis, and compare them with the original SVM-RFE algorithm for non-linear kernels. The three algorithms we proposed performed generally better than the gold standard RFE for non-linear kernels, when comparing the truly most relevant variables with the variable ranks produced by each algorithm in simulation studies. Generally, the RFE-pseudo-samples outperformed the other three methods, even when variables were assumed to be correlated in all tested scenarios.CONCLUSIONS: The proposed approaches can be implemented with accuracy to select variables and assess direction and strength of associations in analysis of biomedical data using SVM for categorical or time-to-event responses. Conducting variable selection and interpreting direction and strength of associations between predictors and outcomes with the proposed approaches, particularly with the RFE-pseudo-samples approach can be implemented with accuracy when analyzing biomedical data. These approaches, perform better than the classical RFE of Guyon for realistic scenarios about the structure of biomedical data.","3":"BMC bioinformatics","4":"30453885","5":"2018","6":"genetics"},{"1":"SVM-RFE: selection and visualization of the most relevant features through non-linear kernels.","2":"BACKGROUND: Support vector machines (SVM) are a powerful tool to analyze data with a number of predictors approximately equal or larger than the number of observations. However, originally, application of SVM to analyze biomedical data was limited because SVM was not designed to evaluate importance of predictor variables. Creating predictor models based on only the most relevant variables is essential in biomedical research. Currently, substantial work has been done to allow assessment of variable importance in SVM models but this work has focused on SVM implemented with linear kernels. The power of SVM as a prediction model is associated with the flexibility generated by use of non-linear kernels. Moreover, SVM has been extended to model survival outcomes. This paper extends the Recursive Feature Elimination (RFE) algorithm by proposing three approaches to rank variables based on non-linear SVM and SVM for survival analysis.RESULTS: The proposed algorithms allows visualization of each one the RFE iterations, and hence, identification of the most relevant predictors of the response variable. Using simulation studies based on time-to-event outcomes and three real datasets, we evaluate the three methods, based on pseudo-samples and kernel principal component analysis, and compare them with the original SVM-RFE algorithm for non-linear kernels. The three algorithms we proposed performed generally better than the gold standard RFE for non-linear kernels, when comparing the truly most relevant variables with the variable ranks produced by each algorithm in simulation studies. Generally, the RFE-pseudo-samples outperformed the other three methods, even when variables were assumed to be correlated in all tested scenarios.CONCLUSIONS: The proposed approaches can be implemented with accuracy to select variables and assess direction and strength of associations in analysis of biomedical data using SVM for categorical or time-to-event responses. Conducting variable selection and interpreting direction and strength of associations between predictors and outcomes with the proposed approaches, particularly with the RFE-pseudo-samples approach can be implemented with accuracy when analyzing biomedical data. These approaches, perform better than the classical RFE of Guyon for realistic scenarios about the structure of biomedical data.","3":"BMC bioinformatics","4":"30453885","5":"2018","6":"mortality"},{"1":"SVM-RFE: selection and visualization of the most relevant features through non-linear kernels.","2":"BACKGROUND: Support vector machines (SVM) are a powerful tool to analyze data with a number of predictors approximately equal or larger than the number of observations. However, originally, application of SVM to analyze biomedical data was limited because SVM was not designed to evaluate importance of predictor variables. Creating predictor models based on only the most relevant variables is essential in biomedical research. Currently, substantial work has been done to allow assessment of variable importance in SVM models but this work has focused on SVM implemented with linear kernels. The power of SVM as a prediction model is associated with the flexibility generated by use of non-linear kernels. Moreover, SVM has been extended to model survival outcomes. This paper extends the Recursive Feature Elimination (RFE) algorithm by proposing three approaches to rank variables based on non-linear SVM and SVM for survival analysis.RESULTS: The proposed algorithms allows visualization of each one the RFE iterations, and hence, identification of the most relevant predictors of the response variable. Using simulation studies based on time-to-event outcomes and three real datasets, we evaluate the three methods, based on pseudo-samples and kernel principal component analysis, and compare them with the original SVM-RFE algorithm for non-linear kernels. The three algorithms we proposed performed generally better than the gold standard RFE for non-linear kernels, when comparing the truly most relevant variables with the variable ranks produced by each algorithm in simulation studies. Generally, the RFE-pseudo-samples outperformed the other three methods, even when variables were assumed to be correlated in all tested scenarios.CONCLUSIONS: The proposed approaches can be implemented with accuracy to select variables and assess direction and strength of associations in analysis of biomedical data using SVM for categorical or time-to-event responses. Conducting variable selection and interpreting direction and strength of associations between predictors and outcomes with the proposed approaches, particularly with the RFE-pseudo-samples approach can be implemented with accuracy when analyzing biomedical data. These approaches, perform better than the classical RFE of Guyon for realistic scenarios about the structure of biomedical data.","3":"BMC bioinformatics","4":"30453885","5":"2018","6":"Support Vector Machine"},{"1":"SVM-RFE: selection and visualization of the most relevant features through non-linear kernels.","2":"BACKGROUND: Support vector machines (SVM) are a powerful tool to analyze data with a number of predictors approximately equal or larger than the number of observations. However, originally, application of SVM to analyze biomedical data was limited because SVM was not designed to evaluate importance of predictor variables. Creating predictor models based on only the most relevant variables is essential in biomedical research. Currently, substantial work has been done to allow assessment of variable importance in SVM models but this work has focused on SVM implemented with linear kernels. The power of SVM as a prediction model is associated with the flexibility generated by use of non-linear kernels. Moreover, SVM has been extended to model survival outcomes. This paper extends the Recursive Feature Elimination (RFE) algorithm by proposing three approaches to rank variables based on non-linear SVM and SVM for survival analysis.RESULTS: The proposed algorithms allows visualization of each one the RFE iterations, and hence, identification of the most relevant predictors of the response variable. Using simulation studies based on time-to-event outcomes and three real datasets, we evaluate the three methods, based on pseudo-samples and kernel principal component analysis, and compare them with the original SVM-RFE algorithm for non-linear kernels. The three algorithms we proposed performed generally better than the gold standard RFE for non-linear kernels, when comparing the truly most relevant variables with the variable ranks produced by each algorithm in simulation studies. Generally, the RFE-pseudo-samples outperformed the other three methods, even when variables were assumed to be correlated in all tested scenarios.CONCLUSIONS: The proposed approaches can be implemented with accuracy to select variables and assess direction and strength of associations in analysis of biomedical data using SVM for categorical or time-to-event responses. Conducting variable selection and interpreting direction and strength of associations between predictors and outcomes with the proposed approaches, particularly with the RFE-pseudo-samples approach can be implemented with accuracy when analyzing biomedical data. These approaches, perform better than the classical RFE of Guyon for realistic scenarios about the structure of biomedical data.","3":"BMC bioinformatics","4":"30453885","5":"2018","6":"Survival Rate"},{"1":"The predictive performance of short-linear motif features in the prediction of calmodulin-binding proteins.","2":"BACKGROUND: The prediction of calmodulin-binding (CaM-binding) proteins plays a very important role in the fields of biology and biochemistry, because the calmodulin protein binds and regulates a multitude of protein targets affecting different cellular processes. Computational methods that can accurately identify CaM-binding proteins and CaM-binding domains would accelerate research in calcium signaling and calmodulin function. Short-linear motifs (SLiMs), on the other hand, have been effectively used as features for analyzing protein-protein interactions, though their properties have not been utilized in the prediction of CaM-binding proteins.RESULTS: We propose a new method for the prediction of CaM-binding proteins based on both the total and average scores of known and new SLiMs in protein sequences using a new scoring method called sliding window scoring (SWS) as features for the prediction module. A dataset of 194 manually curated human CaM-binding proteins and 193 mitochondrial proteins have been obtained and used for testing the proposed model. The motif generation tool, Multiple EM for Motif Elucidation (MEME), has been used to obtain new motifs from each of the positive and negative datasets individually (the SM approach) and from the combined negative and positive datasets (the CM approach). Moreover, the wrapper criterion with random forest for feature selection (FS) has been applied followed by classification using different algorithms such as k-nearest neighbors (k-NN), support vector machines (SVM), naive Bayes (NB) and random forest (RF).CONCLUSIONS: Our proposed method shows very good prediction results and demonstrates how information contained in SLiMs is highly relevant in predicting CaM-binding proteins. Further, three new CaM-binding motifs have been computationally selected and biologically validated in this study, and which can be used for predicting CaM-binding proteins.","3":"BMC bioinformatics","4":"30453876","5":"2018","6":"Amino Acid Motifs"},{"1":"The predictive performance of short-linear motif features in the prediction of calmodulin-binding proteins.","2":"BACKGROUND: The prediction of calmodulin-binding (CaM-binding) proteins plays a very important role in the fields of biology and biochemistry, because the calmodulin protein binds and regulates a multitude of protein targets affecting different cellular processes. Computational methods that can accurately identify CaM-binding proteins and CaM-binding domains would accelerate research in calcium signaling and calmodulin function. Short-linear motifs (SLiMs), on the other hand, have been effectively used as features for analyzing protein-protein interactions, though their properties have not been utilized in the prediction of CaM-binding proteins.RESULTS: We propose a new method for the prediction of CaM-binding proteins based on both the total and average scores of known and new SLiMs in protein sequences using a new scoring method called sliding window scoring (SWS) as features for the prediction module. A dataset of 194 manually curated human CaM-binding proteins and 193 mitochondrial proteins have been obtained and used for testing the proposed model. The motif generation tool, Multiple EM for Motif Elucidation (MEME), has been used to obtain new motifs from each of the positive and negative datasets individually (the SM approach) and from the combined negative and positive datasets (the CM approach). Moreover, the wrapper criterion with random forest for feature selection (FS) has been applied followed by classification using different algorithms such as k-nearest neighbors (k-NN), support vector machines (SVM), naive Bayes (NB) and random forest (RF).CONCLUSIONS: Our proposed method shows very good prediction results and demonstrates how information contained in SLiMs is highly relevant in predicting CaM-binding proteins. Further, three new CaM-binding motifs have been computationally selected and biologically validated in this study, and which can be used for predicting CaM-binding proteins.","3":"BMC bioinformatics","4":"30453876","5":"2018","6":"Amino Acid Sequence"},{"1":"The predictive performance of short-linear motif features in the prediction of calmodulin-binding proteins.","2":"BACKGROUND: The prediction of calmodulin-binding (CaM-binding) proteins plays a very important role in the fields of biology and biochemistry, because the calmodulin protein binds and regulates a multitude of protein targets affecting different cellular processes. Computational methods that can accurately identify CaM-binding proteins and CaM-binding domains would accelerate research in calcium signaling and calmodulin function. Short-linear motifs (SLiMs), on the other hand, have been effectively used as features for analyzing protein-protein interactions, though their properties have not been utilized in the prediction of CaM-binding proteins.RESULTS: We propose a new method for the prediction of CaM-binding proteins based on both the total and average scores of known and new SLiMs in protein sequences using a new scoring method called sliding window scoring (SWS) as features for the prediction module. A dataset of 194 manually curated human CaM-binding proteins and 193 mitochondrial proteins have been obtained and used for testing the proposed model. The motif generation tool, Multiple EM for Motif Elucidation (MEME), has been used to obtain new motifs from each of the positive and negative datasets individually (the SM approach) and from the combined negative and positive datasets (the CM approach). Moreover, the wrapper criterion with random forest for feature selection (FS) has been applied followed by classification using different algorithms such as k-nearest neighbors (k-NN), support vector machines (SVM), naive Bayes (NB) and random forest (RF).CONCLUSIONS: Our proposed method shows very good prediction results and demonstrates how information contained in SLiMs is highly relevant in predicting CaM-binding proteins. Further, three new CaM-binding motifs have been computationally selected and biologically validated in this study, and which can be used for predicting CaM-binding proteins.","3":"BMC bioinformatics","4":"30453876","5":"2018","6":"Bayes Theorem"},{"1":"The predictive performance of short-linear motif features in the prediction of calmodulin-binding proteins.","2":"BACKGROUND: The prediction of calmodulin-binding (CaM-binding) proteins plays a very important role in the fields of biology and biochemistry, because the calmodulin protein binds and regulates a multitude of protein targets affecting different cellular processes. Computational methods that can accurately identify CaM-binding proteins and CaM-binding domains would accelerate research in calcium signaling and calmodulin function. Short-linear motifs (SLiMs), on the other hand, have been effectively used as features for analyzing protein-protein interactions, though their properties have not been utilized in the prediction of CaM-binding proteins.RESULTS: We propose a new method for the prediction of CaM-binding proteins based on both the total and average scores of known and new SLiMs in protein sequences using a new scoring method called sliding window scoring (SWS) as features for the prediction module. A dataset of 194 manually curated human CaM-binding proteins and 193 mitochondrial proteins have been obtained and used for testing the proposed model. The motif generation tool, Multiple EM for Motif Elucidation (MEME), has been used to obtain new motifs from each of the positive and negative datasets individually (the SM approach) and from the combined negative and positive datasets (the CM approach). Moreover, the wrapper criterion with random forest for feature selection (FS) has been applied followed by classification using different algorithms such as k-nearest neighbors (k-NN), support vector machines (SVM), naive Bayes (NB) and random forest (RF).CONCLUSIONS: Our proposed method shows very good prediction results and demonstrates how information contained in SLiMs is highly relevant in predicting CaM-binding proteins. Further, three new CaM-binding motifs have been computationally selected and biologically validated in this study, and which can be used for predicting CaM-binding proteins.","3":"BMC bioinformatics","4":"30453876","5":"2018","6":"Calcium"},{"1":"The predictive performance of short-linear motif features in the prediction of calmodulin-binding proteins.","2":"BACKGROUND: The prediction of calmodulin-binding (CaM-binding) proteins plays a very important role in the fields of biology and biochemistry, because the calmodulin protein binds and regulates a multitude of protein targets affecting different cellular processes. Computational methods that can accurately identify CaM-binding proteins and CaM-binding domains would accelerate research in calcium signaling and calmodulin function. Short-linear motifs (SLiMs), on the other hand, have been effectively used as features for analyzing protein-protein interactions, though their properties have not been utilized in the prediction of CaM-binding proteins.RESULTS: We propose a new method for the prediction of CaM-binding proteins based on both the total and average scores of known and new SLiMs in protein sequences using a new scoring method called sliding window scoring (SWS) as features for the prediction module. A dataset of 194 manually curated human CaM-binding proteins and 193 mitochondrial proteins have been obtained and used for testing the proposed model. The motif generation tool, Multiple EM for Motif Elucidation (MEME), has been used to obtain new motifs from each of the positive and negative datasets individually (the SM approach) and from the combined negative and positive datasets (the CM approach). Moreover, the wrapper criterion with random forest for feature selection (FS) has been applied followed by classification using different algorithms such as k-nearest neighbors (k-NN), support vector machines (SVM), naive Bayes (NB) and random forest (RF).CONCLUSIONS: Our proposed method shows very good prediction results and demonstrates how information contained in SLiMs is highly relevant in predicting CaM-binding proteins. Further, three new CaM-binding motifs have been computationally selected and biologically validated in this study, and which can be used for predicting CaM-binding proteins.","3":"BMC bioinformatics","4":"30453876","5":"2018","6":"metabolism"},{"1":"The predictive performance of short-linear motif features in the prediction of calmodulin-binding proteins.","2":"BACKGROUND: The prediction of calmodulin-binding (CaM-binding) proteins plays a very important role in the fields of biology and biochemistry, because the calmodulin protein binds and regulates a multitude of protein targets affecting different cellular processes. Computational methods that can accurately identify CaM-binding proteins and CaM-binding domains would accelerate research in calcium signaling and calmodulin function. Short-linear motifs (SLiMs), on the other hand, have been effectively used as features for analyzing protein-protein interactions, though their properties have not been utilized in the prediction of CaM-binding proteins.RESULTS: We propose a new method for the prediction of CaM-binding proteins based on both the total and average scores of known and new SLiMs in protein sequences using a new scoring method called sliding window scoring (SWS) as features for the prediction module. A dataset of 194 manually curated human CaM-binding proteins and 193 mitochondrial proteins have been obtained and used for testing the proposed model. The motif generation tool, Multiple EM for Motif Elucidation (MEME), has been used to obtain new motifs from each of the positive and negative datasets individually (the SM approach) and from the combined negative and positive datasets (the CM approach). Moreover, the wrapper criterion with random forest for feature selection (FS) has been applied followed by classification using different algorithms such as k-nearest neighbors (k-NN), support vector machines (SVM), naive Bayes (NB) and random forest (RF).CONCLUSIONS: Our proposed method shows very good prediction results and demonstrates how information contained in SLiMs is highly relevant in predicting CaM-binding proteins. Further, three new CaM-binding motifs have been computationally selected and biologically validated in this study, and which can be used for predicting CaM-binding proteins.","3":"BMC bioinformatics","4":"30453876","5":"2018","6":"Calmodulin-Binding Proteins"},{"1":"The predictive performance of short-linear motif features in the prediction of calmodulin-binding proteins.","2":"BACKGROUND: The prediction of calmodulin-binding (CaM-binding) proteins plays a very important role in the fields of biology and biochemistry, because the calmodulin protein binds and regulates a multitude of protein targets affecting different cellular processes. Computational methods that can accurately identify CaM-binding proteins and CaM-binding domains would accelerate research in calcium signaling and calmodulin function. Short-linear motifs (SLiMs), on the other hand, have been effectively used as features for analyzing protein-protein interactions, though their properties have not been utilized in the prediction of CaM-binding proteins.RESULTS: We propose a new method for the prediction of CaM-binding proteins based on both the total and average scores of known and new SLiMs in protein sequences using a new scoring method called sliding window scoring (SWS) as features for the prediction module. A dataset of 194 manually curated human CaM-binding proteins and 193 mitochondrial proteins have been obtained and used for testing the proposed model. The motif generation tool, Multiple EM for Motif Elucidation (MEME), has been used to obtain new motifs from each of the positive and negative datasets individually (the SM approach) and from the combined negative and positive datasets (the CM approach). Moreover, the wrapper criterion with random forest for feature selection (FS) has been applied followed by classification using different algorithms such as k-nearest neighbors (k-NN), support vector machines (SVM), naive Bayes (NB) and random forest (RF).CONCLUSIONS: Our proposed method shows very good prediction results and demonstrates how information contained in SLiMs is highly relevant in predicting CaM-binding proteins. Further, three new CaM-binding motifs have been computationally selected and biologically validated in this study, and which can be used for predicting CaM-binding proteins.","3":"BMC bioinformatics","4":"30453876","5":"2018","6":"chemistry"},{"1":"The predictive performance of short-linear motif features in the prediction of calmodulin-binding proteins.","2":"BACKGROUND: The prediction of calmodulin-binding (CaM-binding) proteins plays a very important role in the fields of biology and biochemistry, because the calmodulin protein binds and regulates a multitude of protein targets affecting different cellular processes. Computational methods that can accurately identify CaM-binding proteins and CaM-binding domains would accelerate research in calcium signaling and calmodulin function. Short-linear motifs (SLiMs), on the other hand, have been effectively used as features for analyzing protein-protein interactions, though their properties have not been utilized in the prediction of CaM-binding proteins.RESULTS: We propose a new method for the prediction of CaM-binding proteins based on both the total and average scores of known and new SLiMs in protein sequences using a new scoring method called sliding window scoring (SWS) as features for the prediction module. A dataset of 194 manually curated human CaM-binding proteins and 193 mitochondrial proteins have been obtained and used for testing the proposed model. The motif generation tool, Multiple EM for Motif Elucidation (MEME), has been used to obtain new motifs from each of the positive and negative datasets individually (the SM approach) and from the combined negative and positive datasets (the CM approach). Moreover, the wrapper criterion with random forest for feature selection (FS) has been applied followed by classification using different algorithms such as k-nearest neighbors (k-NN), support vector machines (SVM), naive Bayes (NB) and random forest (RF).CONCLUSIONS: Our proposed method shows very good prediction results and demonstrates how information contained in SLiMs is highly relevant in predicting CaM-binding proteins. Further, three new CaM-binding motifs have been computationally selected and biologically validated in this study, and which can be used for predicting CaM-binding proteins.","3":"BMC bioinformatics","4":"30453876","5":"2018","6":"Computational Biology"},{"1":"The predictive performance of short-linear motif features in the prediction of calmodulin-binding proteins.","2":"BACKGROUND: The prediction of calmodulin-binding (CaM-binding) proteins plays a very important role in the fields of biology and biochemistry, because the calmodulin protein binds and regulates a multitude of protein targets affecting different cellular processes. Computational methods that can accurately identify CaM-binding proteins and CaM-binding domains would accelerate research in calcium signaling and calmodulin function. Short-linear motifs (SLiMs), on the other hand, have been effectively used as features for analyzing protein-protein interactions, though their properties have not been utilized in the prediction of CaM-binding proteins.RESULTS: We propose a new method for the prediction of CaM-binding proteins based on both the total and average scores of known and new SLiMs in protein sequences using a new scoring method called sliding window scoring (SWS) as features for the prediction module. A dataset of 194 manually curated human CaM-binding proteins and 193 mitochondrial proteins have been obtained and used for testing the proposed model. The motif generation tool, Multiple EM for Motif Elucidation (MEME), has been used to obtain new motifs from each of the positive and negative datasets individually (the SM approach) and from the combined negative and positive datasets (the CM approach). Moreover, the wrapper criterion with random forest for feature selection (FS) has been applied followed by classification using different algorithms such as k-nearest neighbors (k-NN), support vector machines (SVM), naive Bayes (NB) and random forest (RF).CONCLUSIONS: Our proposed method shows very good prediction results and demonstrates how information contained in SLiMs is highly relevant in predicting CaM-binding proteins. Further, three new CaM-binding motifs have been computationally selected and biologically validated in this study, and which can be used for predicting CaM-binding proteins.","3":"BMC bioinformatics","4":"30453876","5":"2018","6":"methods"},{"1":"The predictive performance of short-linear motif features in the prediction of calmodulin-binding proteins.","2":"BACKGROUND: The prediction of calmodulin-binding (CaM-binding) proteins plays a very important role in the fields of biology and biochemistry, because the calmodulin protein binds and regulates a multitude of protein targets affecting different cellular processes. Computational methods that can accurately identify CaM-binding proteins and CaM-binding domains would accelerate research in calcium signaling and calmodulin function. Short-linear motifs (SLiMs), on the other hand, have been effectively used as features for analyzing protein-protein interactions, though their properties have not been utilized in the prediction of CaM-binding proteins.RESULTS: We propose a new method for the prediction of CaM-binding proteins based on both the total and average scores of known and new SLiMs in protein sequences using a new scoring method called sliding window scoring (SWS) as features for the prediction module. A dataset of 194 manually curated human CaM-binding proteins and 193 mitochondrial proteins have been obtained and used for testing the proposed model. The motif generation tool, Multiple EM for Motif Elucidation (MEME), has been used to obtain new motifs from each of the positive and negative datasets individually (the SM approach) and from the combined negative and positive datasets (the CM approach). Moreover, the wrapper criterion with random forest for feature selection (FS) has been applied followed by classification using different algorithms such as k-nearest neighbors (k-NN), support vector machines (SVM), naive Bayes (NB) and random forest (RF).CONCLUSIONS: Our proposed method shows very good prediction results and demonstrates how information contained in SLiMs is highly relevant in predicting CaM-binding proteins. Further, three new CaM-binding motifs have been computationally selected and biologically validated in this study, and which can be used for predicting CaM-binding proteins.","3":"BMC bioinformatics","4":"30453876","5":"2018","6":"Humans"},{"1":"The predictive performance of short-linear motif features in the prediction of calmodulin-binding proteins.","2":"BACKGROUND: The prediction of calmodulin-binding (CaM-binding) proteins plays a very important role in the fields of biology and biochemistry, because the calmodulin protein binds and regulates a multitude of protein targets affecting different cellular processes. Computational methods that can accurately identify CaM-binding proteins and CaM-binding domains would accelerate research in calcium signaling and calmodulin function. Short-linear motifs (SLiMs), on the other hand, have been effectively used as features for analyzing protein-protein interactions, though their properties have not been utilized in the prediction of CaM-binding proteins.RESULTS: We propose a new method for the prediction of CaM-binding proteins based on both the total and average scores of known and new SLiMs in protein sequences using a new scoring method called sliding window scoring (SWS) as features for the prediction module. A dataset of 194 manually curated human CaM-binding proteins and 193 mitochondrial proteins have been obtained and used for testing the proposed model. The motif generation tool, Multiple EM for Motif Elucidation (MEME), has been used to obtain new motifs from each of the positive and negative datasets individually (the SM approach) and from the combined negative and positive datasets (the CM approach). Moreover, the wrapper criterion with random forest for feature selection (FS) has been applied followed by classification using different algorithms such as k-nearest neighbors (k-NN), support vector machines (SVM), naive Bayes (NB) and random forest (RF).CONCLUSIONS: Our proposed method shows very good prediction results and demonstrates how information contained in SLiMs is highly relevant in predicting CaM-binding proteins. Further, three new CaM-binding motifs have been computationally selected and biologically validated in this study, and which can be used for predicting CaM-binding proteins.","3":"BMC bioinformatics","4":"30453876","5":"2018","6":"Probability"},{"1":"The predictive performance of short-linear motif features in the prediction of calmodulin-binding proteins.","2":"BACKGROUND: The prediction of calmodulin-binding (CaM-binding) proteins plays a very important role in the fields of biology and biochemistry, because the calmodulin protein binds and regulates a multitude of protein targets affecting different cellular processes. Computational methods that can accurately identify CaM-binding proteins and CaM-binding domains would accelerate research in calcium signaling and calmodulin function. Short-linear motifs (SLiMs), on the other hand, have been effectively used as features for analyzing protein-protein interactions, though their properties have not been utilized in the prediction of CaM-binding proteins.RESULTS: We propose a new method for the prediction of CaM-binding proteins based on both the total and average scores of known and new SLiMs in protein sequences using a new scoring method called sliding window scoring (SWS) as features for the prediction module. A dataset of 194 manually curated human CaM-binding proteins and 193 mitochondrial proteins have been obtained and used for testing the proposed model. The motif generation tool, Multiple EM for Motif Elucidation (MEME), has been used to obtain new motifs from each of the positive and negative datasets individually (the SM approach) and from the combined negative and positive datasets (the CM approach). Moreover, the wrapper criterion with random forest for feature selection (FS) has been applied followed by classification using different algorithms such as k-nearest neighbors (k-NN), support vector machines (SVM), naive Bayes (NB) and random forest (RF).CONCLUSIONS: Our proposed method shows very good prediction results and demonstrates how information contained in SLiMs is highly relevant in predicting CaM-binding proteins. Further, three new CaM-binding motifs have been computationally selected and biologically validated in this study, and which can be used for predicting CaM-binding proteins.","3":"BMC bioinformatics","4":"30453876","5":"2018","6":"Protein Structure, Quaternary"},{"1":"The predictive performance of short-linear motif features in the prediction of calmodulin-binding proteins.","2":"BACKGROUND: The prediction of calmodulin-binding (CaM-binding) proteins plays a very important role in the fields of biology and biochemistry, because the calmodulin protein binds and regulates a multitude of protein targets affecting different cellular processes. Computational methods that can accurately identify CaM-binding proteins and CaM-binding domains would accelerate research in calcium signaling and calmodulin function. Short-linear motifs (SLiMs), on the other hand, have been effectively used as features for analyzing protein-protein interactions, though their properties have not been utilized in the prediction of CaM-binding proteins.RESULTS: We propose a new method for the prediction of CaM-binding proteins based on both the total and average scores of known and new SLiMs in protein sequences using a new scoring method called sliding window scoring (SWS) as features for the prediction module. A dataset of 194 manually curated human CaM-binding proteins and 193 mitochondrial proteins have been obtained and used for testing the proposed model. The motif generation tool, Multiple EM for Motif Elucidation (MEME), has been used to obtain new motifs from each of the positive and negative datasets individually (the SM approach) and from the combined negative and positive datasets (the CM approach). Moreover, the wrapper criterion with random forest for feature selection (FS) has been applied followed by classification using different algorithms such as k-nearest neighbors (k-NN), support vector machines (SVM), naive Bayes (NB) and random forest (RF).CONCLUSIONS: Our proposed method shows very good prediction results and demonstrates how information contained in SLiMs is highly relevant in predicting CaM-binding proteins. Further, three new CaM-binding motifs have been computationally selected and biologically validated in this study, and which can be used for predicting CaM-binding proteins.","3":"BMC bioinformatics","4":"30453876","5":"2018","6":"Reproducibility of Results"},{"1":"The predictive performance of short-linear motif features in the prediction of calmodulin-binding proteins.","2":"BACKGROUND: The prediction of calmodulin-binding (CaM-binding) proteins plays a very important role in the fields of biology and biochemistry, because the calmodulin protein binds and regulates a multitude of protein targets affecting different cellular processes. Computational methods that can accurately identify CaM-binding proteins and CaM-binding domains would accelerate research in calcium signaling and calmodulin function. Short-linear motifs (SLiMs), on the other hand, have been effectively used as features for analyzing protein-protein interactions, though their properties have not been utilized in the prediction of CaM-binding proteins.RESULTS: We propose a new method for the prediction of CaM-binding proteins based on both the total and average scores of known and new SLiMs in protein sequences using a new scoring method called sliding window scoring (SWS) as features for the prediction module. A dataset of 194 manually curated human CaM-binding proteins and 193 mitochondrial proteins have been obtained and used for testing the proposed model. The motif generation tool, Multiple EM for Motif Elucidation (MEME), has been used to obtain new motifs from each of the positive and negative datasets individually (the SM approach) and from the combined negative and positive datasets (the CM approach). Moreover, the wrapper criterion with random forest for feature selection (FS) has been applied followed by classification using different algorithms such as k-nearest neighbors (k-NN), support vector machines (SVM), naive Bayes (NB) and random forest (RF).CONCLUSIONS: Our proposed method shows very good prediction results and demonstrates how information contained in SLiMs is highly relevant in predicting CaM-binding proteins. Further, three new CaM-binding motifs have been computationally selected and biologically validated in this study, and which can be used for predicting CaM-binding proteins.","3":"BMC bioinformatics","4":"30453876","5":"2018","6":"Support Vector Machine"},{"1":"Mapping Mangrove Forests of Dongzhaigang Nature Reserve in China Using Landsat 8 and Radarsat-2 Polarimetric SAR Data.","2":"Mangrove forests are distributed in intertidal regions that act as a &quot;natural barrier&quot; to the coast. They have enormous ecological, economic, and social value. However, the world's mangrove forests are declining under immense pressure from anthropogenic and natural disturbances. Accurate information regarding mangrove forests is essential for their protection and restoration. The main objective of this study was to develop a method to improve the classification of mangrove forests using C-band quad-pol Synthetic Aperture Radar (SAR) data (Radarsat-2) and optical data (Landsat 8), and to analyze the spectral and backscattering signatures of mangrove forests. We used a support vector machine (SVM) classification method to classify the land use in Hainan Dongzhaigang National Nature Reserve (HDNNR). The results showed that the overall accuracy using only optical information was 83.5%. Classification accuracy was improved to a varying extent by the addition of different radar data. The highest overall accuracy was 95.0% based on a combination of SAR and optical data. The area of mangrove forest in the reserve was found to be 1981.7 ha, as determined from the group with the highest classification accuracy. Combining optical data with SAR data could improve the classification accuracy and be significant for mangrove forest conservation.","3":"Sensors (Basel, Switzerland)","4":"30453608","5":"2018","6":"Conservation of Natural Resources"},{"1":"Mapping Mangrove Forests of Dongzhaigang Nature Reserve in China Using Landsat 8 and Radarsat-2 Polarimetric SAR Data.","2":"Mangrove forests are distributed in intertidal regions that act as a &quot;natural barrier&quot; to the coast. They have enormous ecological, economic, and social value. However, the world's mangrove forests are declining under immense pressure from anthropogenic and natural disturbances. Accurate information regarding mangrove forests is essential for their protection and restoration. The main objective of this study was to develop a method to improve the classification of mangrove forests using C-band quad-pol Synthetic Aperture Radar (SAR) data (Radarsat-2) and optical data (Landsat 8), and to analyze the spectral and backscattering signatures of mangrove forests. We used a support vector machine (SVM) classification method to classify the land use in Hainan Dongzhaigang National Nature Reserve (HDNNR). The results showed that the overall accuracy using only optical information was 83.5%. Classification accuracy was improved to a varying extent by the addition of different radar data. The highest overall accuracy was 95.0% based on a combination of SAR and optical data. The area of mangrove forest in the reserve was found to be 1981.7 ha, as determined from the group with the highest classification accuracy. Combining optical data with SAR data could improve the classification accuracy and be significant for mangrove forest conservation.","3":"Sensors (Basel, Switzerland)","4":"30453608","5":"2018","6":"Environmental Monitoring"},{"1":"Mapping Mangrove Forests of Dongzhaigang Nature Reserve in China Using Landsat 8 and Radarsat-2 Polarimetric SAR Data.","2":"Mangrove forests are distributed in intertidal regions that act as a &quot;natural barrier&quot; to the coast. They have enormous ecological, economic, and social value. However, the world's mangrove forests are declining under immense pressure from anthropogenic and natural disturbances. Accurate information regarding mangrove forests is essential for their protection and restoration. The main objective of this study was to develop a method to improve the classification of mangrove forests using C-band quad-pol Synthetic Aperture Radar (SAR) data (Radarsat-2) and optical data (Landsat 8), and to analyze the spectral and backscattering signatures of mangrove forests. We used a support vector machine (SVM) classification method to classify the land use in Hainan Dongzhaigang National Nature Reserve (HDNNR). The results showed that the overall accuracy using only optical information was 83.5%. Classification accuracy was improved to a varying extent by the addition of different radar data. The highest overall accuracy was 95.0% based on a combination of SAR and optical data. The area of mangrove forest in the reserve was found to be 1981.7 ha, as determined from the group with the highest classification accuracy. Combining optical data with SAR data could improve the classification accuracy and be significant for mangrove forest conservation.","3":"Sensors (Basel, Switzerland)","4":"30453608","5":"2018","6":"methods"},{"1":"Mapping Mangrove Forests of Dongzhaigang Nature Reserve in China Using Landsat 8 and Radarsat-2 Polarimetric SAR Data.","2":"Mangrove forests are distributed in intertidal regions that act as a &quot;natural barrier&quot; to the coast. They have enormous ecological, economic, and social value. However, the world's mangrove forests are declining under immense pressure from anthropogenic and natural disturbances. Accurate information regarding mangrove forests is essential for their protection and restoration. The main objective of this study was to develop a method to improve the classification of mangrove forests using C-band quad-pol Synthetic Aperture Radar (SAR) data (Radarsat-2) and optical data (Landsat 8), and to analyze the spectral and backscattering signatures of mangrove forests. We used a support vector machine (SVM) classification method to classify the land use in Hainan Dongzhaigang National Nature Reserve (HDNNR). The results showed that the overall accuracy using only optical information was 83.5%. Classification accuracy was improved to a varying extent by the addition of different radar data. The highest overall accuracy was 95.0% based on a combination of SAR and optical data. The area of mangrove forest in the reserve was found to be 1981.7 ha, as determined from the group with the highest classification accuracy. Combining optical data with SAR data could improve the classification accuracy and be significant for mangrove forest conservation.","3":"Sensors (Basel, Switzerland)","4":"30453608","5":"2018","6":"Image Processing, Computer-Assisted"},{"1":"Mapping Mangrove Forests of Dongzhaigang Nature Reserve in China Using Landsat 8 and Radarsat-2 Polarimetric SAR Data.","2":"Mangrove forests are distributed in intertidal regions that act as a &quot;natural barrier&quot; to the coast. They have enormous ecological, economic, and social value. However, the world's mangrove forests are declining under immense pressure from anthropogenic and natural disturbances. Accurate information regarding mangrove forests is essential for their protection and restoration. The main objective of this study was to develop a method to improve the classification of mangrove forests using C-band quad-pol Synthetic Aperture Radar (SAR) data (Radarsat-2) and optical data (Landsat 8), and to analyze the spectral and backscattering signatures of mangrove forests. We used a support vector machine (SVM) classification method to classify the land use in Hainan Dongzhaigang National Nature Reserve (HDNNR). The results showed that the overall accuracy using only optical information was 83.5%. Classification accuracy was improved to a varying extent by the addition of different radar data. The highest overall accuracy was 95.0% based on a combination of SAR and optical data. The area of mangrove forest in the reserve was found to be 1981.7 ha, as determined from the group with the highest classification accuracy. Combining optical data with SAR data could improve the classification accuracy and be significant for mangrove forest conservation.","3":"Sensors (Basel, Switzerland)","4":"30453608","5":"2018","6":"Radar"},{"1":"Mapping Mangrove Forests of Dongzhaigang Nature Reserve in China Using Landsat 8 and Radarsat-2 Polarimetric SAR Data.","2":"Mangrove forests are distributed in intertidal regions that act as a &quot;natural barrier&quot; to the coast. They have enormous ecological, economic, and social value. However, the world's mangrove forests are declining under immense pressure from anthropogenic and natural disturbances. Accurate information regarding mangrove forests is essential for their protection and restoration. The main objective of this study was to develop a method to improve the classification of mangrove forests using C-band quad-pol Synthetic Aperture Radar (SAR) data (Radarsat-2) and optical data (Landsat 8), and to analyze the spectral and backscattering signatures of mangrove forests. We used a support vector machine (SVM) classification method to classify the land use in Hainan Dongzhaigang National Nature Reserve (HDNNR). The results showed that the overall accuracy using only optical information was 83.5%. Classification accuracy was improved to a varying extent by the addition of different radar data. The highest overall accuracy was 95.0% based on a combination of SAR and optical data. The area of mangrove forest in the reserve was found to be 1981.7 ha, as determined from the group with the highest classification accuracy. Combining optical data with SAR data could improve the classification accuracy and be significant for mangrove forest conservation.","3":"Sensors (Basel, Switzerland)","4":"30453608","5":"2018","6":"Support Vector Machine"},{"1":"Mapping Mangrove Forests of Dongzhaigang Nature Reserve in China Using Landsat 8 and Radarsat-2 Polarimetric SAR Data.","2":"Mangrove forests are distributed in intertidal regions that act as a &quot;natural barrier&quot; to the coast. They have enormous ecological, economic, and social value. However, the world's mangrove forests are declining under immense pressure from anthropogenic and natural disturbances. Accurate information regarding mangrove forests is essential for their protection and restoration. The main objective of this study was to develop a method to improve the classification of mangrove forests using C-band quad-pol Synthetic Aperture Radar (SAR) data (Radarsat-2) and optical data (Landsat 8), and to analyze the spectral and backscattering signatures of mangrove forests. We used a support vector machine (SVM) classification method to classify the land use in Hainan Dongzhaigang National Nature Reserve (HDNNR). The results showed that the overall accuracy using only optical information was 83.5%. Classification accuracy was improved to a varying extent by the addition of different radar data. The highest overall accuracy was 95.0% based on a combination of SAR and optical data. The area of mangrove forest in the reserve was found to be 1981.7 ha, as determined from the group with the highest classification accuracy. Combining optical data with SAR data could improve the classification accuracy and be significant for mangrove forest conservation.","3":"Sensors (Basel, Switzerland)","4":"30453608","5":"2018","6":"Wetlands"},{"1":"Overall survival prediction in glioblastoma multiforme patients from volumetric, shape and texture features using machine learning.","2":"Glioblastoma multiforme (GBM) are aggressive brain tumors, which lead to poor overall survival (OS) of patients. OS prediction of GBM patients provides useful information for surgical and treatment planning. Radiomics research attempts at predicting disease prognosis, thus providing beneficial information for personalized treatment from a variety of imaging features extracted from multiple MR images. In this study, MR image derived texture features, tumor shape and volumetric features, and patient age were obtained for 163 patients. OS group prediction was performed for both 2-class (short and long) and 3-class (short, medium and long) survival groups. Support vector machine classification based recursive feature elimination method was used to perform feature selection. The performance of the classification model was assessed using 5-fold cross-validation. The 2-class and 3-class OS group prediction accuracy obtained were 98.7% and 88.95% respectively. The shape features used in this work have been evaluated for OS prediction of GBM patients for the first time. The feature selection and prediction scheme implemented in this study yielded high accuracy for both 2-class and 3-class OS group predictions. This study was performed using routinely acquired MR images for GBM patients, thus making the translation of this work into a clinical setup convenient.","3":"Surgical oncology","4":"30449497","5":"2018","6":"Algorithms"},{"1":"Overall survival prediction in glioblastoma multiforme patients from volumetric, shape and texture features using machine learning.","2":"Glioblastoma multiforme (GBM) are aggressive brain tumors, which lead to poor overall survival (OS) of patients. OS prediction of GBM patients provides useful information for surgical and treatment planning. Radiomics research attempts at predicting disease prognosis, thus providing beneficial information for personalized treatment from a variety of imaging features extracted from multiple MR images. In this study, MR image derived texture features, tumor shape and volumetric features, and patient age were obtained for 163 patients. OS group prediction was performed for both 2-class (short and long) and 3-class (short, medium and long) survival groups. Support vector machine classification based recursive feature elimination method was used to perform feature selection. The performance of the classification model was assessed using 5-fold cross-validation. The 2-class and 3-class OS group prediction accuracy obtained were 98.7% and 88.95% respectively. The shape features used in this work have been evaluated for OS prediction of GBM patients for the first time. The feature selection and prediction scheme implemented in this study yielded high accuracy for both 2-class and 3-class OS group predictions. This study was performed using routinely acquired MR images for GBM patients, thus making the translation of this work into a clinical setup convenient.","3":"Surgical oncology","4":"30449497","5":"2018","6":"Brain Neoplasms"},{"1":"Overall survival prediction in glioblastoma multiforme patients from volumetric, shape and texture features using machine learning.","2":"Glioblastoma multiforme (GBM) are aggressive brain tumors, which lead to poor overall survival (OS) of patients. OS prediction of GBM patients provides useful information for surgical and treatment planning. Radiomics research attempts at predicting disease prognosis, thus providing beneficial information for personalized treatment from a variety of imaging features extracted from multiple MR images. In this study, MR image derived texture features, tumor shape and volumetric features, and patient age were obtained for 163 patients. OS group prediction was performed for both 2-class (short and long) and 3-class (short, medium and long) survival groups. Support vector machine classification based recursive feature elimination method was used to perform feature selection. The performance of the classification model was assessed using 5-fold cross-validation. The 2-class and 3-class OS group prediction accuracy obtained were 98.7% and 88.95% respectively. The shape features used in this work have been evaluated for OS prediction of GBM patients for the first time. The feature selection and prediction scheme implemented in this study yielded high accuracy for both 2-class and 3-class OS group predictions. This study was performed using routinely acquired MR images for GBM patients, thus making the translation of this work into a clinical setup convenient.","3":"Surgical oncology","4":"30449497","5":"2018","6":"mortality"},{"1":"Overall survival prediction in glioblastoma multiforme patients from volumetric, shape and texture features using machine learning.","2":"Glioblastoma multiforme (GBM) are aggressive brain tumors, which lead to poor overall survival (OS) of patients. OS prediction of GBM patients provides useful information for surgical and treatment planning. Radiomics research attempts at predicting disease prognosis, thus providing beneficial information for personalized treatment from a variety of imaging features extracted from multiple MR images. In this study, MR image derived texture features, tumor shape and volumetric features, and patient age were obtained for 163 patients. OS group prediction was performed for both 2-class (short and long) and 3-class (short, medium and long) survival groups. Support vector machine classification based recursive feature elimination method was used to perform feature selection. The performance of the classification model was assessed using 5-fold cross-validation. The 2-class and 3-class OS group prediction accuracy obtained were 98.7% and 88.95% respectively. The shape features used in this work have been evaluated for OS prediction of GBM patients for the first time. The feature selection and prediction scheme implemented in this study yielded high accuracy for both 2-class and 3-class OS group predictions. This study was performed using routinely acquired MR images for GBM patients, thus making the translation of this work into a clinical setup convenient.","3":"Surgical oncology","4":"30449497","5":"2018","6":"pathology"},{"1":"Overall survival prediction in glioblastoma multiforme patients from volumetric, shape and texture features using machine learning.","2":"Glioblastoma multiforme (GBM) are aggressive brain tumors, which lead to poor overall survival (OS) of patients. OS prediction of GBM patients provides useful information for surgical and treatment planning. Radiomics research attempts at predicting disease prognosis, thus providing beneficial information for personalized treatment from a variety of imaging features extracted from multiple MR images. In this study, MR image derived texture features, tumor shape and volumetric features, and patient age were obtained for 163 patients. OS group prediction was performed for both 2-class (short and long) and 3-class (short, medium and long) survival groups. Support vector machine classification based recursive feature elimination method was used to perform feature selection. The performance of the classification model was assessed using 5-fold cross-validation. The 2-class and 3-class OS group prediction accuracy obtained were 98.7% and 88.95% respectively. The shape features used in this work have been evaluated for OS prediction of GBM patients for the first time. The feature selection and prediction scheme implemented in this study yielded high accuracy for both 2-class and 3-class OS group predictions. This study was performed using routinely acquired MR images for GBM patients, thus making the translation of this work into a clinical setup convenient.","3":"Surgical oncology","4":"30449497","5":"2018","6":"surgery"},{"1":"Overall survival prediction in glioblastoma multiforme patients from volumetric, shape and texture features using machine learning.","2":"Glioblastoma multiforme (GBM) are aggressive brain tumors, which lead to poor overall survival (OS) of patients. OS prediction of GBM patients provides useful information for surgical and treatment planning. Radiomics research attempts at predicting disease prognosis, thus providing beneficial information for personalized treatment from a variety of imaging features extracted from multiple MR images. In this study, MR image derived texture features, tumor shape and volumetric features, and patient age were obtained for 163 patients. OS group prediction was performed for both 2-class (short and long) and 3-class (short, medium and long) survival groups. Support vector machine classification based recursive feature elimination method was used to perform feature selection. The performance of the classification model was assessed using 5-fold cross-validation. The 2-class and 3-class OS group prediction accuracy obtained were 98.7% and 88.95% respectively. The shape features used in this work have been evaluated for OS prediction of GBM patients for the first time. The feature selection and prediction scheme implemented in this study yielded high accuracy for both 2-class and 3-class OS group predictions. This study was performed using routinely acquired MR images for GBM patients, thus making the translation of this work into a clinical setup convenient.","3":"Surgical oncology","4":"30449497","5":"2018","6":"Disease Progression"},{"1":"Overall survival prediction in glioblastoma multiforme patients from volumetric, shape and texture features using machine learning.","2":"Glioblastoma multiforme (GBM) are aggressive brain tumors, which lead to poor overall survival (OS) of patients. OS prediction of GBM patients provides useful information for surgical and treatment planning. Radiomics research attempts at predicting disease prognosis, thus providing beneficial information for personalized treatment from a variety of imaging features extracted from multiple MR images. In this study, MR image derived texture features, tumor shape and volumetric features, and patient age were obtained for 163 patients. OS group prediction was performed for both 2-class (short and long) and 3-class (short, medium and long) survival groups. Support vector machine classification based recursive feature elimination method was used to perform feature selection. The performance of the classification model was assessed using 5-fold cross-validation. The 2-class and 3-class OS group prediction accuracy obtained were 98.7% and 88.95% respectively. The shape features used in this work have been evaluated for OS prediction of GBM patients for the first time. The feature selection and prediction scheme implemented in this study yielded high accuracy for both 2-class and 3-class OS group predictions. This study was performed using routinely acquired MR images for GBM patients, thus making the translation of this work into a clinical setup convenient.","3":"Surgical oncology","4":"30449497","5":"2018","6":"Glioblastoma"},{"1":"Overall survival prediction in glioblastoma multiforme patients from volumetric, shape and texture features using machine learning.","2":"Glioblastoma multiforme (GBM) are aggressive brain tumors, which lead to poor overall survival (OS) of patients. OS prediction of GBM patients provides useful information for surgical and treatment planning. Radiomics research attempts at predicting disease prognosis, thus providing beneficial information for personalized treatment from a variety of imaging features extracted from multiple MR images. In this study, MR image derived texture features, tumor shape and volumetric features, and patient age were obtained for 163 patients. OS group prediction was performed for both 2-class (short and long) and 3-class (short, medium and long) survival groups. Support vector machine classification based recursive feature elimination method was used to perform feature selection. The performance of the classification model was assessed using 5-fold cross-validation. The 2-class and 3-class OS group prediction accuracy obtained were 98.7% and 88.95% respectively. The shape features used in this work have been evaluated for OS prediction of GBM patients for the first time. The feature selection and prediction scheme implemented in this study yielded high accuracy for both 2-class and 3-class OS group predictions. This study was performed using routinely acquired MR images for GBM patients, thus making the translation of this work into a clinical setup convenient.","3":"Surgical oncology","4":"30449497","5":"2018","6":"mortality"},{"1":"Overall survival prediction in glioblastoma multiforme patients from volumetric, shape and texture features using machine learning.","2":"Glioblastoma multiforme (GBM) are aggressive brain tumors, which lead to poor overall survival (OS) of patients. OS prediction of GBM patients provides useful information for surgical and treatment planning. Radiomics research attempts at predicting disease prognosis, thus providing beneficial information for personalized treatment from a variety of imaging features extracted from multiple MR images. In this study, MR image derived texture features, tumor shape and volumetric features, and patient age were obtained for 163 patients. OS group prediction was performed for both 2-class (short and long) and 3-class (short, medium and long) survival groups. Support vector machine classification based recursive feature elimination method was used to perform feature selection. The performance of the classification model was assessed using 5-fold cross-validation. The 2-class and 3-class OS group prediction accuracy obtained were 98.7% and 88.95% respectively. The shape features used in this work have been evaluated for OS prediction of GBM patients for the first time. The feature selection and prediction scheme implemented in this study yielded high accuracy for both 2-class and 3-class OS group predictions. This study was performed using routinely acquired MR images for GBM patients, thus making the translation of this work into a clinical setup convenient.","3":"Surgical oncology","4":"30449497","5":"2018","6":"pathology"},{"1":"Overall survival prediction in glioblastoma multiforme patients from volumetric, shape and texture features using machine learning.","2":"Glioblastoma multiforme (GBM) are aggressive brain tumors, which lead to poor overall survival (OS) of patients. OS prediction of GBM patients provides useful information for surgical and treatment planning. Radiomics research attempts at predicting disease prognosis, thus providing beneficial information for personalized treatment from a variety of imaging features extracted from multiple MR images. In this study, MR image derived texture features, tumor shape and volumetric features, and patient age were obtained for 163 patients. OS group prediction was performed for both 2-class (short and long) and 3-class (short, medium and long) survival groups. Support vector machine classification based recursive feature elimination method was used to perform feature selection. The performance of the classification model was assessed using 5-fold cross-validation. The 2-class and 3-class OS group prediction accuracy obtained were 98.7% and 88.95% respectively. The shape features used in this work have been evaluated for OS prediction of GBM patients for the first time. The feature selection and prediction scheme implemented in this study yielded high accuracy for both 2-class and 3-class OS group predictions. This study was performed using routinely acquired MR images for GBM patients, thus making the translation of this work into a clinical setup convenient.","3":"Surgical oncology","4":"30449497","5":"2018","6":"surgery"},{"1":"Overall survival prediction in glioblastoma multiforme patients from volumetric, shape and texture features using machine learning.","2":"Glioblastoma multiforme (GBM) are aggressive brain tumors, which lead to poor overall survival (OS) of patients. OS prediction of GBM patients provides useful information for surgical and treatment planning. Radiomics research attempts at predicting disease prognosis, thus providing beneficial information for personalized treatment from a variety of imaging features extracted from multiple MR images. In this study, MR image derived texture features, tumor shape and volumetric features, and patient age were obtained for 163 patients. OS group prediction was performed for both 2-class (short and long) and 3-class (short, medium and long) survival groups. Support vector machine classification based recursive feature elimination method was used to perform feature selection. The performance of the classification model was assessed using 5-fold cross-validation. The 2-class and 3-class OS group prediction accuracy obtained were 98.7% and 88.95% respectively. The shape features used in this work have been evaluated for OS prediction of GBM patients for the first time. The feature selection and prediction scheme implemented in this study yielded high accuracy for both 2-class and 3-class OS group predictions. This study was performed using routinely acquired MR images for GBM patients, thus making the translation of this work into a clinical setup convenient.","3":"Surgical oncology","4":"30449497","5":"2018","6":"Humans"},{"1":"Overall survival prediction in glioblastoma multiforme patients from volumetric, shape and texture features using machine learning.","2":"Glioblastoma multiforme (GBM) are aggressive brain tumors, which lead to poor overall survival (OS) of patients. OS prediction of GBM patients provides useful information for surgical and treatment planning. Radiomics research attempts at predicting disease prognosis, thus providing beneficial information for personalized treatment from a variety of imaging features extracted from multiple MR images. In this study, MR image derived texture features, tumor shape and volumetric features, and patient age were obtained for 163 patients. OS group prediction was performed for both 2-class (short and long) and 3-class (short, medium and long) survival groups. Support vector machine classification based recursive feature elimination method was used to perform feature selection. The performance of the classification model was assessed using 5-fold cross-validation. The 2-class and 3-class OS group prediction accuracy obtained were 98.7% and 88.95% respectively. The shape features used in this work have been evaluated for OS prediction of GBM patients for the first time. The feature selection and prediction scheme implemented in this study yielded high accuracy for both 2-class and 3-class OS group predictions. This study was performed using routinely acquired MR images for GBM patients, thus making the translation of this work into a clinical setup convenient.","3":"Surgical oncology","4":"30449497","5":"2018","6":"Machine Learning"},{"1":"Overall survival prediction in glioblastoma multiforme patients from volumetric, shape and texture features using machine learning.","2":"Glioblastoma multiforme (GBM) are aggressive brain tumors, which lead to poor overall survival (OS) of patients. OS prediction of GBM patients provides useful information for surgical and treatment planning. Radiomics research attempts at predicting disease prognosis, thus providing beneficial information for personalized treatment from a variety of imaging features extracted from multiple MR images. In this study, MR image derived texture features, tumor shape and volumetric features, and patient age were obtained for 163 patients. OS group prediction was performed for both 2-class (short and long) and 3-class (short, medium and long) survival groups. Support vector machine classification based recursive feature elimination method was used to perform feature selection. The performance of the classification model was assessed using 5-fold cross-validation. The 2-class and 3-class OS group prediction accuracy obtained were 98.7% and 88.95% respectively. The shape features used in this work have been evaluated for OS prediction of GBM patients for the first time. The feature selection and prediction scheme implemented in this study yielded high accuracy for both 2-class and 3-class OS group predictions. This study was performed using routinely acquired MR images for GBM patients, thus making the translation of this work into a clinical setup convenient.","3":"Surgical oncology","4":"30449497","5":"2018","6":"Magnetic Resonance Imaging"},{"1":"Overall survival prediction in glioblastoma multiforme patients from volumetric, shape and texture features using machine learning.","2":"Glioblastoma multiforme (GBM) are aggressive brain tumors, which lead to poor overall survival (OS) of patients. OS prediction of GBM patients provides useful information for surgical and treatment planning. Radiomics research attempts at predicting disease prognosis, thus providing beneficial information for personalized treatment from a variety of imaging features extracted from multiple MR images. In this study, MR image derived texture features, tumor shape and volumetric features, and patient age were obtained for 163 patients. OS group prediction was performed for both 2-class (short and long) and 3-class (short, medium and long) survival groups. Support vector machine classification based recursive feature elimination method was used to perform feature selection. The performance of the classification model was assessed using 5-fold cross-validation. The 2-class and 3-class OS group prediction accuracy obtained were 98.7% and 88.95% respectively. The shape features used in this work have been evaluated for OS prediction of GBM patients for the first time. The feature selection and prediction scheme implemented in this study yielded high accuracy for both 2-class and 3-class OS group predictions. This study was performed using routinely acquired MR images for GBM patients, thus making the translation of this work into a clinical setup convenient.","3":"Surgical oncology","4":"30449497","5":"2018","6":"Models, Statistical"},{"1":"Overall survival prediction in glioblastoma multiforme patients from volumetric, shape and texture features using machine learning.","2":"Glioblastoma multiforme (GBM) are aggressive brain tumors, which lead to poor overall survival (OS) of patients. OS prediction of GBM patients provides useful information for surgical and treatment planning. Radiomics research attempts at predicting disease prognosis, thus providing beneficial information for personalized treatment from a variety of imaging features extracted from multiple MR images. In this study, MR image derived texture features, tumor shape and volumetric features, and patient age were obtained for 163 patients. OS group prediction was performed for both 2-class (short and long) and 3-class (short, medium and long) survival groups. Support vector machine classification based recursive feature elimination method was used to perform feature selection. The performance of the classification model was assessed using 5-fold cross-validation. The 2-class and 3-class OS group prediction accuracy obtained were 98.7% and 88.95% respectively. The shape features used in this work have been evaluated for OS prediction of GBM patients for the first time. The feature selection and prediction scheme implemented in this study yielded high accuracy for both 2-class and 3-class OS group predictions. This study was performed using routinely acquired MR images for GBM patients, thus making the translation of this work into a clinical setup convenient.","3":"Surgical oncology","4":"30449497","5":"2018","6":"Prognosis"},{"1":"Overall survival prediction in glioblastoma multiforme patients from volumetric, shape and texture features using machine learning.","2":"Glioblastoma multiforme (GBM) are aggressive brain tumors, which lead to poor overall survival (OS) of patients. OS prediction of GBM patients provides useful information for surgical and treatment planning. Radiomics research attempts at predicting disease prognosis, thus providing beneficial information for personalized treatment from a variety of imaging features extracted from multiple MR images. In this study, MR image derived texture features, tumor shape and volumetric features, and patient age were obtained for 163 patients. OS group prediction was performed for both 2-class (short and long) and 3-class (short, medium and long) survival groups. Support vector machine classification based recursive feature elimination method was used to perform feature selection. The performance of the classification model was assessed using 5-fold cross-validation. The 2-class and 3-class OS group prediction accuracy obtained were 98.7% and 88.95% respectively. The shape features used in this work have been evaluated for OS prediction of GBM patients for the first time. The feature selection and prediction scheme implemented in this study yielded high accuracy for both 2-class and 3-class OS group predictions. This study was performed using routinely acquired MR images for GBM patients, thus making the translation of this work into a clinical setup convenient.","3":"Surgical oncology","4":"30449497","5":"2018","6":"ROC Curve"},{"1":"Overall survival prediction in glioblastoma multiforme patients from volumetric, shape and texture features using machine learning.","2":"Glioblastoma multiforme (GBM) are aggressive brain tumors, which lead to poor overall survival (OS) of patients. OS prediction of GBM patients provides useful information for surgical and treatment planning. Radiomics research attempts at predicting disease prognosis, thus providing beneficial information for personalized treatment from a variety of imaging features extracted from multiple MR images. In this study, MR image derived texture features, tumor shape and volumetric features, and patient age were obtained for 163 patients. OS group prediction was performed for both 2-class (short and long) and 3-class (short, medium and long) survival groups. Support vector machine classification based recursive feature elimination method was used to perform feature selection. The performance of the classification model was assessed using 5-fold cross-validation. The 2-class and 3-class OS group prediction accuracy obtained were 98.7% and 88.95% respectively. The shape features used in this work have been evaluated for OS prediction of GBM patients for the first time. The feature selection and prediction scheme implemented in this study yielded high accuracy for both 2-class and 3-class OS group predictions. This study was performed using routinely acquired MR images for GBM patients, thus making the translation of this work into a clinical setup convenient.","3":"Surgical oncology","4":"30449497","5":"2018","6":"Survival Rate"},{"1":"A Survey of the Techniques for The Identification and Classification of Human Actions from Visual Data.","2":"Recognition of human actions form videos has been an active area of research because it has applications in various domains. The results of work in this field are used in video surveillance, automatic video labeling and human-computer interaction, among others. Any advancements in this field are tied to advances in the interrelated fields of object recognition, spatio- temporal video analysis and semantic segmentation. Activity recognition is a challenging task since it faces many problems such as occlusion, view point variation, background differences and clutter and illumination variations. Scientific achievements in the field have been numerous and rapid as the applications are far reaching. In this survey, we cover the growth of the field from the earliest solutions, where handcrafted features were used, to later deep learning approaches that use millions of images and videos to learn features automatically. By this discussion, we intend to highlight the major breakthroughs and the directions the future research might take while benefiting from the state-of-the-art methods.","3":"Sensors (Basel, Switzerland)","4":"30445801","5":"2018","6":"Deep Learning"},{"1":"A Survey of the Techniques for The Identification and Classification of Human Actions from Visual Data.","2":"Recognition of human actions form videos has been an active area of research because it has applications in various domains. The results of work in this field are used in video surveillance, automatic video labeling and human-computer interaction, among others. Any advancements in this field are tied to advances in the interrelated fields of object recognition, spatio- temporal video analysis and semantic segmentation. Activity recognition is a challenging task since it faces many problems such as occlusion, view point variation, background differences and clutter and illumination variations. Scientific achievements in the field have been numerous and rapid as the applications are far reaching. In this survey, we cover the growth of the field from the earliest solutions, where handcrafted features were used, to later deep learning approaches that use millions of images and videos to learn features automatically. By this discussion, we intend to highlight the major breakthroughs and the directions the future research might take while benefiting from the state-of-the-art methods.","3":"Sensors (Basel, Switzerland)","4":"30445801","5":"2018","6":"Human Activities"},{"1":"A Survey of the Techniques for The Identification and Classification of Human Actions from Visual Data.","2":"Recognition of human actions form videos has been an active area of research because it has applications in various domains. The results of work in this field are used in video surveillance, automatic video labeling and human-computer interaction, among others. Any advancements in this field are tied to advances in the interrelated fields of object recognition, spatio- temporal video analysis and semantic segmentation. Activity recognition is a challenging task since it faces many problems such as occlusion, view point variation, background differences and clutter and illumination variations. Scientific achievements in the field have been numerous and rapid as the applications are far reaching. In this survey, we cover the growth of the field from the earliest solutions, where handcrafted features were used, to later deep learning approaches that use millions of images and videos to learn features automatically. By this discussion, we intend to highlight the major breakthroughs and the directions the future research might take while benefiting from the state-of-the-art methods.","3":"Sensors (Basel, Switzerland)","4":"30445801","5":"2018","6":"Humans"},{"1":"A Survey of the Techniques for The Identification and Classification of Human Actions from Visual Data.","2":"Recognition of human actions form videos has been an active area of research because it has applications in various domains. The results of work in this field are used in video surveillance, automatic video labeling and human-computer interaction, among others. Any advancements in this field are tied to advances in the interrelated fields of object recognition, spatio- temporal video analysis and semantic segmentation. Activity recognition is a challenging task since it faces many problems such as occlusion, view point variation, background differences and clutter and illumination variations. Scientific achievements in the field have been numerous and rapid as the applications are far reaching. In this survey, we cover the growth of the field from the earliest solutions, where handcrafted features were used, to later deep learning approaches that use millions of images and videos to learn features automatically. By this discussion, we intend to highlight the major breakthroughs and the directions the future research might take while benefiting from the state-of-the-art methods.","3":"Sensors (Basel, Switzerland)","4":"30445801","5":"2018","6":"Spatio-Temporal Analysis"},{"1":"A Survey of the Techniques for The Identification and Classification of Human Actions from Visual Data.","2":"Recognition of human actions form videos has been an active area of research because it has applications in various domains. The results of work in this field are used in video surveillance, automatic video labeling and human-computer interaction, among others. Any advancements in this field are tied to advances in the interrelated fields of object recognition, spatio- temporal video analysis and semantic segmentation. Activity recognition is a challenging task since it faces many problems such as occlusion, view point variation, background differences and clutter and illumination variations. Scientific achievements in the field have been numerous and rapid as the applications are far reaching. In this survey, we cover the growth of the field from the earliest solutions, where handcrafted features were used, to later deep learning approaches that use millions of images and videos to learn features automatically. By this discussion, we intend to highlight the major breakthroughs and the directions the future research might take while benefiting from the state-of-the-art methods.","3":"Sensors (Basel, Switzerland)","4":"30445801","5":"2018","6":"Surveys and Questionnaires"},{"1":"A Survey of the Techniques for The Identification and Classification of Human Actions from Visual Data.","2":"Recognition of human actions form videos has been an active area of research because it has applications in various domains. The results of work in this field are used in video surveillance, automatic video labeling and human-computer interaction, among others. Any advancements in this field are tied to advances in the interrelated fields of object recognition, spatio- temporal video analysis and semantic segmentation. Activity recognition is a challenging task since it faces many problems such as occlusion, view point variation, background differences and clutter and illumination variations. Scientific achievements in the field have been numerous and rapid as the applications are far reaching. In this survey, we cover the growth of the field from the earliest solutions, where handcrafted features were used, to later deep learning approaches that use millions of images and videos to learn features automatically. By this discussion, we intend to highlight the major breakthroughs and the directions the future research might take while benefiting from the state-of-the-art methods.","3":"Sensors (Basel, Switzerland)","4":"30445801","5":"2018","6":"Visual Perception"},{"1":"Learning protein binding affinity using privileged information.","2":"BACKGROUND: Determining protein-protein interactions and their binding affinity are important in understanding cellular biological processes, discovery and design of novel therapeutics, protein engineering, and mutagenesis studies. Due to the time and effort required in wet lab experiments, computational prediction of binding affinity from sequence or structure is an important area of research. Structure-based methods, though more accurate than sequence-based techniques, are limited in their applicability due to limited availability of protein structure data.RESULTS: In this study, we propose a novel machine learning method for predicting binding affinity that uses protein 3D structure as privileged information at training time while expecting only protein sequence information during testing. Using the method, which is based on the framework of learning using privileged information (LUPI), we have achieved improved performance over corresponding sequence-based binding affinity prediction methods that do not have access to privileged information during training. Our experiments show that with the proposed framework which uses structure only during training, it is possible to achieve classification performance comparable to that which is obtained using structure-based features. Evaluation on an independent test set shows improved performance over the PPA-Pred2 method as well.CONCLUSIONS: The proposed method outperforms several baseline learners and a state-of-the-art binding affinity predictor not only in cross-validation, but also on an additional validation dataset, demonstrating the utility of the LUPI framework for problems that would benefit from classification using structure-based features. The implementation of LUPI developed for this work is expected to be useful in other areas of bioinformatics as well.","3":"BMC bioinformatics","4":"30442086","5":"2018","6":"Algorithms"},{"1":"Learning protein binding affinity using privileged information.","2":"BACKGROUND: Determining protein-protein interactions and their binding affinity are important in understanding cellular biological processes, discovery and design of novel therapeutics, protein engineering, and mutagenesis studies. Due to the time and effort required in wet lab experiments, computational prediction of binding affinity from sequence or structure is an important area of research. Structure-based methods, though more accurate than sequence-based techniques, are limited in their applicability due to limited availability of protein structure data.RESULTS: In this study, we propose a novel machine learning method for predicting binding affinity that uses protein 3D structure as privileged information at training time while expecting only protein sequence information during testing. Using the method, which is based on the framework of learning using privileged information (LUPI), we have achieved improved performance over corresponding sequence-based binding affinity prediction methods that do not have access to privileged information during training. Our experiments show that with the proposed framework which uses structure only during training, it is possible to achieve classification performance comparable to that which is obtained using structure-based features. Evaluation on an independent test set shows improved performance over the PPA-Pred2 method as well.CONCLUSIONS: The proposed method outperforms several baseline learners and a state-of-the-art binding affinity predictor not only in cross-validation, but also on an additional validation dataset, demonstrating the utility of the LUPI framework for problems that would benefit from classification using structure-based features. The implementation of LUPI developed for this work is expected to be useful in other areas of bioinformatics as well.","3":"BMC bioinformatics","4":"30442086","5":"2018","6":"Amino Acid Sequence"},{"1":"Learning protein binding affinity using privileged information.","2":"BACKGROUND: Determining protein-protein interactions and their binding affinity are important in understanding cellular biological processes, discovery and design of novel therapeutics, protein engineering, and mutagenesis studies. Due to the time and effort required in wet lab experiments, computational prediction of binding affinity from sequence or structure is an important area of research. Structure-based methods, though more accurate than sequence-based techniques, are limited in their applicability due to limited availability of protein structure data.RESULTS: In this study, we propose a novel machine learning method for predicting binding affinity that uses protein 3D structure as privileged information at training time while expecting only protein sequence information during testing. Using the method, which is based on the framework of learning using privileged information (LUPI), we have achieved improved performance over corresponding sequence-based binding affinity prediction methods that do not have access to privileged information during training. Our experiments show that with the proposed framework which uses structure only during training, it is possible to achieve classification performance comparable to that which is obtained using structure-based features. Evaluation on an independent test set shows improved performance over the PPA-Pred2 method as well.CONCLUSIONS: The proposed method outperforms several baseline learners and a state-of-the-art binding affinity predictor not only in cross-validation, but also on an additional validation dataset, demonstrating the utility of the LUPI framework for problems that would benefit from classification using structure-based features. The implementation of LUPI developed for this work is expected to be useful in other areas of bioinformatics as well.","3":"BMC bioinformatics","4":"30442086","5":"2018","6":"Computational Biology"},{"1":"Learning protein binding affinity using privileged information.","2":"BACKGROUND: Determining protein-protein interactions and their binding affinity are important in understanding cellular biological processes, discovery and design of novel therapeutics, protein engineering, and mutagenesis studies. Due to the time and effort required in wet lab experiments, computational prediction of binding affinity from sequence or structure is an important area of research. Structure-based methods, though more accurate than sequence-based techniques, are limited in their applicability due to limited availability of protein structure data.RESULTS: In this study, we propose a novel machine learning method for predicting binding affinity that uses protein 3D structure as privileged information at training time while expecting only protein sequence information during testing. Using the method, which is based on the framework of learning using privileged information (LUPI), we have achieved improved performance over corresponding sequence-based binding affinity prediction methods that do not have access to privileged information during training. Our experiments show that with the proposed framework which uses structure only during training, it is possible to achieve classification performance comparable to that which is obtained using structure-based features. Evaluation on an independent test set shows improved performance over the PPA-Pred2 method as well.CONCLUSIONS: The proposed method outperforms several baseline learners and a state-of-the-art binding affinity predictor not only in cross-validation, but also on an additional validation dataset, demonstrating the utility of the LUPI framework for problems that would benefit from classification using structure-based features. The implementation of LUPI developed for this work is expected to be useful in other areas of bioinformatics as well.","3":"BMC bioinformatics","4":"30442086","5":"2018","6":"methods"},{"1":"Learning protein binding affinity using privileged information.","2":"BACKGROUND: Determining protein-protein interactions and their binding affinity are important in understanding cellular biological processes, discovery and design of novel therapeutics, protein engineering, and mutagenesis studies. Due to the time and effort required in wet lab experiments, computational prediction of binding affinity from sequence or structure is an important area of research. Structure-based methods, though more accurate than sequence-based techniques, are limited in their applicability due to limited availability of protein structure data.RESULTS: In this study, we propose a novel machine learning method for predicting binding affinity that uses protein 3D structure as privileged information at training time while expecting only protein sequence information during testing. Using the method, which is based on the framework of learning using privileged information (LUPI), we have achieved improved performance over corresponding sequence-based binding affinity prediction methods that do not have access to privileged information during training. Our experiments show that with the proposed framework which uses structure only during training, it is possible to achieve classification performance comparable to that which is obtained using structure-based features. Evaluation on an independent test set shows improved performance over the PPA-Pred2 method as well.CONCLUSIONS: The proposed method outperforms several baseline learners and a state-of-the-art binding affinity predictor not only in cross-validation, but also on an additional validation dataset, demonstrating the utility of the LUPI framework for problems that would benefit from classification using structure-based features. The implementation of LUPI developed for this work is expected to be useful in other areas of bioinformatics as well.","3":"BMC bioinformatics","4":"30442086","5":"2018","6":"Ligands"},{"1":"Learning protein binding affinity using privileged information.","2":"BACKGROUND: Determining protein-protein interactions and their binding affinity are important in understanding cellular biological processes, discovery and design of novel therapeutics, protein engineering, and mutagenesis studies. Due to the time and effort required in wet lab experiments, computational prediction of binding affinity from sequence or structure is an important area of research. Structure-based methods, though more accurate than sequence-based techniques, are limited in their applicability due to limited availability of protein structure data.RESULTS: In this study, we propose a novel machine learning method for predicting binding affinity that uses protein 3D structure as privileged information at training time while expecting only protein sequence information during testing. Using the method, which is based on the framework of learning using privileged information (LUPI), we have achieved improved performance over corresponding sequence-based binding affinity prediction methods that do not have access to privileged information during training. Our experiments show that with the proposed framework which uses structure only during training, it is possible to achieve classification performance comparable to that which is obtained using structure-based features. Evaluation on an independent test set shows improved performance over the PPA-Pred2 method as well.CONCLUSIONS: The proposed method outperforms several baseline learners and a state-of-the-art binding affinity predictor not only in cross-validation, but also on an additional validation dataset, demonstrating the utility of the LUPI framework for problems that would benefit from classification using structure-based features. The implementation of LUPI developed for this work is expected to be useful in other areas of bioinformatics as well.","3":"BMC bioinformatics","4":"30442086","5":"2018","6":"Machine Learning"},{"1":"Learning protein binding affinity using privileged information.","2":"BACKGROUND: Determining protein-protein interactions and their binding affinity are important in understanding cellular biological processes, discovery and design of novel therapeutics, protein engineering, and mutagenesis studies. Due to the time and effort required in wet lab experiments, computational prediction of binding affinity from sequence or structure is an important area of research. Structure-based methods, though more accurate than sequence-based techniques, are limited in their applicability due to limited availability of protein structure data.RESULTS: In this study, we propose a novel machine learning method for predicting binding affinity that uses protein 3D structure as privileged information at training time while expecting only protein sequence information during testing. Using the method, which is based on the framework of learning using privileged information (LUPI), we have achieved improved performance over corresponding sequence-based binding affinity prediction methods that do not have access to privileged information during training. Our experiments show that with the proposed framework which uses structure only during training, it is possible to achieve classification performance comparable to that which is obtained using structure-based features. Evaluation on an independent test set shows improved performance over the PPA-Pred2 method as well.CONCLUSIONS: The proposed method outperforms several baseline learners and a state-of-the-art binding affinity predictor not only in cross-validation, but also on an additional validation dataset, demonstrating the utility of the LUPI framework for problems that would benefit from classification using structure-based features. The implementation of LUPI developed for this work is expected to be useful in other areas of bioinformatics as well.","3":"BMC bioinformatics","4":"30442086","5":"2018","6":"Protein Binding"},{"1":"Learning protein binding affinity using privileged information.","2":"BACKGROUND: Determining protein-protein interactions and their binding affinity are important in understanding cellular biological processes, discovery and design of novel therapeutics, protein engineering, and mutagenesis studies. Due to the time and effort required in wet lab experiments, computational prediction of binding affinity from sequence or structure is an important area of research. Structure-based methods, though more accurate than sequence-based techniques, are limited in their applicability due to limited availability of protein structure data.RESULTS: In this study, we propose a novel machine learning method for predicting binding affinity that uses protein 3D structure as privileged information at training time while expecting only protein sequence information during testing. Using the method, which is based on the framework of learning using privileged information (LUPI), we have achieved improved performance over corresponding sequence-based binding affinity prediction methods that do not have access to privileged information during training. Our experiments show that with the proposed framework which uses structure only during training, it is possible to achieve classification performance comparable to that which is obtained using structure-based features. Evaluation on an independent test set shows improved performance over the PPA-Pred2 method as well.CONCLUSIONS: The proposed method outperforms several baseline learners and a state-of-the-art binding affinity predictor not only in cross-validation, but also on an additional validation dataset, demonstrating the utility of the LUPI framework for problems that would benefit from classification using structure-based features. The implementation of LUPI developed for this work is expected to be useful in other areas of bioinformatics as well.","3":"BMC bioinformatics","4":"30442086","5":"2018","6":"Proteins"},{"1":"Learning protein binding affinity using privileged information.","2":"BACKGROUND: Determining protein-protein interactions and their binding affinity are important in understanding cellular biological processes, discovery and design of novel therapeutics, protein engineering, and mutagenesis studies. Due to the time and effort required in wet lab experiments, computational prediction of binding affinity from sequence or structure is an important area of research. Structure-based methods, though more accurate than sequence-based techniques, are limited in their applicability due to limited availability of protein structure data.RESULTS: In this study, we propose a novel machine learning method for predicting binding affinity that uses protein 3D structure as privileged information at training time while expecting only protein sequence information during testing. Using the method, which is based on the framework of learning using privileged information (LUPI), we have achieved improved performance over corresponding sequence-based binding affinity prediction methods that do not have access to privileged information during training. Our experiments show that with the proposed framework which uses structure only during training, it is possible to achieve classification performance comparable to that which is obtained using structure-based features. Evaluation on an independent test set shows improved performance over the PPA-Pred2 method as well.CONCLUSIONS: The proposed method outperforms several baseline learners and a state-of-the-art binding affinity predictor not only in cross-validation, but also on an additional validation dataset, demonstrating the utility of the LUPI framework for problems that would benefit from classification using structure-based features. The implementation of LUPI developed for this work is expected to be useful in other areas of bioinformatics as well.","3":"BMC bioinformatics","4":"30442086","5":"2018","6":"chemistry"},{"1":"Learning protein binding affinity using privileged information.","2":"BACKGROUND: Determining protein-protein interactions and their binding affinity are important in understanding cellular biological processes, discovery and design of novel therapeutics, protein engineering, and mutagenesis studies. Due to the time and effort required in wet lab experiments, computational prediction of binding affinity from sequence or structure is an important area of research. Structure-based methods, though more accurate than sequence-based techniques, are limited in their applicability due to limited availability of protein structure data.RESULTS: In this study, we propose a novel machine learning method for predicting binding affinity that uses protein 3D structure as privileged information at training time while expecting only protein sequence information during testing. Using the method, which is based on the framework of learning using privileged information (LUPI), we have achieved improved performance over corresponding sequence-based binding affinity prediction methods that do not have access to privileged information during training. Our experiments show that with the proposed framework which uses structure only during training, it is possible to achieve classification performance comparable to that which is obtained using structure-based features. Evaluation on an independent test set shows improved performance over the PPA-Pred2 method as well.CONCLUSIONS: The proposed method outperforms several baseline learners and a state-of-the-art binding affinity predictor not only in cross-validation, but also on an additional validation dataset, demonstrating the utility of the LUPI framework for problems that would benefit from classification using structure-based features. The implementation of LUPI developed for this work is expected to be useful in other areas of bioinformatics as well.","3":"BMC bioinformatics","4":"30442086","5":"2018","6":"metabolism"},{"1":"Learning protein binding affinity using privileged information.","2":"BACKGROUND: Determining protein-protein interactions and their binding affinity are important in understanding cellular biological processes, discovery and design of novel therapeutics, protein engineering, and mutagenesis studies. Due to the time and effort required in wet lab experiments, computational prediction of binding affinity from sequence or structure is an important area of research. Structure-based methods, though more accurate than sequence-based techniques, are limited in their applicability due to limited availability of protein structure data.RESULTS: In this study, we propose a novel machine learning method for predicting binding affinity that uses protein 3D structure as privileged information at training time while expecting only protein sequence information during testing. Using the method, which is based on the framework of learning using privileged information (LUPI), we have achieved improved performance over corresponding sequence-based binding affinity prediction methods that do not have access to privileged information during training. Our experiments show that with the proposed framework which uses structure only during training, it is possible to achieve classification performance comparable to that which is obtained using structure-based features. Evaluation on an independent test set shows improved performance over the PPA-Pred2 method as well.CONCLUSIONS: The proposed method outperforms several baseline learners and a state-of-the-art binding affinity predictor not only in cross-validation, but also on an additional validation dataset, demonstrating the utility of the LUPI framework for problems that would benefit from classification using structure-based features. The implementation of LUPI developed for this work is expected to be useful in other areas of bioinformatics as well.","3":"BMC bioinformatics","4":"30442086","5":"2018","6":"ROC Curve"},{"1":"Learning protein binding affinity using privileged information.","2":"BACKGROUND: Determining protein-protein interactions and their binding affinity are important in understanding cellular biological processes, discovery and design of novel therapeutics, protein engineering, and mutagenesis studies. Due to the time and effort required in wet lab experiments, computational prediction of binding affinity from sequence or structure is an important area of research. Structure-based methods, though more accurate than sequence-based techniques, are limited in their applicability due to limited availability of protein structure data.RESULTS: In this study, we propose a novel machine learning method for predicting binding affinity that uses protein 3D structure as privileged information at training time while expecting only protein sequence information during testing. Using the method, which is based on the framework of learning using privileged information (LUPI), we have achieved improved performance over corresponding sequence-based binding affinity prediction methods that do not have access to privileged information during training. Our experiments show that with the proposed framework which uses structure only during training, it is possible to achieve classification performance comparable to that which is obtained using structure-based features. Evaluation on an independent test set shows improved performance over the PPA-Pred2 method as well.CONCLUSIONS: The proposed method outperforms several baseline learners and a state-of-the-art binding affinity predictor not only in cross-validation, but also on an additional validation dataset, demonstrating the utility of the LUPI framework for problems that would benefit from classification using structure-based features. The implementation of LUPI developed for this work is expected to be useful in other areas of bioinformatics as well.","3":"BMC bioinformatics","4":"30442086","5":"2018","6":"Reproducibility of Results"},{"1":"Learning protein binding affinity using privileged information.","2":"BACKGROUND: Determining protein-protein interactions and their binding affinity are important in understanding cellular biological processes, discovery and design of novel therapeutics, protein engineering, and mutagenesis studies. Due to the time and effort required in wet lab experiments, computational prediction of binding affinity from sequence or structure is an important area of research. Structure-based methods, though more accurate than sequence-based techniques, are limited in their applicability due to limited availability of protein structure data.RESULTS: In this study, we propose a novel machine learning method for predicting binding affinity that uses protein 3D structure as privileged information at training time while expecting only protein sequence information during testing. Using the method, which is based on the framework of learning using privileged information (LUPI), we have achieved improved performance over corresponding sequence-based binding affinity prediction methods that do not have access to privileged information during training. Our experiments show that with the proposed framework which uses structure only during training, it is possible to achieve classification performance comparable to that which is obtained using structure-based features. Evaluation on an independent test set shows improved performance over the PPA-Pred2 method as well.CONCLUSIONS: The proposed method outperforms several baseline learners and a state-of-the-art binding affinity predictor not only in cross-validation, but also on an additional validation dataset, demonstrating the utility of the LUPI framework for problems that would benefit from classification using structure-based features. The implementation of LUPI developed for this work is expected to be useful in other areas of bioinformatics as well.","3":"BMC bioinformatics","4":"30442086","5":"2018","6":"Support Vector Machine"},{"1":"Identification of hub genes with diagnostic values in pancreatic cancer by bioinformatics analyses and supervised learning methods.","2":"BACKGROUND: Pancreatic cancer is one of the most lethal tumors with poor prognosis, and lacks of effective biomarkers in diagnosis and treatment. The aim of this investigation was to identify hub genes in pancreatic cancer, which would serve as potential biomarkers for cancer diagnosis and therapy in the future.METHODS: Combination of two expression profiles of GSE16515 and GSE22780 from Gene Expression Omnibus (GEO) database was served as training set. Differentially expressed genes (DEGs) with top 25% variance followed by protein-protein interaction (PPI) network were performed to find candidate genes. Then, hub genes were further screened by survival and cox analyses in The Cancer Genome Atlas (TCGA) database. Finally, hub genes were validated in GSE15471 dataset from GEO by supervised learning methods k-nearest neighbor (kNN) and random forest algorithms.RESULTS: After quality control and batch effect elimination of training set, 181 DEGs bearing top 25% variance were identified as candidate genes. Then, two hub genes, MMP7 and ITGA2, correlating with diagnosis and prognosis of pancreatic cancer were screened as hub genes according to above-mentioned bioinformatics methods. Finally, hub genes were demonstrated to successfully differ tumor samples from normal tissues with predictive accuracies reached to 93.59 and 81.31% by using kNN and random forest algorithms, respectively.CONCLUSIONS: All the hub genes were associated with the regulation of tumor microenvironment, which implicated in tumor proliferation, progression, migration, and metastasis. Our results provide a novel prospect for diagnosis and treatment of pancreatic cancer, which may have a further application in clinical.","3":"World journal of surgical oncology","4":"30428899","5":"2018","6":"Biomarkers, Tumor"},{"1":"Identification of hub genes with diagnostic values in pancreatic cancer by bioinformatics analyses and supervised learning methods.","2":"BACKGROUND: Pancreatic cancer is one of the most lethal tumors with poor prognosis, and lacks of effective biomarkers in diagnosis and treatment. The aim of this investigation was to identify hub genes in pancreatic cancer, which would serve as potential biomarkers for cancer diagnosis and therapy in the future.METHODS: Combination of two expression profiles of GSE16515 and GSE22780 from Gene Expression Omnibus (GEO) database was served as training set. Differentially expressed genes (DEGs) with top 25% variance followed by protein-protein interaction (PPI) network were performed to find candidate genes. Then, hub genes were further screened by survival and cox analyses in The Cancer Genome Atlas (TCGA) database. Finally, hub genes were validated in GSE15471 dataset from GEO by supervised learning methods k-nearest neighbor (kNN) and random forest algorithms.RESULTS: After quality control and batch effect elimination of training set, 181 DEGs bearing top 25% variance were identified as candidate genes. Then, two hub genes, MMP7 and ITGA2, correlating with diagnosis and prognosis of pancreatic cancer were screened as hub genes according to above-mentioned bioinformatics methods. Finally, hub genes were demonstrated to successfully differ tumor samples from normal tissues with predictive accuracies reached to 93.59 and 81.31% by using kNN and random forest algorithms, respectively.CONCLUSIONS: All the hub genes were associated with the regulation of tumor microenvironment, which implicated in tumor proliferation, progression, migration, and metastasis. Our results provide a novel prospect for diagnosis and treatment of pancreatic cancer, which may have a further application in clinical.","3":"World journal of surgical oncology","4":"30428899","5":"2018","6":"genetics"},{"1":"Identification of hub genes with diagnostic values in pancreatic cancer by bioinformatics analyses and supervised learning methods.","2":"BACKGROUND: Pancreatic cancer is one of the most lethal tumors with poor prognosis, and lacks of effective biomarkers in diagnosis and treatment. The aim of this investigation was to identify hub genes in pancreatic cancer, which would serve as potential biomarkers for cancer diagnosis and therapy in the future.METHODS: Combination of two expression profiles of GSE16515 and GSE22780 from Gene Expression Omnibus (GEO) database was served as training set. Differentially expressed genes (DEGs) with top 25% variance followed by protein-protein interaction (PPI) network were performed to find candidate genes. Then, hub genes were further screened by survival and cox analyses in The Cancer Genome Atlas (TCGA) database. Finally, hub genes were validated in GSE15471 dataset from GEO by supervised learning methods k-nearest neighbor (kNN) and random forest algorithms.RESULTS: After quality control and batch effect elimination of training set, 181 DEGs bearing top 25% variance were identified as candidate genes. Then, two hub genes, MMP7 and ITGA2, correlating with diagnosis and prognosis of pancreatic cancer were screened as hub genes according to above-mentioned bioinformatics methods. Finally, hub genes were demonstrated to successfully differ tumor samples from normal tissues with predictive accuracies reached to 93.59 and 81.31% by using kNN and random forest algorithms, respectively.CONCLUSIONS: All the hub genes were associated with the regulation of tumor microenvironment, which implicated in tumor proliferation, progression, migration, and metastasis. Our results provide a novel prospect for diagnosis and treatment of pancreatic cancer, which may have a further application in clinical.","3":"World journal of surgical oncology","4":"30428899","5":"2018","6":"Computational Biology"},{"1":"Identification of hub genes with diagnostic values in pancreatic cancer by bioinformatics analyses and supervised learning methods.","2":"BACKGROUND: Pancreatic cancer is one of the most lethal tumors with poor prognosis, and lacks of effective biomarkers in diagnosis and treatment. The aim of this investigation was to identify hub genes in pancreatic cancer, which would serve as potential biomarkers for cancer diagnosis and therapy in the future.METHODS: Combination of two expression profiles of GSE16515 and GSE22780 from Gene Expression Omnibus (GEO) database was served as training set. Differentially expressed genes (DEGs) with top 25% variance followed by protein-protein interaction (PPI) network were performed to find candidate genes. Then, hub genes were further screened by survival and cox analyses in The Cancer Genome Atlas (TCGA) database. Finally, hub genes were validated in GSE15471 dataset from GEO by supervised learning methods k-nearest neighbor (kNN) and random forest algorithms.RESULTS: After quality control and batch effect elimination of training set, 181 DEGs bearing top 25% variance were identified as candidate genes. Then, two hub genes, MMP7 and ITGA2, correlating with diagnosis and prognosis of pancreatic cancer were screened as hub genes according to above-mentioned bioinformatics methods. Finally, hub genes were demonstrated to successfully differ tumor samples from normal tissues with predictive accuracies reached to 93.59 and 81.31% by using kNN and random forest algorithms, respectively.CONCLUSIONS: All the hub genes were associated with the regulation of tumor microenvironment, which implicated in tumor proliferation, progression, migration, and metastasis. Our results provide a novel prospect for diagnosis and treatment of pancreatic cancer, which may have a further application in clinical.","3":"World journal of surgical oncology","4":"30428899","5":"2018","6":"Datasets as Topic"},{"1":"Identification of hub genes with diagnostic values in pancreatic cancer by bioinformatics analyses and supervised learning methods.","2":"BACKGROUND: Pancreatic cancer is one of the most lethal tumors with poor prognosis, and lacks of effective biomarkers in diagnosis and treatment. The aim of this investigation was to identify hub genes in pancreatic cancer, which would serve as potential biomarkers for cancer diagnosis and therapy in the future.METHODS: Combination of two expression profiles of GSE16515 and GSE22780 from Gene Expression Omnibus (GEO) database was served as training set. Differentially expressed genes (DEGs) with top 25% variance followed by protein-protein interaction (PPI) network were performed to find candidate genes. Then, hub genes were further screened by survival and cox analyses in The Cancer Genome Atlas (TCGA) database. Finally, hub genes were validated in GSE15471 dataset from GEO by supervised learning methods k-nearest neighbor (kNN) and random forest algorithms.RESULTS: After quality control and batch effect elimination of training set, 181 DEGs bearing top 25% variance were identified as candidate genes. Then, two hub genes, MMP7 and ITGA2, correlating with diagnosis and prognosis of pancreatic cancer were screened as hub genes according to above-mentioned bioinformatics methods. Finally, hub genes were demonstrated to successfully differ tumor samples from normal tissues with predictive accuracies reached to 93.59 and 81.31% by using kNN and random forest algorithms, respectively.CONCLUSIONS: All the hub genes were associated with the regulation of tumor microenvironment, which implicated in tumor proliferation, progression, migration, and metastasis. Our results provide a novel prospect for diagnosis and treatment of pancreatic cancer, which may have a further application in clinical.","3":"World journal of surgical oncology","4":"30428899","5":"2018","6":"Disease Progression"},{"1":"Identification of hub genes with diagnostic values in pancreatic cancer by bioinformatics analyses and supervised learning methods.","2":"BACKGROUND: Pancreatic cancer is one of the most lethal tumors with poor prognosis, and lacks of effective biomarkers in diagnosis and treatment. The aim of this investigation was to identify hub genes in pancreatic cancer, which would serve as potential biomarkers for cancer diagnosis and therapy in the future.METHODS: Combination of two expression profiles of GSE16515 and GSE22780 from Gene Expression Omnibus (GEO) database was served as training set. Differentially expressed genes (DEGs) with top 25% variance followed by protein-protein interaction (PPI) network were performed to find candidate genes. Then, hub genes were further screened by survival and cox analyses in The Cancer Genome Atlas (TCGA) database. Finally, hub genes were validated in GSE15471 dataset from GEO by supervised learning methods k-nearest neighbor (kNN) and random forest algorithms.RESULTS: After quality control and batch effect elimination of training set, 181 DEGs bearing top 25% variance were identified as candidate genes. Then, two hub genes, MMP7 and ITGA2, correlating with diagnosis and prognosis of pancreatic cancer were screened as hub genes according to above-mentioned bioinformatics methods. Finally, hub genes were demonstrated to successfully differ tumor samples from normal tissues with predictive accuracies reached to 93.59 and 81.31% by using kNN and random forest algorithms, respectively.CONCLUSIONS: All the hub genes were associated with the regulation of tumor microenvironment, which implicated in tumor proliferation, progression, migration, and metastasis. Our results provide a novel prospect for diagnosis and treatment of pancreatic cancer, which may have a further application in clinical.","3":"World journal of surgical oncology","4":"30428899","5":"2018","6":"Gene Expression Profiling"},{"1":"Identification of hub genes with diagnostic values in pancreatic cancer by bioinformatics analyses and supervised learning methods.","2":"BACKGROUND: Pancreatic cancer is one of the most lethal tumors with poor prognosis, and lacks of effective biomarkers in diagnosis and treatment. The aim of this investigation was to identify hub genes in pancreatic cancer, which would serve as potential biomarkers for cancer diagnosis and therapy in the future.METHODS: Combination of two expression profiles of GSE16515 and GSE22780 from Gene Expression Omnibus (GEO) database was served as training set. Differentially expressed genes (DEGs) with top 25% variance followed by protein-protein interaction (PPI) network were performed to find candidate genes. Then, hub genes were further screened by survival and cox analyses in The Cancer Genome Atlas (TCGA) database. Finally, hub genes were validated in GSE15471 dataset from GEO by supervised learning methods k-nearest neighbor (kNN) and random forest algorithms.RESULTS: After quality control and batch effect elimination of training set, 181 DEGs bearing top 25% variance were identified as candidate genes. Then, two hub genes, MMP7 and ITGA2, correlating with diagnosis and prognosis of pancreatic cancer were screened as hub genes according to above-mentioned bioinformatics methods. Finally, hub genes were demonstrated to successfully differ tumor samples from normal tissues with predictive accuracies reached to 93.59 and 81.31% by using kNN and random forest algorithms, respectively.CONCLUSIONS: All the hub genes were associated with the regulation of tumor microenvironment, which implicated in tumor proliferation, progression, migration, and metastasis. Our results provide a novel prospect for diagnosis and treatment of pancreatic cancer, which may have a further application in clinical.","3":"World journal of surgical oncology","4":"30428899","5":"2018","6":"Humans"},{"1":"Identification of hub genes with diagnostic values in pancreatic cancer by bioinformatics analyses and supervised learning methods.","2":"BACKGROUND: Pancreatic cancer is one of the most lethal tumors with poor prognosis, and lacks of effective biomarkers in diagnosis and treatment. The aim of this investigation was to identify hub genes in pancreatic cancer, which would serve as potential biomarkers for cancer diagnosis and therapy in the future.METHODS: Combination of two expression profiles of GSE16515 and GSE22780 from Gene Expression Omnibus (GEO) database was served as training set. Differentially expressed genes (DEGs) with top 25% variance followed by protein-protein interaction (PPI) network were performed to find candidate genes. Then, hub genes were further screened by survival and cox analyses in The Cancer Genome Atlas (TCGA) database. Finally, hub genes were validated in GSE15471 dataset from GEO by supervised learning methods k-nearest neighbor (kNN) and random forest algorithms.RESULTS: After quality control and batch effect elimination of training set, 181 DEGs bearing top 25% variance were identified as candidate genes. Then, two hub genes, MMP7 and ITGA2, correlating with diagnosis and prognosis of pancreatic cancer were screened as hub genes according to above-mentioned bioinformatics methods. Finally, hub genes were demonstrated to successfully differ tumor samples from normal tissues with predictive accuracies reached to 93.59 and 81.31% by using kNN and random forest algorithms, respectively.CONCLUSIONS: All the hub genes were associated with the regulation of tumor microenvironment, which implicated in tumor proliferation, progression, migration, and metastasis. Our results provide a novel prospect for diagnosis and treatment of pancreatic cancer, which may have a further application in clinical.","3":"World journal of surgical oncology","4":"30428899","5":"2018","6":"Pancreas"},{"1":"Identification of hub genes with diagnostic values in pancreatic cancer by bioinformatics analyses and supervised learning methods.","2":"BACKGROUND: Pancreatic cancer is one of the most lethal tumors with poor prognosis, and lacks of effective biomarkers in diagnosis and treatment. The aim of this investigation was to identify hub genes in pancreatic cancer, which would serve as potential biomarkers for cancer diagnosis and therapy in the future.METHODS: Combination of two expression profiles of GSE16515 and GSE22780 from Gene Expression Omnibus (GEO) database was served as training set. Differentially expressed genes (DEGs) with top 25% variance followed by protein-protein interaction (PPI) network were performed to find candidate genes. Then, hub genes were further screened by survival and cox analyses in The Cancer Genome Atlas (TCGA) database. Finally, hub genes were validated in GSE15471 dataset from GEO by supervised learning methods k-nearest neighbor (kNN) and random forest algorithms.RESULTS: After quality control and batch effect elimination of training set, 181 DEGs bearing top 25% variance were identified as candidate genes. Then, two hub genes, MMP7 and ITGA2, correlating with diagnosis and prognosis of pancreatic cancer were screened as hub genes according to above-mentioned bioinformatics methods. Finally, hub genes were demonstrated to successfully differ tumor samples from normal tissues with predictive accuracies reached to 93.59 and 81.31% by using kNN and random forest algorithms, respectively.CONCLUSIONS: All the hub genes were associated with the regulation of tumor microenvironment, which implicated in tumor proliferation, progression, migration, and metastasis. Our results provide a novel prospect for diagnosis and treatment of pancreatic cancer, which may have a further application in clinical.","3":"World journal of surgical oncology","4":"30428899","5":"2018","6":"pathology"},{"1":"Identification of hub genes with diagnostic values in pancreatic cancer by bioinformatics analyses and supervised learning methods.","2":"BACKGROUND: Pancreatic cancer is one of the most lethal tumors with poor prognosis, and lacks of effective biomarkers in diagnosis and treatment. The aim of this investigation was to identify hub genes in pancreatic cancer, which would serve as potential biomarkers for cancer diagnosis and therapy in the future.METHODS: Combination of two expression profiles of GSE16515 and GSE22780 from Gene Expression Omnibus (GEO) database was served as training set. Differentially expressed genes (DEGs) with top 25% variance followed by protein-protein interaction (PPI) network were performed to find candidate genes. Then, hub genes were further screened by survival and cox analyses in The Cancer Genome Atlas (TCGA) database. Finally, hub genes were validated in GSE15471 dataset from GEO by supervised learning methods k-nearest neighbor (kNN) and random forest algorithms.RESULTS: After quality control and batch effect elimination of training set, 181 DEGs bearing top 25% variance were identified as candidate genes. Then, two hub genes, MMP7 and ITGA2, correlating with diagnosis and prognosis of pancreatic cancer were screened as hub genes according to above-mentioned bioinformatics methods. Finally, hub genes were demonstrated to successfully differ tumor samples from normal tissues with predictive accuracies reached to 93.59 and 81.31% by using kNN and random forest algorithms, respectively.CONCLUSIONS: All the hub genes were associated with the regulation of tumor microenvironment, which implicated in tumor proliferation, progression, migration, and metastasis. Our results provide a novel prospect for diagnosis and treatment of pancreatic cancer, which may have a further application in clinical.","3":"World journal of surgical oncology","4":"30428899","5":"2018","6":"Pancreatic Neoplasms"},{"1":"Identification of hub genes with diagnostic values in pancreatic cancer by bioinformatics analyses and supervised learning methods.","2":"BACKGROUND: Pancreatic cancer is one of the most lethal tumors with poor prognosis, and lacks of effective biomarkers in diagnosis and treatment. The aim of this investigation was to identify hub genes in pancreatic cancer, which would serve as potential biomarkers for cancer diagnosis and therapy in the future.METHODS: Combination of two expression profiles of GSE16515 and GSE22780 from Gene Expression Omnibus (GEO) database was served as training set. Differentially expressed genes (DEGs) with top 25% variance followed by protein-protein interaction (PPI) network were performed to find candidate genes. Then, hub genes were further screened by survival and cox analyses in The Cancer Genome Atlas (TCGA) database. Finally, hub genes were validated in GSE15471 dataset from GEO by supervised learning methods k-nearest neighbor (kNN) and random forest algorithms.RESULTS: After quality control and batch effect elimination of training set, 181 DEGs bearing top 25% variance were identified as candidate genes. Then, two hub genes, MMP7 and ITGA2, correlating with diagnosis and prognosis of pancreatic cancer were screened as hub genes according to above-mentioned bioinformatics methods. Finally, hub genes were demonstrated to successfully differ tumor samples from normal tissues with predictive accuracies reached to 93.59 and 81.31% by using kNN and random forest algorithms, respectively.CONCLUSIONS: All the hub genes were associated with the regulation of tumor microenvironment, which implicated in tumor proliferation, progression, migration, and metastasis. Our results provide a novel prospect for diagnosis and treatment of pancreatic cancer, which may have a further application in clinical.","3":"World journal of surgical oncology","4":"30428899","5":"2018","6":"diagnosis"},{"1":"Identification of hub genes with diagnostic values in pancreatic cancer by bioinformatics analyses and supervised learning methods.","2":"BACKGROUND: Pancreatic cancer is one of the most lethal tumors with poor prognosis, and lacks of effective biomarkers in diagnosis and treatment. The aim of this investigation was to identify hub genes in pancreatic cancer, which would serve as potential biomarkers for cancer diagnosis and therapy in the future.METHODS: Combination of two expression profiles of GSE16515 and GSE22780 from Gene Expression Omnibus (GEO) database was served as training set. Differentially expressed genes (DEGs) with top 25% variance followed by protein-protein interaction (PPI) network were performed to find candidate genes. Then, hub genes were further screened by survival and cox analyses in The Cancer Genome Atlas (TCGA) database. Finally, hub genes were validated in GSE15471 dataset from GEO by supervised learning methods k-nearest neighbor (kNN) and random forest algorithms.RESULTS: After quality control and batch effect elimination of training set, 181 DEGs bearing top 25% variance were identified as candidate genes. Then, two hub genes, MMP7 and ITGA2, correlating with diagnosis and prognosis of pancreatic cancer were screened as hub genes according to above-mentioned bioinformatics methods. Finally, hub genes were demonstrated to successfully differ tumor samples from normal tissues with predictive accuracies reached to 93.59 and 81.31% by using kNN and random forest algorithms, respectively.CONCLUSIONS: All the hub genes were associated with the regulation of tumor microenvironment, which implicated in tumor proliferation, progression, migration, and metastasis. Our results provide a novel prospect for diagnosis and treatment of pancreatic cancer, which may have a further application in clinical.","3":"World journal of surgical oncology","4":"30428899","5":"2018","6":"genetics"},{"1":"Identification of hub genes with diagnostic values in pancreatic cancer by bioinformatics analyses and supervised learning methods.","2":"BACKGROUND: Pancreatic cancer is one of the most lethal tumors with poor prognosis, and lacks of effective biomarkers in diagnosis and treatment. The aim of this investigation was to identify hub genes in pancreatic cancer, which would serve as potential biomarkers for cancer diagnosis and therapy in the future.METHODS: Combination of two expression profiles of GSE16515 and GSE22780 from Gene Expression Omnibus (GEO) database was served as training set. Differentially expressed genes (DEGs) with top 25% variance followed by protein-protein interaction (PPI) network were performed to find candidate genes. Then, hub genes were further screened by survival and cox analyses in The Cancer Genome Atlas (TCGA) database. Finally, hub genes were validated in GSE15471 dataset from GEO by supervised learning methods k-nearest neighbor (kNN) and random forest algorithms.RESULTS: After quality control and batch effect elimination of training set, 181 DEGs bearing top 25% variance were identified as candidate genes. Then, two hub genes, MMP7 and ITGA2, correlating with diagnosis and prognosis of pancreatic cancer were screened as hub genes according to above-mentioned bioinformatics methods. Finally, hub genes were demonstrated to successfully differ tumor samples from normal tissues with predictive accuracies reached to 93.59 and 81.31% by using kNN and random forest algorithms, respectively.CONCLUSIONS: All the hub genes were associated with the regulation of tumor microenvironment, which implicated in tumor proliferation, progression, migration, and metastasis. Our results provide a novel prospect for diagnosis and treatment of pancreatic cancer, which may have a further application in clinical.","3":"World journal of surgical oncology","4":"30428899","5":"2018","6":"mortality"},{"1":"Identification of hub genes with diagnostic values in pancreatic cancer by bioinformatics analyses and supervised learning methods.","2":"BACKGROUND: Pancreatic cancer is one of the most lethal tumors with poor prognosis, and lacks of effective biomarkers in diagnosis and treatment. The aim of this investigation was to identify hub genes in pancreatic cancer, which would serve as potential biomarkers for cancer diagnosis and therapy in the future.METHODS: Combination of two expression profiles of GSE16515 and GSE22780 from Gene Expression Omnibus (GEO) database was served as training set. Differentially expressed genes (DEGs) with top 25% variance followed by protein-protein interaction (PPI) network were performed to find candidate genes. Then, hub genes were further screened by survival and cox analyses in The Cancer Genome Atlas (TCGA) database. Finally, hub genes were validated in GSE15471 dataset from GEO by supervised learning methods k-nearest neighbor (kNN) and random forest algorithms.RESULTS: After quality control and batch effect elimination of training set, 181 DEGs bearing top 25% variance were identified as candidate genes. Then, two hub genes, MMP7 and ITGA2, correlating with diagnosis and prognosis of pancreatic cancer were screened as hub genes according to above-mentioned bioinformatics methods. Finally, hub genes were demonstrated to successfully differ tumor samples from normal tissues with predictive accuracies reached to 93.59 and 81.31% by using kNN and random forest algorithms, respectively.CONCLUSIONS: All the hub genes were associated with the regulation of tumor microenvironment, which implicated in tumor proliferation, progression, migration, and metastasis. Our results provide a novel prospect for diagnosis and treatment of pancreatic cancer, which may have a further application in clinical.","3":"World journal of surgical oncology","4":"30428899","5":"2018","6":"pathology"},{"1":"Identification of hub genes with diagnostic values in pancreatic cancer by bioinformatics analyses and supervised learning methods.","2":"BACKGROUND: Pancreatic cancer is one of the most lethal tumors with poor prognosis, and lacks of effective biomarkers in diagnosis and treatment. The aim of this investigation was to identify hub genes in pancreatic cancer, which would serve as potential biomarkers for cancer diagnosis and therapy in the future.METHODS: Combination of two expression profiles of GSE16515 and GSE22780 from Gene Expression Omnibus (GEO) database was served as training set. Differentially expressed genes (DEGs) with top 25% variance followed by protein-protein interaction (PPI) network were performed to find candidate genes. Then, hub genes were further screened by survival and cox analyses in The Cancer Genome Atlas (TCGA) database. Finally, hub genes were validated in GSE15471 dataset from GEO by supervised learning methods k-nearest neighbor (kNN) and random forest algorithms.RESULTS: After quality control and batch effect elimination of training set, 181 DEGs bearing top 25% variance were identified as candidate genes. Then, two hub genes, MMP7 and ITGA2, correlating with diagnosis and prognosis of pancreatic cancer were screened as hub genes according to above-mentioned bioinformatics methods. Finally, hub genes were demonstrated to successfully differ tumor samples from normal tissues with predictive accuracies reached to 93.59 and 81.31% by using kNN and random forest algorithms, respectively.CONCLUSIONS: All the hub genes were associated with the regulation of tumor microenvironment, which implicated in tumor proliferation, progression, migration, and metastasis. Our results provide a novel prospect for diagnosis and treatment of pancreatic cancer, which may have a further application in clinical.","3":"World journal of surgical oncology","4":"30428899","5":"2018","6":"Prognosis"},{"1":"Identification of hub genes with diagnostic values in pancreatic cancer by bioinformatics analyses and supervised learning methods.","2":"BACKGROUND: Pancreatic cancer is one of the most lethal tumors with poor prognosis, and lacks of effective biomarkers in diagnosis and treatment. The aim of this investigation was to identify hub genes in pancreatic cancer, which would serve as potential biomarkers for cancer diagnosis and therapy in the future.METHODS: Combination of two expression profiles of GSE16515 and GSE22780 from Gene Expression Omnibus (GEO) database was served as training set. Differentially expressed genes (DEGs) with top 25% variance followed by protein-protein interaction (PPI) network were performed to find candidate genes. Then, hub genes were further screened by survival and cox analyses in The Cancer Genome Atlas (TCGA) database. Finally, hub genes were validated in GSE15471 dataset from GEO by supervised learning methods k-nearest neighbor (kNN) and random forest algorithms.RESULTS: After quality control and batch effect elimination of training set, 181 DEGs bearing top 25% variance were identified as candidate genes. Then, two hub genes, MMP7 and ITGA2, correlating with diagnosis and prognosis of pancreatic cancer were screened as hub genes according to above-mentioned bioinformatics methods. Finally, hub genes were demonstrated to successfully differ tumor samples from normal tissues with predictive accuracies reached to 93.59 and 81.31% by using kNN and random forest algorithms, respectively.CONCLUSIONS: All the hub genes were associated with the regulation of tumor microenvironment, which implicated in tumor proliferation, progression, migration, and metastasis. Our results provide a novel prospect for diagnosis and treatment of pancreatic cancer, which may have a further application in clinical.","3":"World journal of surgical oncology","4":"30428899","5":"2018","6":"Protein Interaction Maps"},{"1":"Identification of hub genes with diagnostic values in pancreatic cancer by bioinformatics analyses and supervised learning methods.","2":"BACKGROUND: Pancreatic cancer is one of the most lethal tumors with poor prognosis, and lacks of effective biomarkers in diagnosis and treatment. The aim of this investigation was to identify hub genes in pancreatic cancer, which would serve as potential biomarkers for cancer diagnosis and therapy in the future.METHODS: Combination of two expression profiles of GSE16515 and GSE22780 from Gene Expression Omnibus (GEO) database was served as training set. Differentially expressed genes (DEGs) with top 25% variance followed by protein-protein interaction (PPI) network were performed to find candidate genes. Then, hub genes were further screened by survival and cox analyses in The Cancer Genome Atlas (TCGA) database. Finally, hub genes were validated in GSE15471 dataset from GEO by supervised learning methods k-nearest neighbor (kNN) and random forest algorithms.RESULTS: After quality control and batch effect elimination of training set, 181 DEGs bearing top 25% variance were identified as candidate genes. Then, two hub genes, MMP7 and ITGA2, correlating with diagnosis and prognosis of pancreatic cancer were screened as hub genes according to above-mentioned bioinformatics methods. Finally, hub genes were demonstrated to successfully differ tumor samples from normal tissues with predictive accuracies reached to 93.59 and 81.31% by using kNN and random forest algorithms, respectively.CONCLUSIONS: All the hub genes were associated with the regulation of tumor microenvironment, which implicated in tumor proliferation, progression, migration, and metastasis. Our results provide a novel prospect for diagnosis and treatment of pancreatic cancer, which may have a further application in clinical.","3":"World journal of surgical oncology","4":"30428899","5":"2018","6":"genetics"},{"1":"Identification of hub genes with diagnostic values in pancreatic cancer by bioinformatics analyses and supervised learning methods.","2":"BACKGROUND: Pancreatic cancer is one of the most lethal tumors with poor prognosis, and lacks of effective biomarkers in diagnosis and treatment. The aim of this investigation was to identify hub genes in pancreatic cancer, which would serve as potential biomarkers for cancer diagnosis and therapy in the future.METHODS: Combination of two expression profiles of GSE16515 and GSE22780 from Gene Expression Omnibus (GEO) database was served as training set. Differentially expressed genes (DEGs) with top 25% variance followed by protein-protein interaction (PPI) network were performed to find candidate genes. Then, hub genes were further screened by survival and cox analyses in The Cancer Genome Atlas (TCGA) database. Finally, hub genes were validated in GSE15471 dataset from GEO by supervised learning methods k-nearest neighbor (kNN) and random forest algorithms.RESULTS: After quality control and batch effect elimination of training set, 181 DEGs bearing top 25% variance were identified as candidate genes. Then, two hub genes, MMP7 and ITGA2, correlating with diagnosis and prognosis of pancreatic cancer were screened as hub genes according to above-mentioned bioinformatics methods. Finally, hub genes were demonstrated to successfully differ tumor samples from normal tissues with predictive accuracies reached to 93.59 and 81.31% by using kNN and random forest algorithms, respectively.CONCLUSIONS: All the hub genes were associated with the regulation of tumor microenvironment, which implicated in tumor proliferation, progression, migration, and metastasis. Our results provide a novel prospect for diagnosis and treatment of pancreatic cancer, which may have a further application in clinical.","3":"World journal of surgical oncology","4":"30428899","5":"2018","6":"Supervised Machine Learning"},{"1":"Identification of hub genes with diagnostic values in pancreatic cancer by bioinformatics analyses and supervised learning methods.","2":"BACKGROUND: Pancreatic cancer is one of the most lethal tumors with poor prognosis, and lacks of effective biomarkers in diagnosis and treatment. The aim of this investigation was to identify hub genes in pancreatic cancer, which would serve as potential biomarkers for cancer diagnosis and therapy in the future.METHODS: Combination of two expression profiles of GSE16515 and GSE22780 from Gene Expression Omnibus (GEO) database was served as training set. Differentially expressed genes (DEGs) with top 25% variance followed by protein-protein interaction (PPI) network were performed to find candidate genes. Then, hub genes were further screened by survival and cox analyses in The Cancer Genome Atlas (TCGA) database. Finally, hub genes were validated in GSE15471 dataset from GEO by supervised learning methods k-nearest neighbor (kNN) and random forest algorithms.RESULTS: After quality control and batch effect elimination of training set, 181 DEGs bearing top 25% variance were identified as candidate genes. Then, two hub genes, MMP7 and ITGA2, correlating with diagnosis and prognosis of pancreatic cancer were screened as hub genes according to above-mentioned bioinformatics methods. Finally, hub genes were demonstrated to successfully differ tumor samples from normal tissues with predictive accuracies reached to 93.59 and 81.31% by using kNN and random forest algorithms, respectively.CONCLUSIONS: All the hub genes were associated with the regulation of tumor microenvironment, which implicated in tumor proliferation, progression, migration, and metastasis. Our results provide a novel prospect for diagnosis and treatment of pancreatic cancer, which may have a further application in clinical.","3":"World journal of surgical oncology","4":"30428899","5":"2018","6":"Survival Analysis"},{"1":"Identification of hub genes with diagnostic values in pancreatic cancer by bioinformatics analyses and supervised learning methods.","2":"BACKGROUND: Pancreatic cancer is one of the most lethal tumors with poor prognosis, and lacks of effective biomarkers in diagnosis and treatment. The aim of this investigation was to identify hub genes in pancreatic cancer, which would serve as potential biomarkers for cancer diagnosis and therapy in the future.METHODS: Combination of two expression profiles of GSE16515 and GSE22780 from Gene Expression Omnibus (GEO) database was served as training set. Differentially expressed genes (DEGs) with top 25% variance followed by protein-protein interaction (PPI) network were performed to find candidate genes. Then, hub genes were further screened by survival and cox analyses in The Cancer Genome Atlas (TCGA) database. Finally, hub genes were validated in GSE15471 dataset from GEO by supervised learning methods k-nearest neighbor (kNN) and random forest algorithms.RESULTS: After quality control and batch effect elimination of training set, 181 DEGs bearing top 25% variance were identified as candidate genes. Then, two hub genes, MMP7 and ITGA2, correlating with diagnosis and prognosis of pancreatic cancer were screened as hub genes according to above-mentioned bioinformatics methods. Finally, hub genes were demonstrated to successfully differ tumor samples from normal tissues with predictive accuracies reached to 93.59 and 81.31% by using kNN and random forest algorithms, respectively.CONCLUSIONS: All the hub genes were associated with the regulation of tumor microenvironment, which implicated in tumor proliferation, progression, migration, and metastasis. Our results provide a novel prospect for diagnosis and treatment of pancreatic cancer, which may have a further application in clinical.","3":"World journal of surgical oncology","4":"30428899","5":"2018","6":"Tissue Array Analysis"},{"1":"Identification of hub genes with diagnostic values in pancreatic cancer by bioinformatics analyses and supervised learning methods.","2":"BACKGROUND: Pancreatic cancer is one of the most lethal tumors with poor prognosis, and lacks of effective biomarkers in diagnosis and treatment. The aim of this investigation was to identify hub genes in pancreatic cancer, which would serve as potential biomarkers for cancer diagnosis and therapy in the future.METHODS: Combination of two expression profiles of GSE16515 and GSE22780 from Gene Expression Omnibus (GEO) database was served as training set. Differentially expressed genes (DEGs) with top 25% variance followed by protein-protein interaction (PPI) network were performed to find candidate genes. Then, hub genes were further screened by survival and cox analyses in The Cancer Genome Atlas (TCGA) database. Finally, hub genes were validated in GSE15471 dataset from GEO by supervised learning methods k-nearest neighbor (kNN) and random forest algorithms.RESULTS: After quality control and batch effect elimination of training set, 181 DEGs bearing top 25% variance were identified as candidate genes. Then, two hub genes, MMP7 and ITGA2, correlating with diagnosis and prognosis of pancreatic cancer were screened as hub genes according to above-mentioned bioinformatics methods. Finally, hub genes were demonstrated to successfully differ tumor samples from normal tissues with predictive accuracies reached to 93.59 and 81.31% by using kNN and random forest algorithms, respectively.CONCLUSIONS: All the hub genes were associated with the regulation of tumor microenvironment, which implicated in tumor proliferation, progression, migration, and metastasis. Our results provide a novel prospect for diagnosis and treatment of pancreatic cancer, which may have a further application in clinical.","3":"World journal of surgical oncology","4":"30428899","5":"2018","6":"Tumor Microenvironment"},{"1":"Identifying Free-Living Physical Activities Using Lab-Based Models with Wearable Accelerometers.","2":"The purpose of this study was to classify, and model various physical activities performed by a diverse group of participants in a supervised lab-based protocol and utilize the model to identify physical activity in a free-living setting. Wrist-worn accelerometer data were collected from ( N = 152 ) adult participants; age 18<U+207B>64 years, and processed the data to identify and model unique physical activities performed by the participants in controlled settings. The Gaussian mixture model (GMM) and the hidden Markov model (HMM) algorithms were used to model the physical activities with time and frequency-based accelerometer features. An overall model accuracy of 92.7% and 94.7% were achieved to classify 24 physical activities using GMM and HMM, respectively. The most accurate model was then used to identify physical activities performed by 20 participants, each recorded for two free-living sessions of approximately six hours each. The free-living activity intensities were estimated with 80% accuracy and showed the dominance of stationary and light intensity activities in 36 out of 40 recorded sessions. This work proposes a novel activity recognition process to identify unsupervised free-living activities using lab-based classification models. In summary, this study contributes to the use of wearable sensors to identify physical activities and estimate energy expenditure in free-living settings.","3":"Sensors (Basel, Switzerland)","4":"30424512","5":"2018","6":"Accelerometry"},{"1":"Identifying Free-Living Physical Activities Using Lab-Based Models with Wearable Accelerometers.","2":"The purpose of this study was to classify, and model various physical activities performed by a diverse group of participants in a supervised lab-based protocol and utilize the model to identify physical activity in a free-living setting. Wrist-worn accelerometer data were collected from ( N = 152 ) adult participants; age 18<U+207B>64 years, and processed the data to identify and model unique physical activities performed by the participants in controlled settings. The Gaussian mixture model (GMM) and the hidden Markov model (HMM) algorithms were used to model the physical activities with time and frequency-based accelerometer features. An overall model accuracy of 92.7% and 94.7% were achieved to classify 24 physical activities using GMM and HMM, respectively. The most accurate model was then used to identify physical activities performed by 20 participants, each recorded for two free-living sessions of approximately six hours each. The free-living activity intensities were estimated with 80% accuracy and showed the dominance of stationary and light intensity activities in 36 out of 40 recorded sessions. This work proposes a novel activity recognition process to identify unsupervised free-living activities using lab-based classification models. In summary, this study contributes to the use of wearable sensors to identify physical activities and estimate energy expenditure in free-living settings.","3":"Sensors (Basel, Switzerland)","4":"30424512","5":"2018","6":"Adolescent"},{"1":"Identifying Free-Living Physical Activities Using Lab-Based Models with Wearable Accelerometers.","2":"The purpose of this study was to classify, and model various physical activities performed by a diverse group of participants in a supervised lab-based protocol and utilize the model to identify physical activity in a free-living setting. Wrist-worn accelerometer data were collected from ( N = 152 ) adult participants; age 18<U+207B>64 years, and processed the data to identify and model unique physical activities performed by the participants in controlled settings. The Gaussian mixture model (GMM) and the hidden Markov model (HMM) algorithms were used to model the physical activities with time and frequency-based accelerometer features. An overall model accuracy of 92.7% and 94.7% were achieved to classify 24 physical activities using GMM and HMM, respectively. The most accurate model was then used to identify physical activities performed by 20 participants, each recorded for two free-living sessions of approximately six hours each. The free-living activity intensities were estimated with 80% accuracy and showed the dominance of stationary and light intensity activities in 36 out of 40 recorded sessions. This work proposes a novel activity recognition process to identify unsupervised free-living activities using lab-based classification models. In summary, this study contributes to the use of wearable sensors to identify physical activities and estimate energy expenditure in free-living settings.","3":"Sensors (Basel, Switzerland)","4":"30424512","5":"2018","6":"Adult"},{"1":"Identifying Free-Living Physical Activities Using Lab-Based Models with Wearable Accelerometers.","2":"The purpose of this study was to classify, and model various physical activities performed by a diverse group of participants in a supervised lab-based protocol and utilize the model to identify physical activity in a free-living setting. Wrist-worn accelerometer data were collected from ( N = 152 ) adult participants; age 18<U+207B>64 years, and processed the data to identify and model unique physical activities performed by the participants in controlled settings. The Gaussian mixture model (GMM) and the hidden Markov model (HMM) algorithms were used to model the physical activities with time and frequency-based accelerometer features. An overall model accuracy of 92.7% and 94.7% were achieved to classify 24 physical activities using GMM and HMM, respectively. The most accurate model was then used to identify physical activities performed by 20 participants, each recorded for two free-living sessions of approximately six hours each. The free-living activity intensities were estimated with 80% accuracy and showed the dominance of stationary and light intensity activities in 36 out of 40 recorded sessions. This work proposes a novel activity recognition process to identify unsupervised free-living activities using lab-based classification models. In summary, this study contributes to the use of wearable sensors to identify physical activities and estimate energy expenditure in free-living settings.","3":"Sensors (Basel, Switzerland)","4":"30424512","5":"2018","6":"Exercise"},{"1":"Identifying Free-Living Physical Activities Using Lab-Based Models with Wearable Accelerometers.","2":"The purpose of this study was to classify, and model various physical activities performed by a diverse group of participants in a supervised lab-based protocol and utilize the model to identify physical activity in a free-living setting. Wrist-worn accelerometer data were collected from ( N = 152 ) adult participants; age 18<U+207B>64 years, and processed the data to identify and model unique physical activities performed by the participants in controlled settings. The Gaussian mixture model (GMM) and the hidden Markov model (HMM) algorithms were used to model the physical activities with time and frequency-based accelerometer features. An overall model accuracy of 92.7% and 94.7% were achieved to classify 24 physical activities using GMM and HMM, respectively. The most accurate model was then used to identify physical activities performed by 20 participants, each recorded for two free-living sessions of approximately six hours each. The free-living activity intensities were estimated with 80% accuracy and showed the dominance of stationary and light intensity activities in 36 out of 40 recorded sessions. This work proposes a novel activity recognition process to identify unsupervised free-living activities using lab-based classification models. In summary, this study contributes to the use of wearable sensors to identify physical activities and estimate energy expenditure in free-living settings.","3":"Sensors (Basel, Switzerland)","4":"30424512","5":"2018","6":"Female"},{"1":"Identifying Free-Living Physical Activities Using Lab-Based Models with Wearable Accelerometers.","2":"The purpose of this study was to classify, and model various physical activities performed by a diverse group of participants in a supervised lab-based protocol and utilize the model to identify physical activity in a free-living setting. Wrist-worn accelerometer data were collected from ( N = 152 ) adult participants; age 18<U+207B>64 years, and processed the data to identify and model unique physical activities performed by the participants in controlled settings. The Gaussian mixture model (GMM) and the hidden Markov model (HMM) algorithms were used to model the physical activities with time and frequency-based accelerometer features. An overall model accuracy of 92.7% and 94.7% were achieved to classify 24 physical activities using GMM and HMM, respectively. The most accurate model was then used to identify physical activities performed by 20 participants, each recorded for two free-living sessions of approximately six hours each. The free-living activity intensities were estimated with 80% accuracy and showed the dominance of stationary and light intensity activities in 36 out of 40 recorded sessions. This work proposes a novel activity recognition process to identify unsupervised free-living activities using lab-based classification models. In summary, this study contributes to the use of wearable sensors to identify physical activities and estimate energy expenditure in free-living settings.","3":"Sensors (Basel, Switzerland)","4":"30424512","5":"2018","6":"Humans"},{"1":"Identifying Free-Living Physical Activities Using Lab-Based Models with Wearable Accelerometers.","2":"The purpose of this study was to classify, and model various physical activities performed by a diverse group of participants in a supervised lab-based protocol and utilize the model to identify physical activity in a free-living setting. Wrist-worn accelerometer data were collected from ( N = 152 ) adult participants; age 18<U+207B>64 years, and processed the data to identify and model unique physical activities performed by the participants in controlled settings. The Gaussian mixture model (GMM) and the hidden Markov model (HMM) algorithms were used to model the physical activities with time and frequency-based accelerometer features. An overall model accuracy of 92.7% and 94.7% were achieved to classify 24 physical activities using GMM and HMM, respectively. The most accurate model was then used to identify physical activities performed by 20 participants, each recorded for two free-living sessions of approximately six hours each. The free-living activity intensities were estimated with 80% accuracy and showed the dominance of stationary and light intensity activities in 36 out of 40 recorded sessions. This work proposes a novel activity recognition process to identify unsupervised free-living activities using lab-based classification models. In summary, this study contributes to the use of wearable sensors to identify physical activities and estimate energy expenditure in free-living settings.","3":"Sensors (Basel, Switzerland)","4":"30424512","5":"2018","6":"Machine Learning"},{"1":"Identifying Free-Living Physical Activities Using Lab-Based Models with Wearable Accelerometers.","2":"The purpose of this study was to classify, and model various physical activities performed by a diverse group of participants in a supervised lab-based protocol and utilize the model to identify physical activity in a free-living setting. Wrist-worn accelerometer data were collected from ( N = 152 ) adult participants; age 18<U+207B>64 years, and processed the data to identify and model unique physical activities performed by the participants in controlled settings. The Gaussian mixture model (GMM) and the hidden Markov model (HMM) algorithms were used to model the physical activities with time and frequency-based accelerometer features. An overall model accuracy of 92.7% and 94.7% were achieved to classify 24 physical activities using GMM and HMM, respectively. The most accurate model was then used to identify physical activities performed by 20 participants, each recorded for two free-living sessions of approximately six hours each. The free-living activity intensities were estimated with 80% accuracy and showed the dominance of stationary and light intensity activities in 36 out of 40 recorded sessions. This work proposes a novel activity recognition process to identify unsupervised free-living activities using lab-based classification models. In summary, this study contributes to the use of wearable sensors to identify physical activities and estimate energy expenditure in free-living settings.","3":"Sensors (Basel, Switzerland)","4":"30424512","5":"2018","6":"Male"},{"1":"Identifying Free-Living Physical Activities Using Lab-Based Models with Wearable Accelerometers.","2":"The purpose of this study was to classify, and model various physical activities performed by a diverse group of participants in a supervised lab-based protocol and utilize the model to identify physical activity in a free-living setting. Wrist-worn accelerometer data were collected from ( N = 152 ) adult participants; age 18<U+207B>64 years, and processed the data to identify and model unique physical activities performed by the participants in controlled settings. The Gaussian mixture model (GMM) and the hidden Markov model (HMM) algorithms were used to model the physical activities with time and frequency-based accelerometer features. An overall model accuracy of 92.7% and 94.7% were achieved to classify 24 physical activities using GMM and HMM, respectively. The most accurate model was then used to identify physical activities performed by 20 participants, each recorded for two free-living sessions of approximately six hours each. The free-living activity intensities were estimated with 80% accuracy and showed the dominance of stationary and light intensity activities in 36 out of 40 recorded sessions. This work proposes a novel activity recognition process to identify unsupervised free-living activities using lab-based classification models. In summary, this study contributes to the use of wearable sensors to identify physical activities and estimate energy expenditure in free-living settings.","3":"Sensors (Basel, Switzerland)","4":"30424512","5":"2018","6":"Markov Chains"},{"1":"Identifying Free-Living Physical Activities Using Lab-Based Models with Wearable Accelerometers.","2":"The purpose of this study was to classify, and model various physical activities performed by a diverse group of participants in a supervised lab-based protocol and utilize the model to identify physical activity in a free-living setting. Wrist-worn accelerometer data were collected from ( N = 152 ) adult participants; age 18<U+207B>64 years, and processed the data to identify and model unique physical activities performed by the participants in controlled settings. The Gaussian mixture model (GMM) and the hidden Markov model (HMM) algorithms were used to model the physical activities with time and frequency-based accelerometer features. An overall model accuracy of 92.7% and 94.7% were achieved to classify 24 physical activities using GMM and HMM, respectively. The most accurate model was then used to identify physical activities performed by 20 participants, each recorded for two free-living sessions of approximately six hours each. The free-living activity intensities were estimated with 80% accuracy and showed the dominance of stationary and light intensity activities in 36 out of 40 recorded sessions. This work proposes a novel activity recognition process to identify unsupervised free-living activities using lab-based classification models. In summary, this study contributes to the use of wearable sensors to identify physical activities and estimate energy expenditure in free-living settings.","3":"Sensors (Basel, Switzerland)","4":"30424512","5":"2018","6":"Middle Aged"},{"1":"Identifying Free-Living Physical Activities Using Lab-Based Models with Wearable Accelerometers.","2":"The purpose of this study was to classify, and model various physical activities performed by a diverse group of participants in a supervised lab-based protocol and utilize the model to identify physical activity in a free-living setting. Wrist-worn accelerometer data were collected from ( N = 152 ) adult participants; age 18<U+207B>64 years, and processed the data to identify and model unique physical activities performed by the participants in controlled settings. The Gaussian mixture model (GMM) and the hidden Markov model (HMM) algorithms were used to model the physical activities with time and frequency-based accelerometer features. An overall model accuracy of 92.7% and 94.7% were achieved to classify 24 physical activities using GMM and HMM, respectively. The most accurate model was then used to identify physical activities performed by 20 participants, each recorded for two free-living sessions of approximately six hours each. The free-living activity intensities were estimated with 80% accuracy and showed the dominance of stationary and light intensity activities in 36 out of 40 recorded sessions. This work proposes a novel activity recognition process to identify unsupervised free-living activities using lab-based classification models. In summary, this study contributes to the use of wearable sensors to identify physical activities and estimate energy expenditure in free-living settings.","3":"Sensors (Basel, Switzerland)","4":"30424512","5":"2018","6":"Monitoring, Physiologic"},{"1":"Identifying Free-Living Physical Activities Using Lab-Based Models with Wearable Accelerometers.","2":"The purpose of this study was to classify, and model various physical activities performed by a diverse group of participants in a supervised lab-based protocol and utilize the model to identify physical activity in a free-living setting. Wrist-worn accelerometer data were collected from ( N = 152 ) adult participants; age 18<U+207B>64 years, and processed the data to identify and model unique physical activities performed by the participants in controlled settings. The Gaussian mixture model (GMM) and the hidden Markov model (HMM) algorithms were used to model the physical activities with time and frequency-based accelerometer features. An overall model accuracy of 92.7% and 94.7% were achieved to classify 24 physical activities using GMM and HMM, respectively. The most accurate model was then used to identify physical activities performed by 20 participants, each recorded for two free-living sessions of approximately six hours each. The free-living activity intensities were estimated with 80% accuracy and showed the dominance of stationary and light intensity activities in 36 out of 40 recorded sessions. This work proposes a novel activity recognition process to identify unsupervised free-living activities using lab-based classification models. In summary, this study contributes to the use of wearable sensors to identify physical activities and estimate energy expenditure in free-living settings.","3":"Sensors (Basel, Switzerland)","4":"30424512","5":"2018","6":"Wearable Electronic Devices"},{"1":"Identifying Free-Living Physical Activities Using Lab-Based Models with Wearable Accelerometers.","2":"The purpose of this study was to classify, and model various physical activities performed by a diverse group of participants in a supervised lab-based protocol and utilize the model to identify physical activity in a free-living setting. Wrist-worn accelerometer data were collected from ( N = 152 ) adult participants; age 18<U+207B>64 years, and processed the data to identify and model unique physical activities performed by the participants in controlled settings. The Gaussian mixture model (GMM) and the hidden Markov model (HMM) algorithms were used to model the physical activities with time and frequency-based accelerometer features. An overall model accuracy of 92.7% and 94.7% were achieved to classify 24 physical activities using GMM and HMM, respectively. The most accurate model was then used to identify physical activities performed by 20 participants, each recorded for two free-living sessions of approximately six hours each. The free-living activity intensities were estimated with 80% accuracy and showed the dominance of stationary and light intensity activities in 36 out of 40 recorded sessions. This work proposes a novel activity recognition process to identify unsupervised free-living activities using lab-based classification models. In summary, this study contributes to the use of wearable sensors to identify physical activities and estimate energy expenditure in free-living settings.","3":"Sensors (Basel, Switzerland)","4":"30424512","5":"2018","6":"Young Adult"},{"1":"A Portable, Wireless Photoplethysomography Sensor for Assessing Health of Arteriovenous Fistula Using Class-Weighted Support Vector Machine.","2":"A portable, wireless photoplethysomography (PPG) sensor for assessing arteriovenous fistula (AVF) by using class-weighted support vector machines (SVM) was presented in this study. Nowadays, in hospital, AVF are assessed by ultrasound Doppler machines, which are bulky, expensive, complicated-to-operate, and time-consuming. In this study, new PPG sensors were proposed and developed successfully to provide portable and inexpensive solutions for AVF assessments. To develop the sensor, at first, by combining the dimensionless number analysis and the optical Beer Lambert's law, five input features were derived for the SVM classifier. In the next step, to increase the signal-noise ratio (SNR) of PPG signals, the front-end readout circuitries were designed to fully use the dynamic range of analog-digital converter (ADC) by controlling the circuitries gain and the light intensity of light emitted diode (LED). Digital signal processing algorithms were proposed next to check and fix signal anomalies. Finally, the class-weighted SVM classifiers employed five different kernel functions to assess AVF quality. The assessment results were provided to doctors for diagonosis and detemining ensuing proper treatments. The experimental results showed that the proposed PPG sensors successfully achieved an accuracy of 89.11% in assessing health of AVF and with a type II error of only 9.59%.","3":"Sensors (Basel, Switzerland)","4":"30423988","5":"2018","6":"Algorithms"},{"1":"A Portable, Wireless Photoplethysomography Sensor for Assessing Health of Arteriovenous Fistula Using Class-Weighted Support Vector Machine.","2":"A portable, wireless photoplethysomography (PPG) sensor for assessing arteriovenous fistula (AVF) by using class-weighted support vector machines (SVM) was presented in this study. Nowadays, in hospital, AVF are assessed by ultrasound Doppler machines, which are bulky, expensive, complicated-to-operate, and time-consuming. In this study, new PPG sensors were proposed and developed successfully to provide portable and inexpensive solutions for AVF assessments. To develop the sensor, at first, by combining the dimensionless number analysis and the optical Beer Lambert's law, five input features were derived for the SVM classifier. In the next step, to increase the signal-noise ratio (SNR) of PPG signals, the front-end readout circuitries were designed to fully use the dynamic range of analog-digital converter (ADC) by controlling the circuitries gain and the light intensity of light emitted diode (LED). Digital signal processing algorithms were proposed next to check and fix signal anomalies. Finally, the class-weighted SVM classifiers employed five different kernel functions to assess AVF quality. The assessment results were provided to doctors for diagonosis and detemining ensuing proper treatments. The experimental results showed that the proposed PPG sensors successfully achieved an accuracy of 89.11% in assessing health of AVF and with a type II error of only 9.59%.","3":"Sensors (Basel, Switzerland)","4":"30423988","5":"2018","6":"Arteriovenous Fistula"},{"1":"A Portable, Wireless Photoplethysomography Sensor for Assessing Health of Arteriovenous Fistula Using Class-Weighted Support Vector Machine.","2":"A portable, wireless photoplethysomography (PPG) sensor for assessing arteriovenous fistula (AVF) by using class-weighted support vector machines (SVM) was presented in this study. Nowadays, in hospital, AVF are assessed by ultrasound Doppler machines, which are bulky, expensive, complicated-to-operate, and time-consuming. In this study, new PPG sensors were proposed and developed successfully to provide portable and inexpensive solutions for AVF assessments. To develop the sensor, at first, by combining the dimensionless number analysis and the optical Beer Lambert's law, five input features were derived for the SVM classifier. In the next step, to increase the signal-noise ratio (SNR) of PPG signals, the front-end readout circuitries were designed to fully use the dynamic range of analog-digital converter (ADC) by controlling the circuitries gain and the light intensity of light emitted diode (LED). Digital signal processing algorithms were proposed next to check and fix signal anomalies. Finally, the class-weighted SVM classifiers employed five different kernel functions to assess AVF quality. The assessment results were provided to doctors for diagonosis and detemining ensuing proper treatments. The experimental results showed that the proposed PPG sensors successfully achieved an accuracy of 89.11% in assessing health of AVF and with a type II error of only 9.59%.","3":"Sensors (Basel, Switzerland)","4":"30423988","5":"2018","6":"diagnostic imaging"},{"1":"A Portable, Wireless Photoplethysomography Sensor for Assessing Health of Arteriovenous Fistula Using Class-Weighted Support Vector Machine.","2":"A portable, wireless photoplethysomography (PPG) sensor for assessing arteriovenous fistula (AVF) by using class-weighted support vector machines (SVM) was presented in this study. Nowadays, in hospital, AVF are assessed by ultrasound Doppler machines, which are bulky, expensive, complicated-to-operate, and time-consuming. In this study, new PPG sensors were proposed and developed successfully to provide portable and inexpensive solutions for AVF assessments. To develop the sensor, at first, by combining the dimensionless number analysis and the optical Beer Lambert's law, five input features were derived for the SVM classifier. In the next step, to increase the signal-noise ratio (SNR) of PPG signals, the front-end readout circuitries were designed to fully use the dynamic range of analog-digital converter (ADC) by controlling the circuitries gain and the light intensity of light emitted diode (LED). Digital signal processing algorithms were proposed next to check and fix signal anomalies. Finally, the class-weighted SVM classifiers employed five different kernel functions to assess AVF quality. The assessment results were provided to doctors for diagonosis and detemining ensuing proper treatments. The experimental results showed that the proposed PPG sensors successfully achieved an accuracy of 89.11% in assessing health of AVF and with a type II error of only 9.59%.","3":"Sensors (Basel, Switzerland)","4":"30423988","5":"2018","6":"Biosensing Techniques"},{"1":"A Portable, Wireless Photoplethysomography Sensor for Assessing Health of Arteriovenous Fistula Using Class-Weighted Support Vector Machine.","2":"A portable, wireless photoplethysomography (PPG) sensor for assessing arteriovenous fistula (AVF) by using class-weighted support vector machines (SVM) was presented in this study. Nowadays, in hospital, AVF are assessed by ultrasound Doppler machines, which are bulky, expensive, complicated-to-operate, and time-consuming. In this study, new PPG sensors were proposed and developed successfully to provide portable and inexpensive solutions for AVF assessments. To develop the sensor, at first, by combining the dimensionless number analysis and the optical Beer Lambert's law, five input features were derived for the SVM classifier. In the next step, to increase the signal-noise ratio (SNR) of PPG signals, the front-end readout circuitries were designed to fully use the dynamic range of analog-digital converter (ADC) by controlling the circuitries gain and the light intensity of light emitted diode (LED). Digital signal processing algorithms were proposed next to check and fix signal anomalies. Finally, the class-weighted SVM classifiers employed five different kernel functions to assess AVF quality. The assessment results were provided to doctors for diagonosis and detemining ensuing proper treatments. The experimental results showed that the proposed PPG sensors successfully achieved an accuracy of 89.11% in assessing health of AVF and with a type II error of only 9.59%.","3":"Sensors (Basel, Switzerland)","4":"30423988","5":"2018","6":"instrumentation"},{"1":"A Portable, Wireless Photoplethysomography Sensor for Assessing Health of Arteriovenous Fistula Using Class-Weighted Support Vector Machine.","2":"A portable, wireless photoplethysomography (PPG) sensor for assessing arteriovenous fistula (AVF) by using class-weighted support vector machines (SVM) was presented in this study. Nowadays, in hospital, AVF are assessed by ultrasound Doppler machines, which are bulky, expensive, complicated-to-operate, and time-consuming. In this study, new PPG sensors were proposed and developed successfully to provide portable and inexpensive solutions for AVF assessments. To develop the sensor, at first, by combining the dimensionless number analysis and the optical Beer Lambert's law, five input features were derived for the SVM classifier. In the next step, to increase the signal-noise ratio (SNR) of PPG signals, the front-end readout circuitries were designed to fully use the dynamic range of analog-digital converter (ADC) by controlling the circuitries gain and the light intensity of light emitted diode (LED). Digital signal processing algorithms were proposed next to check and fix signal anomalies. Finally, the class-weighted SVM classifiers employed five different kernel functions to assess AVF quality. The assessment results were provided to doctors for diagonosis and detemining ensuing proper treatments. The experimental results showed that the proposed PPG sensors successfully achieved an accuracy of 89.11% in assessing health of AVF and with a type II error of only 9.59%.","3":"Sensors (Basel, Switzerland)","4":"30423988","5":"2018","6":"Hospitals"},{"1":"A Portable, Wireless Photoplethysomography Sensor for Assessing Health of Arteriovenous Fistula Using Class-Weighted Support Vector Machine.","2":"A portable, wireless photoplethysomography (PPG) sensor for assessing arteriovenous fistula (AVF) by using class-weighted support vector machines (SVM) was presented in this study. Nowadays, in hospital, AVF are assessed by ultrasound Doppler machines, which are bulky, expensive, complicated-to-operate, and time-consuming. In this study, new PPG sensors were proposed and developed successfully to provide portable and inexpensive solutions for AVF assessments. To develop the sensor, at first, by combining the dimensionless number analysis and the optical Beer Lambert's law, five input features were derived for the SVM classifier. In the next step, to increase the signal-noise ratio (SNR) of PPG signals, the front-end readout circuitries were designed to fully use the dynamic range of analog-digital converter (ADC) by controlling the circuitries gain and the light intensity of light emitted diode (LED). Digital signal processing algorithms were proposed next to check and fix signal anomalies. Finally, the class-weighted SVM classifiers employed five different kernel functions to assess AVF quality. The assessment results were provided to doctors for diagonosis and detemining ensuing proper treatments. The experimental results showed that the proposed PPG sensors successfully achieved an accuracy of 89.11% in assessing health of AVF and with a type II error of only 9.59%.","3":"Sensors (Basel, Switzerland)","4":"30423988","5":"2018","6":"Humans"},{"1":"A Portable, Wireless Photoplethysomography Sensor for Assessing Health of Arteriovenous Fistula Using Class-Weighted Support Vector Machine.","2":"A portable, wireless photoplethysomography (PPG) sensor for assessing arteriovenous fistula (AVF) by using class-weighted support vector machines (SVM) was presented in this study. Nowadays, in hospital, AVF are assessed by ultrasound Doppler machines, which are bulky, expensive, complicated-to-operate, and time-consuming. In this study, new PPG sensors were proposed and developed successfully to provide portable and inexpensive solutions for AVF assessments. To develop the sensor, at first, by combining the dimensionless number analysis and the optical Beer Lambert's law, five input features were derived for the SVM classifier. In the next step, to increase the signal-noise ratio (SNR) of PPG signals, the front-end readout circuitries were designed to fully use the dynamic range of analog-digital converter (ADC) by controlling the circuitries gain and the light intensity of light emitted diode (LED). Digital signal processing algorithms were proposed next to check and fix signal anomalies. Finally, the class-weighted SVM classifiers employed five different kernel functions to assess AVF quality. The assessment results were provided to doctors for diagonosis and detemining ensuing proper treatments. The experimental results showed that the proposed PPG sensors successfully achieved an accuracy of 89.11% in assessing health of AVF and with a type II error of only 9.59%.","3":"Sensors (Basel, Switzerland)","4":"30423988","5":"2018","6":"Outcome Assessment (Health Care)"},{"1":"A Portable, Wireless Photoplethysomography Sensor for Assessing Health of Arteriovenous Fistula Using Class-Weighted Support Vector Machine.","2":"A portable, wireless photoplethysomography (PPG) sensor for assessing arteriovenous fistula (AVF) by using class-weighted support vector machines (SVM) was presented in this study. Nowadays, in hospital, AVF are assessed by ultrasound Doppler machines, which are bulky, expensive, complicated-to-operate, and time-consuming. In this study, new PPG sensors were proposed and developed successfully to provide portable and inexpensive solutions for AVF assessments. To develop the sensor, at first, by combining the dimensionless number analysis and the optical Beer Lambert's law, five input features were derived for the SVM classifier. In the next step, to increase the signal-noise ratio (SNR) of PPG signals, the front-end readout circuitries were designed to fully use the dynamic range of analog-digital converter (ADC) by controlling the circuitries gain and the light intensity of light emitted diode (LED). Digital signal processing algorithms were proposed next to check and fix signal anomalies. Finally, the class-weighted SVM classifiers employed five different kernel functions to assess AVF quality. The assessment results were provided to doctors for diagonosis and detemining ensuing proper treatments. The experimental results showed that the proposed PPG sensors successfully achieved an accuracy of 89.11% in assessing health of AVF and with a type II error of only 9.59%.","3":"Sensors (Basel, Switzerland)","4":"30423988","5":"2018","6":"Photoplethysmography"},{"1":"A Portable, Wireless Photoplethysomography Sensor for Assessing Health of Arteriovenous Fistula Using Class-Weighted Support Vector Machine.","2":"A portable, wireless photoplethysomography (PPG) sensor for assessing arteriovenous fistula (AVF) by using class-weighted support vector machines (SVM) was presented in this study. Nowadays, in hospital, AVF are assessed by ultrasound Doppler machines, which are bulky, expensive, complicated-to-operate, and time-consuming. In this study, new PPG sensors were proposed and developed successfully to provide portable and inexpensive solutions for AVF assessments. To develop the sensor, at first, by combining the dimensionless number analysis and the optical Beer Lambert's law, five input features were derived for the SVM classifier. In the next step, to increase the signal-noise ratio (SNR) of PPG signals, the front-end readout circuitries were designed to fully use the dynamic range of analog-digital converter (ADC) by controlling the circuitries gain and the light intensity of light emitted diode (LED). Digital signal processing algorithms were proposed next to check and fix signal anomalies. Finally, the class-weighted SVM classifiers employed five different kernel functions to assess AVF quality. The assessment results were provided to doctors for diagonosis and detemining ensuing proper treatments. The experimental results showed that the proposed PPG sensors successfully achieved an accuracy of 89.11% in assessing health of AVF and with a type II error of only 9.59%.","3":"Sensors (Basel, Switzerland)","4":"30423988","5":"2018","6":"instrumentation"},{"1":"A Portable, Wireless Photoplethysomography Sensor for Assessing Health of Arteriovenous Fistula Using Class-Weighted Support Vector Machine.","2":"A portable, wireless photoplethysomography (PPG) sensor for assessing arteriovenous fistula (AVF) by using class-weighted support vector machines (SVM) was presented in this study. Nowadays, in hospital, AVF are assessed by ultrasound Doppler machines, which are bulky, expensive, complicated-to-operate, and time-consuming. In this study, new PPG sensors were proposed and developed successfully to provide portable and inexpensive solutions for AVF assessments. To develop the sensor, at first, by combining the dimensionless number analysis and the optical Beer Lambert's law, five input features were derived for the SVM classifier. In the next step, to increase the signal-noise ratio (SNR) of PPG signals, the front-end readout circuitries were designed to fully use the dynamic range of analog-digital converter (ADC) by controlling the circuitries gain and the light intensity of light emitted diode (LED). Digital signal processing algorithms were proposed next to check and fix signal anomalies. Finally, the class-weighted SVM classifiers employed five different kernel functions to assess AVF quality. The assessment results were provided to doctors for diagonosis and detemining ensuing proper treatments. The experimental results showed that the proposed PPG sensors successfully achieved an accuracy of 89.11% in assessing health of AVF and with a type II error of only 9.59%.","3":"Sensors (Basel, Switzerland)","4":"30423988","5":"2018","6":"Signal Processing, Computer-Assisted"},{"1":"A Portable, Wireless Photoplethysomography Sensor for Assessing Health of Arteriovenous Fistula Using Class-Weighted Support Vector Machine.","2":"A portable, wireless photoplethysomography (PPG) sensor for assessing arteriovenous fistula (AVF) by using class-weighted support vector machines (SVM) was presented in this study. Nowadays, in hospital, AVF are assessed by ultrasound Doppler machines, which are bulky, expensive, complicated-to-operate, and time-consuming. In this study, new PPG sensors were proposed and developed successfully to provide portable and inexpensive solutions for AVF assessments. To develop the sensor, at first, by combining the dimensionless number analysis and the optical Beer Lambert's law, five input features were derived for the SVM classifier. In the next step, to increase the signal-noise ratio (SNR) of PPG signals, the front-end readout circuitries were designed to fully use the dynamic range of analog-digital converter (ADC) by controlling the circuitries gain and the light intensity of light emitted diode (LED). Digital signal processing algorithms were proposed next to check and fix signal anomalies. Finally, the class-weighted SVM classifiers employed five different kernel functions to assess AVF quality. The assessment results were provided to doctors for diagonosis and detemining ensuing proper treatments. The experimental results showed that the proposed PPG sensors successfully achieved an accuracy of 89.11% in assessing health of AVF and with a type II error of only 9.59%.","3":"Sensors (Basel, Switzerland)","4":"30423988","5":"2018","6":"Signal-To-Noise Ratio"},{"1":"A Portable, Wireless Photoplethysomography Sensor for Assessing Health of Arteriovenous Fistula Using Class-Weighted Support Vector Machine.","2":"A portable, wireless photoplethysomography (PPG) sensor for assessing arteriovenous fistula (AVF) by using class-weighted support vector machines (SVM) was presented in this study. Nowadays, in hospital, AVF are assessed by ultrasound Doppler machines, which are bulky, expensive, complicated-to-operate, and time-consuming. In this study, new PPG sensors were proposed and developed successfully to provide portable and inexpensive solutions for AVF assessments. To develop the sensor, at first, by combining the dimensionless number analysis and the optical Beer Lambert's law, five input features were derived for the SVM classifier. In the next step, to increase the signal-noise ratio (SNR) of PPG signals, the front-end readout circuitries were designed to fully use the dynamic range of analog-digital converter (ADC) by controlling the circuitries gain and the light intensity of light emitted diode (LED). Digital signal processing algorithms were proposed next to check and fix signal anomalies. Finally, the class-weighted SVM classifiers employed five different kernel functions to assess AVF quality. The assessment results were provided to doctors for diagonosis and detemining ensuing proper treatments. The experimental results showed that the proposed PPG sensors successfully achieved an accuracy of 89.11% in assessing health of AVF and with a type II error of only 9.59%.","3":"Sensors (Basel, Switzerland)","4":"30423988","5":"2018","6":"Support Vector Machine"},{"1":"A Portable, Wireless Photoplethysomography Sensor for Assessing Health of Arteriovenous Fistula Using Class-Weighted Support Vector Machine.","2":"A portable, wireless photoplethysomography (PPG) sensor for assessing arteriovenous fistula (AVF) by using class-weighted support vector machines (SVM) was presented in this study. Nowadays, in hospital, AVF are assessed by ultrasound Doppler machines, which are bulky, expensive, complicated-to-operate, and time-consuming. In this study, new PPG sensors were proposed and developed successfully to provide portable and inexpensive solutions for AVF assessments. To develop the sensor, at first, by combining the dimensionless number analysis and the optical Beer Lambert's law, five input features were derived for the SVM classifier. In the next step, to increase the signal-noise ratio (SNR) of PPG signals, the front-end readout circuitries were designed to fully use the dynamic range of analog-digital converter (ADC) by controlling the circuitries gain and the light intensity of light emitted diode (LED). Digital signal processing algorithms were proposed next to check and fix signal anomalies. Finally, the class-weighted SVM classifiers employed five different kernel functions to assess AVF quality. The assessment results were provided to doctors for diagonosis and detemining ensuing proper treatments. The experimental results showed that the proposed PPG sensors successfully achieved an accuracy of 89.11% in assessing health of AVF and with a type II error of only 9.59%.","3":"Sensors (Basel, Switzerland)","4":"30423988","5":"2018","6":"Ultrasonography"},{"1":"A Portable, Wireless Photoplethysomography Sensor for Assessing Health of Arteriovenous Fistula Using Class-Weighted Support Vector Machine.","2":"A portable, wireless photoplethysomography (PPG) sensor for assessing arteriovenous fistula (AVF) by using class-weighted support vector machines (SVM) was presented in this study. Nowadays, in hospital, AVF are assessed by ultrasound Doppler machines, which are bulky, expensive, complicated-to-operate, and time-consuming. In this study, new PPG sensors were proposed and developed successfully to provide portable and inexpensive solutions for AVF assessments. To develop the sensor, at first, by combining the dimensionless number analysis and the optical Beer Lambert's law, five input features were derived for the SVM classifier. In the next step, to increase the signal-noise ratio (SNR) of PPG signals, the front-end readout circuitries were designed to fully use the dynamic range of analog-digital converter (ADC) by controlling the circuitries gain and the light intensity of light emitted diode (LED). Digital signal processing algorithms were proposed next to check and fix signal anomalies. Finally, the class-weighted SVM classifiers employed five different kernel functions to assess AVF quality. The assessment results were provided to doctors for diagonosis and detemining ensuing proper treatments. The experimental results showed that the proposed PPG sensors successfully achieved an accuracy of 89.11% in assessing health of AVF and with a type II error of only 9.59%.","3":"Sensors (Basel, Switzerland)","4":"30423988","5":"2018","6":"Wireless Technology"},{"1":"Pilot Study on Gait Classification Using fNIRS Signals.","2":"Rehabilitation training is essential for motor dysfunction patients, and the training through their subjective motion intention, comparing to passive training, is more conducive to rehabilitation. This study proposes a method to identify motion intention of different walking states under the normal environment, by using the functional near-infrared spectroscopy (fNIRS) technology. Twenty-two healthy subjects were recruited to walk with three different gaits (including small-step with low-speed, small-step with midspeed, midstep with low-speed). The wavelet packet decomposition was used to find out the main characteristic channels in different motion states, and these channels with links in frequency and space were combined to define as feature vectors. According to different permutations and combinations of all feature vectors, a library for support vector machines (libSVM) was used to achieve the best recognition model. Finally, the accuracy rate of these three walking states was 78.79%. This study implemented the classification of different states' motion intention by using the fNIRS technology. It laid a foundation to apply the classified motion intention of different states timely, to help severe motor dysfunction patients control a walking-assistive device for rehabilitation training, so as to help them restore independent walking abilities and reduce the economic burdens on society.","3":"Computational intelligence and neuroscience","4":"30416520","5":"2018","6":"Biomechanical Phenomena"},{"1":"Pilot Study on Gait Classification Using fNIRS Signals.","2":"Rehabilitation training is essential for motor dysfunction patients, and the training through their subjective motion intention, comparing to passive training, is more conducive to rehabilitation. This study proposes a method to identify motion intention of different walking states under the normal environment, by using the functional near-infrared spectroscopy (fNIRS) technology. Twenty-two healthy subjects were recruited to walk with three different gaits (including small-step with low-speed, small-step with midspeed, midstep with low-speed). The wavelet packet decomposition was used to find out the main characteristic channels in different motion states, and these channels with links in frequency and space were combined to define as feature vectors. According to different permutations and combinations of all feature vectors, a library for support vector machines (libSVM) was used to achieve the best recognition model. Finally, the accuracy rate of these three walking states was 78.79%. This study implemented the classification of different states' motion intention by using the fNIRS technology. It laid a foundation to apply the classified motion intention of different states timely, to help severe motor dysfunction patients control a walking-assistive device for rehabilitation training, so as to help them restore independent walking abilities and reduce the economic burdens on society.","3":"Computational intelligence and neuroscience","4":"30416520","5":"2018","6":"Cerebral Cortex"},{"1":"Pilot Study on Gait Classification Using fNIRS Signals.","2":"Rehabilitation training is essential for motor dysfunction patients, and the training through their subjective motion intention, comparing to passive training, is more conducive to rehabilitation. This study proposes a method to identify motion intention of different walking states under the normal environment, by using the functional near-infrared spectroscopy (fNIRS) technology. Twenty-two healthy subjects were recruited to walk with three different gaits (including small-step with low-speed, small-step with midspeed, midstep with low-speed). The wavelet packet decomposition was used to find out the main characteristic channels in different motion states, and these channels with links in frequency and space were combined to define as feature vectors. According to different permutations and combinations of all feature vectors, a library for support vector machines (libSVM) was used to achieve the best recognition model. Finally, the accuracy rate of these three walking states was 78.79%. This study implemented the classification of different states' motion intention by using the fNIRS technology. It laid a foundation to apply the classified motion intention of different states timely, to help severe motor dysfunction patients control a walking-assistive device for rehabilitation training, so as to help them restore independent walking abilities and reduce the economic burdens on society.","3":"Computational intelligence and neuroscience","4":"30416520","5":"2018","6":"diagnostic imaging"},{"1":"Pilot Study on Gait Classification Using fNIRS Signals.","2":"Rehabilitation training is essential for motor dysfunction patients, and the training through their subjective motion intention, comparing to passive training, is more conducive to rehabilitation. This study proposes a method to identify motion intention of different walking states under the normal environment, by using the functional near-infrared spectroscopy (fNIRS) technology. Twenty-two healthy subjects were recruited to walk with three different gaits (including small-step with low-speed, small-step with midspeed, midstep with low-speed). The wavelet packet decomposition was used to find out the main characteristic channels in different motion states, and these channels with links in frequency and space were combined to define as feature vectors. According to different permutations and combinations of all feature vectors, a library for support vector machines (libSVM) was used to achieve the best recognition model. Finally, the accuracy rate of these three walking states was 78.79%. This study implemented the classification of different states' motion intention by using the fNIRS technology. It laid a foundation to apply the classified motion intention of different states timely, to help severe motor dysfunction patients control a walking-assistive device for rehabilitation training, so as to help them restore independent walking abilities and reduce the economic burdens on society.","3":"Computational intelligence and neuroscience","4":"30416520","5":"2018","6":"metabolism"},{"1":"Pilot Study on Gait Classification Using fNIRS Signals.","2":"Rehabilitation training is essential for motor dysfunction patients, and the training through their subjective motion intention, comparing to passive training, is more conducive to rehabilitation. This study proposes a method to identify motion intention of different walking states under the normal environment, by using the functional near-infrared spectroscopy (fNIRS) technology. Twenty-two healthy subjects were recruited to walk with three different gaits (including small-step with low-speed, small-step with midspeed, midstep with low-speed). The wavelet packet decomposition was used to find out the main characteristic channels in different motion states, and these channels with links in frequency and space were combined to define as feature vectors. According to different permutations and combinations of all feature vectors, a library for support vector machines (libSVM) was used to achieve the best recognition model. Finally, the accuracy rate of these three walking states was 78.79%. This study implemented the classification of different states' motion intention by using the fNIRS technology. It laid a foundation to apply the classified motion intention of different states timely, to help severe motor dysfunction patients control a walking-assistive device for rehabilitation training, so as to help them restore independent walking abilities and reduce the economic burdens on society.","3":"Computational intelligence and neuroscience","4":"30416520","5":"2018","6":"Female"},{"1":"Pilot Study on Gait Classification Using fNIRS Signals.","2":"Rehabilitation training is essential for motor dysfunction patients, and the training through their subjective motion intention, comparing to passive training, is more conducive to rehabilitation. This study proposes a method to identify motion intention of different walking states under the normal environment, by using the functional near-infrared spectroscopy (fNIRS) technology. Twenty-two healthy subjects were recruited to walk with three different gaits (including small-step with low-speed, small-step with midspeed, midstep with low-speed). The wavelet packet decomposition was used to find out the main characteristic channels in different motion states, and these channels with links in frequency and space were combined to define as feature vectors. According to different permutations and combinations of all feature vectors, a library for support vector machines (libSVM) was used to achieve the best recognition model. Finally, the accuracy rate of these three walking states was 78.79%. This study implemented the classification of different states' motion intention by using the fNIRS technology. It laid a foundation to apply the classified motion intention of different states timely, to help severe motor dysfunction patients control a walking-assistive device for rehabilitation training, so as to help them restore independent walking abilities and reduce the economic burdens on society.","3":"Computational intelligence and neuroscience","4":"30416520","5":"2018","6":"Gait Analysis"},{"1":"Pilot Study on Gait Classification Using fNIRS Signals.","2":"Rehabilitation training is essential for motor dysfunction patients, and the training through their subjective motion intention, comparing to passive training, is more conducive to rehabilitation. This study proposes a method to identify motion intention of different walking states under the normal environment, by using the functional near-infrared spectroscopy (fNIRS) technology. Twenty-two healthy subjects were recruited to walk with three different gaits (including small-step with low-speed, small-step with midspeed, midstep with low-speed). The wavelet packet decomposition was used to find out the main characteristic channels in different motion states, and these channels with links in frequency and space were combined to define as feature vectors. According to different permutations and combinations of all feature vectors, a library for support vector machines (libSVM) was used to achieve the best recognition model. Finally, the accuracy rate of these three walking states was 78.79%. This study implemented the classification of different states' motion intention by using the fNIRS technology. It laid a foundation to apply the classified motion intention of different states timely, to help severe motor dysfunction patients control a walking-assistive device for rehabilitation training, so as to help them restore independent walking abilities and reduce the economic burdens on society.","3":"Computational intelligence and neuroscience","4":"30416520","5":"2018","6":"methods"},{"1":"Pilot Study on Gait Classification Using fNIRS Signals.","2":"Rehabilitation training is essential for motor dysfunction patients, and the training through their subjective motion intention, comparing to passive training, is more conducive to rehabilitation. This study proposes a method to identify motion intention of different walking states under the normal environment, by using the functional near-infrared spectroscopy (fNIRS) technology. Twenty-two healthy subjects were recruited to walk with three different gaits (including small-step with low-speed, small-step with midspeed, midstep with low-speed). The wavelet packet decomposition was used to find out the main characteristic channels in different motion states, and these channels with links in frequency and space were combined to define as feature vectors. According to different permutations and combinations of all feature vectors, a library for support vector machines (libSVM) was used to achieve the best recognition model. Finally, the accuracy rate of these three walking states was 78.79%. This study implemented the classification of different states' motion intention by using the fNIRS technology. It laid a foundation to apply the classified motion intention of different states timely, to help severe motor dysfunction patients control a walking-assistive device for rehabilitation training, so as to help them restore independent walking abilities and reduce the economic burdens on society.","3":"Computational intelligence and neuroscience","4":"30416520","5":"2018","6":"Humans"},{"1":"Pilot Study on Gait Classification Using fNIRS Signals.","2":"Rehabilitation training is essential for motor dysfunction patients, and the training through their subjective motion intention, comparing to passive training, is more conducive to rehabilitation. This study proposes a method to identify motion intention of different walking states under the normal environment, by using the functional near-infrared spectroscopy (fNIRS) technology. Twenty-two healthy subjects were recruited to walk with three different gaits (including small-step with low-speed, small-step with midspeed, midstep with low-speed). The wavelet packet decomposition was used to find out the main characteristic channels in different motion states, and these channels with links in frequency and space were combined to define as feature vectors. According to different permutations and combinations of all feature vectors, a library for support vector machines (libSVM) was used to achieve the best recognition model. Finally, the accuracy rate of these three walking states was 78.79%. This study implemented the classification of different states' motion intention by using the fNIRS technology. It laid a foundation to apply the classified motion intention of different states timely, to help severe motor dysfunction patients control a walking-assistive device for rehabilitation training, so as to help them restore independent walking abilities and reduce the economic burdens on society.","3":"Computational intelligence and neuroscience","4":"30416520","5":"2018","6":"Intention"},{"1":"Pilot Study on Gait Classification Using fNIRS Signals.","2":"Rehabilitation training is essential for motor dysfunction patients, and the training through their subjective motion intention, comparing to passive training, is more conducive to rehabilitation. This study proposes a method to identify motion intention of different walking states under the normal environment, by using the functional near-infrared spectroscopy (fNIRS) technology. Twenty-two healthy subjects were recruited to walk with three different gaits (including small-step with low-speed, small-step with midspeed, midstep with low-speed). The wavelet packet decomposition was used to find out the main characteristic channels in different motion states, and these channels with links in frequency and space were combined to define as feature vectors. According to different permutations and combinations of all feature vectors, a library for support vector machines (libSVM) was used to achieve the best recognition model. Finally, the accuracy rate of these three walking states was 78.79%. This study implemented the classification of different states' motion intention by using the fNIRS technology. It laid a foundation to apply the classified motion intention of different states timely, to help severe motor dysfunction patients control a walking-assistive device for rehabilitation training, so as to help them restore independent walking abilities and reduce the economic burdens on society.","3":"Computational intelligence and neuroscience","4":"30416520","5":"2018","6":"Male"},{"1":"Pilot Study on Gait Classification Using fNIRS Signals.","2":"Rehabilitation training is essential for motor dysfunction patients, and the training through their subjective motion intention, comparing to passive training, is more conducive to rehabilitation. This study proposes a method to identify motion intention of different walking states under the normal environment, by using the functional near-infrared spectroscopy (fNIRS) technology. Twenty-two healthy subjects were recruited to walk with three different gaits (including small-step with low-speed, small-step with midspeed, midstep with low-speed). The wavelet packet decomposition was used to find out the main characteristic channels in different motion states, and these channels with links in frequency and space were combined to define as feature vectors. According to different permutations and combinations of all feature vectors, a library for support vector machines (libSVM) was used to achieve the best recognition model. Finally, the accuracy rate of these three walking states was 78.79%. This study implemented the classification of different states' motion intention by using the fNIRS technology. It laid a foundation to apply the classified motion intention of different states timely, to help severe motor dysfunction patients control a walking-assistive device for rehabilitation training, so as to help them restore independent walking abilities and reduce the economic burdens on society.","3":"Computational intelligence and neuroscience","4":"30416520","5":"2018","6":"Pattern Recognition, Automated"},{"1":"Pilot Study on Gait Classification Using fNIRS Signals.","2":"Rehabilitation training is essential for motor dysfunction patients, and the training through their subjective motion intention, comparing to passive training, is more conducive to rehabilitation. This study proposes a method to identify motion intention of different walking states under the normal environment, by using the functional near-infrared spectroscopy (fNIRS) technology. Twenty-two healthy subjects were recruited to walk with three different gaits (including small-step with low-speed, small-step with midspeed, midstep with low-speed). The wavelet packet decomposition was used to find out the main characteristic channels in different motion states, and these channels with links in frequency and space were combined to define as feature vectors. According to different permutations and combinations of all feature vectors, a library for support vector machines (libSVM) was used to achieve the best recognition model. Finally, the accuracy rate of these three walking states was 78.79%. This study implemented the classification of different states' motion intention by using the fNIRS technology. It laid a foundation to apply the classified motion intention of different states timely, to help severe motor dysfunction patients control a walking-assistive device for rehabilitation training, so as to help them restore independent walking abilities and reduce the economic burdens on society.","3":"Computational intelligence and neuroscience","4":"30416520","5":"2018","6":"methods"},{"1":"Pilot Study on Gait Classification Using fNIRS Signals.","2":"Rehabilitation training is essential for motor dysfunction patients, and the training through their subjective motion intention, comparing to passive training, is more conducive to rehabilitation. This study proposes a method to identify motion intention of different walking states under the normal environment, by using the functional near-infrared spectroscopy (fNIRS) technology. Twenty-two healthy subjects were recruited to walk with three different gaits (including small-step with low-speed, small-step with midspeed, midstep with low-speed). The wavelet packet decomposition was used to find out the main characteristic channels in different motion states, and these channels with links in frequency and space were combined to define as feature vectors. According to different permutations and combinations of all feature vectors, a library for support vector machines (libSVM) was used to achieve the best recognition model. Finally, the accuracy rate of these three walking states was 78.79%. This study implemented the classification of different states' motion intention by using the fNIRS technology. It laid a foundation to apply the classified motion intention of different states timely, to help severe motor dysfunction patients control a walking-assistive device for rehabilitation training, so as to help them restore independent walking abilities and reduce the economic burdens on society.","3":"Computational intelligence and neuroscience","4":"30416520","5":"2018","6":"Pilot Projects"},{"1":"Pilot Study on Gait Classification Using fNIRS Signals.","2":"Rehabilitation training is essential for motor dysfunction patients, and the training through their subjective motion intention, comparing to passive training, is more conducive to rehabilitation. This study proposes a method to identify motion intention of different walking states under the normal environment, by using the functional near-infrared spectroscopy (fNIRS) technology. Twenty-two healthy subjects were recruited to walk with three different gaits (including small-step with low-speed, small-step with midspeed, midstep with low-speed). The wavelet packet decomposition was used to find out the main characteristic channels in different motion states, and these channels with links in frequency and space were combined to define as feature vectors. According to different permutations and combinations of all feature vectors, a library for support vector machines (libSVM) was used to achieve the best recognition model. Finally, the accuracy rate of these three walking states was 78.79%. This study implemented the classification of different states' motion intention by using the fNIRS technology. It laid a foundation to apply the classified motion intention of different states timely, to help severe motor dysfunction patients control a walking-assistive device for rehabilitation training, so as to help them restore independent walking abilities and reduce the economic burdens on society.","3":"Computational intelligence and neuroscience","4":"30416520","5":"2018","6":"Spectroscopy, Near-Infrared"},{"1":"Pilot Study on Gait Classification Using fNIRS Signals.","2":"Rehabilitation training is essential for motor dysfunction patients, and the training through their subjective motion intention, comparing to passive training, is more conducive to rehabilitation. This study proposes a method to identify motion intention of different walking states under the normal environment, by using the functional near-infrared spectroscopy (fNIRS) technology. Twenty-two healthy subjects were recruited to walk with three different gaits (including small-step with low-speed, small-step with midspeed, midstep with low-speed). The wavelet packet decomposition was used to find out the main characteristic channels in different motion states, and these channels with links in frequency and space were combined to define as feature vectors. According to different permutations and combinations of all feature vectors, a library for support vector machines (libSVM) was used to achieve the best recognition model. Finally, the accuracy rate of these three walking states was 78.79%. This study implemented the classification of different states' motion intention by using the fNIRS technology. It laid a foundation to apply the classified motion intention of different states timely, to help severe motor dysfunction patients control a walking-assistive device for rehabilitation training, so as to help them restore independent walking abilities and reduce the economic burdens on society.","3":"Computational intelligence and neuroscience","4":"30416520","5":"2018","6":"methods"},{"1":"Pilot Study on Gait Classification Using fNIRS Signals.","2":"Rehabilitation training is essential for motor dysfunction patients, and the training through their subjective motion intention, comparing to passive training, is more conducive to rehabilitation. This study proposes a method to identify motion intention of different walking states under the normal environment, by using the functional near-infrared spectroscopy (fNIRS) technology. Twenty-two healthy subjects were recruited to walk with three different gaits (including small-step with low-speed, small-step with midspeed, midstep with low-speed). The wavelet packet decomposition was used to find out the main characteristic channels in different motion states, and these channels with links in frequency and space were combined to define as feature vectors. According to different permutations and combinations of all feature vectors, a library for support vector machines (libSVM) was used to achieve the best recognition model. Finally, the accuracy rate of these three walking states was 78.79%. This study implemented the classification of different states' motion intention by using the fNIRS technology. It laid a foundation to apply the classified motion intention of different states timely, to help severe motor dysfunction patients control a walking-assistive device for rehabilitation training, so as to help them restore independent walking abilities and reduce the economic burdens on society.","3":"Computational intelligence and neuroscience","4":"30416520","5":"2018","6":"Support Vector Machine"},{"1":"Pilot Study on Gait Classification Using fNIRS Signals.","2":"Rehabilitation training is essential for motor dysfunction patients, and the training through their subjective motion intention, comparing to passive training, is more conducive to rehabilitation. This study proposes a method to identify motion intention of different walking states under the normal environment, by using the functional near-infrared spectroscopy (fNIRS) technology. Twenty-two healthy subjects were recruited to walk with three different gaits (including small-step with low-speed, small-step with midspeed, midstep with low-speed). The wavelet packet decomposition was used to find out the main characteristic channels in different motion states, and these channels with links in frequency and space were combined to define as feature vectors. According to different permutations and combinations of all feature vectors, a library for support vector machines (libSVM) was used to achieve the best recognition model. Finally, the accuracy rate of these three walking states was 78.79%. This study implemented the classification of different states' motion intention by using the fNIRS technology. It laid a foundation to apply the classified motion intention of different states timely, to help severe motor dysfunction patients control a walking-assistive device for rehabilitation training, so as to help them restore independent walking abilities and reduce the economic burdens on society.","3":"Computational intelligence and neuroscience","4":"30416520","5":"2018","6":"Wavelet Analysis"},{"1":"Pilot Study on Gait Classification Using fNIRS Signals.","2":"Rehabilitation training is essential for motor dysfunction patients, and the training through their subjective motion intention, comparing to passive training, is more conducive to rehabilitation. This study proposes a method to identify motion intention of different walking states under the normal environment, by using the functional near-infrared spectroscopy (fNIRS) technology. Twenty-two healthy subjects were recruited to walk with three different gaits (including small-step with low-speed, small-step with midspeed, midstep with low-speed). The wavelet packet decomposition was used to find out the main characteristic channels in different motion states, and these channels with links in frequency and space were combined to define as feature vectors. According to different permutations and combinations of all feature vectors, a library for support vector machines (libSVM) was used to achieve the best recognition model. Finally, the accuracy rate of these three walking states was 78.79%. This study implemented the classification of different states' motion intention by using the fNIRS technology. It laid a foundation to apply the classified motion intention of different states timely, to help severe motor dysfunction patients control a walking-assistive device for rehabilitation training, so as to help them restore independent walking abilities and reduce the economic burdens on society.","3":"Computational intelligence and neuroscience","4":"30416520","5":"2018","6":"Young Adult"},{"1":"Information-Based Boundary Equilibrium Generative Adversarial Networks with Interpretable Representation Learning.","2":"This paper describes a new image generation algorithm based on generative adversarial network. With an information-theoretic extension to the autoencoder-based discriminator, this new algorithm is able to learn interpretable representations from the input images. Our model not only adversarially minimizes the Wasserstein distance-based losses of the discriminator and generator but also maximizes the mutual information between small subset of the latent variables and the observation. We also train our model with proportional control theory to keep the equilibrium between the discriminator and the generator balanced, and as a result, our generative adversarial network can mitigate the convergence problem. Through the experiments on real images, we validate our proposed method, which can manipulate the generated images as desired by controlling the latent codes of input variables. In addition, the visual qualities of produced images are effectively maintained, and the model can stably converge to the equilibrium. However, our model has a difficulty in learning disentangling factors because our model does not regularize the independence between the interpretable factors. Therefore, in the future, we will develop a generative model that can learn disentangling factors.","3":"Computational intelligence and neuroscience","4":"30416519","5":"2018","6":"Face"},{"1":"Information-Based Boundary Equilibrium Generative Adversarial Networks with Interpretable Representation Learning.","2":"This paper describes a new image generation algorithm based on generative adversarial network. With an information-theoretic extension to the autoencoder-based discriminator, this new algorithm is able to learn interpretable representations from the input images. Our model not only adversarially minimizes the Wasserstein distance-based losses of the discriminator and generator but also maximizes the mutual information between small subset of the latent variables and the observation. We also train our model with proportional control theory to keep the equilibrium between the discriminator and the generator balanced, and as a result, our generative adversarial network can mitigate the convergence problem. Through the experiments on real images, we validate our proposed method, which can manipulate the generated images as desired by controlling the latent codes of input variables. In addition, the visual qualities of produced images are effectively maintained, and the model can stably converge to the equilibrium. However, our model has a difficulty in learning disentangling factors because our model does not regularize the independence between the interpretable factors. Therefore, in the future, we will develop a generative model that can learn disentangling factors.","3":"Computational intelligence and neuroscience","4":"30416519","5":"2018","6":"Housing"},{"1":"Information-Based Boundary Equilibrium Generative Adversarial Networks with Interpretable Representation Learning.","2":"This paper describes a new image generation algorithm based on generative adversarial network. With an information-theoretic extension to the autoencoder-based discriminator, this new algorithm is able to learn interpretable representations from the input images. Our model not only adversarially minimizes the Wasserstein distance-based losses of the discriminator and generator but also maximizes the mutual information between small subset of the latent variables and the observation. We also train our model with proportional control theory to keep the equilibrium between the discriminator and the generator balanced, and as a result, our generative adversarial network can mitigate the convergence problem. Through the experiments on real images, we validate our proposed method, which can manipulate the generated images as desired by controlling the latent codes of input variables. In addition, the visual qualities of produced images are effectively maintained, and the model can stably converge to the equilibrium. However, our model has a difficulty in learning disentangling factors because our model does not regularize the independence between the interpretable factors. Therefore, in the future, we will develop a generative model that can learn disentangling factors.","3":"Computational intelligence and neuroscience","4":"30416519","5":"2018","6":"Humans"},{"1":"Information-Based Boundary Equilibrium Generative Adversarial Networks with Interpretable Representation Learning.","2":"This paper describes a new image generation algorithm based on generative adversarial network. With an information-theoretic extension to the autoencoder-based discriminator, this new algorithm is able to learn interpretable representations from the input images. Our model not only adversarially minimizes the Wasserstein distance-based losses of the discriminator and generator but also maximizes the mutual information between small subset of the latent variables and the observation. We also train our model with proportional control theory to keep the equilibrium between the discriminator and the generator balanced, and as a result, our generative adversarial network can mitigate the convergence problem. Through the experiments on real images, we validate our proposed method, which can manipulate the generated images as desired by controlling the latent codes of input variables. In addition, the visual qualities of produced images are effectively maintained, and the model can stably converge to the equilibrium. However, our model has a difficulty in learning disentangling factors because our model does not regularize the independence between the interpretable factors. Therefore, in the future, we will develop a generative model that can learn disentangling factors.","3":"Computational intelligence and neuroscience","4":"30416519","5":"2018","6":"Image Processing, Computer-Assisted"},{"1":"Information-Based Boundary Equilibrium Generative Adversarial Networks with Interpretable Representation Learning.","2":"This paper describes a new image generation algorithm based on generative adversarial network. With an information-theoretic extension to the autoencoder-based discriminator, this new algorithm is able to learn interpretable representations from the input images. Our model not only adversarially minimizes the Wasserstein distance-based losses of the discriminator and generator but also maximizes the mutual information between small subset of the latent variables and the observation. We also train our model with proportional control theory to keep the equilibrium between the discriminator and the generator balanced, and as a result, our generative adversarial network can mitigate the convergence problem. Through the experiments on real images, we validate our proposed method, which can manipulate the generated images as desired by controlling the latent codes of input variables. In addition, the visual qualities of produced images are effectively maintained, and the model can stably converge to the equilibrium. However, our model has a difficulty in learning disentangling factors because our model does not regularize the independence between the interpretable factors. Therefore, in the future, we will develop a generative model that can learn disentangling factors.","3":"Computational intelligence and neuroscience","4":"30416519","5":"2018","6":"methods"},{"1":"Information-Based Boundary Equilibrium Generative Adversarial Networks with Interpretable Representation Learning.","2":"This paper describes a new image generation algorithm based on generative adversarial network. With an information-theoretic extension to the autoencoder-based discriminator, this new algorithm is able to learn interpretable representations from the input images. Our model not only adversarially minimizes the Wasserstein distance-based losses of the discriminator and generator but also maximizes the mutual information between small subset of the latent variables and the observation. We also train our model with proportional control theory to keep the equilibrium between the discriminator and the generator balanced, and as a result, our generative adversarial network can mitigate the convergence problem. Through the experiments on real images, we validate our proposed method, which can manipulate the generated images as desired by controlling the latent codes of input variables. In addition, the visual qualities of produced images are effectively maintained, and the model can stably converge to the equilibrium. However, our model has a difficulty in learning disentangling factors because our model does not regularize the independence between the interpretable factors. Therefore, in the future, we will develop a generative model that can learn disentangling factors.","3":"Computational intelligence and neuroscience","4":"30416519","5":"2018","6":"Information Theory"},{"1":"Information-Based Boundary Equilibrium Generative Adversarial Networks with Interpretable Representation Learning.","2":"This paper describes a new image generation algorithm based on generative adversarial network. With an information-theoretic extension to the autoencoder-based discriminator, this new algorithm is able to learn interpretable representations from the input images. Our model not only adversarially minimizes the Wasserstein distance-based losses of the discriminator and generator but also maximizes the mutual information between small subset of the latent variables and the observation. We also train our model with proportional control theory to keep the equilibrium between the discriminator and the generator balanced, and as a result, our generative adversarial network can mitigate the convergence problem. Through the experiments on real images, we validate our proposed method, which can manipulate the generated images as desired by controlling the latent codes of input variables. In addition, the visual qualities of produced images are effectively maintained, and the model can stably converge to the equilibrium. However, our model has a difficulty in learning disentangling factors because our model does not regularize the independence between the interpretable factors. Therefore, in the future, we will develop a generative model that can learn disentangling factors.","3":"Computational intelligence and neuroscience","4":"30416519","5":"2018","6":"Machine Learning"},{"1":"Performance assessment of artificial neural networks and support vector regression models for stream flow predictions.","2":"Water resources planning, development, and management need reliable forecasts of river flows. In past few decades, an important dimension has been introduced in the prediction of the hydrologic phenomenon through artificial intelligence-based modeling. In this paper, the performance of three artificial neural network (ANN) and four support vector regression (SVR) models was investigated to predict streamflows in the Upper Indus River. Results from ANN models using three different optimization techniques, namely Broyden-Fletcher-Goldfarb-Shannon, Conjugate Gradient, and Back Propagation algorithms, were compared with one another. A further comparison was made between these ANNs and four types of SVR models which were based on linear, polynomial, radial basis function, and sigmoid kernels. Past 30 years' monthly data for precipitation, temperature, and streamflow obtained from Pakistan Surface Water Hydrology Department Lahore were used for this purpose. Three types of input combinations with respect to the main input variables (temperature, precipitation, and stream flow) and several types of input combinations with respect to time lag were tested. The best input for ANN and SVR models was identified using correlation coefficient analysis and genetic algorithm. The performance of the ANN and SVR models was evaluated by mean bias error, Nash-Sutcliffe efficiency, root mean square error, and correlation coefficient. The efficiency of the Broyden-Fletcher-Goldfarb-Shannon-ANN model was found to be much better than that of other models, while the SVR model based on radial basis function kernel predicted stream flows with comparatively higher accuracy than the other kernels. Finally, long-term predictions of streamflow have been made by the best ANN model. It was found that stream flow of Upper Indus River has a decreasing trend.","3":"Environmental monitoring and assessment","4":"30406854","5":"2018","6":"Algorithms"},{"1":"Performance assessment of artificial neural networks and support vector regression models for stream flow predictions.","2":"Water resources planning, development, and management need reliable forecasts of river flows. In past few decades, an important dimension has been introduced in the prediction of the hydrologic phenomenon through artificial intelligence-based modeling. In this paper, the performance of three artificial neural network (ANN) and four support vector regression (SVR) models was investigated to predict streamflows in the Upper Indus River. Results from ANN models using three different optimization techniques, namely Broyden-Fletcher-Goldfarb-Shannon, Conjugate Gradient, and Back Propagation algorithms, were compared with one another. A further comparison was made between these ANNs and four types of SVR models which were based on linear, polynomial, radial basis function, and sigmoid kernels. Past 30 years' monthly data for precipitation, temperature, and streamflow obtained from Pakistan Surface Water Hydrology Department Lahore were used for this purpose. Three types of input combinations with respect to the main input variables (temperature, precipitation, and stream flow) and several types of input combinations with respect to time lag were tested. The best input for ANN and SVR models was identified using correlation coefficient analysis and genetic algorithm. The performance of the ANN and SVR models was evaluated by mean bias error, Nash-Sutcliffe efficiency, root mean square error, and correlation coefficient. The efficiency of the Broyden-Fletcher-Goldfarb-Shannon-ANN model was found to be much better than that of other models, while the SVR model based on radial basis function kernel predicted stream flows with comparatively higher accuracy than the other kernels. Finally, long-term predictions of streamflow have been made by the best ANN model. It was found that stream flow of Upper Indus River has a decreasing trend.","3":"Environmental monitoring and assessment","4":"30406854","5":"2018","6":"Artificial Intelligence"},{"1":"Performance assessment of artificial neural networks and support vector regression models for stream flow predictions.","2":"Water resources planning, development, and management need reliable forecasts of river flows. In past few decades, an important dimension has been introduced in the prediction of the hydrologic phenomenon through artificial intelligence-based modeling. In this paper, the performance of three artificial neural network (ANN) and four support vector regression (SVR) models was investigated to predict streamflows in the Upper Indus River. Results from ANN models using three different optimization techniques, namely Broyden-Fletcher-Goldfarb-Shannon, Conjugate Gradient, and Back Propagation algorithms, were compared with one another. A further comparison was made between these ANNs and four types of SVR models which were based on linear, polynomial, radial basis function, and sigmoid kernels. Past 30 years' monthly data for precipitation, temperature, and streamflow obtained from Pakistan Surface Water Hydrology Department Lahore were used for this purpose. Three types of input combinations with respect to the main input variables (temperature, precipitation, and stream flow) and several types of input combinations with respect to time lag were tested. The best input for ANN and SVR models was identified using correlation coefficient analysis and genetic algorithm. The performance of the ANN and SVR models was evaluated by mean bias error, Nash-Sutcliffe efficiency, root mean square error, and correlation coefficient. The efficiency of the Broyden-Fletcher-Goldfarb-Shannon-ANN model was found to be much better than that of other models, while the SVR model based on radial basis function kernel predicted stream flows with comparatively higher accuracy than the other kernels. Finally, long-term predictions of streamflow have been made by the best ANN model. It was found that stream flow of Upper Indus River has a decreasing trend.","3":"Environmental monitoring and assessment","4":"30406854","5":"2018","6":"Environmental Monitoring"},{"1":"Performance assessment of artificial neural networks and support vector regression models for stream flow predictions.","2":"Water resources planning, development, and management need reliable forecasts of river flows. In past few decades, an important dimension has been introduced in the prediction of the hydrologic phenomenon through artificial intelligence-based modeling. In this paper, the performance of three artificial neural network (ANN) and four support vector regression (SVR) models was investigated to predict streamflows in the Upper Indus River. Results from ANN models using three different optimization techniques, namely Broyden-Fletcher-Goldfarb-Shannon, Conjugate Gradient, and Back Propagation algorithms, were compared with one another. A further comparison was made between these ANNs and four types of SVR models which were based on linear, polynomial, radial basis function, and sigmoid kernels. Past 30 years' monthly data for precipitation, temperature, and streamflow obtained from Pakistan Surface Water Hydrology Department Lahore were used for this purpose. Three types of input combinations with respect to the main input variables (temperature, precipitation, and stream flow) and several types of input combinations with respect to time lag were tested. The best input for ANN and SVR models was identified using correlation coefficient analysis and genetic algorithm. The performance of the ANN and SVR models was evaluated by mean bias error, Nash-Sutcliffe efficiency, root mean square error, and correlation coefficient. The efficiency of the Broyden-Fletcher-Goldfarb-Shannon-ANN model was found to be much better than that of other models, while the SVR model based on radial basis function kernel predicted stream flows with comparatively higher accuracy than the other kernels. Finally, long-term predictions of streamflow have been made by the best ANN model. It was found that stream flow of Upper Indus River has a decreasing trend.","3":"Environmental monitoring and assessment","4":"30406854","5":"2018","6":"methods"},{"1":"Performance assessment of artificial neural networks and support vector regression models for stream flow predictions.","2":"Water resources planning, development, and management need reliable forecasts of river flows. In past few decades, an important dimension has been introduced in the prediction of the hydrologic phenomenon through artificial intelligence-based modeling. In this paper, the performance of three artificial neural network (ANN) and four support vector regression (SVR) models was investigated to predict streamflows in the Upper Indus River. Results from ANN models using three different optimization techniques, namely Broyden-Fletcher-Goldfarb-Shannon, Conjugate Gradient, and Back Propagation algorithms, were compared with one another. A further comparison was made between these ANNs and four types of SVR models which were based on linear, polynomial, radial basis function, and sigmoid kernels. Past 30 years' monthly data for precipitation, temperature, and streamflow obtained from Pakistan Surface Water Hydrology Department Lahore were used for this purpose. Three types of input combinations with respect to the main input variables (temperature, precipitation, and stream flow) and several types of input combinations with respect to time lag were tested. The best input for ANN and SVR models was identified using correlation coefficient analysis and genetic algorithm. The performance of the ANN and SVR models was evaluated by mean bias error, Nash-Sutcliffe efficiency, root mean square error, and correlation coefficient. The efficiency of the Broyden-Fletcher-Goldfarb-Shannon-ANN model was found to be much better than that of other models, while the SVR model based on radial basis function kernel predicted stream flows with comparatively higher accuracy than the other kernels. Finally, long-term predictions of streamflow have been made by the best ANN model. It was found that stream flow of Upper Indus River has a decreasing trend.","3":"Environmental monitoring and assessment","4":"30406854","5":"2018","6":"Hydrology"},{"1":"Performance assessment of artificial neural networks and support vector regression models for stream flow predictions.","2":"Water resources planning, development, and management need reliable forecasts of river flows. In past few decades, an important dimension has been introduced in the prediction of the hydrologic phenomenon through artificial intelligence-based modeling. In this paper, the performance of three artificial neural network (ANN) and four support vector regression (SVR) models was investigated to predict streamflows in the Upper Indus River. Results from ANN models using three different optimization techniques, namely Broyden-Fletcher-Goldfarb-Shannon, Conjugate Gradient, and Back Propagation algorithms, were compared with one another. A further comparison was made between these ANNs and four types of SVR models which were based on linear, polynomial, radial basis function, and sigmoid kernels. Past 30 years' monthly data for precipitation, temperature, and streamflow obtained from Pakistan Surface Water Hydrology Department Lahore were used for this purpose. Three types of input combinations with respect to the main input variables (temperature, precipitation, and stream flow) and several types of input combinations with respect to time lag were tested. The best input for ANN and SVR models was identified using correlation coefficient analysis and genetic algorithm. The performance of the ANN and SVR models was evaluated by mean bias error, Nash-Sutcliffe efficiency, root mean square error, and correlation coefficient. The efficiency of the Broyden-Fletcher-Goldfarb-Shannon-ANN model was found to be much better than that of other models, while the SVR model based on radial basis function kernel predicted stream flows with comparatively higher accuracy than the other kernels. Finally, long-term predictions of streamflow have been made by the best ANN model. It was found that stream flow of Upper Indus River has a decreasing trend.","3":"Environmental monitoring and assessment","4":"30406854","5":"2018","6":"methods"},{"1":"Performance assessment of artificial neural networks and support vector regression models for stream flow predictions.","2":"Water resources planning, development, and management need reliable forecasts of river flows. In past few decades, an important dimension has been introduced in the prediction of the hydrologic phenomenon through artificial intelligence-based modeling. In this paper, the performance of three artificial neural network (ANN) and four support vector regression (SVR) models was investigated to predict streamflows in the Upper Indus River. Results from ANN models using three different optimization techniques, namely Broyden-Fletcher-Goldfarb-Shannon, Conjugate Gradient, and Back Propagation algorithms, were compared with one another. A further comparison was made between these ANNs and four types of SVR models which were based on linear, polynomial, radial basis function, and sigmoid kernels. Past 30 years' monthly data for precipitation, temperature, and streamflow obtained from Pakistan Surface Water Hydrology Department Lahore were used for this purpose. Three types of input combinations with respect to the main input variables (temperature, precipitation, and stream flow) and several types of input combinations with respect to time lag were tested. The best input for ANN and SVR models was identified using correlation coefficient analysis and genetic algorithm. The performance of the ANN and SVR models was evaluated by mean bias error, Nash-Sutcliffe efficiency, root mean square error, and correlation coefficient. The efficiency of the Broyden-Fletcher-Goldfarb-Shannon-ANN model was found to be much better than that of other models, while the SVR model based on radial basis function kernel predicted stream flows with comparatively higher accuracy than the other kernels. Finally, long-term predictions of streamflow have been made by the best ANN model. It was found that stream flow of Upper Indus River has a decreasing trend.","3":"Environmental monitoring and assessment","4":"30406854","5":"2018","6":"Neural Networks (Computer)"},{"1":"Performance assessment of artificial neural networks and support vector regression models for stream flow predictions.","2":"Water resources planning, development, and management need reliable forecasts of river flows. In past few decades, an important dimension has been introduced in the prediction of the hydrologic phenomenon through artificial intelligence-based modeling. In this paper, the performance of three artificial neural network (ANN) and four support vector regression (SVR) models was investigated to predict streamflows in the Upper Indus River. Results from ANN models using three different optimization techniques, namely Broyden-Fletcher-Goldfarb-Shannon, Conjugate Gradient, and Back Propagation algorithms, were compared with one another. A further comparison was made between these ANNs and four types of SVR models which were based on linear, polynomial, radial basis function, and sigmoid kernels. Past 30 years' monthly data for precipitation, temperature, and streamflow obtained from Pakistan Surface Water Hydrology Department Lahore were used for this purpose. Three types of input combinations with respect to the main input variables (temperature, precipitation, and stream flow) and several types of input combinations with respect to time lag were tested. The best input for ANN and SVR models was identified using correlation coefficient analysis and genetic algorithm. The performance of the ANN and SVR models was evaluated by mean bias error, Nash-Sutcliffe efficiency, root mean square error, and correlation coefficient. The efficiency of the Broyden-Fletcher-Goldfarb-Shannon-ANN model was found to be much better than that of other models, while the SVR model based on radial basis function kernel predicted stream flows with comparatively higher accuracy than the other kernels. Finally, long-term predictions of streamflow have been made by the best ANN model. It was found that stream flow of Upper Indus River has a decreasing trend.","3":"Environmental monitoring and assessment","4":"30406854","5":"2018","6":"Pakistan"},{"1":"Performance assessment of artificial neural networks and support vector regression models for stream flow predictions.","2":"Water resources planning, development, and management need reliable forecasts of river flows. In past few decades, an important dimension has been introduced in the prediction of the hydrologic phenomenon through artificial intelligence-based modeling. In this paper, the performance of three artificial neural network (ANN) and four support vector regression (SVR) models was investigated to predict streamflows in the Upper Indus River. Results from ANN models using three different optimization techniques, namely Broyden-Fletcher-Goldfarb-Shannon, Conjugate Gradient, and Back Propagation algorithms, were compared with one another. A further comparison was made between these ANNs and four types of SVR models which were based on linear, polynomial, radial basis function, and sigmoid kernels. Past 30 years' monthly data for precipitation, temperature, and streamflow obtained from Pakistan Surface Water Hydrology Department Lahore were used for this purpose. Three types of input combinations with respect to the main input variables (temperature, precipitation, and stream flow) and several types of input combinations with respect to time lag were tested. The best input for ANN and SVR models was identified using correlation coefficient analysis and genetic algorithm. The performance of the ANN and SVR models was evaluated by mean bias error, Nash-Sutcliffe efficiency, root mean square error, and correlation coefficient. The efficiency of the Broyden-Fletcher-Goldfarb-Shannon-ANN model was found to be much better than that of other models, while the SVR model based on radial basis function kernel predicted stream flows with comparatively higher accuracy than the other kernels. Finally, long-term predictions of streamflow have been made by the best ANN model. It was found that stream flow of Upper Indus River has a decreasing trend.","3":"Environmental monitoring and assessment","4":"30406854","5":"2018","6":"Rivers"},{"1":"Performance assessment of artificial neural networks and support vector regression models for stream flow predictions.","2":"Water resources planning, development, and management need reliable forecasts of river flows. In past few decades, an important dimension has been introduced in the prediction of the hydrologic phenomenon through artificial intelligence-based modeling. In this paper, the performance of three artificial neural network (ANN) and four support vector regression (SVR) models was investigated to predict streamflows in the Upper Indus River. Results from ANN models using three different optimization techniques, namely Broyden-Fletcher-Goldfarb-Shannon, Conjugate Gradient, and Back Propagation algorithms, were compared with one another. A further comparison was made between these ANNs and four types of SVR models which were based on linear, polynomial, radial basis function, and sigmoid kernels. Past 30 years' monthly data for precipitation, temperature, and streamflow obtained from Pakistan Surface Water Hydrology Department Lahore were used for this purpose. Three types of input combinations with respect to the main input variables (temperature, precipitation, and stream flow) and several types of input combinations with respect to time lag were tested. The best input for ANN and SVR models was identified using correlation coefficient analysis and genetic algorithm. The performance of the ANN and SVR models was evaluated by mean bias error, Nash-Sutcliffe efficiency, root mean square error, and correlation coefficient. The efficiency of the Broyden-Fletcher-Goldfarb-Shannon-ANN model was found to be much better than that of other models, while the SVR model based on radial basis function kernel predicted stream flows with comparatively higher accuracy than the other kernels. Finally, long-term predictions of streamflow have been made by the best ANN model. It was found that stream flow of Upper Indus River has a decreasing trend.","3":"Environmental monitoring and assessment","4":"30406854","5":"2018","6":"Support Vector Machine"},{"1":"Performance assessment of artificial neural networks and support vector regression models for stream flow predictions.","2":"Water resources planning, development, and management need reliable forecasts of river flows. In past few decades, an important dimension has been introduced in the prediction of the hydrologic phenomenon through artificial intelligence-based modeling. In this paper, the performance of three artificial neural network (ANN) and four support vector regression (SVR) models was investigated to predict streamflows in the Upper Indus River. Results from ANN models using three different optimization techniques, namely Broyden-Fletcher-Goldfarb-Shannon, Conjugate Gradient, and Back Propagation algorithms, were compared with one another. A further comparison was made between these ANNs and four types of SVR models which were based on linear, polynomial, radial basis function, and sigmoid kernels. Past 30 years' monthly data for precipitation, temperature, and streamflow obtained from Pakistan Surface Water Hydrology Department Lahore were used for this purpose. Three types of input combinations with respect to the main input variables (temperature, precipitation, and stream flow) and several types of input combinations with respect to time lag were tested. The best input for ANN and SVR models was identified using correlation coefficient analysis and genetic algorithm. The performance of the ANN and SVR models was evaluated by mean bias error, Nash-Sutcliffe efficiency, root mean square error, and correlation coefficient. The efficiency of the Broyden-Fletcher-Goldfarb-Shannon-ANN model was found to be much better than that of other models, while the SVR model based on radial basis function kernel predicted stream flows with comparatively higher accuracy than the other kernels. Finally, long-term predictions of streamflow have been made by the best ANN model. It was found that stream flow of Upper Indus River has a decreasing trend.","3":"Environmental monitoring and assessment","4":"30406854","5":"2018","6":"Water Movements"},{"1":"Modeling daily water temperature for rivers: comparison between adaptive neuro-fuzzy inference systems and artificial neural networks models.","2":"","3":"Environmental science and pollution research international","4":"30406582","5":"2018","6":"Algorithms"},{"1":"Modeling daily water temperature for rivers: comparison between adaptive neuro-fuzzy inference systems and artificial neural networks models.","2":"","3":"Environmental science and pollution research international","4":"30406582","5":"2018","6":"Cluster Analysis"},{"1":"Modeling daily water temperature for rivers: comparison between adaptive neuro-fuzzy inference systems and artificial neural networks models.","2":"","3":"Environmental science and pollution research international","4":"30406582","5":"2018","6":"Environmental Monitoring"},{"1":"Modeling daily water temperature for rivers: comparison between adaptive neuro-fuzzy inference systems and artificial neural networks models.","2":"","3":"Environmental science and pollution research international","4":"30406582","5":"2018","6":"Fuzzy Logic"},{"1":"Modeling daily water temperature for rivers: comparison between adaptive neuro-fuzzy inference systems and artificial neural networks models.","2":"","3":"Environmental science and pollution research international","4":"30406582","5":"2018","6":"Machine Learning"},{"1":"Modeling daily water temperature for rivers: comparison between adaptive neuro-fuzzy inference systems and artificial neural networks models.","2":"","3":"Environmental science and pollution research international","4":"30406582","5":"2018","6":"Models, Chemical"},{"1":"Modeling daily water temperature for rivers: comparison between adaptive neuro-fuzzy inference systems and artificial neural networks models.","2":"","3":"Environmental science and pollution research international","4":"30406582","5":"2018","6":"Neural Networks (Computer)"},{"1":"Modeling daily water temperature for rivers: comparison between adaptive neuro-fuzzy inference systems and artificial neural networks models.","2":"","3":"Environmental science and pollution research international","4":"30406582","5":"2018","6":"Rivers"},{"1":"Modeling daily water temperature for rivers: comparison between adaptive neuro-fuzzy inference systems and artificial neural networks models.","2":"","3":"Environmental science and pollution research international","4":"30406582","5":"2018","6":"chemistry"},{"1":"Modeling daily water temperature for rivers: comparison between adaptive neuro-fuzzy inference systems and artificial neural networks models.","2":"","3":"Environmental science and pollution research international","4":"30406582","5":"2018","6":"Temperature"},{"1":"Modeling daily water temperature for rivers: comparison between adaptive neuro-fuzzy inference systems and artificial neural networks models.","2":"","3":"Environmental science and pollution research international","4":"30406582","5":"2018","6":"Water"},{"1":"Modeling daily water temperature for rivers: comparison between adaptive neuro-fuzzy inference systems and artificial neural networks models.","2":"","3":"Environmental science and pollution research international","4":"30406582","5":"2018","6":"Water Quality"},{"1":"Improving the Security and QoE in Mobile Devices through an Intelligent and Adaptive Continuous Authentication System.","2":"Continuous authentication systems for mobile devices focus on identifying users according to their behaviour patterns when they interact with mobile devices. Among the benefits provided by these systems, we highlight the enhancement of the system security, having permanently authenticated the users; and the improvement of the users' quality of experience, minimising the use of authentication credentials. Despite the benefits of these systems, they also have open challenges such as the authentication accuracy and the adaptability to new users' behaviours. Continuous authentication systems should manage these challenges without forgetting critical aspects of mobile devices such as battery consumption, computational limitations and response time. With the goal of improving these previous challenges, the main contribution of this paper is the design and implementation of an intelligent and adaptive continuous authentication system for mobile devices. The proposed system enables the real-time users' authentication by considering statistical information from applications, sensors and Machine Learning techniques based on anomaly detection. Several experiments demonstrated the accuracy, adaptability, and resources consumption of our solution. Finally, its utility is validated through the design and implementation of an online bank application as proof of concept, which allows users to perform different actions according to their authentication level.","3":"Sensors (Basel, Switzerland)","4":"30400377","5":"2018","6":"Algorithms"},{"1":"Improving the Security and QoE in Mobile Devices through an Intelligent and Adaptive Continuous Authentication System.","2":"Continuous authentication systems for mobile devices focus on identifying users according to their behaviour patterns when they interact with mobile devices. Among the benefits provided by these systems, we highlight the enhancement of the system security, having permanently authenticated the users; and the improvement of the users' quality of experience, minimising the use of authentication credentials. Despite the benefits of these systems, they also have open challenges such as the authentication accuracy and the adaptability to new users' behaviours. Continuous authentication systems should manage these challenges without forgetting critical aspects of mobile devices such as battery consumption, computational limitations and response time. With the goal of improving these previous challenges, the main contribution of this paper is the design and implementation of an intelligent and adaptive continuous authentication system for mobile devices. The proposed system enables the real-time users' authentication by considering statistical information from applications, sensors and Machine Learning techniques based on anomaly detection. Several experiments demonstrated the accuracy, adaptability, and resources consumption of our solution. Finally, its utility is validated through the design and implementation of an online bank application as proof of concept, which allows users to perform different actions according to their authentication level.","3":"Sensors (Basel, Switzerland)","4":"30400377","5":"2018","6":"Area Under Curve"},{"1":"Improving the Security and QoE in Mobile Devices through an Intelligent and Adaptive Continuous Authentication System.","2":"Continuous authentication systems for mobile devices focus on identifying users according to their behaviour patterns when they interact with mobile devices. Among the benefits provided by these systems, we highlight the enhancement of the system security, having permanently authenticated the users; and the improvement of the users' quality of experience, minimising the use of authentication credentials. Despite the benefits of these systems, they also have open challenges such as the authentication accuracy and the adaptability to new users' behaviours. Continuous authentication systems should manage these challenges without forgetting critical aspects of mobile devices such as battery consumption, computational limitations and response time. With the goal of improving these previous challenges, the main contribution of this paper is the design and implementation of an intelligent and adaptive continuous authentication system for mobile devices. The proposed system enables the real-time users' authentication by considering statistical information from applications, sensors and Machine Learning techniques based on anomaly detection. Several experiments demonstrated the accuracy, adaptability, and resources consumption of our solution. Finally, its utility is validated through the design and implementation of an online bank application as proof of concept, which allows users to perform different actions according to their authentication level.","3":"Sensors (Basel, Switzerland)","4":"30400377","5":"2018","6":"Cell Phone"},{"1":"Improving the Security and QoE in Mobile Devices through an Intelligent and Adaptive Continuous Authentication System.","2":"Continuous authentication systems for mobile devices focus on identifying users according to their behaviour patterns when they interact with mobile devices. Among the benefits provided by these systems, we highlight the enhancement of the system security, having permanently authenticated the users; and the improvement of the users' quality of experience, minimising the use of authentication credentials. Despite the benefits of these systems, they also have open challenges such as the authentication accuracy and the adaptability to new users' behaviours. Continuous authentication systems should manage these challenges without forgetting critical aspects of mobile devices such as battery consumption, computational limitations and response time. With the goal of improving these previous challenges, the main contribution of this paper is the design and implementation of an intelligent and adaptive continuous authentication system for mobile devices. The proposed system enables the real-time users' authentication by considering statistical information from applications, sensors and Machine Learning techniques based on anomaly detection. Several experiments demonstrated the accuracy, adaptability, and resources consumption of our solution. Finally, its utility is validated through the design and implementation of an online bank application as proof of concept, which allows users to perform different actions according to their authentication level.","3":"Sensors (Basel, Switzerland)","4":"30400377","5":"2018","6":"Computer Security"},{"1":"Improving the Security and QoE in Mobile Devices through an Intelligent and Adaptive Continuous Authentication System.","2":"Continuous authentication systems for mobile devices focus on identifying users according to their behaviour patterns when they interact with mobile devices. Among the benefits provided by these systems, we highlight the enhancement of the system security, having permanently authenticated the users; and the improvement of the users' quality of experience, minimising the use of authentication credentials. Despite the benefits of these systems, they also have open challenges such as the authentication accuracy and the adaptability to new users' behaviours. Continuous authentication systems should manage these challenges without forgetting critical aspects of mobile devices such as battery consumption, computational limitations and response time. With the goal of improving these previous challenges, the main contribution of this paper is the design and implementation of an intelligent and adaptive continuous authentication system for mobile devices. The proposed system enables the real-time users' authentication by considering statistical information from applications, sensors and Machine Learning techniques based on anomaly detection. Several experiments demonstrated the accuracy, adaptability, and resources consumption of our solution. Finally, its utility is validated through the design and implementation of an online bank application as proof of concept, which allows users to perform different actions according to their authentication level.","3":"Sensors (Basel, Switzerland)","4":"30400377","5":"2018","6":"Electric Power Supplies"},{"1":"Improving the Security and QoE in Mobile Devices through an Intelligent and Adaptive Continuous Authentication System.","2":"Continuous authentication systems for mobile devices focus on identifying users according to their behaviour patterns when they interact with mobile devices. Among the benefits provided by these systems, we highlight the enhancement of the system security, having permanently authenticated the users; and the improvement of the users' quality of experience, minimising the use of authentication credentials. Despite the benefits of these systems, they also have open challenges such as the authentication accuracy and the adaptability to new users' behaviours. Continuous authentication systems should manage these challenges without forgetting critical aspects of mobile devices such as battery consumption, computational limitations and response time. With the goal of improving these previous challenges, the main contribution of this paper is the design and implementation of an intelligent and adaptive continuous authentication system for mobile devices. The proposed system enables the real-time users' authentication by considering statistical information from applications, sensors and Machine Learning techniques based on anomaly detection. Several experiments demonstrated the accuracy, adaptability, and resources consumption of our solution. Finally, its utility is validated through the design and implementation of an online bank application as proof of concept, which allows users to perform different actions according to their authentication level.","3":"Sensors (Basel, Switzerland)","4":"30400377","5":"2018","6":"Humans"},{"1":"Improving the Security and QoE in Mobile Devices through an Intelligent and Adaptive Continuous Authentication System.","2":"Continuous authentication systems for mobile devices focus on identifying users according to their behaviour patterns when they interact with mobile devices. Among the benefits provided by these systems, we highlight the enhancement of the system security, having permanently authenticated the users; and the improvement of the users' quality of experience, minimising the use of authentication credentials. Despite the benefits of these systems, they also have open challenges such as the authentication accuracy and the adaptability to new users' behaviours. Continuous authentication systems should manage these challenges without forgetting critical aspects of mobile devices such as battery consumption, computational limitations and response time. With the goal of improving these previous challenges, the main contribution of this paper is the design and implementation of an intelligent and adaptive continuous authentication system for mobile devices. The proposed system enables the real-time users' authentication by considering statistical information from applications, sensors and Machine Learning techniques based on anomaly detection. Several experiments demonstrated the accuracy, adaptability, and resources consumption of our solution. Finally, its utility is validated through the design and implementation of an online bank application as proof of concept, which allows users to perform different actions according to their authentication level.","3":"Sensors (Basel, Switzerland)","4":"30400377","5":"2018","6":"Support Vector Machine"},{"1":"Improving the Security and QoE in Mobile Devices through an Intelligent and Adaptive Continuous Authentication System.","2":"Continuous authentication systems for mobile devices focus on identifying users according to their behaviour patterns when they interact with mobile devices. Among the benefits provided by these systems, we highlight the enhancement of the system security, having permanently authenticated the users; and the improvement of the users' quality of experience, minimising the use of authentication credentials. Despite the benefits of these systems, they also have open challenges such as the authentication accuracy and the adaptability to new users' behaviours. Continuous authentication systems should manage these challenges without forgetting critical aspects of mobile devices such as battery consumption, computational limitations and response time. With the goal of improving these previous challenges, the main contribution of this paper is the design and implementation of an intelligent and adaptive continuous authentication system for mobile devices. The proposed system enables the real-time users' authentication by considering statistical information from applications, sensors and Machine Learning techniques based on anomaly detection. Several experiments demonstrated the accuracy, adaptability, and resources consumption of our solution. Finally, its utility is validated through the design and implementation of an online bank application as proof of concept, which allows users to perform different actions according to their authentication level.","3":"Sensors (Basel, Switzerland)","4":"30400377","5":"2018","6":"Time Factors"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"Adult"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"Aged"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"Brain"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"pathology"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"Brain Neoplasms"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"pathology"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"Diagnosis, Differential"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"Female"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"Glioblastoma"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"pathology"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"Humans"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"Image Enhancement"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"methods"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"Logistic Models"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"Lymphoma"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"diagnosis"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"pathology"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"Machine Learning"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"Magnetic Resonance Imaging"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"methods"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"Male"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"Middle Aged"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"ROC Curve"},{"1":"Machine learning based on multi-parametric magnetic resonance imaging to differentiate glioblastoma multiforme from primary cerebral nervous system lymphoma.","2":"PURPOSE: To evaluate the performance of a machine learning method based on texture features in multi-parametric magnetic resonance imaging (MRI) to differentiate a glioblastoma multiforme (GBM) from a primary cerebral nervous system lymphoma (PCNSL).MATERIALS AND METHODS: We included 70 patients who underwent contrast enhanced brain MRI at 3<U+2009>T with brain tumors diagnosed as GBM (n<U+2009>=<U+2009>45) and PCNSL (n<U+2009>=<U+2009>25) in this retrospective study. Twelve histograms and texture parameters were assessed on T2-weighted images (T2WIs), apparent diffusion coefficient maps, relative cerebral blood volume (rCBV) map, and contrast-enhanced T1-weighted images (CE-T1WIs). A prediction model was developed using a machine learning method (univariate logistic regression and multivariate eXtreme gradient boosting-XGBoost) and the area under the receiver operating characteristic curve of this model was calculated via 10-fold cross validation. In addition, the performance of the machine learning method was compared with the judgments of two board certified radiologists.RESULTS: With the univariate logistic regression model, the standard deviation of rCBV offered the highest AUC (0.86), followed by mean value of rCBV (0.83), skewness of CE-T1WI (0.78), mean value of CET1 (0.78), and max value of rCBV (0.77). The AUC of the XGBoost was significantly higher than the two radiologists (0.98 vs. 0.84; p<U+2009>&lt;<U+2009>0.01 and 0.98 vs. 0.79; p<U+2009>&lt;<U+2009>0.01, respectively).CONCLUSION: The performance of machine learning based on histogram and texture features in multi-parametric MRI was superior to that of conventional cut-off method and the board certified radiologists to differentiate a GBM from a PCNSL.","3":"European journal of radiology","4":"30396648","5":"2018","6":"Retrospective Studies"},{"1":"Predicting reservoir hosts and arthropod vectors from evolutionary signatures in RNA virus genomes.","2":"Identifying the animal origins of RNA viruses requires years of field and laboratory studies that stall responses to emerging infectious diseases. Using large genomic and ecological datasets, we demonstrate that animal reservoirs and the existence and identity of arthropod vectors can be predicted directly from viral genome sequences via machine learning. We illustrate the ability of these models to predict the epidemiology of diverse viruses across most human-infective families of single-stranded RNA viruses, including 69 viruses with previously elusive or never-investigated reservoirs or vectors. Models such as these, which capitalize on the proliferation of low-cost genomic sequencing, can narrow the time lag between virus discovery and targeted research, surveillance, and management.","3":"Science (New York, N.Y.)","4":"30385576","5":"2018","6":"Animals"},{"1":"Predicting reservoir hosts and arthropod vectors from evolutionary signatures in RNA virus genomes.","2":"Identifying the animal origins of RNA viruses requires years of field and laboratory studies that stall responses to emerging infectious diseases. Using large genomic and ecological datasets, we demonstrate that animal reservoirs and the existence and identity of arthropod vectors can be predicted directly from viral genome sequences via machine learning. We illustrate the ability of these models to predict the epidemiology of diverse viruses across most human-infective families of single-stranded RNA viruses, including 69 viruses with previously elusive or never-investigated reservoirs or vectors. Models such as these, which capitalize on the proliferation of low-cost genomic sequencing, can narrow the time lag between virus discovery and targeted research, surveillance, and management.","3":"Science (New York, N.Y.)","4":"30385576","5":"2018","6":"Arthropod Vectors"},{"1":"Predicting reservoir hosts and arthropod vectors from evolutionary signatures in RNA virus genomes.","2":"Identifying the animal origins of RNA viruses requires years of field and laboratory studies that stall responses to emerging infectious diseases. Using large genomic and ecological datasets, we demonstrate that animal reservoirs and the existence and identity of arthropod vectors can be predicted directly from viral genome sequences via machine learning. We illustrate the ability of these models to predict the epidemiology of diverse viruses across most human-infective families of single-stranded RNA viruses, including 69 viruses with previously elusive or never-investigated reservoirs or vectors. Models such as these, which capitalize on the proliferation of low-cost genomic sequencing, can narrow the time lag between virus discovery and targeted research, surveillance, and management.","3":"Science (New York, N.Y.)","4":"30385576","5":"2018","6":"genetics"},{"1":"Predicting reservoir hosts and arthropod vectors from evolutionary signatures in RNA virus genomes.","2":"Identifying the animal origins of RNA viruses requires years of field and laboratory studies that stall responses to emerging infectious diseases. Using large genomic and ecological datasets, we demonstrate that animal reservoirs and the existence and identity of arthropod vectors can be predicted directly from viral genome sequences via machine learning. We illustrate the ability of these models to predict the epidemiology of diverse viruses across most human-infective families of single-stranded RNA viruses, including 69 viruses with previously elusive or never-investigated reservoirs or vectors. Models such as these, which capitalize on the proliferation of low-cost genomic sequencing, can narrow the time lag between virus discovery and targeted research, surveillance, and management.","3":"Science (New York, N.Y.)","4":"30385576","5":"2018","6":"Biodiversity"},{"1":"Predicting reservoir hosts and arthropod vectors from evolutionary signatures in RNA virus genomes.","2":"Identifying the animal origins of RNA viruses requires years of field and laboratory studies that stall responses to emerging infectious diseases. Using large genomic and ecological datasets, we demonstrate that animal reservoirs and the existence and identity of arthropod vectors can be predicted directly from viral genome sequences via machine learning. We illustrate the ability of these models to predict the epidemiology of diverse viruses across most human-infective families of single-stranded RNA viruses, including 69 viruses with previously elusive or never-investigated reservoirs or vectors. Models such as these, which capitalize on the proliferation of low-cost genomic sequencing, can narrow the time lag between virus discovery and targeted research, surveillance, and management.","3":"Science (New York, N.Y.)","4":"30385576","5":"2018","6":"Communicable Diseases, Emerging"},{"1":"Predicting reservoir hosts and arthropod vectors from evolutionary signatures in RNA virus genomes.","2":"Identifying the animal origins of RNA viruses requires years of field and laboratory studies that stall responses to emerging infectious diseases. Using large genomic and ecological datasets, we demonstrate that animal reservoirs and the existence and identity of arthropod vectors can be predicted directly from viral genome sequences via machine learning. We illustrate the ability of these models to predict the epidemiology of diverse viruses across most human-infective families of single-stranded RNA viruses, including 69 viruses with previously elusive or never-investigated reservoirs or vectors. Models such as these, which capitalize on the proliferation of low-cost genomic sequencing, can narrow the time lag between virus discovery and targeted research, surveillance, and management.","3":"Science (New York, N.Y.)","4":"30385576","5":"2018","6":"prevention &amp; control"},{"1":"Predicting reservoir hosts and arthropod vectors from evolutionary signatures in RNA virus genomes.","2":"Identifying the animal origins of RNA viruses requires years of field and laboratory studies that stall responses to emerging infectious diseases. Using large genomic and ecological datasets, we demonstrate that animal reservoirs and the existence and identity of arthropod vectors can be predicted directly from viral genome sequences via machine learning. We illustrate the ability of these models to predict the epidemiology of diverse viruses across most human-infective families of single-stranded RNA viruses, including 69 viruses with previously elusive or never-investigated reservoirs or vectors. Models such as these, which capitalize on the proliferation of low-cost genomic sequencing, can narrow the time lag between virus discovery and targeted research, surveillance, and management.","3":"Science (New York, N.Y.)","4":"30385576","5":"2018","6":"virology"},{"1":"Predicting reservoir hosts and arthropod vectors from evolutionary signatures in RNA virus genomes.","2":"Identifying the animal origins of RNA viruses requires years of field and laboratory studies that stall responses to emerging infectious diseases. Using large genomic and ecological datasets, we demonstrate that animal reservoirs and the existence and identity of arthropod vectors can be predicted directly from viral genome sequences via machine learning. We illustrate the ability of these models to predict the epidemiology of diverse viruses across most human-infective families of single-stranded RNA viruses, including 69 viruses with previously elusive or never-investigated reservoirs or vectors. Models such as these, which capitalize on the proliferation of low-cost genomic sequencing, can narrow the time lag between virus discovery and targeted research, surveillance, and management.","3":"Science (New York, N.Y.)","4":"30385576","5":"2018","6":"Disease Reservoirs"},{"1":"Predicting reservoir hosts and arthropod vectors from evolutionary signatures in RNA virus genomes.","2":"Identifying the animal origins of RNA viruses requires years of field and laboratory studies that stall responses to emerging infectious diseases. Using large genomic and ecological datasets, we demonstrate that animal reservoirs and the existence and identity of arthropod vectors can be predicted directly from viral genome sequences via machine learning. We illustrate the ability of these models to predict the epidemiology of diverse viruses across most human-infective families of single-stranded RNA viruses, including 69 viruses with previously elusive or never-investigated reservoirs or vectors. Models such as these, which capitalize on the proliferation of low-cost genomic sequencing, can narrow the time lag between virus discovery and targeted research, surveillance, and management.","3":"Science (New York, N.Y.)","4":"30385576","5":"2018","6":"virology"},{"1":"Predicting reservoir hosts and arthropod vectors from evolutionary signatures in RNA virus genomes.","2":"Identifying the animal origins of RNA viruses requires years of field and laboratory studies that stall responses to emerging infectious diseases. Using large genomic and ecological datasets, we demonstrate that animal reservoirs and the existence and identity of arthropod vectors can be predicted directly from viral genome sequences via machine learning. We illustrate the ability of these models to predict the epidemiology of diverse viruses across most human-infective families of single-stranded RNA viruses, including 69 viruses with previously elusive or never-investigated reservoirs or vectors. Models such as these, which capitalize on the proliferation of low-cost genomic sequencing, can narrow the time lag between virus discovery and targeted research, surveillance, and management.","3":"Science (New York, N.Y.)","4":"30385576","5":"2018","6":"Epidemiological Monitoring"},{"1":"Predicting reservoir hosts and arthropod vectors from evolutionary signatures in RNA virus genomes.","2":"Identifying the animal origins of RNA viruses requires years of field and laboratory studies that stall responses to emerging infectious diseases. Using large genomic and ecological datasets, we demonstrate that animal reservoirs and the existence and identity of arthropod vectors can be predicted directly from viral genome sequences via machine learning. We illustrate the ability of these models to predict the epidemiology of diverse viruses across most human-infective families of single-stranded RNA viruses, including 69 viruses with previously elusive or never-investigated reservoirs or vectors. Models such as these, which capitalize on the proliferation of low-cost genomic sequencing, can narrow the time lag between virus discovery and targeted research, surveillance, and management.","3":"Science (New York, N.Y.)","4":"30385576","5":"2018","6":"Evolution, Molecular"},{"1":"Predicting reservoir hosts and arthropod vectors from evolutionary signatures in RNA virus genomes.","2":"Identifying the animal origins of RNA viruses requires years of field and laboratory studies that stall responses to emerging infectious diseases. Using large genomic and ecological datasets, we demonstrate that animal reservoirs and the existence and identity of arthropod vectors can be predicted directly from viral genome sequences via machine learning. We illustrate the ability of these models to predict the epidemiology of diverse viruses across most human-infective families of single-stranded RNA viruses, including 69 viruses with previously elusive or never-investigated reservoirs or vectors. Models such as these, which capitalize on the proliferation of low-cost genomic sequencing, can narrow the time lag between virus discovery and targeted research, surveillance, and management.","3":"Science (New York, N.Y.)","4":"30385576","5":"2018","6":"Genome, Viral"},{"1":"Predicting reservoir hosts and arthropod vectors from evolutionary signatures in RNA virus genomes.","2":"Identifying the animal origins of RNA viruses requires years of field and laboratory studies that stall responses to emerging infectious diseases. Using large genomic and ecological datasets, we demonstrate that animal reservoirs and the existence and identity of arthropod vectors can be predicted directly from viral genome sequences via machine learning. We illustrate the ability of these models to predict the epidemiology of diverse viruses across most human-infective families of single-stranded RNA viruses, including 69 viruses with previously elusive or never-investigated reservoirs or vectors. Models such as these, which capitalize on the proliferation of low-cost genomic sequencing, can narrow the time lag between virus discovery and targeted research, surveillance, and management.","3":"Science (New York, N.Y.)","4":"30385576","5":"2018","6":"Genomics"},{"1":"Predicting reservoir hosts and arthropod vectors from evolutionary signatures in RNA virus genomes.","2":"Identifying the animal origins of RNA viruses requires years of field and laboratory studies that stall responses to emerging infectious diseases. Using large genomic and ecological datasets, we demonstrate that animal reservoirs and the existence and identity of arthropod vectors can be predicted directly from viral genome sequences via machine learning. We illustrate the ability of these models to predict the epidemiology of diverse viruses across most human-infective families of single-stranded RNA viruses, including 69 viruses with previously elusive or never-investigated reservoirs or vectors. Models such as these, which capitalize on the proliferation of low-cost genomic sequencing, can narrow the time lag between virus discovery and targeted research, surveillance, and management.","3":"Science (New York, N.Y.)","4":"30385576","5":"2018","6":"Host-Pathogen Interactions"},{"1":"Predicting reservoir hosts and arthropod vectors from evolutionary signatures in RNA virus genomes.","2":"Identifying the animal origins of RNA viruses requires years of field and laboratory studies that stall responses to emerging infectious diseases. Using large genomic and ecological datasets, we demonstrate that animal reservoirs and the existence and identity of arthropod vectors can be predicted directly from viral genome sequences via machine learning. We illustrate the ability of these models to predict the epidemiology of diverse viruses across most human-infective families of single-stranded RNA viruses, including 69 viruses with previously elusive or never-investigated reservoirs or vectors. Models such as these, which capitalize on the proliferation of low-cost genomic sequencing, can narrow the time lag between virus discovery and targeted research, surveillance, and management.","3":"Science (New York, N.Y.)","4":"30385576","5":"2018","6":"Humans"},{"1":"Predicting reservoir hosts and arthropod vectors from evolutionary signatures in RNA virus genomes.","2":"Identifying the animal origins of RNA viruses requires years of field and laboratory studies that stall responses to emerging infectious diseases. Using large genomic and ecological datasets, we demonstrate that animal reservoirs and the existence and identity of arthropod vectors can be predicted directly from viral genome sequences via machine learning. We illustrate the ability of these models to predict the epidemiology of diverse viruses across most human-infective families of single-stranded RNA viruses, including 69 viruses with previously elusive or never-investigated reservoirs or vectors. Models such as these, which capitalize on the proliferation of low-cost genomic sequencing, can narrow the time lag between virus discovery and targeted research, surveillance, and management.","3":"Science (New York, N.Y.)","4":"30385576","5":"2018","6":"Machine Learning"},{"1":"Predicting reservoir hosts and arthropod vectors from evolutionary signatures in RNA virus genomes.","2":"Identifying the animal origins of RNA viruses requires years of field and laboratory studies that stall responses to emerging infectious diseases. Using large genomic and ecological datasets, we demonstrate that animal reservoirs and the existence and identity of arthropod vectors can be predicted directly from viral genome sequences via machine learning. We illustrate the ability of these models to predict the epidemiology of diverse viruses across most human-infective families of single-stranded RNA viruses, including 69 viruses with previously elusive or never-investigated reservoirs or vectors. Models such as these, which capitalize on the proliferation of low-cost genomic sequencing, can narrow the time lag between virus discovery and targeted research, surveillance, and management.","3":"Science (New York, N.Y.)","4":"30385576","5":"2018","6":"RNA Virus Infections"},{"1":"Predicting reservoir hosts and arthropod vectors from evolutionary signatures in RNA virus genomes.","2":"Identifying the animal origins of RNA viruses requires years of field and laboratory studies that stall responses to emerging infectious diseases. Using large genomic and ecological datasets, we demonstrate that animal reservoirs and the existence and identity of arthropod vectors can be predicted directly from viral genome sequences via machine learning. We illustrate the ability of these models to predict the epidemiology of diverse viruses across most human-infective families of single-stranded RNA viruses, including 69 viruses with previously elusive or never-investigated reservoirs or vectors. Models such as these, which capitalize on the proliferation of low-cost genomic sequencing, can narrow the time lag between virus discovery and targeted research, surveillance, and management.","3":"Science (New York, N.Y.)","4":"30385576","5":"2018","6":"prevention &amp; control"},{"1":"Predicting reservoir hosts and arthropod vectors from evolutionary signatures in RNA virus genomes.","2":"Identifying the animal origins of RNA viruses requires years of field and laboratory studies that stall responses to emerging infectious diseases. Using large genomic and ecological datasets, we demonstrate that animal reservoirs and the existence and identity of arthropod vectors can be predicted directly from viral genome sequences via machine learning. We illustrate the ability of these models to predict the epidemiology of diverse viruses across most human-infective families of single-stranded RNA viruses, including 69 viruses with previously elusive or never-investigated reservoirs or vectors. Models such as these, which capitalize on the proliferation of low-cost genomic sequencing, can narrow the time lag between virus discovery and targeted research, surveillance, and management.","3":"Science (New York, N.Y.)","4":"30385576","5":"2018","6":"virology"},{"1":"Predicting reservoir hosts and arthropod vectors from evolutionary signatures in RNA virus genomes.","2":"Identifying the animal origins of RNA viruses requires years of field and laboratory studies that stall responses to emerging infectious diseases. Using large genomic and ecological datasets, we demonstrate that animal reservoirs and the existence and identity of arthropod vectors can be predicted directly from viral genome sequences via machine learning. We illustrate the ability of these models to predict the epidemiology of diverse viruses across most human-infective families of single-stranded RNA viruses, including 69 viruses with previously elusive or never-investigated reservoirs or vectors. Models such as these, which capitalize on the proliferation of low-cost genomic sequencing, can narrow the time lag between virus discovery and targeted research, surveillance, and management.","3":"Science (New York, N.Y.)","4":"30385576","5":"2018","6":"RNA Viruses"},{"1":"Automatic detection of oral and pharyngeal phases in swallowing using classification algorithms and multichannel EMG.","2":"Swallowing is a complex process that involves sequential voluntary and involuntary muscle contractions. Malfunctioning of swallowing related muscles could lead to dysphagia. However, there is a lack of standardized and non-invasive methods that support and improve the diagnosis and ambulatory care. This paper presents a classification scheme of two swallowing phases (oral and pharyngeal) based on signals of surface electromyography (sEMG). Eight acquisition channels recorded the EMG activity of 47 healthy subjects while they swallowed water, yogurt and saliva. Every signal was processed, segmented and labeled with background activity, oral or pharyngeal classes. Nine time domain and four frequency domain features were extracted from the segments, assessed individually and then compared in groups according to a correlation analysis. A support vector machine (SVM) with radial basis function kernel and a feedforward artificial neural network (ANN) with one hidden layer were used as classifiers. Different hyperparameters of the SVM and number of hidden neurons of the ANN were assessed for the proposed scheme. The recognition accuracy of SVM (92,03%) was higher than ANN's (90,26%). Time domain features were found to have better capability of representation than their frequency domain counterpart. Nevertheless, expanding the feature space improved the performance of the classifiers. Experimental results show that proposed sEMG-based method can correctly distinguish between oral and pharyngeal swallowing phases and can be used for assessment of continuous swallowing tasks. This paper extends previous reported findings to small muscles with low signal-to-noise ratio and high crosstalk acquired in multichannel systems.","3":"Journal of electromyography and kinesiology : official journal of the International Society of Electrophysiological Kinesiology","4":"30384221","5":"2018","6":"Adult"},{"1":"Automatic detection of oral and pharyngeal phases in swallowing using classification algorithms and multichannel EMG.","2":"Swallowing is a complex process that involves sequential voluntary and involuntary muscle contractions. Malfunctioning of swallowing related muscles could lead to dysphagia. However, there is a lack of standardized and non-invasive methods that support and improve the diagnosis and ambulatory care. This paper presents a classification scheme of two swallowing phases (oral and pharyngeal) based on signals of surface electromyography (sEMG). Eight acquisition channels recorded the EMG activity of 47 healthy subjects while they swallowed water, yogurt and saliva. Every signal was processed, segmented and labeled with background activity, oral or pharyngeal classes. Nine time domain and four frequency domain features were extracted from the segments, assessed individually and then compared in groups according to a correlation analysis. A support vector machine (SVM) with radial basis function kernel and a feedforward artificial neural network (ANN) with one hidden layer were used as classifiers. Different hyperparameters of the SVM and number of hidden neurons of the ANN were assessed for the proposed scheme. The recognition accuracy of SVM (92,03%) was higher than ANN's (90,26%). Time domain features were found to have better capability of representation than their frequency domain counterpart. Nevertheless, expanding the feature space improved the performance of the classifiers. Experimental results show that proposed sEMG-based method can correctly distinguish between oral and pharyngeal swallowing phases and can be used for assessment of continuous swallowing tasks. This paper extends previous reported findings to small muscles with low signal-to-noise ratio and high crosstalk acquired in multichannel systems.","3":"Journal of electromyography and kinesiology : official journal of the International Society of Electrophysiological Kinesiology","4":"30384221","5":"2018","6":"Aged"},{"1":"Automatic detection of oral and pharyngeal phases in swallowing using classification algorithms and multichannel EMG.","2":"Swallowing is a complex process that involves sequential voluntary and involuntary muscle contractions. Malfunctioning of swallowing related muscles could lead to dysphagia. However, there is a lack of standardized and non-invasive methods that support and improve the diagnosis and ambulatory care. This paper presents a classification scheme of two swallowing phases (oral and pharyngeal) based on signals of surface electromyography (sEMG). Eight acquisition channels recorded the EMG activity of 47 healthy subjects while they swallowed water, yogurt and saliva. Every signal was processed, segmented and labeled with background activity, oral or pharyngeal classes. Nine time domain and four frequency domain features were extracted from the segments, assessed individually and then compared in groups according to a correlation analysis. A support vector machine (SVM) with radial basis function kernel and a feedforward artificial neural network (ANN) with one hidden layer were used as classifiers. Different hyperparameters of the SVM and number of hidden neurons of the ANN were assessed for the proposed scheme. The recognition accuracy of SVM (92,03%) was higher than ANN's (90,26%). Time domain features were found to have better capability of representation than their frequency domain counterpart. Nevertheless, expanding the feature space improved the performance of the classifiers. Experimental results show that proposed sEMG-based method can correctly distinguish between oral and pharyngeal swallowing phases and can be used for assessment of continuous swallowing tasks. This paper extends previous reported findings to small muscles with low signal-to-noise ratio and high crosstalk acquired in multichannel systems.","3":"Journal of electromyography and kinesiology : official journal of the International Society of Electrophysiological Kinesiology","4":"30384221","5":"2018","6":"Aged, 80 and over"},{"1":"Automatic detection of oral and pharyngeal phases in swallowing using classification algorithms and multichannel EMG.","2":"Swallowing is a complex process that involves sequential voluntary and involuntary muscle contractions. Malfunctioning of swallowing related muscles could lead to dysphagia. However, there is a lack of standardized and non-invasive methods that support and improve the diagnosis and ambulatory care. This paper presents a classification scheme of two swallowing phases (oral and pharyngeal) based on signals of surface electromyography (sEMG). Eight acquisition channels recorded the EMG activity of 47 healthy subjects while they swallowed water, yogurt and saliva. Every signal was processed, segmented and labeled with background activity, oral or pharyngeal classes. Nine time domain and four frequency domain features were extracted from the segments, assessed individually and then compared in groups according to a correlation analysis. A support vector machine (SVM) with radial basis function kernel and a feedforward artificial neural network (ANN) with one hidden layer were used as classifiers. Different hyperparameters of the SVM and number of hidden neurons of the ANN were assessed for the proposed scheme. The recognition accuracy of SVM (92,03%) was higher than ANN's (90,26%). Time domain features were found to have better capability of representation than their frequency domain counterpart. Nevertheless, expanding the feature space improved the performance of the classifiers. Experimental results show that proposed sEMG-based method can correctly distinguish between oral and pharyngeal swallowing phases and can be used for assessment of continuous swallowing tasks. This paper extends previous reported findings to small muscles with low signal-to-noise ratio and high crosstalk acquired in multichannel systems.","3":"Journal of electromyography and kinesiology : official journal of the International Society of Electrophysiological Kinesiology","4":"30384221","5":"2018","6":"Deglutition"},{"1":"Automatic detection of oral and pharyngeal phases in swallowing using classification algorithms and multichannel EMG.","2":"Swallowing is a complex process that involves sequential voluntary and involuntary muscle contractions. Malfunctioning of swallowing related muscles could lead to dysphagia. However, there is a lack of standardized and non-invasive methods that support and improve the diagnosis and ambulatory care. This paper presents a classification scheme of two swallowing phases (oral and pharyngeal) based on signals of surface electromyography (sEMG). Eight acquisition channels recorded the EMG activity of 47 healthy subjects while they swallowed water, yogurt and saliva. Every signal was processed, segmented and labeled with background activity, oral or pharyngeal classes. Nine time domain and four frequency domain features were extracted from the segments, assessed individually and then compared in groups according to a correlation analysis. A support vector machine (SVM) with radial basis function kernel and a feedforward artificial neural network (ANN) with one hidden layer were used as classifiers. Different hyperparameters of the SVM and number of hidden neurons of the ANN were assessed for the proposed scheme. The recognition accuracy of SVM (92,03%) was higher than ANN's (90,26%). Time domain features were found to have better capability of representation than their frequency domain counterpart. Nevertheless, expanding the feature space improved the performance of the classifiers. Experimental results show that proposed sEMG-based method can correctly distinguish between oral and pharyngeal swallowing phases and can be used for assessment of continuous swallowing tasks. This paper extends previous reported findings to small muscles with low signal-to-noise ratio and high crosstalk acquired in multichannel systems.","3":"Journal of electromyography and kinesiology : official journal of the International Society of Electrophysiological Kinesiology","4":"30384221","5":"2018","6":"physiology"},{"1":"Automatic detection of oral and pharyngeal phases in swallowing using classification algorithms and multichannel EMG.","2":"Swallowing is a complex process that involves sequential voluntary and involuntary muscle contractions. Malfunctioning of swallowing related muscles could lead to dysphagia. However, there is a lack of standardized and non-invasive methods that support and improve the diagnosis and ambulatory care. This paper presents a classification scheme of two swallowing phases (oral and pharyngeal) based on signals of surface electromyography (sEMG). Eight acquisition channels recorded the EMG activity of 47 healthy subjects while they swallowed water, yogurt and saliva. Every signal was processed, segmented and labeled with background activity, oral or pharyngeal classes. Nine time domain and four frequency domain features were extracted from the segments, assessed individually and then compared in groups according to a correlation analysis. A support vector machine (SVM) with radial basis function kernel and a feedforward artificial neural network (ANN) with one hidden layer were used as classifiers. Different hyperparameters of the SVM and number of hidden neurons of the ANN were assessed for the proposed scheme. The recognition accuracy of SVM (92,03%) was higher than ANN's (90,26%). Time domain features were found to have better capability of representation than their frequency domain counterpart. Nevertheless, expanding the feature space improved the performance of the classifiers. Experimental results show that proposed sEMG-based method can correctly distinguish between oral and pharyngeal swallowing phases and can be used for assessment of continuous swallowing tasks. This paper extends previous reported findings to small muscles with low signal-to-noise ratio and high crosstalk acquired in multichannel systems.","3":"Journal of electromyography and kinesiology : official journal of the International Society of Electrophysiological Kinesiology","4":"30384221","5":"2018","6":"Electromyography"},{"1":"Automatic detection of oral and pharyngeal phases in swallowing using classification algorithms and multichannel EMG.","2":"Swallowing is a complex process that involves sequential voluntary and involuntary muscle contractions. Malfunctioning of swallowing related muscles could lead to dysphagia. However, there is a lack of standardized and non-invasive methods that support and improve the diagnosis and ambulatory care. This paper presents a classification scheme of two swallowing phases (oral and pharyngeal) based on signals of surface electromyography (sEMG). Eight acquisition channels recorded the EMG activity of 47 healthy subjects while they swallowed water, yogurt and saliva. Every signal was processed, segmented and labeled with background activity, oral or pharyngeal classes. Nine time domain and four frequency domain features were extracted from the segments, assessed individually and then compared in groups according to a correlation analysis. A support vector machine (SVM) with radial basis function kernel and a feedforward artificial neural network (ANN) with one hidden layer were used as classifiers. Different hyperparameters of the SVM and number of hidden neurons of the ANN were assessed for the proposed scheme. The recognition accuracy of SVM (92,03%) was higher than ANN's (90,26%). Time domain features were found to have better capability of representation than their frequency domain counterpart. Nevertheless, expanding the feature space improved the performance of the classifiers. Experimental results show that proposed sEMG-based method can correctly distinguish between oral and pharyngeal swallowing phases and can be used for assessment of continuous swallowing tasks. This paper extends previous reported findings to small muscles with low signal-to-noise ratio and high crosstalk acquired in multichannel systems.","3":"Journal of electromyography and kinesiology : official journal of the International Society of Electrophysiological Kinesiology","4":"30384221","5":"2018","6":"methods"},{"1":"Automatic detection of oral and pharyngeal phases in swallowing using classification algorithms and multichannel EMG.","2":"Swallowing is a complex process that involves sequential voluntary and involuntary muscle contractions. Malfunctioning of swallowing related muscles could lead to dysphagia. However, there is a lack of standardized and non-invasive methods that support and improve the diagnosis and ambulatory care. This paper presents a classification scheme of two swallowing phases (oral and pharyngeal) based on signals of surface electromyography (sEMG). Eight acquisition channels recorded the EMG activity of 47 healthy subjects while they swallowed water, yogurt and saliva. Every signal was processed, segmented and labeled with background activity, oral or pharyngeal classes. Nine time domain and four frequency domain features were extracted from the segments, assessed individually and then compared in groups according to a correlation analysis. A support vector machine (SVM) with radial basis function kernel and a feedforward artificial neural network (ANN) with one hidden layer were used as classifiers. Different hyperparameters of the SVM and number of hidden neurons of the ANN were assessed for the proposed scheme. The recognition accuracy of SVM (92,03%) was higher than ANN's (90,26%). Time domain features were found to have better capability of representation than their frequency domain counterpart. Nevertheless, expanding the feature space improved the performance of the classifiers. Experimental results show that proposed sEMG-based method can correctly distinguish between oral and pharyngeal swallowing phases and can be used for assessment of continuous swallowing tasks. This paper extends previous reported findings to small muscles with low signal-to-noise ratio and high crosstalk acquired in multichannel systems.","3":"Journal of electromyography and kinesiology : official journal of the International Society of Electrophysiological Kinesiology","4":"30384221","5":"2018","6":"standards"},{"1":"Automatic detection of oral and pharyngeal phases in swallowing using classification algorithms and multichannel EMG.","2":"Swallowing is a complex process that involves sequential voluntary and involuntary muscle contractions. Malfunctioning of swallowing related muscles could lead to dysphagia. However, there is a lack of standardized and non-invasive methods that support and improve the diagnosis and ambulatory care. This paper presents a classification scheme of two swallowing phases (oral and pharyngeal) based on signals of surface electromyography (sEMG). Eight acquisition channels recorded the EMG activity of 47 healthy subjects while they swallowed water, yogurt and saliva. Every signal was processed, segmented and labeled with background activity, oral or pharyngeal classes. Nine time domain and four frequency domain features were extracted from the segments, assessed individually and then compared in groups according to a correlation analysis. A support vector machine (SVM) with radial basis function kernel and a feedforward artificial neural network (ANN) with one hidden layer were used as classifiers. Different hyperparameters of the SVM and number of hidden neurons of the ANN were assessed for the proposed scheme. The recognition accuracy of SVM (92,03%) was higher than ANN's (90,26%). Time domain features were found to have better capability of representation than their frequency domain counterpart. Nevertheless, expanding the feature space improved the performance of the classifiers. Experimental results show that proposed sEMG-based method can correctly distinguish between oral and pharyngeal swallowing phases and can be used for assessment of continuous swallowing tasks. This paper extends previous reported findings to small muscles with low signal-to-noise ratio and high crosstalk acquired in multichannel systems.","3":"Journal of electromyography and kinesiology : official journal of the International Society of Electrophysiological Kinesiology","4":"30384221","5":"2018","6":"Female"},{"1":"Automatic detection of oral and pharyngeal phases in swallowing using classification algorithms and multichannel EMG.","2":"Swallowing is a complex process that involves sequential voluntary and involuntary muscle contractions. Malfunctioning of swallowing related muscles could lead to dysphagia. However, there is a lack of standardized and non-invasive methods that support and improve the diagnosis and ambulatory care. This paper presents a classification scheme of two swallowing phases (oral and pharyngeal) based on signals of surface electromyography (sEMG). Eight acquisition channels recorded the EMG activity of 47 healthy subjects while they swallowed water, yogurt and saliva. Every signal was processed, segmented and labeled with background activity, oral or pharyngeal classes. Nine time domain and four frequency domain features were extracted from the segments, assessed individually and then compared in groups according to a correlation analysis. A support vector machine (SVM) with radial basis function kernel and a feedforward artificial neural network (ANN) with one hidden layer were used as classifiers. Different hyperparameters of the SVM and number of hidden neurons of the ANN were assessed for the proposed scheme. The recognition accuracy of SVM (92,03%) was higher than ANN's (90,26%). Time domain features were found to have better capability of representation than their frequency domain counterpart. Nevertheless, expanding the feature space improved the performance of the classifiers. Experimental results show that proposed sEMG-based method can correctly distinguish between oral and pharyngeal swallowing phases and can be used for assessment of continuous swallowing tasks. This paper extends previous reported findings to small muscles with low signal-to-noise ratio and high crosstalk acquired in multichannel systems.","3":"Journal of electromyography and kinesiology : official journal of the International Society of Electrophysiological Kinesiology","4":"30384221","5":"2018","6":"Humans"},{"1":"Automatic detection of oral and pharyngeal phases in swallowing using classification algorithms and multichannel EMG.","2":"Swallowing is a complex process that involves sequential voluntary and involuntary muscle contractions. Malfunctioning of swallowing related muscles could lead to dysphagia. However, there is a lack of standardized and non-invasive methods that support and improve the diagnosis and ambulatory care. This paper presents a classification scheme of two swallowing phases (oral and pharyngeal) based on signals of surface electromyography (sEMG). Eight acquisition channels recorded the EMG activity of 47 healthy subjects while they swallowed water, yogurt and saliva. Every signal was processed, segmented and labeled with background activity, oral or pharyngeal classes. Nine time domain and four frequency domain features were extracted from the segments, assessed individually and then compared in groups according to a correlation analysis. A support vector machine (SVM) with radial basis function kernel and a feedforward artificial neural network (ANN) with one hidden layer were used as classifiers. Different hyperparameters of the SVM and number of hidden neurons of the ANN were assessed for the proposed scheme. The recognition accuracy of SVM (92,03%) was higher than ANN's (90,26%). Time domain features were found to have better capability of representation than their frequency domain counterpart. Nevertheless, expanding the feature space improved the performance of the classifiers. Experimental results show that proposed sEMG-based method can correctly distinguish between oral and pharyngeal swallowing phases and can be used for assessment of continuous swallowing tasks. This paper extends previous reported findings to small muscles with low signal-to-noise ratio and high crosstalk acquired in multichannel systems.","3":"Journal of electromyography and kinesiology : official journal of the International Society of Electrophysiological Kinesiology","4":"30384221","5":"2018","6":"Male"},{"1":"Automatic detection of oral and pharyngeal phases in swallowing using classification algorithms and multichannel EMG.","2":"Swallowing is a complex process that involves sequential voluntary and involuntary muscle contractions. Malfunctioning of swallowing related muscles could lead to dysphagia. However, there is a lack of standardized and non-invasive methods that support and improve the diagnosis and ambulatory care. This paper presents a classification scheme of two swallowing phases (oral and pharyngeal) based on signals of surface electromyography (sEMG). Eight acquisition channels recorded the EMG activity of 47 healthy subjects while they swallowed water, yogurt and saliva. Every signal was processed, segmented and labeled with background activity, oral or pharyngeal classes. Nine time domain and four frequency domain features were extracted from the segments, assessed individually and then compared in groups according to a correlation analysis. A support vector machine (SVM) with radial basis function kernel and a feedforward artificial neural network (ANN) with one hidden layer were used as classifiers. Different hyperparameters of the SVM and number of hidden neurons of the ANN were assessed for the proposed scheme. The recognition accuracy of SVM (92,03%) was higher than ANN's (90,26%). Time domain features were found to have better capability of representation than their frequency domain counterpart. Nevertheless, expanding the feature space improved the performance of the classifiers. Experimental results show that proposed sEMG-based method can correctly distinguish between oral and pharyngeal swallowing phases and can be used for assessment of continuous swallowing tasks. This paper extends previous reported findings to small muscles with low signal-to-noise ratio and high crosstalk acquired in multichannel systems.","3":"Journal of electromyography and kinesiology : official journal of the International Society of Electrophysiological Kinesiology","4":"30384221","5":"2018","6":"Middle Aged"},{"1":"Automatic detection of oral and pharyngeal phases in swallowing using classification algorithms and multichannel EMG.","2":"Swallowing is a complex process that involves sequential voluntary and involuntary muscle contractions. Malfunctioning of swallowing related muscles could lead to dysphagia. However, there is a lack of standardized and non-invasive methods that support and improve the diagnosis and ambulatory care. This paper presents a classification scheme of two swallowing phases (oral and pharyngeal) based on signals of surface electromyography (sEMG). Eight acquisition channels recorded the EMG activity of 47 healthy subjects while they swallowed water, yogurt and saliva. Every signal was processed, segmented and labeled with background activity, oral or pharyngeal classes. Nine time domain and four frequency domain features were extracted from the segments, assessed individually and then compared in groups according to a correlation analysis. A support vector machine (SVM) with radial basis function kernel and a feedforward artificial neural network (ANN) with one hidden layer were used as classifiers. Different hyperparameters of the SVM and number of hidden neurons of the ANN were assessed for the proposed scheme. The recognition accuracy of SVM (92,03%) was higher than ANN's (90,26%). Time domain features were found to have better capability of representation than their frequency domain counterpart. Nevertheless, expanding the feature space improved the performance of the classifiers. Experimental results show that proposed sEMG-based method can correctly distinguish between oral and pharyngeal swallowing phases and can be used for assessment of continuous swallowing tasks. This paper extends previous reported findings to small muscles with low signal-to-noise ratio and high crosstalk acquired in multichannel systems.","3":"Journal of electromyography and kinesiology : official journal of the International Society of Electrophysiological Kinesiology","4":"30384221","5":"2018","6":"Mouth"},{"1":"Automatic detection of oral and pharyngeal phases in swallowing using classification algorithms and multichannel EMG.","2":"Swallowing is a complex process that involves sequential voluntary and involuntary muscle contractions. Malfunctioning of swallowing related muscles could lead to dysphagia. However, there is a lack of standardized and non-invasive methods that support and improve the diagnosis and ambulatory care. This paper presents a classification scheme of two swallowing phases (oral and pharyngeal) based on signals of surface electromyography (sEMG). Eight acquisition channels recorded the EMG activity of 47 healthy subjects while they swallowed water, yogurt and saliva. Every signal was processed, segmented and labeled with background activity, oral or pharyngeal classes. Nine time domain and four frequency domain features were extracted from the segments, assessed individually and then compared in groups according to a correlation analysis. A support vector machine (SVM) with radial basis function kernel and a feedforward artificial neural network (ANN) with one hidden layer were used as classifiers. Different hyperparameters of the SVM and number of hidden neurons of the ANN were assessed for the proposed scheme. The recognition accuracy of SVM (92,03%) was higher than ANN's (90,26%). Time domain features were found to have better capability of representation than their frequency domain counterpart. Nevertheless, expanding the feature space improved the performance of the classifiers. Experimental results show that proposed sEMG-based method can correctly distinguish between oral and pharyngeal swallowing phases and can be used for assessment of continuous swallowing tasks. This paper extends previous reported findings to small muscles with low signal-to-noise ratio and high crosstalk acquired in multichannel systems.","3":"Journal of electromyography and kinesiology : official journal of the International Society of Electrophysiological Kinesiology","4":"30384221","5":"2018","6":"physiology"},{"1":"Automatic detection of oral and pharyngeal phases in swallowing using classification algorithms and multichannel EMG.","2":"Swallowing is a complex process that involves sequential voluntary and involuntary muscle contractions. Malfunctioning of swallowing related muscles could lead to dysphagia. However, there is a lack of standardized and non-invasive methods that support and improve the diagnosis and ambulatory care. This paper presents a classification scheme of two swallowing phases (oral and pharyngeal) based on signals of surface electromyography (sEMG). Eight acquisition channels recorded the EMG activity of 47 healthy subjects while they swallowed water, yogurt and saliva. Every signal was processed, segmented and labeled with background activity, oral or pharyngeal classes. Nine time domain and four frequency domain features were extracted from the segments, assessed individually and then compared in groups according to a correlation analysis. A support vector machine (SVM) with radial basis function kernel and a feedforward artificial neural network (ANN) with one hidden layer were used as classifiers. Different hyperparameters of the SVM and number of hidden neurons of the ANN were assessed for the proposed scheme. The recognition accuracy of SVM (92,03%) was higher than ANN's (90,26%). Time domain features were found to have better capability of representation than their frequency domain counterpart. Nevertheless, expanding the feature space improved the performance of the classifiers. Experimental results show that proposed sEMG-based method can correctly distinguish between oral and pharyngeal swallowing phases and can be used for assessment of continuous swallowing tasks. This paper extends previous reported findings to small muscles with low signal-to-noise ratio and high crosstalk acquired in multichannel systems.","3":"Journal of electromyography and kinesiology : official journal of the International Society of Electrophysiological Kinesiology","4":"30384221","5":"2018","6":"Pharynx"},{"1":"Automatic detection of oral and pharyngeal phases in swallowing using classification algorithms and multichannel EMG.","2":"Swallowing is a complex process that involves sequential voluntary and involuntary muscle contractions. Malfunctioning of swallowing related muscles could lead to dysphagia. However, there is a lack of standardized and non-invasive methods that support and improve the diagnosis and ambulatory care. This paper presents a classification scheme of two swallowing phases (oral and pharyngeal) based on signals of surface electromyography (sEMG). Eight acquisition channels recorded the EMG activity of 47 healthy subjects while they swallowed water, yogurt and saliva. Every signal was processed, segmented and labeled with background activity, oral or pharyngeal classes. Nine time domain and four frequency domain features were extracted from the segments, assessed individually and then compared in groups according to a correlation analysis. A support vector machine (SVM) with radial basis function kernel and a feedforward artificial neural network (ANN) with one hidden layer were used as classifiers. Different hyperparameters of the SVM and number of hidden neurons of the ANN were assessed for the proposed scheme. The recognition accuracy of SVM (92,03%) was higher than ANN's (90,26%). Time domain features were found to have better capability of representation than their frequency domain counterpart. Nevertheless, expanding the feature space improved the performance of the classifiers. Experimental results show that proposed sEMG-based method can correctly distinguish between oral and pharyngeal swallowing phases and can be used for assessment of continuous swallowing tasks. This paper extends previous reported findings to small muscles with low signal-to-noise ratio and high crosstalk acquired in multichannel systems.","3":"Journal of electromyography and kinesiology : official journal of the International Society of Electrophysiological Kinesiology","4":"30384221","5":"2018","6":"physiology"},{"1":"Automatic detection of oral and pharyngeal phases in swallowing using classification algorithms and multichannel EMG.","2":"Swallowing is a complex process that involves sequential voluntary and involuntary muscle contractions. Malfunctioning of swallowing related muscles could lead to dysphagia. However, there is a lack of standardized and non-invasive methods that support and improve the diagnosis and ambulatory care. This paper presents a classification scheme of two swallowing phases (oral and pharyngeal) based on signals of surface electromyography (sEMG). Eight acquisition channels recorded the EMG activity of 47 healthy subjects while they swallowed water, yogurt and saliva. Every signal was processed, segmented and labeled with background activity, oral or pharyngeal classes. Nine time domain and four frequency domain features were extracted from the segments, assessed individually and then compared in groups according to a correlation analysis. A support vector machine (SVM) with radial basis function kernel and a feedforward artificial neural network (ANN) with one hidden layer were used as classifiers. Different hyperparameters of the SVM and number of hidden neurons of the ANN were assessed for the proposed scheme. The recognition accuracy of SVM (92,03%) was higher than ANN's (90,26%). Time domain features were found to have better capability of representation than their frequency domain counterpart. Nevertheless, expanding the feature space improved the performance of the classifiers. Experimental results show that proposed sEMG-based method can correctly distinguish between oral and pharyngeal swallowing phases and can be used for assessment of continuous swallowing tasks. This paper extends previous reported findings to small muscles with low signal-to-noise ratio and high crosstalk acquired in multichannel systems.","3":"Journal of electromyography and kinesiology : official journal of the International Society of Electrophysiological Kinesiology","4":"30384221","5":"2018","6":"Signal-To-Noise Ratio"},{"1":"Automatic detection of oral and pharyngeal phases in swallowing using classification algorithms and multichannel EMG.","2":"Swallowing is a complex process that involves sequential voluntary and involuntary muscle contractions. Malfunctioning of swallowing related muscles could lead to dysphagia. However, there is a lack of standardized and non-invasive methods that support and improve the diagnosis and ambulatory care. This paper presents a classification scheme of two swallowing phases (oral and pharyngeal) based on signals of surface electromyography (sEMG). Eight acquisition channels recorded the EMG activity of 47 healthy subjects while they swallowed water, yogurt and saliva. Every signal was processed, segmented and labeled with background activity, oral or pharyngeal classes. Nine time domain and four frequency domain features were extracted from the segments, assessed individually and then compared in groups according to a correlation analysis. A support vector machine (SVM) with radial basis function kernel and a feedforward artificial neural network (ANN) with one hidden layer were used as classifiers. Different hyperparameters of the SVM and number of hidden neurons of the ANN were assessed for the proposed scheme. The recognition accuracy of SVM (92,03%) was higher than ANN's (90,26%). Time domain features were found to have better capability of representation than their frequency domain counterpart. Nevertheless, expanding the feature space improved the performance of the classifiers. Experimental results show that proposed sEMG-based method can correctly distinguish between oral and pharyngeal swallowing phases and can be used for assessment of continuous swallowing tasks. This paper extends previous reported findings to small muscles with low signal-to-noise ratio and high crosstalk acquired in multichannel systems.","3":"Journal of electromyography and kinesiology : official journal of the International Society of Electrophysiological Kinesiology","4":"30384221","5":"2018","6":"Support Vector Machine"},{"1":"Automatic treatment planning based on three-dimensional dose distribution predicted from deep learning technique.","2":"PURPOSE: To develop an automated treatment planning strategy for external beam intensity-modulated radiation therapy (IMRT), including a deep learning-based three-dimensional (3D) dose prediction and a dose distribution-based plan generation algorithm.METHODS AND MATERIALS: A residual neural network-based deep learning model is trained to predict a dose distribution based on patient-specific geometry and prescription dose. A total of 270 head-and-neck cancer cases were enrolled in this study, including 195 cases in the training dataset, 25 cases in the validation dataset, and 50 cases in the testing dataset. All patients were treated with IMRT with a variety of different prescription patterns. The model input consists of CT images and contours delineating the organs at risk (OARs) and planning target volumes (PTVs). The algorithm output is trained to predict the dose distribution on the CT image slices. The obtained prediction model is used to predict dose distributions for new patients. Then, an optimization objective function based on these predicted dose distributions is created for automatic plan generation.CONCLUSION: This study developed a new automated radiotherapy treatment planning system based on 3D dose prediction and 3D dose distribution-based optimization. It is a promising approach for realizing automated treatment planning in the future.","3":"Medical physics","4":"30383300","5":"2018","6":"Algorithms"},{"1":"Automatic treatment planning based on three-dimensional dose distribution predicted from deep learning technique.","2":"PURPOSE: To develop an automated treatment planning strategy for external beam intensity-modulated radiation therapy (IMRT), including a deep learning-based three-dimensional (3D) dose prediction and a dose distribution-based plan generation algorithm.METHODS AND MATERIALS: A residual neural network-based deep learning model is trained to predict a dose distribution based on patient-specific geometry and prescription dose. A total of 270 head-and-neck cancer cases were enrolled in this study, including 195 cases in the training dataset, 25 cases in the validation dataset, and 50 cases in the testing dataset. All patients were treated with IMRT with a variety of different prescription patterns. The model input consists of CT images and contours delineating the organs at risk (OARs) and planning target volumes (PTVs). The algorithm output is trained to predict the dose distribution on the CT image slices. The obtained prediction model is used to predict dose distributions for new patients. Then, an optimization objective function based on these predicted dose distributions is created for automatic plan generation.CONCLUSION: This study developed a new automated radiotherapy treatment planning system based on 3D dose prediction and 3D dose distribution-based optimization. It is a promising approach for realizing automated treatment planning in the future.","3":"Medical physics","4":"30383300","5":"2018","6":"Automation"},{"1":"Automatic treatment planning based on three-dimensional dose distribution predicted from deep learning technique.","2":"PURPOSE: To develop an automated treatment planning strategy for external beam intensity-modulated radiation therapy (IMRT), including a deep learning-based three-dimensional (3D) dose prediction and a dose distribution-based plan generation algorithm.METHODS AND MATERIALS: A residual neural network-based deep learning model is trained to predict a dose distribution based on patient-specific geometry and prescription dose. A total of 270 head-and-neck cancer cases were enrolled in this study, including 195 cases in the training dataset, 25 cases in the validation dataset, and 50 cases in the testing dataset. All patients were treated with IMRT with a variety of different prescription patterns. The model input consists of CT images and contours delineating the organs at risk (OARs) and planning target volumes (PTVs). The algorithm output is trained to predict the dose distribution on the CT image slices. The obtained prediction model is used to predict dose distributions for new patients. Then, an optimization objective function based on these predicted dose distributions is created for automatic plan generation.CONCLUSION: This study developed a new automated radiotherapy treatment planning system based on 3D dose prediction and 3D dose distribution-based optimization. It is a promising approach for realizing automated treatment planning in the future.","3":"Medical physics","4":"30383300","5":"2018","6":"Deep Learning"},{"1":"Automatic treatment planning based on three-dimensional dose distribution predicted from deep learning technique.","2":"PURPOSE: To develop an automated treatment planning strategy for external beam intensity-modulated radiation therapy (IMRT), including a deep learning-based three-dimensional (3D) dose prediction and a dose distribution-based plan generation algorithm.METHODS AND MATERIALS: A residual neural network-based deep learning model is trained to predict a dose distribution based on patient-specific geometry and prescription dose. A total of 270 head-and-neck cancer cases were enrolled in this study, including 195 cases in the training dataset, 25 cases in the validation dataset, and 50 cases in the testing dataset. All patients were treated with IMRT with a variety of different prescription patterns. The model input consists of CT images and contours delineating the organs at risk (OARs) and planning target volumes (PTVs). The algorithm output is trained to predict the dose distribution on the CT image slices. The obtained prediction model is used to predict dose distributions for new patients. Then, an optimization objective function based on these predicted dose distributions is created for automatic plan generation.CONCLUSION: This study developed a new automated radiotherapy treatment planning system based on 3D dose prediction and 3D dose distribution-based optimization. It is a promising approach for realizing automated treatment planning in the future.","3":"Medical physics","4":"30383300","5":"2018","6":"Head and Neck Neoplasms"},{"1":"Automatic treatment planning based on three-dimensional dose distribution predicted from deep learning technique.","2":"PURPOSE: To develop an automated treatment planning strategy for external beam intensity-modulated radiation therapy (IMRT), including a deep learning-based three-dimensional (3D) dose prediction and a dose distribution-based plan generation algorithm.METHODS AND MATERIALS: A residual neural network-based deep learning model is trained to predict a dose distribution based on patient-specific geometry and prescription dose. A total of 270 head-and-neck cancer cases were enrolled in this study, including 195 cases in the training dataset, 25 cases in the validation dataset, and 50 cases in the testing dataset. All patients were treated with IMRT with a variety of different prescription patterns. The model input consists of CT images and contours delineating the organs at risk (OARs) and planning target volumes (PTVs). The algorithm output is trained to predict the dose distribution on the CT image slices. The obtained prediction model is used to predict dose distributions for new patients. Then, an optimization objective function based on these predicted dose distributions is created for automatic plan generation.CONCLUSION: This study developed a new automated radiotherapy treatment planning system based on 3D dose prediction and 3D dose distribution-based optimization. It is a promising approach for realizing automated treatment planning in the future.","3":"Medical physics","4":"30383300","5":"2018","6":"radiotherapy"},{"1":"Automatic treatment planning based on three-dimensional dose distribution predicted from deep learning technique.","2":"PURPOSE: To develop an automated treatment planning strategy for external beam intensity-modulated radiation therapy (IMRT), including a deep learning-based three-dimensional (3D) dose prediction and a dose distribution-based plan generation algorithm.METHODS AND MATERIALS: A residual neural network-based deep learning model is trained to predict a dose distribution based on patient-specific geometry and prescription dose. A total of 270 head-and-neck cancer cases were enrolled in this study, including 195 cases in the training dataset, 25 cases in the validation dataset, and 50 cases in the testing dataset. All patients were treated with IMRT with a variety of different prescription patterns. The model input consists of CT images and contours delineating the organs at risk (OARs) and planning target volumes (PTVs). The algorithm output is trained to predict the dose distribution on the CT image slices. The obtained prediction model is used to predict dose distributions for new patients. Then, an optimization objective function based on these predicted dose distributions is created for automatic plan generation.CONCLUSION: This study developed a new automated radiotherapy treatment planning system based on 3D dose prediction and 3D dose distribution-based optimization. It is a promising approach for realizing automated treatment planning in the future.","3":"Medical physics","4":"30383300","5":"2018","6":"Humans"},{"1":"Automatic treatment planning based on three-dimensional dose distribution predicted from deep learning technique.","2":"PURPOSE: To develop an automated treatment planning strategy for external beam intensity-modulated radiation therapy (IMRT), including a deep learning-based three-dimensional (3D) dose prediction and a dose distribution-based plan generation algorithm.METHODS AND MATERIALS: A residual neural network-based deep learning model is trained to predict a dose distribution based on patient-specific geometry and prescription dose. A total of 270 head-and-neck cancer cases were enrolled in this study, including 195 cases in the training dataset, 25 cases in the validation dataset, and 50 cases in the testing dataset. All patients were treated with IMRT with a variety of different prescription patterns. The model input consists of CT images and contours delineating the organs at risk (OARs) and planning target volumes (PTVs). The algorithm output is trained to predict the dose distribution on the CT image slices. The obtained prediction model is used to predict dose distributions for new patients. Then, an optimization objective function based on these predicted dose distributions is created for automatic plan generation.CONCLUSION: This study developed a new automated radiotherapy treatment planning system based on 3D dose prediction and 3D dose distribution-based optimization. It is a promising approach for realizing automated treatment planning in the future.","3":"Medical physics","4":"30383300","5":"2018","6":"Radiation Dosage"},{"1":"Automatic treatment planning based on three-dimensional dose distribution predicted from deep learning technique.","2":"PURPOSE: To develop an automated treatment planning strategy for external beam intensity-modulated radiation therapy (IMRT), including a deep learning-based three-dimensional (3D) dose prediction and a dose distribution-based plan generation algorithm.METHODS AND MATERIALS: A residual neural network-based deep learning model is trained to predict a dose distribution based on patient-specific geometry and prescription dose. A total of 270 head-and-neck cancer cases were enrolled in this study, including 195 cases in the training dataset, 25 cases in the validation dataset, and 50 cases in the testing dataset. All patients were treated with IMRT with a variety of different prescription patterns. The model input consists of CT images and contours delineating the organs at risk (OARs) and planning target volumes (PTVs). The algorithm output is trained to predict the dose distribution on the CT image slices. The obtained prediction model is used to predict dose distributions for new patients. Then, an optimization objective function based on these predicted dose distributions is created for automatic plan generation.CONCLUSION: This study developed a new automated radiotherapy treatment planning system based on 3D dose prediction and 3D dose distribution-based optimization. It is a promising approach for realizing automated treatment planning in the future.","3":"Medical physics","4":"30383300","5":"2018","6":"Radiotherapy Dosage"},{"1":"Automatic treatment planning based on three-dimensional dose distribution predicted from deep learning technique.","2":"PURPOSE: To develop an automated treatment planning strategy for external beam intensity-modulated radiation therapy (IMRT), including a deep learning-based three-dimensional (3D) dose prediction and a dose distribution-based plan generation algorithm.METHODS AND MATERIALS: A residual neural network-based deep learning model is trained to predict a dose distribution based on patient-specific geometry and prescription dose. A total of 270 head-and-neck cancer cases were enrolled in this study, including 195 cases in the training dataset, 25 cases in the validation dataset, and 50 cases in the testing dataset. All patients were treated with IMRT with a variety of different prescription patterns. The model input consists of CT images and contours delineating the organs at risk (OARs) and planning target volumes (PTVs). The algorithm output is trained to predict the dose distribution on the CT image slices. The obtained prediction model is used to predict dose distributions for new patients. Then, an optimization objective function based on these predicted dose distributions is created for automatic plan generation.CONCLUSION: This study developed a new automated radiotherapy treatment planning system based on 3D dose prediction and 3D dose distribution-based optimization. It is a promising approach for realizing automated treatment planning in the future.","3":"Medical physics","4":"30383300","5":"2018","6":"Radiotherapy Planning, Computer-Assisted"},{"1":"Automatic treatment planning based on three-dimensional dose distribution predicted from deep learning technique.","2":"PURPOSE: To develop an automated treatment planning strategy for external beam intensity-modulated radiation therapy (IMRT), including a deep learning-based three-dimensional (3D) dose prediction and a dose distribution-based plan generation algorithm.METHODS AND MATERIALS: A residual neural network-based deep learning model is trained to predict a dose distribution based on patient-specific geometry and prescription dose. A total of 270 head-and-neck cancer cases were enrolled in this study, including 195 cases in the training dataset, 25 cases in the validation dataset, and 50 cases in the testing dataset. All patients were treated with IMRT with a variety of different prescription patterns. The model input consists of CT images and contours delineating the organs at risk (OARs) and planning target volumes (PTVs). The algorithm output is trained to predict the dose distribution on the CT image slices. The obtained prediction model is used to predict dose distributions for new patients. Then, an optimization objective function based on these predicted dose distributions is created for automatic plan generation.CONCLUSION: This study developed a new automated radiotherapy treatment planning system based on 3D dose prediction and 3D dose distribution-based optimization. It is a promising approach for realizing automated treatment planning in the future.","3":"Medical physics","4":"30383300","5":"2018","6":"methods"},{"1":"Automatic treatment planning based on three-dimensional dose distribution predicted from deep learning technique.","2":"PURPOSE: To develop an automated treatment planning strategy for external beam intensity-modulated radiation therapy (IMRT), including a deep learning-based three-dimensional (3D) dose prediction and a dose distribution-based plan generation algorithm.METHODS AND MATERIALS: A residual neural network-based deep learning model is trained to predict a dose distribution based on patient-specific geometry and prescription dose. A total of 270 head-and-neck cancer cases were enrolled in this study, including 195 cases in the training dataset, 25 cases in the validation dataset, and 50 cases in the testing dataset. All patients were treated with IMRT with a variety of different prescription patterns. The model input consists of CT images and contours delineating the organs at risk (OARs) and planning target volumes (PTVs). The algorithm output is trained to predict the dose distribution on the CT image slices. The obtained prediction model is used to predict dose distributions for new patients. Then, an optimization objective function based on these predicted dose distributions is created for automatic plan generation.CONCLUSION: This study developed a new automated radiotherapy treatment planning system based on 3D dose prediction and 3D dose distribution-based optimization. It is a promising approach for realizing automated treatment planning in the future.","3":"Medical physics","4":"30383300","5":"2018","6":"Radiotherapy, Intensity-Modulated"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"Algorithms"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"Antimalarials"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"chemistry"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"Enzyme Inhibitors"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"chemistry"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"Folic Acid Antagonists"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"chemistry"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"Machine Learning"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"Molecular Docking Simulation"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"Molecular Structure"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"Plasmodium falciparum"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"enzymology"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"Proguanil"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"chemistry"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"metabolism"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"pharmacology"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"Protein Binding"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"Quantitative Structure-Activity Relationship"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"Reproducibility of Results"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"Stereoisomerism"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"Substrate Specificity"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"Tetrahydrofolate Dehydrogenase"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"metabolism"},{"1":"Application of molecular docking and PSO-SVR intelligent approaches in antimalarial activity prediction of enantiomeric cycloguanil analogues.","2":"","3":"SAR and QSAR in environmental research","4":"30381963","5":"2018","6":"Triazines"},{"1":"NA","2":"","3":"Environmental pollution (Barking, Essex : 1987)","4":"30373037","5":"2018","6":"Air Pollutants"},{"1":"NA","2":"","3":"Environmental pollution (Barking, Essex : 1987)","4":"30373037","5":"2018","6":"analysis"},{"1":"NA","2":"","3":"Environmental pollution (Barking, Essex : 1987)","4":"30373037","5":"2018","6":"China"},{"1":"NA","2":"","3":"Environmental pollution (Barking, Essex : 1987)","4":"30373037","5":"2018","6":"Dust"},{"1":"NA","2":"","3":"Environmental pollution (Barking, Essex : 1987)","4":"30373037","5":"2018","6":"analysis"},{"1":"NA","2":"","3":"Environmental pollution (Barking, Essex : 1987)","4":"30373037","5":"2018","6":"Environmental Monitoring"},{"1":"NA","2":"","3":"Environmental pollution (Barking, Essex : 1987)","4":"30373037","5":"2018","6":"methods"},{"1":"NA","2":"","3":"Environmental pollution (Barking, Essex : 1987)","4":"30373037","5":"2018","6":"Environmental Pollution"},{"1":"NA","2":"","3":"Environmental pollution (Barking, Essex : 1987)","4":"30373037","5":"2018","6":"analysis"},{"1":"NA","2":"","3":"Environmental pollution (Barking, Essex : 1987)","4":"30373037","5":"2018","6":"Industry"},{"1":"NA","2":"","3":"Environmental pollution (Barking, Essex : 1987)","4":"30373037","5":"2018","6":"Magnetics"},{"1":"NA","2":"","3":"Environmental pollution (Barking, Essex : 1987)","4":"30373037","5":"2018","6":"Metals, Heavy"},{"1":"NA","2":"","3":"Environmental pollution (Barking, Essex : 1987)","4":"30373037","5":"2018","6":"analysis"},{"1":"NA","2":"","3":"Environmental pollution (Barking, Essex : 1987)","4":"30373037","5":"2018","6":"Particulate Matter"},{"1":"NA","2":"","3":"Environmental pollution (Barking, Essex : 1987)","4":"30373037","5":"2018","6":"analysis"},{"1":"NA","2":"","3":"Environmental pollution (Barking, Essex : 1987)","4":"30373037","5":"2018","6":"Plant Leaves"},{"1":"NA","2":"","3":"Environmental pollution (Barking, Essex : 1987)","4":"30373037","5":"2018","6":"chemistry"},{"1":"NA","2":"","3":"Environmental pollution (Barking, Essex : 1987)","4":"30373037","5":"2018","6":"Support Vector Machine"},{"1":"NA","2":"","3":"Environmental pollution (Barking, Essex : 1987)","4":"30373037","5":"2018","6":"Trees"},{"1":"Predicting diabetic retinopathy and identifying interpretable biomedical features using machine learning algorithms.","2":"BACKGROUND: The risk factors of diabetic retinopathy (DR) were investigated extensively in the past studies, but it remains unknown which risk factors were more associated with the DR than others. If we can detect the DR related risk factors more accurately, we can then exercise early prevention strategies for diabetic retinopathy in the most high-risk population. The purpose of this study is to build a prediction model for the DR in type 2 diabetes mellitus using data mining techniques including the support vector machines, decision trees, artificial neural networks, and logistic regressions.RESULTS: Experimental results demonstrated that prediction performance by support vector machines performed better than the other machine learning algorithms and achieved 79.5% and 0.839 in accuracy and area under the receiver operating characteristic curve using percentage split (i.e., data set divided into 80% as trainning and 20% as test), respectively. Evaluated by three-way data split scheme (i.e., data set divided into 60% as training, 20% as validation, and 20% as independent test), our method obtained slightly lower performance compared to percentage split, which suggested that three-way data split is a better way to evaluate the real performance and prevent overestimation. Moreover, we incorporated approaches proposed in previous studies to evaluate our data set and our prediction performance outperformed the other previous studies in most evaluation measures. This lends support to our assumption that appropriate machine learning algorithms combined with discriminative clinical features can effectively detect diabetic retinopathy.CONCLUSIONS: Our method identifies use of insulin and duration of diabetes as novel interpretable features to assist with clinical decisions in identifying the high-risk populations for diabetic retinopathy. If duration of DM increases by 1 year, the odds ratio to have DMR is increased by 9.3%. The odds ratio to have DR is increased by 3.561 times for patients who use insulin compared to patients who do not use insulin. Our results can be used to facilitate development of clinical decision support systems for clinical practice in the future.","3":"BMC bioinformatics","4":"30367589","5":"2018","6":"Adult"},{"1":"Predicting diabetic retinopathy and identifying interpretable biomedical features using machine learning algorithms.","2":"BACKGROUND: The risk factors of diabetic retinopathy (DR) were investigated extensively in the past studies, but it remains unknown which risk factors were more associated with the DR than others. If we can detect the DR related risk factors more accurately, we can then exercise early prevention strategies for diabetic retinopathy in the most high-risk population. The purpose of this study is to build a prediction model for the DR in type 2 diabetes mellitus using data mining techniques including the support vector machines, decision trees, artificial neural networks, and logistic regressions.RESULTS: Experimental results demonstrated that prediction performance by support vector machines performed better than the other machine learning algorithms and achieved 79.5% and 0.839 in accuracy and area under the receiver operating characteristic curve using percentage split (i.e., data set divided into 80% as trainning and 20% as test), respectively. Evaluated by three-way data split scheme (i.e., data set divided into 60% as training, 20% as validation, and 20% as independent test), our method obtained slightly lower performance compared to percentage split, which suggested that three-way data split is a better way to evaluate the real performance and prevent overestimation. Moreover, we incorporated approaches proposed in previous studies to evaluate our data set and our prediction performance outperformed the other previous studies in most evaluation measures. This lends support to our assumption that appropriate machine learning algorithms combined with discriminative clinical features can effectively detect diabetic retinopathy.CONCLUSIONS: Our method identifies use of insulin and duration of diabetes as novel interpretable features to assist with clinical decisions in identifying the high-risk populations for diabetic retinopathy. If duration of DM increases by 1 year, the odds ratio to have DMR is increased by 9.3%. The odds ratio to have DR is increased by 3.561 times for patients who use insulin compared to patients who do not use insulin. Our results can be used to facilitate development of clinical decision support systems for clinical practice in the future.","3":"BMC bioinformatics","4":"30367589","5":"2018","6":"Aged"},{"1":"Predicting diabetic retinopathy and identifying interpretable biomedical features using machine learning algorithms.","2":"BACKGROUND: The risk factors of diabetic retinopathy (DR) were investigated extensively in the past studies, but it remains unknown which risk factors were more associated with the DR than others. If we can detect the DR related risk factors more accurately, we can then exercise early prevention strategies for diabetic retinopathy in the most high-risk population. The purpose of this study is to build a prediction model for the DR in type 2 diabetes mellitus using data mining techniques including the support vector machines, decision trees, artificial neural networks, and logistic regressions.RESULTS: Experimental results demonstrated that prediction performance by support vector machines performed better than the other machine learning algorithms and achieved 79.5% and 0.839 in accuracy and area under the receiver operating characteristic curve using percentage split (i.e., data set divided into 80% as trainning and 20% as test), respectively. Evaluated by three-way data split scheme (i.e., data set divided into 60% as training, 20% as validation, and 20% as independent test), our method obtained slightly lower performance compared to percentage split, which suggested that three-way data split is a better way to evaluate the real performance and prevent overestimation. Moreover, we incorporated approaches proposed in previous studies to evaluate our data set and our prediction performance outperformed the other previous studies in most evaluation measures. This lends support to our assumption that appropriate machine learning algorithms combined with discriminative clinical features can effectively detect diabetic retinopathy.CONCLUSIONS: Our method identifies use of insulin and duration of diabetes as novel interpretable features to assist with clinical decisions in identifying the high-risk populations for diabetic retinopathy. If duration of DM increases by 1 year, the odds ratio to have DMR is increased by 9.3%. The odds ratio to have DR is increased by 3.561 times for patients who use insulin compared to patients who do not use insulin. Our results can be used to facilitate development of clinical decision support systems for clinical practice in the future.","3":"BMC bioinformatics","4":"30367589","5":"2018","6":"Aged, 80 and over"},{"1":"Predicting diabetic retinopathy and identifying interpretable biomedical features using machine learning algorithms.","2":"BACKGROUND: The risk factors of diabetic retinopathy (DR) were investigated extensively in the past studies, but it remains unknown which risk factors were more associated with the DR than others. If we can detect the DR related risk factors more accurately, we can then exercise early prevention strategies for diabetic retinopathy in the most high-risk population. The purpose of this study is to build a prediction model for the DR in type 2 diabetes mellitus using data mining techniques including the support vector machines, decision trees, artificial neural networks, and logistic regressions.RESULTS: Experimental results demonstrated that prediction performance by support vector machines performed better than the other machine learning algorithms and achieved 79.5% and 0.839 in accuracy and area under the receiver operating characteristic curve using percentage split (i.e., data set divided into 80% as trainning and 20% as test), respectively. Evaluated by three-way data split scheme (i.e., data set divided into 60% as training, 20% as validation, and 20% as independent test), our method obtained slightly lower performance compared to percentage split, which suggested that three-way data split is a better way to evaluate the real performance and prevent overestimation. Moreover, we incorporated approaches proposed in previous studies to evaluate our data set and our prediction performance outperformed the other previous studies in most evaluation measures. This lends support to our assumption that appropriate machine learning algorithms combined with discriminative clinical features can effectively detect diabetic retinopathy.CONCLUSIONS: Our method identifies use of insulin and duration of diabetes as novel interpretable features to assist with clinical decisions in identifying the high-risk populations for diabetic retinopathy. If duration of DM increases by 1 year, the odds ratio to have DMR is increased by 9.3%. The odds ratio to have DR is increased by 3.561 times for patients who use insulin compared to patients who do not use insulin. Our results can be used to facilitate development of clinical decision support systems for clinical practice in the future.","3":"BMC bioinformatics","4":"30367589","5":"2018","6":"Algorithms"},{"1":"Predicting diabetic retinopathy and identifying interpretable biomedical features using machine learning algorithms.","2":"BACKGROUND: The risk factors of diabetic retinopathy (DR) were investigated extensively in the past studies, but it remains unknown which risk factors were more associated with the DR than others. If we can detect the DR related risk factors more accurately, we can then exercise early prevention strategies for diabetic retinopathy in the most high-risk population. The purpose of this study is to build a prediction model for the DR in type 2 diabetes mellitus using data mining techniques including the support vector machines, decision trees, artificial neural networks, and logistic regressions.RESULTS: Experimental results demonstrated that prediction performance by support vector machines performed better than the other machine learning algorithms and achieved 79.5% and 0.839 in accuracy and area under the receiver operating characteristic curve using percentage split (i.e., data set divided into 80% as trainning and 20% as test), respectively. Evaluated by three-way data split scheme (i.e., data set divided into 60% as training, 20% as validation, and 20% as independent test), our method obtained slightly lower performance compared to percentage split, which suggested that three-way data split is a better way to evaluate the real performance and prevent overestimation. Moreover, we incorporated approaches proposed in previous studies to evaluate our data set and our prediction performance outperformed the other previous studies in most evaluation measures. This lends support to our assumption that appropriate machine learning algorithms combined with discriminative clinical features can effectively detect diabetic retinopathy.CONCLUSIONS: Our method identifies use of insulin and duration of diabetes as novel interpretable features to assist with clinical decisions in identifying the high-risk populations for diabetic retinopathy. If duration of DM increases by 1 year, the odds ratio to have DMR is increased by 9.3%. The odds ratio to have DR is increased by 3.561 times for patients who use insulin compared to patients who do not use insulin. Our results can be used to facilitate development of clinical decision support systems for clinical practice in the future.","3":"BMC bioinformatics","4":"30367589","5":"2018","6":"Decision Support Systems, Clinical"},{"1":"Predicting diabetic retinopathy and identifying interpretable biomedical features using machine learning algorithms.","2":"BACKGROUND: The risk factors of diabetic retinopathy (DR) were investigated extensively in the past studies, but it remains unknown which risk factors were more associated with the DR than others. If we can detect the DR related risk factors more accurately, we can then exercise early prevention strategies for diabetic retinopathy in the most high-risk population. The purpose of this study is to build a prediction model for the DR in type 2 diabetes mellitus using data mining techniques including the support vector machines, decision trees, artificial neural networks, and logistic regressions.RESULTS: Experimental results demonstrated that prediction performance by support vector machines performed better than the other machine learning algorithms and achieved 79.5% and 0.839 in accuracy and area under the receiver operating characteristic curve using percentage split (i.e., data set divided into 80% as trainning and 20% as test), respectively. Evaluated by three-way data split scheme (i.e., data set divided into 60% as training, 20% as validation, and 20% as independent test), our method obtained slightly lower performance compared to percentage split, which suggested that three-way data split is a better way to evaluate the real performance and prevent overestimation. Moreover, we incorporated approaches proposed in previous studies to evaluate our data set and our prediction performance outperformed the other previous studies in most evaluation measures. This lends support to our assumption that appropriate machine learning algorithms combined with discriminative clinical features can effectively detect diabetic retinopathy.CONCLUSIONS: Our method identifies use of insulin and duration of diabetes as novel interpretable features to assist with clinical decisions in identifying the high-risk populations for diabetic retinopathy. If duration of DM increases by 1 year, the odds ratio to have DMR is increased by 9.3%. The odds ratio to have DR is increased by 3.561 times for patients who use insulin compared to patients who do not use insulin. Our results can be used to facilitate development of clinical decision support systems for clinical practice in the future.","3":"BMC bioinformatics","4":"30367589","5":"2018","6":"Diabetes Mellitus, Type 2"},{"1":"Predicting diabetic retinopathy and identifying interpretable biomedical features using machine learning algorithms.","2":"BACKGROUND: The risk factors of diabetic retinopathy (DR) were investigated extensively in the past studies, but it remains unknown which risk factors were more associated with the DR than others. If we can detect the DR related risk factors more accurately, we can then exercise early prevention strategies for diabetic retinopathy in the most high-risk population. The purpose of this study is to build a prediction model for the DR in type 2 diabetes mellitus using data mining techniques including the support vector machines, decision trees, artificial neural networks, and logistic regressions.RESULTS: Experimental results demonstrated that prediction performance by support vector machines performed better than the other machine learning algorithms and achieved 79.5% and 0.839 in accuracy and area under the receiver operating characteristic curve using percentage split (i.e., data set divided into 80% as trainning and 20% as test), respectively. Evaluated by three-way data split scheme (i.e., data set divided into 60% as training, 20% as validation, and 20% as independent test), our method obtained slightly lower performance compared to percentage split, which suggested that three-way data split is a better way to evaluate the real performance and prevent overestimation. Moreover, we incorporated approaches proposed in previous studies to evaluate our data set and our prediction performance outperformed the other previous studies in most evaluation measures. This lends support to our assumption that appropriate machine learning algorithms combined with discriminative clinical features can effectively detect diabetic retinopathy.CONCLUSIONS: Our method identifies use of insulin and duration of diabetes as novel interpretable features to assist with clinical decisions in identifying the high-risk populations for diabetic retinopathy. If duration of DM increases by 1 year, the odds ratio to have DMR is increased by 9.3%. The odds ratio to have DR is increased by 3.561 times for patients who use insulin compared to patients who do not use insulin. Our results can be used to facilitate development of clinical decision support systems for clinical practice in the future.","3":"BMC bioinformatics","4":"30367589","5":"2018","6":"complications"},{"1":"Predicting diabetic retinopathy and identifying interpretable biomedical features using machine learning algorithms.","2":"BACKGROUND: The risk factors of diabetic retinopathy (DR) were investigated extensively in the past studies, but it remains unknown which risk factors were more associated with the DR than others. If we can detect the DR related risk factors more accurately, we can then exercise early prevention strategies for diabetic retinopathy in the most high-risk population. The purpose of this study is to build a prediction model for the DR in type 2 diabetes mellitus using data mining techniques including the support vector machines, decision trees, artificial neural networks, and logistic regressions.RESULTS: Experimental results demonstrated that prediction performance by support vector machines performed better than the other machine learning algorithms and achieved 79.5% and 0.839 in accuracy and area under the receiver operating characteristic curve using percentage split (i.e., data set divided into 80% as trainning and 20% as test), respectively. Evaluated by three-way data split scheme (i.e., data set divided into 60% as training, 20% as validation, and 20% as independent test), our method obtained slightly lower performance compared to percentage split, which suggested that three-way data split is a better way to evaluate the real performance and prevent overestimation. Moreover, we incorporated approaches proposed in previous studies to evaluate our data set and our prediction performance outperformed the other previous studies in most evaluation measures. This lends support to our assumption that appropriate machine learning algorithms combined with discriminative clinical features can effectively detect diabetic retinopathy.CONCLUSIONS: Our method identifies use of insulin and duration of diabetes as novel interpretable features to assist with clinical decisions in identifying the high-risk populations for diabetic retinopathy. If duration of DM increases by 1 year, the odds ratio to have DMR is increased by 9.3%. The odds ratio to have DR is increased by 3.561 times for patients who use insulin compared to patients who do not use insulin. Our results can be used to facilitate development of clinical decision support systems for clinical practice in the future.","3":"BMC bioinformatics","4":"30367589","5":"2018","6":"Diabetic Retinopathy"},{"1":"Predicting diabetic retinopathy and identifying interpretable biomedical features using machine learning algorithms.","2":"BACKGROUND: The risk factors of diabetic retinopathy (DR) were investigated extensively in the past studies, but it remains unknown which risk factors were more associated with the DR than others. If we can detect the DR related risk factors more accurately, we can then exercise early prevention strategies for diabetic retinopathy in the most high-risk population. The purpose of this study is to build a prediction model for the DR in type 2 diabetes mellitus using data mining techniques including the support vector machines, decision trees, artificial neural networks, and logistic regressions.RESULTS: Experimental results demonstrated that prediction performance by support vector machines performed better than the other machine learning algorithms and achieved 79.5% and 0.839 in accuracy and area under the receiver operating characteristic curve using percentage split (i.e., data set divided into 80% as trainning and 20% as test), respectively. Evaluated by three-way data split scheme (i.e., data set divided into 60% as training, 20% as validation, and 20% as independent test), our method obtained slightly lower performance compared to percentage split, which suggested that three-way data split is a better way to evaluate the real performance and prevent overestimation. Moreover, we incorporated approaches proposed in previous studies to evaluate our data set and our prediction performance outperformed the other previous studies in most evaluation measures. This lends support to our assumption that appropriate machine learning algorithms combined with discriminative clinical features can effectively detect diabetic retinopathy.CONCLUSIONS: Our method identifies use of insulin and duration of diabetes as novel interpretable features to assist with clinical decisions in identifying the high-risk populations for diabetic retinopathy. If duration of DM increases by 1 year, the odds ratio to have DMR is increased by 9.3%. The odds ratio to have DR is increased by 3.561 times for patients who use insulin compared to patients who do not use insulin. Our results can be used to facilitate development of clinical decision support systems for clinical practice in the future.","3":"BMC bioinformatics","4":"30367589","5":"2018","6":"diagnosis"},{"1":"Predicting diabetic retinopathy and identifying interpretable biomedical features using machine learning algorithms.","2":"BACKGROUND: The risk factors of diabetic retinopathy (DR) were investigated extensively in the past studies, but it remains unknown which risk factors were more associated with the DR than others. If we can detect the DR related risk factors more accurately, we can then exercise early prevention strategies for diabetic retinopathy in the most high-risk population. The purpose of this study is to build a prediction model for the DR in type 2 diabetes mellitus using data mining techniques including the support vector machines, decision trees, artificial neural networks, and logistic regressions.RESULTS: Experimental results demonstrated that prediction performance by support vector machines performed better than the other machine learning algorithms and achieved 79.5% and 0.839 in accuracy and area under the receiver operating characteristic curve using percentage split (i.e., data set divided into 80% as trainning and 20% as test), respectively. Evaluated by three-way data split scheme (i.e., data set divided into 60% as training, 20% as validation, and 20% as independent test), our method obtained slightly lower performance compared to percentage split, which suggested that three-way data split is a better way to evaluate the real performance and prevent overestimation. Moreover, we incorporated approaches proposed in previous studies to evaluate our data set and our prediction performance outperformed the other previous studies in most evaluation measures. This lends support to our assumption that appropriate machine learning algorithms combined with discriminative clinical features can effectively detect diabetic retinopathy.CONCLUSIONS: Our method identifies use of insulin and duration of diabetes as novel interpretable features to assist with clinical decisions in identifying the high-risk populations for diabetic retinopathy. If duration of DM increases by 1 year, the odds ratio to have DMR is increased by 9.3%. The odds ratio to have DR is increased by 3.561 times for patients who use insulin compared to patients who do not use insulin. Our results can be used to facilitate development of clinical decision support systems for clinical practice in the future.","3":"BMC bioinformatics","4":"30367589","5":"2018","6":"etiology"},{"1":"Predicting diabetic retinopathy and identifying interpretable biomedical features using machine learning algorithms.","2":"BACKGROUND: The risk factors of diabetic retinopathy (DR) were investigated extensively in the past studies, but it remains unknown which risk factors were more associated with the DR than others. If we can detect the DR related risk factors more accurately, we can then exercise early prevention strategies for diabetic retinopathy in the most high-risk population. The purpose of this study is to build a prediction model for the DR in type 2 diabetes mellitus using data mining techniques including the support vector machines, decision trees, artificial neural networks, and logistic regressions.RESULTS: Experimental results demonstrated that prediction performance by support vector machines performed better than the other machine learning algorithms and achieved 79.5% and 0.839 in accuracy and area under the receiver operating characteristic curve using percentage split (i.e., data set divided into 80% as trainning and 20% as test), respectively. Evaluated by three-way data split scheme (i.e., data set divided into 60% as training, 20% as validation, and 20% as independent test), our method obtained slightly lower performance compared to percentage split, which suggested that three-way data split is a better way to evaluate the real performance and prevent overestimation. Moreover, we incorporated approaches proposed in previous studies to evaluate our data set and our prediction performance outperformed the other previous studies in most evaluation measures. This lends support to our assumption that appropriate machine learning algorithms combined with discriminative clinical features can effectively detect diabetic retinopathy.CONCLUSIONS: Our method identifies use of insulin and duration of diabetes as novel interpretable features to assist with clinical decisions in identifying the high-risk populations for diabetic retinopathy. If duration of DM increases by 1 year, the odds ratio to have DMR is increased by 9.3%. The odds ratio to have DR is increased by 3.561 times for patients who use insulin compared to patients who do not use insulin. Our results can be used to facilitate development of clinical decision support systems for clinical practice in the future.","3":"BMC bioinformatics","4":"30367589","5":"2018","6":"Female"},{"1":"Predicting diabetic retinopathy and identifying interpretable biomedical features using machine learning algorithms.","2":"BACKGROUND: The risk factors of diabetic retinopathy (DR) were investigated extensively in the past studies, but it remains unknown which risk factors were more associated with the DR than others. If we can detect the DR related risk factors more accurately, we can then exercise early prevention strategies for diabetic retinopathy in the most high-risk population. The purpose of this study is to build a prediction model for the DR in type 2 diabetes mellitus using data mining techniques including the support vector machines, decision trees, artificial neural networks, and logistic regressions.RESULTS: Experimental results demonstrated that prediction performance by support vector machines performed better than the other machine learning algorithms and achieved 79.5% and 0.839 in accuracy and area under the receiver operating characteristic curve using percentage split (i.e., data set divided into 80% as trainning and 20% as test), respectively. Evaluated by three-way data split scheme (i.e., data set divided into 60% as training, 20% as validation, and 20% as independent test), our method obtained slightly lower performance compared to percentage split, which suggested that three-way data split is a better way to evaluate the real performance and prevent overestimation. Moreover, we incorporated approaches proposed in previous studies to evaluate our data set and our prediction performance outperformed the other previous studies in most evaluation measures. This lends support to our assumption that appropriate machine learning algorithms combined with discriminative clinical features can effectively detect diabetic retinopathy.CONCLUSIONS: Our method identifies use of insulin and duration of diabetes as novel interpretable features to assist with clinical decisions in identifying the high-risk populations for diabetic retinopathy. If duration of DM increases by 1 year, the odds ratio to have DMR is increased by 9.3%. The odds ratio to have DR is increased by 3.561 times for patients who use insulin compared to patients who do not use insulin. Our results can be used to facilitate development of clinical decision support systems for clinical practice in the future.","3":"BMC bioinformatics","4":"30367589","5":"2018","6":"Humans"},{"1":"Predicting diabetic retinopathy and identifying interpretable biomedical features using machine learning algorithms.","2":"BACKGROUND: The risk factors of diabetic retinopathy (DR) were investigated extensively in the past studies, but it remains unknown which risk factors were more associated with the DR than others. If we can detect the DR related risk factors more accurately, we can then exercise early prevention strategies for diabetic retinopathy in the most high-risk population. The purpose of this study is to build a prediction model for the DR in type 2 diabetes mellitus using data mining techniques including the support vector machines, decision trees, artificial neural networks, and logistic regressions.RESULTS: Experimental results demonstrated that prediction performance by support vector machines performed better than the other machine learning algorithms and achieved 79.5% and 0.839 in accuracy and area under the receiver operating characteristic curve using percentage split (i.e., data set divided into 80% as trainning and 20% as test), respectively. Evaluated by three-way data split scheme (i.e., data set divided into 60% as training, 20% as validation, and 20% as independent test), our method obtained slightly lower performance compared to percentage split, which suggested that three-way data split is a better way to evaluate the real performance and prevent overestimation. Moreover, we incorporated approaches proposed in previous studies to evaluate our data set and our prediction performance outperformed the other previous studies in most evaluation measures. This lends support to our assumption that appropriate machine learning algorithms combined with discriminative clinical features can effectively detect diabetic retinopathy.CONCLUSIONS: Our method identifies use of insulin and duration of diabetes as novel interpretable features to assist with clinical decisions in identifying the high-risk populations for diabetic retinopathy. If duration of DM increases by 1 year, the odds ratio to have DMR is increased by 9.3%. The odds ratio to have DR is increased by 3.561 times for patients who use insulin compared to patients who do not use insulin. Our results can be used to facilitate development of clinical decision support systems for clinical practice in the future.","3":"BMC bioinformatics","4":"30367589","5":"2018","6":"Machine Learning"},{"1":"Predicting diabetic retinopathy and identifying interpretable biomedical features using machine learning algorithms.","2":"BACKGROUND: The risk factors of diabetic retinopathy (DR) were investigated extensively in the past studies, but it remains unknown which risk factors were more associated with the DR than others. If we can detect the DR related risk factors more accurately, we can then exercise early prevention strategies for diabetic retinopathy in the most high-risk population. The purpose of this study is to build a prediction model for the DR in type 2 diabetes mellitus using data mining techniques including the support vector machines, decision trees, artificial neural networks, and logistic regressions.RESULTS: Experimental results demonstrated that prediction performance by support vector machines performed better than the other machine learning algorithms and achieved 79.5% and 0.839 in accuracy and area under the receiver operating characteristic curve using percentage split (i.e., data set divided into 80% as trainning and 20% as test), respectively. Evaluated by three-way data split scheme (i.e., data set divided into 60% as training, 20% as validation, and 20% as independent test), our method obtained slightly lower performance compared to percentage split, which suggested that three-way data split is a better way to evaluate the real performance and prevent overestimation. Moreover, we incorporated approaches proposed in previous studies to evaluate our data set and our prediction performance outperformed the other previous studies in most evaluation measures. This lends support to our assumption that appropriate machine learning algorithms combined with discriminative clinical features can effectively detect diabetic retinopathy.CONCLUSIONS: Our method identifies use of insulin and duration of diabetes as novel interpretable features to assist with clinical decisions in identifying the high-risk populations for diabetic retinopathy. If duration of DM increases by 1 year, the odds ratio to have DMR is increased by 9.3%. The odds ratio to have DR is increased by 3.561 times for patients who use insulin compared to patients who do not use insulin. Our results can be used to facilitate development of clinical decision support systems for clinical practice in the future.","3":"BMC bioinformatics","4":"30367589","5":"2018","6":"Male"},{"1":"Predicting diabetic retinopathy and identifying interpretable biomedical features using machine learning algorithms.","2":"BACKGROUND: The risk factors of diabetic retinopathy (DR) were investigated extensively in the past studies, but it remains unknown which risk factors were more associated with the DR than others. If we can detect the DR related risk factors more accurately, we can then exercise early prevention strategies for diabetic retinopathy in the most high-risk population. The purpose of this study is to build a prediction model for the DR in type 2 diabetes mellitus using data mining techniques including the support vector machines, decision trees, artificial neural networks, and logistic regressions.RESULTS: Experimental results demonstrated that prediction performance by support vector machines performed better than the other machine learning algorithms and achieved 79.5% and 0.839 in accuracy and area under the receiver operating characteristic curve using percentage split (i.e., data set divided into 80% as trainning and 20% as test), respectively. Evaluated by three-way data split scheme (i.e., data set divided into 60% as training, 20% as validation, and 20% as independent test), our method obtained slightly lower performance compared to percentage split, which suggested that three-way data split is a better way to evaluate the real performance and prevent overestimation. Moreover, we incorporated approaches proposed in previous studies to evaluate our data set and our prediction performance outperformed the other previous studies in most evaluation measures. This lends support to our assumption that appropriate machine learning algorithms combined with discriminative clinical features can effectively detect diabetic retinopathy.CONCLUSIONS: Our method identifies use of insulin and duration of diabetes as novel interpretable features to assist with clinical decisions in identifying the high-risk populations for diabetic retinopathy. If duration of DM increases by 1 year, the odds ratio to have DMR is increased by 9.3%. The odds ratio to have DR is increased by 3.561 times for patients who use insulin compared to patients who do not use insulin. Our results can be used to facilitate development of clinical decision support systems for clinical practice in the future.","3":"BMC bioinformatics","4":"30367589","5":"2018","6":"Middle Aged"},{"1":"Predicting diabetic retinopathy and identifying interpretable biomedical features using machine learning algorithms.","2":"BACKGROUND: The risk factors of diabetic retinopathy (DR) were investigated extensively in the past studies, but it remains unknown which risk factors were more associated with the DR than others. If we can detect the DR related risk factors more accurately, we can then exercise early prevention strategies for diabetic retinopathy in the most high-risk population. The purpose of this study is to build a prediction model for the DR in type 2 diabetes mellitus using data mining techniques including the support vector machines, decision trees, artificial neural networks, and logistic regressions.RESULTS: Experimental results demonstrated that prediction performance by support vector machines performed better than the other machine learning algorithms and achieved 79.5% and 0.839 in accuracy and area under the receiver operating characteristic curve using percentage split (i.e., data set divided into 80% as trainning and 20% as test), respectively. Evaluated by three-way data split scheme (i.e., data set divided into 60% as training, 20% as validation, and 20% as independent test), our method obtained slightly lower performance compared to percentage split, which suggested that three-way data split is a better way to evaluate the real performance and prevent overestimation. Moreover, we incorporated approaches proposed in previous studies to evaluate our data set and our prediction performance outperformed the other previous studies in most evaluation measures. This lends support to our assumption that appropriate machine learning algorithms combined with discriminative clinical features can effectively detect diabetic retinopathy.CONCLUSIONS: Our method identifies use of insulin and duration of diabetes as novel interpretable features to assist with clinical decisions in identifying the high-risk populations for diabetic retinopathy. If duration of DM increases by 1 year, the odds ratio to have DMR is increased by 9.3%. The odds ratio to have DR is increased by 3.561 times for patients who use insulin compared to patients who do not use insulin. Our results can be used to facilitate development of clinical decision support systems for clinical practice in the future.","3":"BMC bioinformatics","4":"30367589","5":"2018","6":"Neural Networks (Computer)"},{"1":"Predicting diabetic retinopathy and identifying interpretable biomedical features using machine learning algorithms.","2":"BACKGROUND: The risk factors of diabetic retinopathy (DR) were investigated extensively in the past studies, but it remains unknown which risk factors were more associated with the DR than others. If we can detect the DR related risk factors more accurately, we can then exercise early prevention strategies for diabetic retinopathy in the most high-risk population. The purpose of this study is to build a prediction model for the DR in type 2 diabetes mellitus using data mining techniques including the support vector machines, decision trees, artificial neural networks, and logistic regressions.RESULTS: Experimental results demonstrated that prediction performance by support vector machines performed better than the other machine learning algorithms and achieved 79.5% and 0.839 in accuracy and area under the receiver operating characteristic curve using percentage split (i.e., data set divided into 80% as trainning and 20% as test), respectively. Evaluated by three-way data split scheme (i.e., data set divided into 60% as training, 20% as validation, and 20% as independent test), our method obtained slightly lower performance compared to percentage split, which suggested that three-way data split is a better way to evaluate the real performance and prevent overestimation. Moreover, we incorporated approaches proposed in previous studies to evaluate our data set and our prediction performance outperformed the other previous studies in most evaluation measures. This lends support to our assumption that appropriate machine learning algorithms combined with discriminative clinical features can effectively detect diabetic retinopathy.CONCLUSIONS: Our method identifies use of insulin and duration of diabetes as novel interpretable features to assist with clinical decisions in identifying the high-risk populations for diabetic retinopathy. If duration of DM increases by 1 year, the odds ratio to have DMR is increased by 9.3%. The odds ratio to have DR is increased by 3.561 times for patients who use insulin compared to patients who do not use insulin. Our results can be used to facilitate development of clinical decision support systems for clinical practice in the future.","3":"BMC bioinformatics","4":"30367589","5":"2018","6":"ROC Curve"},{"1":"Predicting diabetic retinopathy and identifying interpretable biomedical features using machine learning algorithms.","2":"BACKGROUND: The risk factors of diabetic retinopathy (DR) were investigated extensively in the past studies, but it remains unknown which risk factors were more associated with the DR than others. If we can detect the DR related risk factors more accurately, we can then exercise early prevention strategies for diabetic retinopathy in the most high-risk population. The purpose of this study is to build a prediction model for the DR in type 2 diabetes mellitus using data mining techniques including the support vector machines, decision trees, artificial neural networks, and logistic regressions.RESULTS: Experimental results demonstrated that prediction performance by support vector machines performed better than the other machine learning algorithms and achieved 79.5% and 0.839 in accuracy and area under the receiver operating characteristic curve using percentage split (i.e., data set divided into 80% as trainning and 20% as test), respectively. Evaluated by three-way data split scheme (i.e., data set divided into 60% as training, 20% as validation, and 20% as independent test), our method obtained slightly lower performance compared to percentage split, which suggested that three-way data split is a better way to evaluate the real performance and prevent overestimation. Moreover, we incorporated approaches proposed in previous studies to evaluate our data set and our prediction performance outperformed the other previous studies in most evaluation measures. This lends support to our assumption that appropriate machine learning algorithms combined with discriminative clinical features can effectively detect diabetic retinopathy.CONCLUSIONS: Our method identifies use of insulin and duration of diabetes as novel interpretable features to assist with clinical decisions in identifying the high-risk populations for diabetic retinopathy. If duration of DM increases by 1 year, the odds ratio to have DMR is increased by 9.3%. The odds ratio to have DR is increased by 3.561 times for patients who use insulin compared to patients who do not use insulin. Our results can be used to facilitate development of clinical decision support systems for clinical practice in the future.","3":"BMC bioinformatics","4":"30367589","5":"2018","6":"Risk Factors"},{"1":"An infrastructure for precision medicine through analysis of big data.","2":"BACKGROUND: Nowadays, the increasing availability of omics data, due to both the advancements in the acquisition of molecular biology results and in systems biology simulation technologies, provides the bases for precision medicine. Success in precision medicine depends on the access to healthcare and biomedical data. To this end, the digitization of all clinical exams and medical records is becoming a standard in hospitals. The digitization is essential to collect, share, and aggregate large volumes of heterogeneous data to support the discovery of hidden patterns with the aim to define predictive models for biomedical purposes. Patients' data sharing is a critical process. In fact, it raises ethical, social, legal, and technological issues that must be properly addressed.RESULTS: In this work, we present an infrastructure devised to deal with the integration of large volumes of heterogeneous biological data. The infrastructure was applied to the data collected between 2010-2016 in one of the major diagnostic analysis laboratories in Italy. Data from three different platforms were collected (i.e., laboratory exams, pathological anatomy exams, biopsy exams). The infrastructure has been designed to allow the extraction and aggregation of both unstructured and semi-structured data. Data are properly treated to ensure data security and privacy. Specialized algorithms have also been implemented to process the aggregated information with the aim to obtain a precise historical analysis of the clinical activities of one or more patients. Moreover, three Bayesian classifiers have been developed to analyze examinations reported as free text. Experimental results show that the classifiers exhibit a good accuracy when used to analyze sentences related to the sample location, diseases presence and status of the illnesses.CONCLUSIONS: The infrastructure allows the integration of multiple and heterogeneous sources of anonymized data from the different clinical platforms. Both unstructured and semi-structured data are processed to obtain a precise historical analysis of the clinical activities of one or more patients. Data aggregation allows to perform a series of statistical assessments required to answer complex questions that can be used in a variety of fields, such as predictive and precision medicine. In particular, studying the clinical history of patients that have developed similar pathologies can help to predict or individuate markers able to allow an early diagnosis of possible illnesses.","3":"BMC bioinformatics","4":"30367571","5":"2018","6":"Algorithms"},{"1":"An infrastructure for precision medicine through analysis of big data.","2":"BACKGROUND: Nowadays, the increasing availability of omics data, due to both the advancements in the acquisition of molecular biology results and in systems biology simulation technologies, provides the bases for precision medicine. Success in precision medicine depends on the access to healthcare and biomedical data. To this end, the digitization of all clinical exams and medical records is becoming a standard in hospitals. The digitization is essential to collect, share, and aggregate large volumes of heterogeneous data to support the discovery of hidden patterns with the aim to define predictive models for biomedical purposes. Patients' data sharing is a critical process. In fact, it raises ethical, social, legal, and technological issues that must be properly addressed.RESULTS: In this work, we present an infrastructure devised to deal with the integration of large volumes of heterogeneous biological data. The infrastructure was applied to the data collected between 2010-2016 in one of the major diagnostic analysis laboratories in Italy. Data from three different platforms were collected (i.e., laboratory exams, pathological anatomy exams, biopsy exams). The infrastructure has been designed to allow the extraction and aggregation of both unstructured and semi-structured data. Data are properly treated to ensure data security and privacy. Specialized algorithms have also been implemented to process the aggregated information with the aim to obtain a precise historical analysis of the clinical activities of one or more patients. Moreover, three Bayesian classifiers have been developed to analyze examinations reported as free text. Experimental results show that the classifiers exhibit a good accuracy when used to analyze sentences related to the sample location, diseases presence and status of the illnesses.CONCLUSIONS: The infrastructure allows the integration of multiple and heterogeneous sources of anonymized data from the different clinical platforms. Both unstructured and semi-structured data are processed to obtain a precise historical analysis of the clinical activities of one or more patients. Data aggregation allows to perform a series of statistical assessments required to answer complex questions that can be used in a variety of fields, such as predictive and precision medicine. In particular, studying the clinical history of patients that have developed similar pathologies can help to predict or individuate markers able to allow an early diagnosis of possible illnesses.","3":"BMC bioinformatics","4":"30367571","5":"2018","6":"Bayes Theorem"},{"1":"An infrastructure for precision medicine through analysis of big data.","2":"BACKGROUND: Nowadays, the increasing availability of omics data, due to both the advancements in the acquisition of molecular biology results and in systems biology simulation technologies, provides the bases for precision medicine. Success in precision medicine depends on the access to healthcare and biomedical data. To this end, the digitization of all clinical exams and medical records is becoming a standard in hospitals. The digitization is essential to collect, share, and aggregate large volumes of heterogeneous data to support the discovery of hidden patterns with the aim to define predictive models for biomedical purposes. Patients' data sharing is a critical process. In fact, it raises ethical, social, legal, and technological issues that must be properly addressed.RESULTS: In this work, we present an infrastructure devised to deal with the integration of large volumes of heterogeneous biological data. The infrastructure was applied to the data collected between 2010-2016 in one of the major diagnostic analysis laboratories in Italy. Data from three different platforms were collected (i.e., laboratory exams, pathological anatomy exams, biopsy exams). The infrastructure has been designed to allow the extraction and aggregation of both unstructured and semi-structured data. Data are properly treated to ensure data security and privacy. Specialized algorithms have also been implemented to process the aggregated information with the aim to obtain a precise historical analysis of the clinical activities of one or more patients. Moreover, three Bayesian classifiers have been developed to analyze examinations reported as free text. Experimental results show that the classifiers exhibit a good accuracy when used to analyze sentences related to the sample location, diseases presence and status of the illnesses.CONCLUSIONS: The infrastructure allows the integration of multiple and heterogeneous sources of anonymized data from the different clinical platforms. Both unstructured and semi-structured data are processed to obtain a precise historical analysis of the clinical activities of one or more patients. Data aggregation allows to perform a series of statistical assessments required to answer complex questions that can be used in a variety of fields, such as predictive and precision medicine. In particular, studying the clinical history of patients that have developed similar pathologies can help to predict or individuate markers able to allow an early diagnosis of possible illnesses.","3":"BMC bioinformatics","4":"30367571","5":"2018","6":"Big Data"},{"1":"An infrastructure for precision medicine through analysis of big data.","2":"BACKGROUND: Nowadays, the increasing availability of omics data, due to both the advancements in the acquisition of molecular biology results and in systems biology simulation technologies, provides the bases for precision medicine. Success in precision medicine depends on the access to healthcare and biomedical data. To this end, the digitization of all clinical exams and medical records is becoming a standard in hospitals. The digitization is essential to collect, share, and aggregate large volumes of heterogeneous data to support the discovery of hidden patterns with the aim to define predictive models for biomedical purposes. Patients' data sharing is a critical process. In fact, it raises ethical, social, legal, and technological issues that must be properly addressed.RESULTS: In this work, we present an infrastructure devised to deal with the integration of large volumes of heterogeneous biological data. The infrastructure was applied to the data collected between 2010-2016 in one of the major diagnostic analysis laboratories in Italy. Data from three different platforms were collected (i.e., laboratory exams, pathological anatomy exams, biopsy exams). The infrastructure has been designed to allow the extraction and aggregation of both unstructured and semi-structured data. Data are properly treated to ensure data security and privacy. Specialized algorithms have also been implemented to process the aggregated information with the aim to obtain a precise historical analysis of the clinical activities of one or more patients. Moreover, three Bayesian classifiers have been developed to analyze examinations reported as free text. Experimental results show that the classifiers exhibit a good accuracy when used to analyze sentences related to the sample location, diseases presence and status of the illnesses.CONCLUSIONS: The infrastructure allows the integration of multiple and heterogeneous sources of anonymized data from the different clinical platforms. Both unstructured and semi-structured data are processed to obtain a precise historical analysis of the clinical activities of one or more patients. Data aggregation allows to perform a series of statistical assessments required to answer complex questions that can be used in a variety of fields, such as predictive and precision medicine. In particular, studying the clinical history of patients that have developed similar pathologies can help to predict or individuate markers able to allow an early diagnosis of possible illnesses.","3":"BMC bioinformatics","4":"30367571","5":"2018","6":"Biopsy"},{"1":"An infrastructure for precision medicine through analysis of big data.","2":"BACKGROUND: Nowadays, the increasing availability of omics data, due to both the advancements in the acquisition of molecular biology results and in systems biology simulation technologies, provides the bases for precision medicine. Success in precision medicine depends on the access to healthcare and biomedical data. To this end, the digitization of all clinical exams and medical records is becoming a standard in hospitals. The digitization is essential to collect, share, and aggregate large volumes of heterogeneous data to support the discovery of hidden patterns with the aim to define predictive models for biomedical purposes. Patients' data sharing is a critical process. In fact, it raises ethical, social, legal, and technological issues that must be properly addressed.RESULTS: In this work, we present an infrastructure devised to deal with the integration of large volumes of heterogeneous biological data. The infrastructure was applied to the data collected between 2010-2016 in one of the major diagnostic analysis laboratories in Italy. Data from three different platforms were collected (i.e., laboratory exams, pathological anatomy exams, biopsy exams). The infrastructure has been designed to allow the extraction and aggregation of both unstructured and semi-structured data. Data are properly treated to ensure data security and privacy. Specialized algorithms have also been implemented to process the aggregated information with the aim to obtain a precise historical analysis of the clinical activities of one or more patients. Moreover, three Bayesian classifiers have been developed to analyze examinations reported as free text. Experimental results show that the classifiers exhibit a good accuracy when used to analyze sentences related to the sample location, diseases presence and status of the illnesses.CONCLUSIONS: The infrastructure allows the integration of multiple and heterogeneous sources of anonymized data from the different clinical platforms. Both unstructured and semi-structured data are processed to obtain a precise historical analysis of the clinical activities of one or more patients. Data aggregation allows to perform a series of statistical assessments required to answer complex questions that can be used in a variety of fields, such as predictive and precision medicine. In particular, studying the clinical history of patients that have developed similar pathologies can help to predict or individuate markers able to allow an early diagnosis of possible illnesses.","3":"BMC bioinformatics","4":"30367571","5":"2018","6":"Computer Simulation"},{"1":"An infrastructure for precision medicine through analysis of big data.","2":"BACKGROUND: Nowadays, the increasing availability of omics data, due to both the advancements in the acquisition of molecular biology results and in systems biology simulation technologies, provides the bases for precision medicine. Success in precision medicine depends on the access to healthcare and biomedical data. To this end, the digitization of all clinical exams and medical records is becoming a standard in hospitals. The digitization is essential to collect, share, and aggregate large volumes of heterogeneous data to support the discovery of hidden patterns with the aim to define predictive models for biomedical purposes. Patients' data sharing is a critical process. In fact, it raises ethical, social, legal, and technological issues that must be properly addressed.RESULTS: In this work, we present an infrastructure devised to deal with the integration of large volumes of heterogeneous biological data. The infrastructure was applied to the data collected between 2010-2016 in one of the major diagnostic analysis laboratories in Italy. Data from three different platforms were collected (i.e., laboratory exams, pathological anatomy exams, biopsy exams). The infrastructure has been designed to allow the extraction and aggregation of both unstructured and semi-structured data. Data are properly treated to ensure data security and privacy. Specialized algorithms have also been implemented to process the aggregated information with the aim to obtain a precise historical analysis of the clinical activities of one or more patients. Moreover, three Bayesian classifiers have been developed to analyze examinations reported as free text. Experimental results show that the classifiers exhibit a good accuracy when used to analyze sentences related to the sample location, diseases presence and status of the illnesses.CONCLUSIONS: The infrastructure allows the integration of multiple and heterogeneous sources of anonymized data from the different clinical platforms. Both unstructured and semi-structured data are processed to obtain a precise historical analysis of the clinical activities of one or more patients. Data aggregation allows to perform a series of statistical assessments required to answer complex questions that can be used in a variety of fields, such as predictive and precision medicine. In particular, studying the clinical history of patients that have developed similar pathologies can help to predict or individuate markers able to allow an early diagnosis of possible illnesses.","3":"BMC bioinformatics","4":"30367571","5":"2018","6":"Data Analysis"},{"1":"An infrastructure for precision medicine through analysis of big data.","2":"BACKGROUND: Nowadays, the increasing availability of omics data, due to both the advancements in the acquisition of molecular biology results and in systems biology simulation technologies, provides the bases for precision medicine. Success in precision medicine depends on the access to healthcare and biomedical data. To this end, the digitization of all clinical exams and medical records is becoming a standard in hospitals. The digitization is essential to collect, share, and aggregate large volumes of heterogeneous data to support the discovery of hidden patterns with the aim to define predictive models for biomedical purposes. Patients' data sharing is a critical process. In fact, it raises ethical, social, legal, and technological issues that must be properly addressed.RESULTS: In this work, we present an infrastructure devised to deal with the integration of large volumes of heterogeneous biological data. The infrastructure was applied to the data collected between 2010-2016 in one of the major diagnostic analysis laboratories in Italy. Data from three different platforms were collected (i.e., laboratory exams, pathological anatomy exams, biopsy exams). The infrastructure has been designed to allow the extraction and aggregation of both unstructured and semi-structured data. Data are properly treated to ensure data security and privacy. Specialized algorithms have also been implemented to process the aggregated information with the aim to obtain a precise historical analysis of the clinical activities of one or more patients. Moreover, three Bayesian classifiers have been developed to analyze examinations reported as free text. Experimental results show that the classifiers exhibit a good accuracy when used to analyze sentences related to the sample location, diseases presence and status of the illnesses.CONCLUSIONS: The infrastructure allows the integration of multiple and heterogeneous sources of anonymized data from the different clinical platforms. Both unstructured and semi-structured data are processed to obtain a precise historical analysis of the clinical activities of one or more patients. Data aggregation allows to perform a series of statistical assessments required to answer complex questions that can be used in a variety of fields, such as predictive and precision medicine. In particular, studying the clinical history of patients that have developed similar pathologies can help to predict or individuate markers able to allow an early diagnosis of possible illnesses.","3":"BMC bioinformatics","4":"30367571","5":"2018","6":"Humans"},{"1":"An infrastructure for precision medicine through analysis of big data.","2":"BACKGROUND: Nowadays, the increasing availability of omics data, due to both the advancements in the acquisition of molecular biology results and in systems biology simulation technologies, provides the bases for precision medicine. Success in precision medicine depends on the access to healthcare and biomedical data. To this end, the digitization of all clinical exams and medical records is becoming a standard in hospitals. The digitization is essential to collect, share, and aggregate large volumes of heterogeneous data to support the discovery of hidden patterns with the aim to define predictive models for biomedical purposes. Patients' data sharing is a critical process. In fact, it raises ethical, social, legal, and technological issues that must be properly addressed.RESULTS: In this work, we present an infrastructure devised to deal with the integration of large volumes of heterogeneous biological data. The infrastructure was applied to the data collected between 2010-2016 in one of the major diagnostic analysis laboratories in Italy. Data from three different platforms were collected (i.e., laboratory exams, pathological anatomy exams, biopsy exams). The infrastructure has been designed to allow the extraction and aggregation of both unstructured and semi-structured data. Data are properly treated to ensure data security and privacy. Specialized algorithms have also been implemented to process the aggregated information with the aim to obtain a precise historical analysis of the clinical activities of one or more patients. Moreover, three Bayesian classifiers have been developed to analyze examinations reported as free text. Experimental results show that the classifiers exhibit a good accuracy when used to analyze sentences related to the sample location, diseases presence and status of the illnesses.CONCLUSIONS: The infrastructure allows the integration of multiple and heterogeneous sources of anonymized data from the different clinical platforms. Both unstructured and semi-structured data are processed to obtain a precise historical analysis of the clinical activities of one or more patients. Data aggregation allows to perform a series of statistical assessments required to answer complex questions that can be used in a variety of fields, such as predictive and precision medicine. In particular, studying the clinical history of patients that have developed similar pathologies can help to predict or individuate markers able to allow an early diagnosis of possible illnesses.","3":"BMC bioinformatics","4":"30367571","5":"2018","6":"Machine Learning"},{"1":"An infrastructure for precision medicine through analysis of big data.","2":"BACKGROUND: Nowadays, the increasing availability of omics data, due to both the advancements in the acquisition of molecular biology results and in systems biology simulation technologies, provides the bases for precision medicine. Success in precision medicine depends on the access to healthcare and biomedical data. To this end, the digitization of all clinical exams and medical records is becoming a standard in hospitals. The digitization is essential to collect, share, and aggregate large volumes of heterogeneous data to support the discovery of hidden patterns with the aim to define predictive models for biomedical purposes. Patients' data sharing is a critical process. In fact, it raises ethical, social, legal, and technological issues that must be properly addressed.RESULTS: In this work, we present an infrastructure devised to deal with the integration of large volumes of heterogeneous biological data. The infrastructure was applied to the data collected between 2010-2016 in one of the major diagnostic analysis laboratories in Italy. Data from three different platforms were collected (i.e., laboratory exams, pathological anatomy exams, biopsy exams). The infrastructure has been designed to allow the extraction and aggregation of both unstructured and semi-structured data. Data are properly treated to ensure data security and privacy. Specialized algorithms have also been implemented to process the aggregated information with the aim to obtain a precise historical analysis of the clinical activities of one or more patients. Moreover, three Bayesian classifiers have been developed to analyze examinations reported as free text. Experimental results show that the classifiers exhibit a good accuracy when used to analyze sentences related to the sample location, diseases presence and status of the illnesses.CONCLUSIONS: The infrastructure allows the integration of multiple and heterogeneous sources of anonymized data from the different clinical platforms. Both unstructured and semi-structured data are processed to obtain a precise historical analysis of the clinical activities of one or more patients. Data aggregation allows to perform a series of statistical assessments required to answer complex questions that can be used in a variety of fields, such as predictive and precision medicine. In particular, studying the clinical history of patients that have developed similar pathologies can help to predict or individuate markers able to allow an early diagnosis of possible illnesses.","3":"BMC bioinformatics","4":"30367571","5":"2018","6":"Precision Medicine"},{"1":"Deep learning in medical imaging and radiation therapy.","2":"The goals of this review paper on deep learning (DL) in medical imaging and radiation therapy are to (a) summarize what has been achieved to date; (b) identify common and unique challenges, and strategies that researchers have taken to address these challenges; and (c) identify some of the promising avenues for the future both in terms of applications as well as technical innovations. We introduce the general principles of DL and convolutional neural networks, survey five major areas of application of DL in medical imaging and radiation therapy, identify common themes, discuss methods for dataset expansion, and conclude by summarizing lessons learned, remaining challenges, and future directions.","3":"Medical physics","4":"30367497","5":"2018","6":"Artifacts"},{"1":"Deep learning in medical imaging and radiation therapy.","2":"The goals of this review paper on deep learning (DL) in medical imaging and radiation therapy are to (a) summarize what has been achieved to date; (b) identify common and unique challenges, and strategies that researchers have taken to address these challenges; and (c) identify some of the promising avenues for the future both in terms of applications as well as technical innovations. We introduce the general principles of DL and convolutional neural networks, survey five major areas of application of DL in medical imaging and radiation therapy, identify common themes, discuss methods for dataset expansion, and conclude by summarizing lessons learned, remaining challenges, and future directions.","3":"Medical physics","4":"30367497","5":"2018","6":"Deep Learning"},{"1":"Deep learning in medical imaging and radiation therapy.","2":"The goals of this review paper on deep learning (DL) in medical imaging and radiation therapy are to (a) summarize what has been achieved to date; (b) identify common and unique challenges, and strategies that researchers have taken to address these challenges; and (c) identify some of the promising avenues for the future both in terms of applications as well as technical innovations. We introduce the general principles of DL and convolutional neural networks, survey five major areas of application of DL in medical imaging and radiation therapy, identify common themes, discuss methods for dataset expansion, and conclude by summarizing lessons learned, remaining challenges, and future directions.","3":"Medical physics","4":"30367497","5":"2018","6":"Diagnostic Imaging"},{"1":"Deep learning in medical imaging and radiation therapy.","2":"The goals of this review paper on deep learning (DL) in medical imaging and radiation therapy are to (a) summarize what has been achieved to date; (b) identify common and unique challenges, and strategies that researchers have taken to address these challenges; and (c) identify some of the promising avenues for the future both in terms of applications as well as technical innovations. We introduce the general principles of DL and convolutional neural networks, survey five major areas of application of DL in medical imaging and radiation therapy, identify common themes, discuss methods for dataset expansion, and conclude by summarizing lessons learned, remaining challenges, and future directions.","3":"Medical physics","4":"30367497","5":"2018","6":"methods"},{"1":"Deep learning in medical imaging and radiation therapy.","2":"The goals of this review paper on deep learning (DL) in medical imaging and radiation therapy are to (a) summarize what has been achieved to date; (b) identify common and unique challenges, and strategies that researchers have taken to address these challenges; and (c) identify some of the promising avenues for the future both in terms of applications as well as technical innovations. We introduce the general principles of DL and convolutional neural networks, survey five major areas of application of DL in medical imaging and radiation therapy, identify common themes, discuss methods for dataset expansion, and conclude by summarizing lessons learned, remaining challenges, and future directions.","3":"Medical physics","4":"30367497","5":"2018","6":"Humans"},{"1":"Deep learning in medical imaging and radiation therapy.","2":"The goals of this review paper on deep learning (DL) in medical imaging and radiation therapy are to (a) summarize what has been achieved to date; (b) identify common and unique challenges, and strategies that researchers have taken to address these challenges; and (c) identify some of the promising avenues for the future both in terms of applications as well as technical innovations. We introduce the general principles of DL and convolutional neural networks, survey five major areas of application of DL in medical imaging and radiation therapy, identify common themes, discuss methods for dataset expansion, and conclude by summarizing lessons learned, remaining challenges, and future directions.","3":"Medical physics","4":"30367497","5":"2018","6":"Image Processing, Computer-Assisted"},{"1":"Deep learning in medical imaging and radiation therapy.","2":"The goals of this review paper on deep learning (DL) in medical imaging and radiation therapy are to (a) summarize what has been achieved to date; (b) identify common and unique challenges, and strategies that researchers have taken to address these challenges; and (c) identify some of the promising avenues for the future both in terms of applications as well as technical innovations. We introduce the general principles of DL and convolutional neural networks, survey five major areas of application of DL in medical imaging and radiation therapy, identify common themes, discuss methods for dataset expansion, and conclude by summarizing lessons learned, remaining challenges, and future directions.","3":"Medical physics","4":"30367497","5":"2018","6":"Radiotherapy"},{"1":"Deep learning in medical imaging and radiation therapy.","2":"The goals of this review paper on deep learning (DL) in medical imaging and radiation therapy are to (a) summarize what has been achieved to date; (b) identify common and unique challenges, and strategies that researchers have taken to address these challenges; and (c) identify some of the promising avenues for the future both in terms of applications as well as technical innovations. We introduce the general principles of DL and convolutional neural networks, survey five major areas of application of DL in medical imaging and radiation therapy, identify common themes, discuss methods for dataset expansion, and conclude by summarizing lessons learned, remaining challenges, and future directions.","3":"Medical physics","4":"30367497","5":"2018","6":"methods"},{"1":"Deep learning in medical imaging and radiation therapy.","2":"The goals of this review paper on deep learning (DL) in medical imaging and radiation therapy are to (a) summarize what has been achieved to date; (b) identify common and unique challenges, and strategies that researchers have taken to address these challenges; and (c) identify some of the promising avenues for the future both in terms of applications as well as technical innovations. We introduce the general principles of DL and convolutional neural networks, survey five major areas of application of DL in medical imaging and radiation therapy, identify common themes, discuss methods for dataset expansion, and conclude by summarizing lessons learned, remaining challenges, and future directions.","3":"Medical physics","4":"30367497","5":"2018","6":"Signal-To-Noise Ratio"},{"1":"A feasibility study on an automated method to generate patient-specific dose distributions for radiotherapy using deep learning.","2":"PURPOSE: To develop a method for predicting optimal dose distributions, given the planning image and segmented anatomy, by applying deep learning techniques to a database of previously optimized and approved Intensity-modulated radiation therapy treatment plans.METHODS: Eighty cases of early-stage nasopharyngeal cancer (NPC) were included in the study. Seventy cases were chosen randomly as the training set and the remaining as the test set. The inputs were the images with structures, with each target and organs at risk (OARs) assigned a unique label. The outputs were dose maps, including coarse dose maps and converted fine dose maps (FDM) from convolution. Two types of input images with structures were used in the model building. One type of input included the images (with associated structures) without manipulation. The second type of input involved modifying the image gray label with information from radiation beam geometry. ResNet101 was chosen as the deep learning network for both. The accuracy of predicted dose distributions was evaluated against the corresponding dose as used in the clinic. A global three-dimensional gamma analysis was calculated for the evaluation.RESULTS: The proposed model trained with the two different sets of input images and structures could both predict patient-specific dose distributions accurately. For the out-of-field dose distributions, the model obtained from the input with radiation geometry performed better (dose difference in %, 4.7 ± 6.1% vs 5.5 ± 7.9%, P &lt; 0.05). The mean Gamma pass rates of dose distributions predicted with both types of input were comparable for most OARs (P &gt; 0.05), except for the bilateral optic nerves and the optic chiasm.CONCLUSIONS: The proposed system with radiation geometry added to the input is a promising method to generate patient-specific dose distributions for radiotherapy. It can be applied to obtain the dose distributions slice-by-slice for planning quality assurance and for guiding automated planning.","3":"Medical physics","4":"30367492","5":"2018","6":"Automation"},{"1":"A feasibility study on an automated method to generate patient-specific dose distributions for radiotherapy using deep learning.","2":"PURPOSE: To develop a method for predicting optimal dose distributions, given the planning image and segmented anatomy, by applying deep learning techniques to a database of previously optimized and approved Intensity-modulated radiation therapy treatment plans.METHODS: Eighty cases of early-stage nasopharyngeal cancer (NPC) were included in the study. Seventy cases were chosen randomly as the training set and the remaining as the test set. The inputs were the images with structures, with each target and organs at risk (OARs) assigned a unique label. The outputs were dose maps, including coarse dose maps and converted fine dose maps (FDM) from convolution. Two types of input images with structures were used in the model building. One type of input included the images (with associated structures) without manipulation. The second type of input involved modifying the image gray label with information from radiation beam geometry. ResNet101 was chosen as the deep learning network for both. The accuracy of predicted dose distributions was evaluated against the corresponding dose as used in the clinic. A global three-dimensional gamma analysis was calculated for the evaluation.RESULTS: The proposed model trained with the two different sets of input images and structures could both predict patient-specific dose distributions accurately. For the out-of-field dose distributions, the model obtained from the input with radiation geometry performed better (dose difference in %, 4.7 ± 6.1% vs 5.5 ± 7.9%, P &lt; 0.05). The mean Gamma pass rates of dose distributions predicted with both types of input were comparable for most OARs (P &gt; 0.05), except for the bilateral optic nerves and the optic chiasm.CONCLUSIONS: The proposed system with radiation geometry added to the input is a promising method to generate patient-specific dose distributions for radiotherapy. It can be applied to obtain the dose distributions slice-by-slice for planning quality assurance and for guiding automated planning.","3":"Medical physics","4":"30367492","5":"2018","6":"Deep Learning"},{"1":"A feasibility study on an automated method to generate patient-specific dose distributions for radiotherapy using deep learning.","2":"PURPOSE: To develop a method for predicting optimal dose distributions, given the planning image and segmented anatomy, by applying deep learning techniques to a database of previously optimized and approved Intensity-modulated radiation therapy treatment plans.METHODS: Eighty cases of early-stage nasopharyngeal cancer (NPC) were included in the study. Seventy cases were chosen randomly as the training set and the remaining as the test set. The inputs were the images with structures, with each target and organs at risk (OARs) assigned a unique label. The outputs were dose maps, including coarse dose maps and converted fine dose maps (FDM) from convolution. Two types of input images with structures were used in the model building. One type of input included the images (with associated structures) without manipulation. The second type of input involved modifying the image gray label with information from radiation beam geometry. ResNet101 was chosen as the deep learning network for both. The accuracy of predicted dose distributions was evaluated against the corresponding dose as used in the clinic. A global three-dimensional gamma analysis was calculated for the evaluation.RESULTS: The proposed model trained with the two different sets of input images and structures could both predict patient-specific dose distributions accurately. For the out-of-field dose distributions, the model obtained from the input with radiation geometry performed better (dose difference in %, 4.7 ± 6.1% vs 5.5 ± 7.9%, P &lt; 0.05). The mean Gamma pass rates of dose distributions predicted with both types of input were comparable for most OARs (P &gt; 0.05), except for the bilateral optic nerves and the optic chiasm.CONCLUSIONS: The proposed system with radiation geometry added to the input is a promising method to generate patient-specific dose distributions for radiotherapy. It can be applied to obtain the dose distributions slice-by-slice for planning quality assurance and for guiding automated planning.","3":"Medical physics","4":"30367492","5":"2018","6":"Feasibility Studies"},{"1":"A feasibility study on an automated method to generate patient-specific dose distributions for radiotherapy using deep learning.","2":"PURPOSE: To develop a method for predicting optimal dose distributions, given the planning image and segmented anatomy, by applying deep learning techniques to a database of previously optimized and approved Intensity-modulated radiation therapy treatment plans.METHODS: Eighty cases of early-stage nasopharyngeal cancer (NPC) were included in the study. Seventy cases were chosen randomly as the training set and the remaining as the test set. The inputs were the images with structures, with each target and organs at risk (OARs) assigned a unique label. The outputs were dose maps, including coarse dose maps and converted fine dose maps (FDM) from convolution. Two types of input images with structures were used in the model building. One type of input included the images (with associated structures) without manipulation. The second type of input involved modifying the image gray label with information from radiation beam geometry. ResNet101 was chosen as the deep learning network for both. The accuracy of predicted dose distributions was evaluated against the corresponding dose as used in the clinic. A global three-dimensional gamma analysis was calculated for the evaluation.RESULTS: The proposed model trained with the two different sets of input images and structures could both predict patient-specific dose distributions accurately. For the out-of-field dose distributions, the model obtained from the input with radiation geometry performed better (dose difference in %, 4.7 ± 6.1% vs 5.5 ± 7.9%, P &lt; 0.05). The mean Gamma pass rates of dose distributions predicted with both types of input were comparable for most OARs (P &gt; 0.05), except for the bilateral optic nerves and the optic chiasm.CONCLUSIONS: The proposed system with radiation geometry added to the input is a promising method to generate patient-specific dose distributions for radiotherapy. It can be applied to obtain the dose distributions slice-by-slice for planning quality assurance and for guiding automated planning.","3":"Medical physics","4":"30367492","5":"2018","6":"Humans"},{"1":"A feasibility study on an automated method to generate patient-specific dose distributions for radiotherapy using deep learning.","2":"PURPOSE: To develop a method for predicting optimal dose distributions, given the planning image and segmented anatomy, by applying deep learning techniques to a database of previously optimized and approved Intensity-modulated radiation therapy treatment plans.METHODS: Eighty cases of early-stage nasopharyngeal cancer (NPC) were included in the study. Seventy cases were chosen randomly as the training set and the remaining as the test set. The inputs were the images with structures, with each target and organs at risk (OARs) assigned a unique label. The outputs were dose maps, including coarse dose maps and converted fine dose maps (FDM) from convolution. Two types of input images with structures were used in the model building. One type of input included the images (with associated structures) without manipulation. The second type of input involved modifying the image gray label with information from radiation beam geometry. ResNet101 was chosen as the deep learning network for both. The accuracy of predicted dose distributions was evaluated against the corresponding dose as used in the clinic. A global three-dimensional gamma analysis was calculated for the evaluation.RESULTS: The proposed model trained with the two different sets of input images and structures could both predict patient-specific dose distributions accurately. For the out-of-field dose distributions, the model obtained from the input with radiation geometry performed better (dose difference in %, 4.7 ± 6.1% vs 5.5 ± 7.9%, P &lt; 0.05). The mean Gamma pass rates of dose distributions predicted with both types of input were comparable for most OARs (P &gt; 0.05), except for the bilateral optic nerves and the optic chiasm.CONCLUSIONS: The proposed system with radiation geometry added to the input is a promising method to generate patient-specific dose distributions for radiotherapy. It can be applied to obtain the dose distributions slice-by-slice for planning quality assurance and for guiding automated planning.","3":"Medical physics","4":"30367492","5":"2018","6":"Neural Networks (Computer)"},{"1":"A feasibility study on an automated method to generate patient-specific dose distributions for radiotherapy using deep learning.","2":"PURPOSE: To develop a method for predicting optimal dose distributions, given the planning image and segmented anatomy, by applying deep learning techniques to a database of previously optimized and approved Intensity-modulated radiation therapy treatment plans.METHODS: Eighty cases of early-stage nasopharyngeal cancer (NPC) were included in the study. Seventy cases were chosen randomly as the training set and the remaining as the test set. The inputs were the images with structures, with each target and organs at risk (OARs) assigned a unique label. The outputs were dose maps, including coarse dose maps and converted fine dose maps (FDM) from convolution. Two types of input images with structures were used in the model building. One type of input included the images (with associated structures) without manipulation. The second type of input involved modifying the image gray label with information from radiation beam geometry. ResNet101 was chosen as the deep learning network for both. The accuracy of predicted dose distributions was evaluated against the corresponding dose as used in the clinic. A global three-dimensional gamma analysis was calculated for the evaluation.RESULTS: The proposed model trained with the two different sets of input images and structures could both predict patient-specific dose distributions accurately. For the out-of-field dose distributions, the model obtained from the input with radiation geometry performed better (dose difference in %, 4.7 ± 6.1% vs 5.5 ± 7.9%, P &lt; 0.05). The mean Gamma pass rates of dose distributions predicted with both types of input were comparable for most OARs (P &gt; 0.05), except for the bilateral optic nerves and the optic chiasm.CONCLUSIONS: The proposed system with radiation geometry added to the input is a promising method to generate patient-specific dose distributions for radiotherapy. It can be applied to obtain the dose distributions slice-by-slice for planning quality assurance and for guiding automated planning.","3":"Medical physics","4":"30367492","5":"2018","6":"Radiation Dosage"},{"1":"A feasibility study on an automated method to generate patient-specific dose distributions for radiotherapy using deep learning.","2":"PURPOSE: To develop a method for predicting optimal dose distributions, given the planning image and segmented anatomy, by applying deep learning techniques to a database of previously optimized and approved Intensity-modulated radiation therapy treatment plans.METHODS: Eighty cases of early-stage nasopharyngeal cancer (NPC) were included in the study. Seventy cases were chosen randomly as the training set and the remaining as the test set. The inputs were the images with structures, with each target and organs at risk (OARs) assigned a unique label. The outputs were dose maps, including coarse dose maps and converted fine dose maps (FDM) from convolution. Two types of input images with structures were used in the model building. One type of input included the images (with associated structures) without manipulation. The second type of input involved modifying the image gray label with information from radiation beam geometry. ResNet101 was chosen as the deep learning network for both. The accuracy of predicted dose distributions was evaluated against the corresponding dose as used in the clinic. A global three-dimensional gamma analysis was calculated for the evaluation.RESULTS: The proposed model trained with the two different sets of input images and structures could both predict patient-specific dose distributions accurately. For the out-of-field dose distributions, the model obtained from the input with radiation geometry performed better (dose difference in %, 4.7 ± 6.1% vs 5.5 ± 7.9%, P &lt; 0.05). The mean Gamma pass rates of dose distributions predicted with both types of input were comparable for most OARs (P &gt; 0.05), except for the bilateral optic nerves and the optic chiasm.CONCLUSIONS: The proposed system with radiation geometry added to the input is a promising method to generate patient-specific dose distributions for radiotherapy. It can be applied to obtain the dose distributions slice-by-slice for planning quality assurance and for guiding automated planning.","3":"Medical physics","4":"30367492","5":"2018","6":"Radiotherapy Dosage"},{"1":"A feasibility study on an automated method to generate patient-specific dose distributions for radiotherapy using deep learning.","2":"PURPOSE: To develop a method for predicting optimal dose distributions, given the planning image and segmented anatomy, by applying deep learning techniques to a database of previously optimized and approved Intensity-modulated radiation therapy treatment plans.METHODS: Eighty cases of early-stage nasopharyngeal cancer (NPC) were included in the study. Seventy cases were chosen randomly as the training set and the remaining as the test set. The inputs were the images with structures, with each target and organs at risk (OARs) assigned a unique label. The outputs were dose maps, including coarse dose maps and converted fine dose maps (FDM) from convolution. Two types of input images with structures were used in the model building. One type of input included the images (with associated structures) without manipulation. The second type of input involved modifying the image gray label with information from radiation beam geometry. ResNet101 was chosen as the deep learning network for both. The accuracy of predicted dose distributions was evaluated against the corresponding dose as used in the clinic. A global three-dimensional gamma analysis was calculated for the evaluation.RESULTS: The proposed model trained with the two different sets of input images and structures could both predict patient-specific dose distributions accurately. For the out-of-field dose distributions, the model obtained from the input with radiation geometry performed better (dose difference in %, 4.7 ± 6.1% vs 5.5 ± 7.9%, P &lt; 0.05). The mean Gamma pass rates of dose distributions predicted with both types of input were comparable for most OARs (P &gt; 0.05), except for the bilateral optic nerves and the optic chiasm.CONCLUSIONS: The proposed system with radiation geometry added to the input is a promising method to generate patient-specific dose distributions for radiotherapy. It can be applied to obtain the dose distributions slice-by-slice for planning quality assurance and for guiding automated planning.","3":"Medical physics","4":"30367492","5":"2018","6":"Radiotherapy Planning, Computer-Assisted"},{"1":"A feasibility study on an automated method to generate patient-specific dose distributions for radiotherapy using deep learning.","2":"PURPOSE: To develop a method for predicting optimal dose distributions, given the planning image and segmented anatomy, by applying deep learning techniques to a database of previously optimized and approved Intensity-modulated radiation therapy treatment plans.METHODS: Eighty cases of early-stage nasopharyngeal cancer (NPC) were included in the study. Seventy cases were chosen randomly as the training set and the remaining as the test set. The inputs were the images with structures, with each target and organs at risk (OARs) assigned a unique label. The outputs were dose maps, including coarse dose maps and converted fine dose maps (FDM) from convolution. Two types of input images with structures were used in the model building. One type of input included the images (with associated structures) without manipulation. The second type of input involved modifying the image gray label with information from radiation beam geometry. ResNet101 was chosen as the deep learning network for both. The accuracy of predicted dose distributions was evaluated against the corresponding dose as used in the clinic. A global three-dimensional gamma analysis was calculated for the evaluation.RESULTS: The proposed model trained with the two different sets of input images and structures could both predict patient-specific dose distributions accurately. For the out-of-field dose distributions, the model obtained from the input with radiation geometry performed better (dose difference in %, 4.7 ± 6.1% vs 5.5 ± 7.9%, P &lt; 0.05). The mean Gamma pass rates of dose distributions predicted with both types of input were comparable for most OARs (P &gt; 0.05), except for the bilateral optic nerves and the optic chiasm.CONCLUSIONS: The proposed system with radiation geometry added to the input is a promising method to generate patient-specific dose distributions for radiotherapy. It can be applied to obtain the dose distributions slice-by-slice for planning quality assurance and for guiding automated planning.","3":"Medical physics","4":"30367492","5":"2018","6":"methods"},{"1":"A feasibility study on an automated method to generate patient-specific dose distributions for radiotherapy using deep learning.","2":"PURPOSE: To develop a method for predicting optimal dose distributions, given the planning image and segmented anatomy, by applying deep learning techniques to a database of previously optimized and approved Intensity-modulated radiation therapy treatment plans.METHODS: Eighty cases of early-stage nasopharyngeal cancer (NPC) were included in the study. Seventy cases were chosen randomly as the training set and the remaining as the test set. The inputs were the images with structures, with each target and organs at risk (OARs) assigned a unique label. The outputs were dose maps, including coarse dose maps and converted fine dose maps (FDM) from convolution. Two types of input images with structures were used in the model building. One type of input included the images (with associated structures) without manipulation. The second type of input involved modifying the image gray label with information from radiation beam geometry. ResNet101 was chosen as the deep learning network for both. The accuracy of predicted dose distributions was evaluated against the corresponding dose as used in the clinic. A global three-dimensional gamma analysis was calculated for the evaluation.RESULTS: The proposed model trained with the two different sets of input images and structures could both predict patient-specific dose distributions accurately. For the out-of-field dose distributions, the model obtained from the input with radiation geometry performed better (dose difference in %, 4.7 ± 6.1% vs 5.5 ± 7.9%, P &lt; 0.05). The mean Gamma pass rates of dose distributions predicted with both types of input were comparable for most OARs (P &gt; 0.05), except for the bilateral optic nerves and the optic chiasm.CONCLUSIONS: The proposed system with radiation geometry added to the input is a promising method to generate patient-specific dose distributions for radiotherapy. It can be applied to obtain the dose distributions slice-by-slice for planning quality assurance and for guiding automated planning.","3":"Medical physics","4":"30367492","5":"2018","6":"Radiotherapy, Intensity-Modulated"},{"1":"High quality imaging from sparsely sampled computed tomography data with deep learning and wavelet transform in various domains.","2":"PURPOSE: Sparsely sampled computed tomography (CT) has been attracting attention as a technique that can reduce the high radiation dose of conventional CT. In general, iterative reconstruction techniques have been applied to sparsely sampled CT to realize high quality images. These methodologies require high computing power due to the modeling of the system and the trajectory of radiation rays. Therefore, the purpose of this study was to obtain high quality three-dimensional (3D) reconstructed images with deep learning under sparse sampling conditions.METHODS: We used a deep learning model based on a fully convolutional network and a wavelet transform to predict high quality images. To reduce the spatial resolution loss of predicted images, we replaced the pooling layer with a wavelet transform. Three different domains were evaluated - the sinogram domain, the image domain, and the hybrid domain - to optimize a reconstruction technique based on deep learning. To train and develop a deep learning model, The Cancer Imaging Archive (TCIA) dataset was used.RESULTS: Streak artifacts, which generally occur under sparse sampling conditions, were effectively removed from deep learning-based sparsely sampled reconstructed images. However, image characteristics of fine structures varied depending on the application of deep learning technologies. The use of deep learning techniques in the sinogram domain removed streak artifacts well, but some image noise remained. Likewise, when applying deep learning technology to the image domain, a blurring effect occurred. The proposed hybrid domain sparsely sampled reconstruction based on deep learning was able to restore images to a quality similar to fully sampled images. The structural similarity (SSIM) index values of sparsely sampled CT reconstruction based on deep learning technology were 0.85 or higher. Among the three domains studied, the hybrid domain techniques achieved the highest SSIM index values (0.9 or more).CONCLUSION: We proposed a method of sparsely sampled CT reconstruction from a new perspective - unlike iterative reconstruction. In addition, we developed an optimal deep learning-based sparse sampling reconstruction technique by evaluating image quality with deep learning technologies.","3":"Medical physics","4":"30362117","5":"2018","6":"Deep Learning"},{"1":"High quality imaging from sparsely sampled computed tomography data with deep learning and wavelet transform in various domains.","2":"PURPOSE: Sparsely sampled computed tomography (CT) has been attracting attention as a technique that can reduce the high radiation dose of conventional CT. In general, iterative reconstruction techniques have been applied to sparsely sampled CT to realize high quality images. These methodologies require high computing power due to the modeling of the system and the trajectory of radiation rays. Therefore, the purpose of this study was to obtain high quality three-dimensional (3D) reconstructed images with deep learning under sparse sampling conditions.METHODS: We used a deep learning model based on a fully convolutional network and a wavelet transform to predict high quality images. To reduce the spatial resolution loss of predicted images, we replaced the pooling layer with a wavelet transform. Three different domains were evaluated - the sinogram domain, the image domain, and the hybrid domain - to optimize a reconstruction technique based on deep learning. To train and develop a deep learning model, The Cancer Imaging Archive (TCIA) dataset was used.RESULTS: Streak artifacts, which generally occur under sparse sampling conditions, were effectively removed from deep learning-based sparsely sampled reconstructed images. However, image characteristics of fine structures varied depending on the application of deep learning technologies. The use of deep learning techniques in the sinogram domain removed streak artifacts well, but some image noise remained. Likewise, when applying deep learning technology to the image domain, a blurring effect occurred. The proposed hybrid domain sparsely sampled reconstruction based on deep learning was able to restore images to a quality similar to fully sampled images. The structural similarity (SSIM) index values of sparsely sampled CT reconstruction based on deep learning technology were 0.85 or higher. Among the three domains studied, the hybrid domain techniques achieved the highest SSIM index values (0.9 or more).CONCLUSION: We proposed a method of sparsely sampled CT reconstruction from a new perspective - unlike iterative reconstruction. In addition, we developed an optimal deep learning-based sparse sampling reconstruction technique by evaluating image quality with deep learning technologies.","3":"Medical physics","4":"30362117","5":"2018","6":"Humans"},{"1":"High quality imaging from sparsely sampled computed tomography data with deep learning and wavelet transform in various domains.","2":"PURPOSE: Sparsely sampled computed tomography (CT) has been attracting attention as a technique that can reduce the high radiation dose of conventional CT. In general, iterative reconstruction techniques have been applied to sparsely sampled CT to realize high quality images. These methodologies require high computing power due to the modeling of the system and the trajectory of radiation rays. Therefore, the purpose of this study was to obtain high quality three-dimensional (3D) reconstructed images with deep learning under sparse sampling conditions.METHODS: We used a deep learning model based on a fully convolutional network and a wavelet transform to predict high quality images. To reduce the spatial resolution loss of predicted images, we replaced the pooling layer with a wavelet transform. Three different domains were evaluated - the sinogram domain, the image domain, and the hybrid domain - to optimize a reconstruction technique based on deep learning. To train and develop a deep learning model, The Cancer Imaging Archive (TCIA) dataset was used.RESULTS: Streak artifacts, which generally occur under sparse sampling conditions, were effectively removed from deep learning-based sparsely sampled reconstructed images. However, image characteristics of fine structures varied depending on the application of deep learning technologies. The use of deep learning techniques in the sinogram domain removed streak artifacts well, but some image noise remained. Likewise, when applying deep learning technology to the image domain, a blurring effect occurred. The proposed hybrid domain sparsely sampled reconstruction based on deep learning was able to restore images to a quality similar to fully sampled images. The structural similarity (SSIM) index values of sparsely sampled CT reconstruction based on deep learning technology were 0.85 or higher. Among the three domains studied, the hybrid domain techniques achieved the highest SSIM index values (0.9 or more).CONCLUSION: We proposed a method of sparsely sampled CT reconstruction from a new perspective - unlike iterative reconstruction. In addition, we developed an optimal deep learning-based sparse sampling reconstruction technique by evaluating image quality with deep learning technologies.","3":"Medical physics","4":"30362117","5":"2018","6":"Image Processing, Computer-Assisted"},{"1":"High quality imaging from sparsely sampled computed tomography data with deep learning and wavelet transform in various domains.","2":"PURPOSE: Sparsely sampled computed tomography (CT) has been attracting attention as a technique that can reduce the high radiation dose of conventional CT. In general, iterative reconstruction techniques have been applied to sparsely sampled CT to realize high quality images. These methodologies require high computing power due to the modeling of the system and the trajectory of radiation rays. Therefore, the purpose of this study was to obtain high quality three-dimensional (3D) reconstructed images with deep learning under sparse sampling conditions.METHODS: We used a deep learning model based on a fully convolutional network and a wavelet transform to predict high quality images. To reduce the spatial resolution loss of predicted images, we replaced the pooling layer with a wavelet transform. Three different domains were evaluated - the sinogram domain, the image domain, and the hybrid domain - to optimize a reconstruction technique based on deep learning. To train and develop a deep learning model, The Cancer Imaging Archive (TCIA) dataset was used.RESULTS: Streak artifacts, which generally occur under sparse sampling conditions, were effectively removed from deep learning-based sparsely sampled reconstructed images. However, image characteristics of fine structures varied depending on the application of deep learning technologies. The use of deep learning techniques in the sinogram domain removed streak artifacts well, but some image noise remained. Likewise, when applying deep learning technology to the image domain, a blurring effect occurred. The proposed hybrid domain sparsely sampled reconstruction based on deep learning was able to restore images to a quality similar to fully sampled images. The structural similarity (SSIM) index values of sparsely sampled CT reconstruction based on deep learning technology were 0.85 or higher. Among the three domains studied, the hybrid domain techniques achieved the highest SSIM index values (0.9 or more).CONCLUSION: We proposed a method of sparsely sampled CT reconstruction from a new perspective - unlike iterative reconstruction. In addition, we developed an optimal deep learning-based sparse sampling reconstruction technique by evaluating image quality with deep learning technologies.","3":"Medical physics","4":"30362117","5":"2018","6":"methods"},{"1":"High quality imaging from sparsely sampled computed tomography data with deep learning and wavelet transform in various domains.","2":"PURPOSE: Sparsely sampled computed tomography (CT) has been attracting attention as a technique that can reduce the high radiation dose of conventional CT. In general, iterative reconstruction techniques have been applied to sparsely sampled CT to realize high quality images. These methodologies require high computing power due to the modeling of the system and the trajectory of radiation rays. Therefore, the purpose of this study was to obtain high quality three-dimensional (3D) reconstructed images with deep learning under sparse sampling conditions.METHODS: We used a deep learning model based on a fully convolutional network and a wavelet transform to predict high quality images. To reduce the spatial resolution loss of predicted images, we replaced the pooling layer with a wavelet transform. Three different domains were evaluated - the sinogram domain, the image domain, and the hybrid domain - to optimize a reconstruction technique based on deep learning. To train and develop a deep learning model, The Cancer Imaging Archive (TCIA) dataset was used.RESULTS: Streak artifacts, which generally occur under sparse sampling conditions, were effectively removed from deep learning-based sparsely sampled reconstructed images. However, image characteristics of fine structures varied depending on the application of deep learning technologies. The use of deep learning techniques in the sinogram domain removed streak artifacts well, but some image noise remained. Likewise, when applying deep learning technology to the image domain, a blurring effect occurred. The proposed hybrid domain sparsely sampled reconstruction based on deep learning was able to restore images to a quality similar to fully sampled images. The structural similarity (SSIM) index values of sparsely sampled CT reconstruction based on deep learning technology were 0.85 or higher. Among the three domains studied, the hybrid domain techniques achieved the highest SSIM index values (0.9 or more).CONCLUSION: We proposed a method of sparsely sampled CT reconstruction from a new perspective - unlike iterative reconstruction. In addition, we developed an optimal deep learning-based sparse sampling reconstruction technique by evaluating image quality with deep learning technologies.","3":"Medical physics","4":"30362117","5":"2018","6":"Lung"},{"1":"High quality imaging from sparsely sampled computed tomography data with deep learning and wavelet transform in various domains.","2":"PURPOSE: Sparsely sampled computed tomography (CT) has been attracting attention as a technique that can reduce the high radiation dose of conventional CT. In general, iterative reconstruction techniques have been applied to sparsely sampled CT to realize high quality images. These methodologies require high computing power due to the modeling of the system and the trajectory of radiation rays. Therefore, the purpose of this study was to obtain high quality three-dimensional (3D) reconstructed images with deep learning under sparse sampling conditions.METHODS: We used a deep learning model based on a fully convolutional network and a wavelet transform to predict high quality images. To reduce the spatial resolution loss of predicted images, we replaced the pooling layer with a wavelet transform. Three different domains were evaluated - the sinogram domain, the image domain, and the hybrid domain - to optimize a reconstruction technique based on deep learning. To train and develop a deep learning model, The Cancer Imaging Archive (TCIA) dataset was used.RESULTS: Streak artifacts, which generally occur under sparse sampling conditions, were effectively removed from deep learning-based sparsely sampled reconstructed images. However, image characteristics of fine structures varied depending on the application of deep learning technologies. The use of deep learning techniques in the sinogram domain removed streak artifacts well, but some image noise remained. Likewise, when applying deep learning technology to the image domain, a blurring effect occurred. The proposed hybrid domain sparsely sampled reconstruction based on deep learning was able to restore images to a quality similar to fully sampled images. The structural similarity (SSIM) index values of sparsely sampled CT reconstruction based on deep learning technology were 0.85 or higher. Among the three domains studied, the hybrid domain techniques achieved the highest SSIM index values (0.9 or more).CONCLUSION: We proposed a method of sparsely sampled CT reconstruction from a new perspective - unlike iterative reconstruction. In addition, we developed an optimal deep learning-based sparse sampling reconstruction technique by evaluating image quality with deep learning technologies.","3":"Medical physics","4":"30362117","5":"2018","6":"diagnostic imaging"},{"1":"High quality imaging from sparsely sampled computed tomography data with deep learning and wavelet transform in various domains.","2":"PURPOSE: Sparsely sampled computed tomography (CT) has been attracting attention as a technique that can reduce the high radiation dose of conventional CT. In general, iterative reconstruction techniques have been applied to sparsely sampled CT to realize high quality images. These methodologies require high computing power due to the modeling of the system and the trajectory of radiation rays. Therefore, the purpose of this study was to obtain high quality three-dimensional (3D) reconstructed images with deep learning under sparse sampling conditions.METHODS: We used a deep learning model based on a fully convolutional network and a wavelet transform to predict high quality images. To reduce the spatial resolution loss of predicted images, we replaced the pooling layer with a wavelet transform. Three different domains were evaluated - the sinogram domain, the image domain, and the hybrid domain - to optimize a reconstruction technique based on deep learning. To train and develop a deep learning model, The Cancer Imaging Archive (TCIA) dataset was used.RESULTS: Streak artifacts, which generally occur under sparse sampling conditions, were effectively removed from deep learning-based sparsely sampled reconstructed images. However, image characteristics of fine structures varied depending on the application of deep learning technologies. The use of deep learning techniques in the sinogram domain removed streak artifacts well, but some image noise remained. Likewise, when applying deep learning technology to the image domain, a blurring effect occurred. The proposed hybrid domain sparsely sampled reconstruction based on deep learning was able to restore images to a quality similar to fully sampled images. The structural similarity (SSIM) index values of sparsely sampled CT reconstruction based on deep learning technology were 0.85 or higher. Among the three domains studied, the hybrid domain techniques achieved the highest SSIM index values (0.9 or more).CONCLUSION: We proposed a method of sparsely sampled CT reconstruction from a new perspective - unlike iterative reconstruction. In addition, we developed an optimal deep learning-based sparse sampling reconstruction technique by evaluating image quality with deep learning technologies.","3":"Medical physics","4":"30362117","5":"2018","6":"Quality Control"},{"1":"High quality imaging from sparsely sampled computed tomography data with deep learning and wavelet transform in various domains.","2":"PURPOSE: Sparsely sampled computed tomography (CT) has been attracting attention as a technique that can reduce the high radiation dose of conventional CT. In general, iterative reconstruction techniques have been applied to sparsely sampled CT to realize high quality images. These methodologies require high computing power due to the modeling of the system and the trajectory of radiation rays. Therefore, the purpose of this study was to obtain high quality three-dimensional (3D) reconstructed images with deep learning under sparse sampling conditions.METHODS: We used a deep learning model based on a fully convolutional network and a wavelet transform to predict high quality images. To reduce the spatial resolution loss of predicted images, we replaced the pooling layer with a wavelet transform. Three different domains were evaluated - the sinogram domain, the image domain, and the hybrid domain - to optimize a reconstruction technique based on deep learning. To train and develop a deep learning model, The Cancer Imaging Archive (TCIA) dataset was used.RESULTS: Streak artifacts, which generally occur under sparse sampling conditions, were effectively removed from deep learning-based sparsely sampled reconstructed images. However, image characteristics of fine structures varied depending on the application of deep learning technologies. The use of deep learning techniques in the sinogram domain removed streak artifacts well, but some image noise remained. Likewise, when applying deep learning technology to the image domain, a blurring effect occurred. The proposed hybrid domain sparsely sampled reconstruction based on deep learning was able to restore images to a quality similar to fully sampled images. The structural similarity (SSIM) index values of sparsely sampled CT reconstruction based on deep learning technology were 0.85 or higher. Among the three domains studied, the hybrid domain techniques achieved the highest SSIM index values (0.9 or more).CONCLUSION: We proposed a method of sparsely sampled CT reconstruction from a new perspective - unlike iterative reconstruction. In addition, we developed an optimal deep learning-based sparse sampling reconstruction technique by evaluating image quality with deep learning technologies.","3":"Medical physics","4":"30362117","5":"2018","6":"Radiation Dosage"},{"1":"High quality imaging from sparsely sampled computed tomography data with deep learning and wavelet transform in various domains.","2":"PURPOSE: Sparsely sampled computed tomography (CT) has been attracting attention as a technique that can reduce the high radiation dose of conventional CT. In general, iterative reconstruction techniques have been applied to sparsely sampled CT to realize high quality images. These methodologies require high computing power due to the modeling of the system and the trajectory of radiation rays. Therefore, the purpose of this study was to obtain high quality three-dimensional (3D) reconstructed images with deep learning under sparse sampling conditions.METHODS: We used a deep learning model based on a fully convolutional network and a wavelet transform to predict high quality images. To reduce the spatial resolution loss of predicted images, we replaced the pooling layer with a wavelet transform. Three different domains were evaluated - the sinogram domain, the image domain, and the hybrid domain - to optimize a reconstruction technique based on deep learning. To train and develop a deep learning model, The Cancer Imaging Archive (TCIA) dataset was used.RESULTS: Streak artifacts, which generally occur under sparse sampling conditions, were effectively removed from deep learning-based sparsely sampled reconstructed images. However, image characteristics of fine structures varied depending on the application of deep learning technologies. The use of deep learning techniques in the sinogram domain removed streak artifacts well, but some image noise remained. Likewise, when applying deep learning technology to the image domain, a blurring effect occurred. The proposed hybrid domain sparsely sampled reconstruction based on deep learning was able to restore images to a quality similar to fully sampled images. The structural similarity (SSIM) index values of sparsely sampled CT reconstruction based on deep learning technology were 0.85 or higher. Among the three domains studied, the hybrid domain techniques achieved the highest SSIM index values (0.9 or more).CONCLUSION: We proposed a method of sparsely sampled CT reconstruction from a new perspective - unlike iterative reconstruction. In addition, we developed an optimal deep learning-based sparse sampling reconstruction technique by evaluating image quality with deep learning technologies.","3":"Medical physics","4":"30362117","5":"2018","6":"Tomography, X-Ray Computed"},{"1":"High quality imaging from sparsely sampled computed tomography data with deep learning and wavelet transform in various domains.","2":"PURPOSE: Sparsely sampled computed tomography (CT) has been attracting attention as a technique that can reduce the high radiation dose of conventional CT. In general, iterative reconstruction techniques have been applied to sparsely sampled CT to realize high quality images. These methodologies require high computing power due to the modeling of the system and the trajectory of radiation rays. Therefore, the purpose of this study was to obtain high quality three-dimensional (3D) reconstructed images with deep learning under sparse sampling conditions.METHODS: We used a deep learning model based on a fully convolutional network and a wavelet transform to predict high quality images. To reduce the spatial resolution loss of predicted images, we replaced the pooling layer with a wavelet transform. Three different domains were evaluated - the sinogram domain, the image domain, and the hybrid domain - to optimize a reconstruction technique based on deep learning. To train and develop a deep learning model, The Cancer Imaging Archive (TCIA) dataset was used.RESULTS: Streak artifacts, which generally occur under sparse sampling conditions, were effectively removed from deep learning-based sparsely sampled reconstructed images. However, image characteristics of fine structures varied depending on the application of deep learning technologies. The use of deep learning techniques in the sinogram domain removed streak artifacts well, but some image noise remained. Likewise, when applying deep learning technology to the image domain, a blurring effect occurred. The proposed hybrid domain sparsely sampled reconstruction based on deep learning was able to restore images to a quality similar to fully sampled images. The structural similarity (SSIM) index values of sparsely sampled CT reconstruction based on deep learning technology were 0.85 or higher. Among the three domains studied, the hybrid domain techniques achieved the highest SSIM index values (0.9 or more).CONCLUSION: We proposed a method of sparsely sampled CT reconstruction from a new perspective - unlike iterative reconstruction. In addition, we developed an optimal deep learning-based sparse sampling reconstruction technique by evaluating image quality with deep learning technologies.","3":"Medical physics","4":"30362117","5":"2018","6":"Wavelet Analysis"},{"1":"Key Immunological Functions Involved in the Progression of Epithelial Ovarian Serous Carcinoma Discovered by the Gene Ontology-Based Immunofunctionome Analysis.","2":"Serous carcinoma (SC) is the most common and lethal subtype of epithelial ovarian carcinoma; immunotherapy is a potential treatment for SC, however, the global immunological functions of SC as well as their change during the progression of SC have not been investigated in detail till now. We conducted a genome-wide integrative analysis to investigate the immunofunctionomes of SC at four tumor stages by quantifying the immunological functions defined by the Gene Ontology gene sets. DNA microarray gene expression profiles of 1100 SCs and 136 normal ovarian tissue controls were downloaded from the Gene Expression Omnibus database and converted to the functionome. Then the immunofunctionomes were reconstructed by extracting the offspring from the functionome for the four SC staging groups. The key immunological functions extracted from immunofunctionomes with a series of filters revealed that the immunopathy of SC consisted of a group of deregulated functions with the core members including B cell activation and differentiation, regulation of leukocyte chemotaxis/cellular extravasation, antigen receptor mediated signaling pathway, T helper mediated immunity and macrophage activation; and the auxiliary elements included leukocyte mediated immunity, regulation of inflammatory response, T cell differentiation, mononuclear cell migration, megakaryocyte differentiation, complement activation and cytokine production. These deregulated immunological functions reveal the candidates to target in the immunotherapy.","3":"International journal of molecular sciences","4":"30356023","5":"2018","6":"Carcinoma, Ovarian Epithelial"},{"1":"Key Immunological Functions Involved in the Progression of Epithelial Ovarian Serous Carcinoma Discovered by the Gene Ontology-Based Immunofunctionome Analysis.","2":"Serous carcinoma (SC) is the most common and lethal subtype of epithelial ovarian carcinoma; immunotherapy is a potential treatment for SC, however, the global immunological functions of SC as well as their change during the progression of SC have not been investigated in detail till now. We conducted a genome-wide integrative analysis to investigate the immunofunctionomes of SC at four tumor stages by quantifying the immunological functions defined by the Gene Ontology gene sets. DNA microarray gene expression profiles of 1100 SCs and 136 normal ovarian tissue controls were downloaded from the Gene Expression Omnibus database and converted to the functionome. Then the immunofunctionomes were reconstructed by extracting the offspring from the functionome for the four SC staging groups. The key immunological functions extracted from immunofunctionomes with a series of filters revealed that the immunopathy of SC consisted of a group of deregulated functions with the core members including B cell activation and differentiation, regulation of leukocyte chemotaxis/cellular extravasation, antigen receptor mediated signaling pathway, T helper mediated immunity and macrophage activation; and the auxiliary elements included leukocyte mediated immunity, regulation of inflammatory response, T cell differentiation, mononuclear cell migration, megakaryocyte differentiation, complement activation and cytokine production. These deregulated immunological functions reveal the candidates to target in the immunotherapy.","3":"International journal of molecular sciences","4":"30356023","5":"2018","6":"genetics"},{"1":"Key Immunological Functions Involved in the Progression of Epithelial Ovarian Serous Carcinoma Discovered by the Gene Ontology-Based Immunofunctionome Analysis.","2":"Serous carcinoma (SC) is the most common and lethal subtype of epithelial ovarian carcinoma; immunotherapy is a potential treatment for SC, however, the global immunological functions of SC as well as their change during the progression of SC have not been investigated in detail till now. We conducted a genome-wide integrative analysis to investigate the immunofunctionomes of SC at four tumor stages by quantifying the immunological functions defined by the Gene Ontology gene sets. DNA microarray gene expression profiles of 1100 SCs and 136 normal ovarian tissue controls were downloaded from the Gene Expression Omnibus database and converted to the functionome. Then the immunofunctionomes were reconstructed by extracting the offspring from the functionome for the four SC staging groups. The key immunological functions extracted from immunofunctionomes with a series of filters revealed that the immunopathy of SC consisted of a group of deregulated functions with the core members including B cell activation and differentiation, regulation of leukocyte chemotaxis/cellular extravasation, antigen receptor mediated signaling pathway, T helper mediated immunity and macrophage activation; and the auxiliary elements included leukocyte mediated immunity, regulation of inflammatory response, T cell differentiation, mononuclear cell migration, megakaryocyte differentiation, complement activation and cytokine production. These deregulated immunological functions reveal the candidates to target in the immunotherapy.","3":"International journal of molecular sciences","4":"30356023","5":"2018","6":"immunology"},{"1":"Key Immunological Functions Involved in the Progression of Epithelial Ovarian Serous Carcinoma Discovered by the Gene Ontology-Based Immunofunctionome Analysis.","2":"Serous carcinoma (SC) is the most common and lethal subtype of epithelial ovarian carcinoma; immunotherapy is a potential treatment for SC, however, the global immunological functions of SC as well as their change during the progression of SC have not been investigated in detail till now. We conducted a genome-wide integrative analysis to investigate the immunofunctionomes of SC at four tumor stages by quantifying the immunological functions defined by the Gene Ontology gene sets. DNA microarray gene expression profiles of 1100 SCs and 136 normal ovarian tissue controls were downloaded from the Gene Expression Omnibus database and converted to the functionome. Then the immunofunctionomes were reconstructed by extracting the offspring from the functionome for the four SC staging groups. The key immunological functions extracted from immunofunctionomes with a series of filters revealed that the immunopathy of SC consisted of a group of deregulated functions with the core members including B cell activation and differentiation, regulation of leukocyte chemotaxis/cellular extravasation, antigen receptor mediated signaling pathway, T helper mediated immunity and macrophage activation; and the auxiliary elements included leukocyte mediated immunity, regulation of inflammatory response, T cell differentiation, mononuclear cell migration, megakaryocyte differentiation, complement activation and cytokine production. These deregulated immunological functions reveal the candidates to target in the immunotherapy.","3":"International journal of molecular sciences","4":"30356023","5":"2018","6":"pathology"},{"1":"Key Immunological Functions Involved in the Progression of Epithelial Ovarian Serous Carcinoma Discovered by the Gene Ontology-Based Immunofunctionome Analysis.","2":"Serous carcinoma (SC) is the most common and lethal subtype of epithelial ovarian carcinoma; immunotherapy is a potential treatment for SC, however, the global immunological functions of SC as well as their change during the progression of SC have not been investigated in detail till now. We conducted a genome-wide integrative analysis to investigate the immunofunctionomes of SC at four tumor stages by quantifying the immunological functions defined by the Gene Ontology gene sets. DNA microarray gene expression profiles of 1100 SCs and 136 normal ovarian tissue controls were downloaded from the Gene Expression Omnibus database and converted to the functionome. Then the immunofunctionomes were reconstructed by extracting the offspring from the functionome for the four SC staging groups. The key immunological functions extracted from immunofunctionomes with a series of filters revealed that the immunopathy of SC consisted of a group of deregulated functions with the core members including B cell activation and differentiation, regulation of leukocyte chemotaxis/cellular extravasation, antigen receptor mediated signaling pathway, T helper mediated immunity and macrophage activation; and the auxiliary elements included leukocyte mediated immunity, regulation of inflammatory response, T cell differentiation, mononuclear cell migration, megakaryocyte differentiation, complement activation and cytokine production. These deregulated immunological functions reveal the candidates to target in the immunotherapy.","3":"International journal of molecular sciences","4":"30356023","5":"2018","6":"Case-Control Studies"},{"1":"Key Immunological Functions Involved in the Progression of Epithelial Ovarian Serous Carcinoma Discovered by the Gene Ontology-Based Immunofunctionome Analysis.","2":"Serous carcinoma (SC) is the most common and lethal subtype of epithelial ovarian carcinoma; immunotherapy is a potential treatment for SC, however, the global immunological functions of SC as well as their change during the progression of SC have not been investigated in detail till now. We conducted a genome-wide integrative analysis to investigate the immunofunctionomes of SC at four tumor stages by quantifying the immunological functions defined by the Gene Ontology gene sets. DNA microarray gene expression profiles of 1100 SCs and 136 normal ovarian tissue controls were downloaded from the Gene Expression Omnibus database and converted to the functionome. Then the immunofunctionomes were reconstructed by extracting the offspring from the functionome for the four SC staging groups. The key immunological functions extracted from immunofunctionomes with a series of filters revealed that the immunopathy of SC consisted of a group of deregulated functions with the core members including B cell activation and differentiation, regulation of leukocyte chemotaxis/cellular extravasation, antigen receptor mediated signaling pathway, T helper mediated immunity and macrophage activation; and the auxiliary elements included leukocyte mediated immunity, regulation of inflammatory response, T cell differentiation, mononuclear cell migration, megakaryocyte differentiation, complement activation and cytokine production. These deregulated immunological functions reveal the candidates to target in the immunotherapy.","3":"International journal of molecular sciences","4":"30356023","5":"2018","6":"Female"},{"1":"Key Immunological Functions Involved in the Progression of Epithelial Ovarian Serous Carcinoma Discovered by the Gene Ontology-Based Immunofunctionome Analysis.","2":"Serous carcinoma (SC) is the most common and lethal subtype of epithelial ovarian carcinoma; immunotherapy is a potential treatment for SC, however, the global immunological functions of SC as well as their change during the progression of SC have not been investigated in detail till now. We conducted a genome-wide integrative analysis to investigate the immunofunctionomes of SC at four tumor stages by quantifying the immunological functions defined by the Gene Ontology gene sets. DNA microarray gene expression profiles of 1100 SCs and 136 normal ovarian tissue controls were downloaded from the Gene Expression Omnibus database and converted to the functionome. Then the immunofunctionomes were reconstructed by extracting the offspring from the functionome for the four SC staging groups. The key immunological functions extracted from immunofunctionomes with a series of filters revealed that the immunopathy of SC consisted of a group of deregulated functions with the core members including B cell activation and differentiation, regulation of leukocyte chemotaxis/cellular extravasation, antigen receptor mediated signaling pathway, T helper mediated immunity and macrophage activation; and the auxiliary elements included leukocyte mediated immunity, regulation of inflammatory response, T cell differentiation, mononuclear cell migration, megakaryocyte differentiation, complement activation and cytokine production. These deregulated immunological functions reveal the candidates to target in the immunotherapy.","3":"International journal of molecular sciences","4":"30356023","5":"2018","6":"Gene Expression Regulation, Neoplastic"},{"1":"Key Immunological Functions Involved in the Progression of Epithelial Ovarian Serous Carcinoma Discovered by the Gene Ontology-Based Immunofunctionome Analysis.","2":"Serous carcinoma (SC) is the most common and lethal subtype of epithelial ovarian carcinoma; immunotherapy is a potential treatment for SC, however, the global immunological functions of SC as well as their change during the progression of SC have not been investigated in detail till now. We conducted a genome-wide integrative analysis to investigate the immunofunctionomes of SC at four tumor stages by quantifying the immunological functions defined by the Gene Ontology gene sets. DNA microarray gene expression profiles of 1100 SCs and 136 normal ovarian tissue controls were downloaded from the Gene Expression Omnibus database and converted to the functionome. Then the immunofunctionomes were reconstructed by extracting the offspring from the functionome for the four SC staging groups. The key immunological functions extracted from immunofunctionomes with a series of filters revealed that the immunopathy of SC consisted of a group of deregulated functions with the core members including B cell activation and differentiation, regulation of leukocyte chemotaxis/cellular extravasation, antigen receptor mediated signaling pathway, T helper mediated immunity and macrophage activation; and the auxiliary elements included leukocyte mediated immunity, regulation of inflammatory response, T cell differentiation, mononuclear cell migration, megakaryocyte differentiation, complement activation and cytokine production. These deregulated immunological functions reveal the candidates to target in the immunotherapy.","3":"International journal of molecular sciences","4":"30356023","5":"2018","6":"Humans"},{"1":"Key Immunological Functions Involved in the Progression of Epithelial Ovarian Serous Carcinoma Discovered by the Gene Ontology-Based Immunofunctionome Analysis.","2":"Serous carcinoma (SC) is the most common and lethal subtype of epithelial ovarian carcinoma; immunotherapy is a potential treatment for SC, however, the global immunological functions of SC as well as their change during the progression of SC have not been investigated in detail till now. We conducted a genome-wide integrative analysis to investigate the immunofunctionomes of SC at four tumor stages by quantifying the immunological functions defined by the Gene Ontology gene sets. DNA microarray gene expression profiles of 1100 SCs and 136 normal ovarian tissue controls were downloaded from the Gene Expression Omnibus database and converted to the functionome. Then the immunofunctionomes were reconstructed by extracting the offspring from the functionome for the four SC staging groups. The key immunological functions extracted from immunofunctionomes with a series of filters revealed that the immunopathy of SC consisted of a group of deregulated functions with the core members including B cell activation and differentiation, regulation of leukocyte chemotaxis/cellular extravasation, antigen receptor mediated signaling pathway, T helper mediated immunity and macrophage activation; and the auxiliary elements included leukocyte mediated immunity, regulation of inflammatory response, T cell differentiation, mononuclear cell migration, megakaryocyte differentiation, complement activation and cytokine production. These deregulated immunological functions reveal the candidates to target in the immunotherapy.","3":"International journal of molecular sciences","4":"30356023","5":"2018","6":"Machine Learning"},{"1":"Key Immunological Functions Involved in the Progression of Epithelial Ovarian Serous Carcinoma Discovered by the Gene Ontology-Based Immunofunctionome Analysis.","2":"Serous carcinoma (SC) is the most common and lethal subtype of epithelial ovarian carcinoma; immunotherapy is a potential treatment for SC, however, the global immunological functions of SC as well as their change during the progression of SC have not been investigated in detail till now. We conducted a genome-wide integrative analysis to investigate the immunofunctionomes of SC at four tumor stages by quantifying the immunological functions defined by the Gene Ontology gene sets. DNA microarray gene expression profiles of 1100 SCs and 136 normal ovarian tissue controls were downloaded from the Gene Expression Omnibus database and converted to the functionome. Then the immunofunctionomes were reconstructed by extracting the offspring from the functionome for the four SC staging groups. The key immunological functions extracted from immunofunctionomes with a series of filters revealed that the immunopathy of SC consisted of a group of deregulated functions with the core members including B cell activation and differentiation, regulation of leukocyte chemotaxis/cellular extravasation, antigen receptor mediated signaling pathway, T helper mediated immunity and macrophage activation; and the auxiliary elements included leukocyte mediated immunity, regulation of inflammatory response, T cell differentiation, mononuclear cell migration, megakaryocyte differentiation, complement activation and cytokine production. These deregulated immunological functions reveal the candidates to target in the immunotherapy.","3":"International journal of molecular sciences","4":"30356023","5":"2018","6":"Ovarian Neoplasms"},{"1":"Prediction of bioavailability and toxicity of complex chemical mixtures through machine learning models.","2":"Empirical data from a 6-month mesocosms experiment were used to assess the ability and performance of two machine learning (ML) models, including artificial neural network (NN) and random forest (RF), to predict temporal bioavailability changes of complex chemical mixtures in contaminated soils amended with compost or biochar. From the predicted bioavailability data, toxicity response for relevant ecological receptors was then forecasted to establish environmental risk implications and determine acceptable end-point remediation. The dataset corresponds to replicate samples collected over 180 days and analysed for total and bioavailable petroleum hydrocarbons and heavy metals/metalloids content. Further to this, a range of biological indicators including bacteria count, soil respiration, microbial community fingerprint, seeds germination, earthworm's lethality, and bioluminescent bacteria were evaluated to inform the environmental risk assessment. Parameters such as soil type, amendment (biochar and compost), initial concentration of individual compounds, and incubation time were used as inputs of the ML models. The relative importance of the input variables was also analysed to better understand the drivers of temporal changes in bioavailability and toxicity. It showed that toxicity changes can be driven by multiple factors (combined effects), which may not be accounted for in classical linear regression analysis (correlation). The use of ML models could improve our understanding of rate-limiting processes affecting the freely available fraction (bioavailable) of contaminants in soil, therefore contributing to mitigate potential risks and to inform appropriate response and recovery methods.","3":"Chemosphere","4":"30347356","5":"2018","6":"Biological Availability"},{"1":"Prediction of bioavailability and toxicity of complex chemical mixtures through machine learning models.","2":"Empirical data from a 6-month mesocosms experiment were used to assess the ability and performance of two machine learning (ML) models, including artificial neural network (NN) and random forest (RF), to predict temporal bioavailability changes of complex chemical mixtures in contaminated soils amended with compost or biochar. From the predicted bioavailability data, toxicity response for relevant ecological receptors was then forecasted to establish environmental risk implications and determine acceptable end-point remediation. The dataset corresponds to replicate samples collected over 180 days and analysed for total and bioavailable petroleum hydrocarbons and heavy metals/metalloids content. Further to this, a range of biological indicators including bacteria count, soil respiration, microbial community fingerprint, seeds germination, earthworm's lethality, and bioluminescent bacteria were evaluated to inform the environmental risk assessment. Parameters such as soil type, amendment (biochar and compost), initial concentration of individual compounds, and incubation time were used as inputs of the ML models. The relative importance of the input variables was also analysed to better understand the drivers of temporal changes in bioavailability and toxicity. It showed that toxicity changes can be driven by multiple factors (combined effects), which may not be accounted for in classical linear regression analysis (correlation). The use of ML models could improve our understanding of rate-limiting processes affecting the freely available fraction (bioavailable) of contaminants in soil, therefore contributing to mitigate potential risks and to inform appropriate response and recovery methods.","3":"Chemosphere","4":"30347356","5":"2018","6":"Charcoal"},{"1":"Prediction of bioavailability and toxicity of complex chemical mixtures through machine learning models.","2":"Empirical data from a 6-month mesocosms experiment were used to assess the ability and performance of two machine learning (ML) models, including artificial neural network (NN) and random forest (RF), to predict temporal bioavailability changes of complex chemical mixtures in contaminated soils amended with compost or biochar. From the predicted bioavailability data, toxicity response for relevant ecological receptors was then forecasted to establish environmental risk implications and determine acceptable end-point remediation. The dataset corresponds to replicate samples collected over 180 days and analysed for total and bioavailable petroleum hydrocarbons and heavy metals/metalloids content. Further to this, a range of biological indicators including bacteria count, soil respiration, microbial community fingerprint, seeds germination, earthworm's lethality, and bioluminescent bacteria were evaluated to inform the environmental risk assessment. Parameters such as soil type, amendment (biochar and compost), initial concentration of individual compounds, and incubation time were used as inputs of the ML models. The relative importance of the input variables was also analysed to better understand the drivers of temporal changes in bioavailability and toxicity. It showed that toxicity changes can be driven by multiple factors (combined effects), which may not be accounted for in classical linear regression analysis (correlation). The use of ML models could improve our understanding of rate-limiting processes affecting the freely available fraction (bioavailable) of contaminants in soil, therefore contributing to mitigate potential risks and to inform appropriate response and recovery methods.","3":"Chemosphere","4":"30347356","5":"2018","6":"Complex Mixtures"},{"1":"Prediction of bioavailability and toxicity of complex chemical mixtures through machine learning models.","2":"Empirical data from a 6-month mesocosms experiment were used to assess the ability and performance of two machine learning (ML) models, including artificial neural network (NN) and random forest (RF), to predict temporal bioavailability changes of complex chemical mixtures in contaminated soils amended with compost or biochar. From the predicted bioavailability data, toxicity response for relevant ecological receptors was then forecasted to establish environmental risk implications and determine acceptable end-point remediation. The dataset corresponds to replicate samples collected over 180 days and analysed for total and bioavailable petroleum hydrocarbons and heavy metals/metalloids content. Further to this, a range of biological indicators including bacteria count, soil respiration, microbial community fingerprint, seeds germination, earthworm's lethality, and bioluminescent bacteria were evaluated to inform the environmental risk assessment. Parameters such as soil type, amendment (biochar and compost), initial concentration of individual compounds, and incubation time were used as inputs of the ML models. The relative importance of the input variables was also analysed to better understand the drivers of temporal changes in bioavailability and toxicity. It showed that toxicity changes can be driven by multiple factors (combined effects), which may not be accounted for in classical linear regression analysis (correlation). The use of ML models could improve our understanding of rate-limiting processes affecting the freely available fraction (bioavailable) of contaminants in soil, therefore contributing to mitigate potential risks and to inform appropriate response and recovery methods.","3":"Chemosphere","4":"30347356","5":"2018","6":"pharmacokinetics"},{"1":"Prediction of bioavailability and toxicity of complex chemical mixtures through machine learning models.","2":"Empirical data from a 6-month mesocosms experiment were used to assess the ability and performance of two machine learning (ML) models, including artificial neural network (NN) and random forest (RF), to predict temporal bioavailability changes of complex chemical mixtures in contaminated soils amended with compost or biochar. From the predicted bioavailability data, toxicity response for relevant ecological receptors was then forecasted to establish environmental risk implications and determine acceptable end-point remediation. The dataset corresponds to replicate samples collected over 180 days and analysed for total and bioavailable petroleum hydrocarbons and heavy metals/metalloids content. Further to this, a range of biological indicators including bacteria count, soil respiration, microbial community fingerprint, seeds germination, earthworm's lethality, and bioluminescent bacteria were evaluated to inform the environmental risk assessment. Parameters such as soil type, amendment (biochar and compost), initial concentration of individual compounds, and incubation time were used as inputs of the ML models. The relative importance of the input variables was also analysed to better understand the drivers of temporal changes in bioavailability and toxicity. It showed that toxicity changes can be driven by multiple factors (combined effects), which may not be accounted for in classical linear regression analysis (correlation). The use of ML models could improve our understanding of rate-limiting processes affecting the freely available fraction (bioavailable) of contaminants in soil, therefore contributing to mitigate potential risks and to inform appropriate response and recovery methods.","3":"Chemosphere","4":"30347356","5":"2018","6":"toxicity"},{"1":"Prediction of bioavailability and toxicity of complex chemical mixtures through machine learning models.","2":"Empirical data from a 6-month mesocosms experiment were used to assess the ability and performance of two machine learning (ML) models, including artificial neural network (NN) and random forest (RF), to predict temporal bioavailability changes of complex chemical mixtures in contaminated soils amended with compost or biochar. From the predicted bioavailability data, toxicity response for relevant ecological receptors was then forecasted to establish environmental risk implications and determine acceptable end-point remediation. The dataset corresponds to replicate samples collected over 180 days and analysed for total and bioavailable petroleum hydrocarbons and heavy metals/metalloids content. Further to this, a range of biological indicators including bacteria count, soil respiration, microbial community fingerprint, seeds germination, earthworm's lethality, and bioluminescent bacteria were evaluated to inform the environmental risk assessment. Parameters such as soil type, amendment (biochar and compost), initial concentration of individual compounds, and incubation time were used as inputs of the ML models. The relative importance of the input variables was also analysed to better understand the drivers of temporal changes in bioavailability and toxicity. It showed that toxicity changes can be driven by multiple factors (combined effects), which may not be accounted for in classical linear regression analysis (correlation). The use of ML models could improve our understanding of rate-limiting processes affecting the freely available fraction (bioavailable) of contaminants in soil, therefore contributing to mitigate potential risks and to inform appropriate response and recovery methods.","3":"Chemosphere","4":"30347356","5":"2018","6":"Environmental Pollution"},{"1":"Prediction of bioavailability and toxicity of complex chemical mixtures through machine learning models.","2":"Empirical data from a 6-month mesocosms experiment were used to assess the ability and performance of two machine learning (ML) models, including artificial neural network (NN) and random forest (RF), to predict temporal bioavailability changes of complex chemical mixtures in contaminated soils amended with compost or biochar. From the predicted bioavailability data, toxicity response for relevant ecological receptors was then forecasted to establish environmental risk implications and determine acceptable end-point remediation. The dataset corresponds to replicate samples collected over 180 days and analysed for total and bioavailable petroleum hydrocarbons and heavy metals/metalloids content. Further to this, a range of biological indicators including bacteria count, soil respiration, microbial community fingerprint, seeds germination, earthworm's lethality, and bioluminescent bacteria were evaluated to inform the environmental risk assessment. Parameters such as soil type, amendment (biochar and compost), initial concentration of individual compounds, and incubation time were used as inputs of the ML models. The relative importance of the input variables was also analysed to better understand the drivers of temporal changes in bioavailability and toxicity. It showed that toxicity changes can be driven by multiple factors (combined effects), which may not be accounted for in classical linear regression analysis (correlation). The use of ML models could improve our understanding of rate-limiting processes affecting the freely available fraction (bioavailable) of contaminants in soil, therefore contributing to mitigate potential risks and to inform appropriate response and recovery methods.","3":"Chemosphere","4":"30347356","5":"2018","6":"analysis"},{"1":"Prediction of bioavailability and toxicity of complex chemical mixtures through machine learning models.","2":"Empirical data from a 6-month mesocosms experiment were used to assess the ability and performance of two machine learning (ML) models, including artificial neural network (NN) and random forest (RF), to predict temporal bioavailability changes of complex chemical mixtures in contaminated soils amended with compost or biochar. From the predicted bioavailability data, toxicity response for relevant ecological receptors was then forecasted to establish environmental risk implications and determine acceptable end-point remediation. The dataset corresponds to replicate samples collected over 180 days and analysed for total and bioavailable petroleum hydrocarbons and heavy metals/metalloids content. Further to this, a range of biological indicators including bacteria count, soil respiration, microbial community fingerprint, seeds germination, earthworm's lethality, and bioluminescent bacteria were evaluated to inform the environmental risk assessment. Parameters such as soil type, amendment (biochar and compost), initial concentration of individual compounds, and incubation time were used as inputs of the ML models. The relative importance of the input variables was also analysed to better understand the drivers of temporal changes in bioavailability and toxicity. It showed that toxicity changes can be driven by multiple factors (combined effects), which may not be accounted for in classical linear regression analysis (correlation). The use of ML models could improve our understanding of rate-limiting processes affecting the freely available fraction (bioavailable) of contaminants in soil, therefore contributing to mitigate potential risks and to inform appropriate response and recovery methods.","3":"Chemosphere","4":"30347356","5":"2018","6":"Hydrocarbons"},{"1":"Prediction of bioavailability and toxicity of complex chemical mixtures through machine learning models.","2":"Empirical data from a 6-month mesocosms experiment were used to assess the ability and performance of two machine learning (ML) models, including artificial neural network (NN) and random forest (RF), to predict temporal bioavailability changes of complex chemical mixtures in contaminated soils amended with compost or biochar. From the predicted bioavailability data, toxicity response for relevant ecological receptors was then forecasted to establish environmental risk implications and determine acceptable end-point remediation. The dataset corresponds to replicate samples collected over 180 days and analysed for total and bioavailable petroleum hydrocarbons and heavy metals/metalloids content. Further to this, a range of biological indicators including bacteria count, soil respiration, microbial community fingerprint, seeds germination, earthworm's lethality, and bioluminescent bacteria were evaluated to inform the environmental risk assessment. Parameters such as soil type, amendment (biochar and compost), initial concentration of individual compounds, and incubation time were used as inputs of the ML models. The relative importance of the input variables was also analysed to better understand the drivers of temporal changes in bioavailability and toxicity. It showed that toxicity changes can be driven by multiple factors (combined effects), which may not be accounted for in classical linear regression analysis (correlation). The use of ML models could improve our understanding of rate-limiting processes affecting the freely available fraction (bioavailable) of contaminants in soil, therefore contributing to mitigate potential risks and to inform appropriate response and recovery methods.","3":"Chemosphere","4":"30347356","5":"2018","6":"pharmacokinetics"},{"1":"Prediction of bioavailability and toxicity of complex chemical mixtures through machine learning models.","2":"Empirical data from a 6-month mesocosms experiment were used to assess the ability and performance of two machine learning (ML) models, including artificial neural network (NN) and random forest (RF), to predict temporal bioavailability changes of complex chemical mixtures in contaminated soils amended with compost or biochar. From the predicted bioavailability data, toxicity response for relevant ecological receptors was then forecasted to establish environmental risk implications and determine acceptable end-point remediation. The dataset corresponds to replicate samples collected over 180 days and analysed for total and bioavailable petroleum hydrocarbons and heavy metals/metalloids content. Further to this, a range of biological indicators including bacteria count, soil respiration, microbial community fingerprint, seeds germination, earthworm's lethality, and bioluminescent bacteria were evaluated to inform the environmental risk assessment. Parameters such as soil type, amendment (biochar and compost), initial concentration of individual compounds, and incubation time were used as inputs of the ML models. The relative importance of the input variables was also analysed to better understand the drivers of temporal changes in bioavailability and toxicity. It showed that toxicity changes can be driven by multiple factors (combined effects), which may not be accounted for in classical linear regression analysis (correlation). The use of ML models could improve our understanding of rate-limiting processes affecting the freely available fraction (bioavailable) of contaminants in soil, therefore contributing to mitigate potential risks and to inform appropriate response and recovery methods.","3":"Chemosphere","4":"30347356","5":"2018","6":"toxicity"},{"1":"Prediction of bioavailability and toxicity of complex chemical mixtures through machine learning models.","2":"Empirical data from a 6-month mesocosms experiment were used to assess the ability and performance of two machine learning (ML) models, including artificial neural network (NN) and random forest (RF), to predict temporal bioavailability changes of complex chemical mixtures in contaminated soils amended with compost or biochar. From the predicted bioavailability data, toxicity response for relevant ecological receptors was then forecasted to establish environmental risk implications and determine acceptable end-point remediation. The dataset corresponds to replicate samples collected over 180 days and analysed for total and bioavailable petroleum hydrocarbons and heavy metals/metalloids content. Further to this, a range of biological indicators including bacteria count, soil respiration, microbial community fingerprint, seeds germination, earthworm's lethality, and bioluminescent bacteria were evaluated to inform the environmental risk assessment. Parameters such as soil type, amendment (biochar and compost), initial concentration of individual compounds, and incubation time were used as inputs of the ML models. The relative importance of the input variables was also analysed to better understand the drivers of temporal changes in bioavailability and toxicity. It showed that toxicity changes can be driven by multiple factors (combined effects), which may not be accounted for in classical linear regression analysis (correlation). The use of ML models could improve our understanding of rate-limiting processes affecting the freely available fraction (bioavailable) of contaminants in soil, therefore contributing to mitigate potential risks and to inform appropriate response and recovery methods.","3":"Chemosphere","4":"30347356","5":"2018","6":"Machine Learning"},{"1":"Prediction of bioavailability and toxicity of complex chemical mixtures through machine learning models.","2":"Empirical data from a 6-month mesocosms experiment were used to assess the ability and performance of two machine learning (ML) models, including artificial neural network (NN) and random forest (RF), to predict temporal bioavailability changes of complex chemical mixtures in contaminated soils amended with compost or biochar. From the predicted bioavailability data, toxicity response for relevant ecological receptors was then forecasted to establish environmental risk implications and determine acceptable end-point remediation. The dataset corresponds to replicate samples collected over 180 days and analysed for total and bioavailable petroleum hydrocarbons and heavy metals/metalloids content. Further to this, a range of biological indicators including bacteria count, soil respiration, microbial community fingerprint, seeds germination, earthworm's lethality, and bioluminescent bacteria were evaluated to inform the environmental risk assessment. Parameters such as soil type, amendment (biochar and compost), initial concentration of individual compounds, and incubation time were used as inputs of the ML models. The relative importance of the input variables was also analysed to better understand the drivers of temporal changes in bioavailability and toxicity. It showed that toxicity changes can be driven by multiple factors (combined effects), which may not be accounted for in classical linear regression analysis (correlation). The use of ML models could improve our understanding of rate-limiting processes affecting the freely available fraction (bioavailable) of contaminants in soil, therefore contributing to mitigate potential risks and to inform appropriate response and recovery methods.","3":"Chemosphere","4":"30347356","5":"2018","6":"Metals, Heavy"},{"1":"Prediction of bioavailability and toxicity of complex chemical mixtures through machine learning models.","2":"Empirical data from a 6-month mesocosms experiment were used to assess the ability and performance of two machine learning (ML) models, including artificial neural network (NN) and random forest (RF), to predict temporal bioavailability changes of complex chemical mixtures in contaminated soils amended with compost or biochar. From the predicted bioavailability data, toxicity response for relevant ecological receptors was then forecasted to establish environmental risk implications and determine acceptable end-point remediation. The dataset corresponds to replicate samples collected over 180 days and analysed for total and bioavailable petroleum hydrocarbons and heavy metals/metalloids content. Further to this, a range of biological indicators including bacteria count, soil respiration, microbial community fingerprint, seeds germination, earthworm's lethality, and bioluminescent bacteria were evaluated to inform the environmental risk assessment. Parameters such as soil type, amendment (biochar and compost), initial concentration of individual compounds, and incubation time were used as inputs of the ML models. The relative importance of the input variables was also analysed to better understand the drivers of temporal changes in bioavailability and toxicity. It showed that toxicity changes can be driven by multiple factors (combined effects), which may not be accounted for in classical linear regression analysis (correlation). The use of ML models could improve our understanding of rate-limiting processes affecting the freely available fraction (bioavailable) of contaminants in soil, therefore contributing to mitigate potential risks and to inform appropriate response and recovery methods.","3":"Chemosphere","4":"30347356","5":"2018","6":"analysis"},{"1":"Prediction of bioavailability and toxicity of complex chemical mixtures through machine learning models.","2":"Empirical data from a 6-month mesocosms experiment were used to assess the ability and performance of two machine learning (ML) models, including artificial neural network (NN) and random forest (RF), to predict temporal bioavailability changes of complex chemical mixtures in contaminated soils amended with compost or biochar. From the predicted bioavailability data, toxicity response for relevant ecological receptors was then forecasted to establish environmental risk implications and determine acceptable end-point remediation. The dataset corresponds to replicate samples collected over 180 days and analysed for total and bioavailable petroleum hydrocarbons and heavy metals/metalloids content. Further to this, a range of biological indicators including bacteria count, soil respiration, microbial community fingerprint, seeds germination, earthworm's lethality, and bioluminescent bacteria were evaluated to inform the environmental risk assessment. Parameters such as soil type, amendment (biochar and compost), initial concentration of individual compounds, and incubation time were used as inputs of the ML models. The relative importance of the input variables was also analysed to better understand the drivers of temporal changes in bioavailability and toxicity. It showed that toxicity changes can be driven by multiple factors (combined effects), which may not be accounted for in classical linear regression analysis (correlation). The use of ML models could improve our understanding of rate-limiting processes affecting the freely available fraction (bioavailable) of contaminants in soil, therefore contributing to mitigate potential risks and to inform appropriate response and recovery methods.","3":"Chemosphere","4":"30347356","5":"2018","6":"Neural Networks (Computer)"},{"1":"Prediction of bioavailability and toxicity of complex chemical mixtures through machine learning models.","2":"Empirical data from a 6-month mesocosms experiment were used to assess the ability and performance of two machine learning (ML) models, including artificial neural network (NN) and random forest (RF), to predict temporal bioavailability changes of complex chemical mixtures in contaminated soils amended with compost or biochar. From the predicted bioavailability data, toxicity response for relevant ecological receptors was then forecasted to establish environmental risk implications and determine acceptable end-point remediation. The dataset corresponds to replicate samples collected over 180 days and analysed for total and bioavailable petroleum hydrocarbons and heavy metals/metalloids content. Further to this, a range of biological indicators including bacteria count, soil respiration, microbial community fingerprint, seeds germination, earthworm's lethality, and bioluminescent bacteria were evaluated to inform the environmental risk assessment. Parameters such as soil type, amendment (biochar and compost), initial concentration of individual compounds, and incubation time were used as inputs of the ML models. The relative importance of the input variables was also analysed to better understand the drivers of temporal changes in bioavailability and toxicity. It showed that toxicity changes can be driven by multiple factors (combined effects), which may not be accounted for in classical linear regression analysis (correlation). The use of ML models could improve our understanding of rate-limiting processes affecting the freely available fraction (bioavailable) of contaminants in soil, therefore contributing to mitigate potential risks and to inform appropriate response and recovery methods.","3":"Chemosphere","4":"30347356","5":"2018","6":"Petroleum"},{"1":"Prediction of bioavailability and toxicity of complex chemical mixtures through machine learning models.","2":"Empirical data from a 6-month mesocosms experiment were used to assess the ability and performance of two machine learning (ML) models, including artificial neural network (NN) and random forest (RF), to predict temporal bioavailability changes of complex chemical mixtures in contaminated soils amended with compost or biochar. From the predicted bioavailability data, toxicity response for relevant ecological receptors was then forecasted to establish environmental risk implications and determine acceptable end-point remediation. The dataset corresponds to replicate samples collected over 180 days and analysed for total and bioavailable petroleum hydrocarbons and heavy metals/metalloids content. Further to this, a range of biological indicators including bacteria count, soil respiration, microbial community fingerprint, seeds germination, earthworm's lethality, and bioluminescent bacteria were evaluated to inform the environmental risk assessment. Parameters such as soil type, amendment (biochar and compost), initial concentration of individual compounds, and incubation time were used as inputs of the ML models. The relative importance of the input variables was also analysed to better understand the drivers of temporal changes in bioavailability and toxicity. It showed that toxicity changes can be driven by multiple factors (combined effects), which may not be accounted for in classical linear regression analysis (correlation). The use of ML models could improve our understanding of rate-limiting processes affecting the freely available fraction (bioavailable) of contaminants in soil, therefore contributing to mitigate potential risks and to inform appropriate response and recovery methods.","3":"Chemosphere","4":"30347356","5":"2018","6":"toxicity"},{"1":"Prediction of bioavailability and toxicity of complex chemical mixtures through machine learning models.","2":"Empirical data from a 6-month mesocosms experiment were used to assess the ability and performance of two machine learning (ML) models, including artificial neural network (NN) and random forest (RF), to predict temporal bioavailability changes of complex chemical mixtures in contaminated soils amended with compost or biochar. From the predicted bioavailability data, toxicity response for relevant ecological receptors was then forecasted to establish environmental risk implications and determine acceptable end-point remediation. The dataset corresponds to replicate samples collected over 180 days and analysed for total and bioavailable petroleum hydrocarbons and heavy metals/metalloids content. Further to this, a range of biological indicators including bacteria count, soil respiration, microbial community fingerprint, seeds germination, earthworm's lethality, and bioluminescent bacteria were evaluated to inform the environmental risk assessment. Parameters such as soil type, amendment (biochar and compost), initial concentration of individual compounds, and incubation time were used as inputs of the ML models. The relative importance of the input variables was also analysed to better understand the drivers of temporal changes in bioavailability and toxicity. It showed that toxicity changes can be driven by multiple factors (combined effects), which may not be accounted for in classical linear regression analysis (correlation). The use of ML models could improve our understanding of rate-limiting processes affecting the freely available fraction (bioavailable) of contaminants in soil, therefore contributing to mitigate potential risks and to inform appropriate response and recovery methods.","3":"Chemosphere","4":"30347356","5":"2018","6":"Risk Assessment"},{"1":"Prediction of bioavailability and toxicity of complex chemical mixtures through machine learning models.","2":"Empirical data from a 6-month mesocosms experiment were used to assess the ability and performance of two machine learning (ML) models, including artificial neural network (NN) and random forest (RF), to predict temporal bioavailability changes of complex chemical mixtures in contaminated soils amended with compost or biochar. From the predicted bioavailability data, toxicity response for relevant ecological receptors was then forecasted to establish environmental risk implications and determine acceptable end-point remediation. The dataset corresponds to replicate samples collected over 180 days and analysed for total and bioavailable petroleum hydrocarbons and heavy metals/metalloids content. Further to this, a range of biological indicators including bacteria count, soil respiration, microbial community fingerprint, seeds germination, earthworm's lethality, and bioluminescent bacteria were evaluated to inform the environmental risk assessment. Parameters such as soil type, amendment (biochar and compost), initial concentration of individual compounds, and incubation time were used as inputs of the ML models. The relative importance of the input variables was also analysed to better understand the drivers of temporal changes in bioavailability and toxicity. It showed that toxicity changes can be driven by multiple factors (combined effects), which may not be accounted for in classical linear regression analysis (correlation). The use of ML models could improve our understanding of rate-limiting processes affecting the freely available fraction (bioavailable) of contaminants in soil, therefore contributing to mitigate potential risks and to inform appropriate response and recovery methods.","3":"Chemosphere","4":"30347356","5":"2018","6":"Soil"},{"1":"Prediction of bioavailability and toxicity of complex chemical mixtures through machine learning models.","2":"Empirical data from a 6-month mesocosms experiment were used to assess the ability and performance of two machine learning (ML) models, including artificial neural network (NN) and random forest (RF), to predict temporal bioavailability changes of complex chemical mixtures in contaminated soils amended with compost or biochar. From the predicted bioavailability data, toxicity response for relevant ecological receptors was then forecasted to establish environmental risk implications and determine acceptable end-point remediation. The dataset corresponds to replicate samples collected over 180 days and analysed for total and bioavailable petroleum hydrocarbons and heavy metals/metalloids content. Further to this, a range of biological indicators including bacteria count, soil respiration, microbial community fingerprint, seeds germination, earthworm's lethality, and bioluminescent bacteria were evaluated to inform the environmental risk assessment. Parameters such as soil type, amendment (biochar and compost), initial concentration of individual compounds, and incubation time were used as inputs of the ML models. The relative importance of the input variables was also analysed to better understand the drivers of temporal changes in bioavailability and toxicity. It showed that toxicity changes can be driven by multiple factors (combined effects), which may not be accounted for in classical linear regression analysis (correlation). The use of ML models could improve our understanding of rate-limiting processes affecting the freely available fraction (bioavailable) of contaminants in soil, therefore contributing to mitigate potential risks and to inform appropriate response and recovery methods.","3":"Chemosphere","4":"30347356","5":"2018","6":"chemistry"},{"1":"Prediction of bioavailability and toxicity of complex chemical mixtures through machine learning models.","2":"Empirical data from a 6-month mesocosms experiment were used to assess the ability and performance of two machine learning (ML) models, including artificial neural network (NN) and random forest (RF), to predict temporal bioavailability changes of complex chemical mixtures in contaminated soils amended with compost or biochar. From the predicted bioavailability data, toxicity response for relevant ecological receptors was then forecasted to establish environmental risk implications and determine acceptable end-point remediation. The dataset corresponds to replicate samples collected over 180 days and analysed for total and bioavailable petroleum hydrocarbons and heavy metals/metalloids content. Further to this, a range of biological indicators including bacteria count, soil respiration, microbial community fingerprint, seeds germination, earthworm's lethality, and bioluminescent bacteria were evaluated to inform the environmental risk assessment. Parameters such as soil type, amendment (biochar and compost), initial concentration of individual compounds, and incubation time were used as inputs of the ML models. The relative importance of the input variables was also analysed to better understand the drivers of temporal changes in bioavailability and toxicity. It showed that toxicity changes can be driven by multiple factors (combined effects), which may not be accounted for in classical linear regression analysis (correlation). The use of ML models could improve our understanding of rate-limiting processes affecting the freely available fraction (bioavailable) of contaminants in soil, therefore contributing to mitigate potential risks and to inform appropriate response and recovery methods.","3":"Chemosphere","4":"30347356","5":"2018","6":"Soil Microbiology"},{"1":"Prediction of bioavailability and toxicity of complex chemical mixtures through machine learning models.","2":"Empirical data from a 6-month mesocosms experiment were used to assess the ability and performance of two machine learning (ML) models, including artificial neural network (NN) and random forest (RF), to predict temporal bioavailability changes of complex chemical mixtures in contaminated soils amended with compost or biochar. From the predicted bioavailability data, toxicity response for relevant ecological receptors was then forecasted to establish environmental risk implications and determine acceptable end-point remediation. The dataset corresponds to replicate samples collected over 180 days and analysed for total and bioavailable petroleum hydrocarbons and heavy metals/metalloids content. Further to this, a range of biological indicators including bacteria count, soil respiration, microbial community fingerprint, seeds germination, earthworm's lethality, and bioluminescent bacteria were evaluated to inform the environmental risk assessment. Parameters such as soil type, amendment (biochar and compost), initial concentration of individual compounds, and incubation time were used as inputs of the ML models. The relative importance of the input variables was also analysed to better understand the drivers of temporal changes in bioavailability and toxicity. It showed that toxicity changes can be driven by multiple factors (combined effects), which may not be accounted for in classical linear regression analysis (correlation). The use of ML models could improve our understanding of rate-limiting processes affecting the freely available fraction (bioavailable) of contaminants in soil, therefore contributing to mitigate potential risks and to inform appropriate response and recovery methods.","3":"Chemosphere","4":"30347356","5":"2018","6":"Soil Pollutants"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"Adult"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"Anger"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"Anxiety"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"psychology"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"Breast Neoplasms"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"surgery"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"Chronic Pain"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"psychology"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"Cohort Studies"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"Depression"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"psychology"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"Female"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"Humans"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"Machine Learning"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"Mastectomy"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"Middle Aged"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"Pain Measurement"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"methods"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"psychology"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"Pain, Postoperative"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"psychology"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"Predictive Value of Tests"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"Psychiatric Status Rating Scales"},{"1":"Machine-learned selection of psychological questionnaire items relevant to the development of persistent pain after breast cancer surgery.","2":"BACKGROUND: Prevention of persistent pain after breast cancer surgery, via early identification of patients at high risk, is a clinical need. Psychological factors are among the most consistently proposed predictive parameters for the development of persistent pain. However, repeated use of long psychological questionnaires in this context may be exhaustive for a patient and inconvenient in everyday clinical practice.METHODS: Supervised machine learning was used to create a short form of questionnaires that would provide the same predictive performance of pain persistence as the full questionnaires in a cohort of 1000 women followed up for 3 yr after breast cancer surgery. Machine-learned predictors were first trained with the full-item set of Beck's Depression Inventory (BDI), Spielberger's State-Trait Anxiety Inventory (STAI), and the State-Trait Anger Expression Inventory (STAXI-2). Subsequently, features were selected from the questionnaires to create predictors having a reduced set of items.RESULTS: A combined seven-item set of 10% of the original psychological questions from STAI and BDI, provided the same predictive performance parameters as the full questionnaires for the development of persistent postsurgical pain. The seven-item version offers a shorter and at least as accurate identification of women in whom pain persistence is unlikely (almost 95% negative predictive value).CONCLUSIONS: Using a data-driven machine-learning approach, a short list of seven items from BDI and STAI is proposed as a basis for a predictive tool for the persistence of pain after breast cancer surgery.","3":"British journal of anaesthesia","4":"30336857","5":"2018","6":"Surveys and Questionnaires"},{"1":"Editorial Conference Report 5th International One Health Congress, Saskatoon, Canada, 22-25 June 2018.","2":"","3":"Journal of medical microbiology","4":"30328807","5":"2018","6":"Animals"},{"1":"Editorial Conference Report 5th International One Health Congress, Saskatoon, Canada, 22-25 June 2018.","2":"","3":"Journal of medical microbiology","4":"30328807","5":"2018","6":"Anti-Infective Agents"},{"1":"Editorial Conference Report 5th International One Health Congress, Saskatoon, Canada, 22-25 June 2018.","2":"","3":"Journal of medical microbiology","4":"30328807","5":"2018","6":"chemical synthesis"},{"1":"Editorial Conference Report 5th International One Health Congress, Saskatoon, Canada, 22-25 June 2018.","2":"","3":"Journal of medical microbiology","4":"30328807","5":"2018","6":"isolation &amp; purification"},{"1":"Editorial Conference Report 5th International One Health Congress, Saskatoon, Canada, 22-25 June 2018.","2":"","3":"Journal of medical microbiology","4":"30328807","5":"2018","6":"supply &amp; distribution"},{"1":"Editorial Conference Report 5th International One Health Congress, Saskatoon, Canada, 22-25 June 2018.","2":"","3":"Journal of medical microbiology","4":"30328807","5":"2018","6":"Antimicrobial Stewardship"},{"1":"Editorial Conference Report 5th International One Health Congress, Saskatoon, Canada, 22-25 June 2018.","2":"","3":"Journal of medical microbiology","4":"30328807","5":"2018","6":"Canada"},{"1":"Editorial Conference Report 5th International One Health Congress, Saskatoon, Canada, 22-25 June 2018.","2":"","3":"Journal of medical microbiology","4":"30328807","5":"2018","6":"Drug Discovery"},{"1":"Editorial Conference Report 5th International One Health Congress, Saskatoon, Canada, 22-25 June 2018.","2":"","3":"Journal of medical microbiology","4":"30328807","5":"2018","6":"Drug Resistance, Microbial"},{"1":"Editorial Conference Report 5th International One Health Congress, Saskatoon, Canada, 22-25 June 2018.","2":"","3":"Journal of medical microbiology","4":"30328807","5":"2018","6":"Epidemiological Monitoring"},{"1":"Editorial Conference Report 5th International One Health Congress, Saskatoon, Canada, 22-25 June 2018.","2":"","3":"Journal of medical microbiology","4":"30328807","5":"2018","6":"Global Health"},{"1":"Editorial Conference Report 5th International One Health Congress, Saskatoon, Canada, 22-25 June 2018.","2":"","3":"Journal of medical microbiology","4":"30328807","5":"2018","6":"trends"},{"1":"Editorial Conference Report 5th International One Health Congress, Saskatoon, Canada, 22-25 June 2018.","2":"","3":"Journal of medical microbiology","4":"30328807","5":"2018","6":"Humans"},{"1":"Editorial Conference Report 5th International One Health Congress, Saskatoon, Canada, 22-25 June 2018.","2":"","3":"Journal of medical microbiology","4":"30328807","5":"2018","6":"Machine Learning"},{"1":"Editorial Conference Report 5th International One Health Congress, Saskatoon, Canada, 22-25 June 2018.","2":"","3":"Journal of medical microbiology","4":"30328807","5":"2018","6":"One Health"},{"1":"Particle Swarm Optimization-Based Support Vector Regression for Tourist Arrivals Forecasting.","2":"The tourism industry has become one of the most important economic sectors for governments worldwide. Accurately forecasting tourism demand is crucial because it provides useful information to related industries and governments, enabling stakeholders to adjust plans and policies. To develop a forecasting tool for the tourism industry, this study proposes a method that combines feature selection (FS) and support vector regression (SVR) with particle swarm optimization (PSO), named FS-PSOSVR. To ensure high forecast accuracy, FS and a PSO algorithm are employed to, respectively, select reliable input variables and to identify the optimal initial parameters of SVR. The proposed method was tested using a data set of monthly tourist arrivals to Taiwan from January 2006 to December 2016. The results reveal that the errors obtained using FS-PSOSVR are comparatively smaller than those obtained using other methods, indicating that FS-PSOSVR is an effective method for forecasting tourism demand.","3":"Computational intelligence and neuroscience","4":"30327666","5":"2018","6":"Forecasting"},{"1":"Particle Swarm Optimization-Based Support Vector Regression for Tourist Arrivals Forecasting.","2":"The tourism industry has become one of the most important economic sectors for governments worldwide. Accurately forecasting tourism demand is crucial because it provides useful information to related industries and governments, enabling stakeholders to adjust plans and policies. To develop a forecasting tool for the tourism industry, this study proposes a method that combines feature selection (FS) and support vector regression (SVR) with particle swarm optimization (PSO), named FS-PSOSVR. To ensure high forecast accuracy, FS and a PSO algorithm are employed to, respectively, select reliable input variables and to identify the optimal initial parameters of SVR. The proposed method was tested using a data set of monthly tourist arrivals to Taiwan from January 2006 to December 2016. The results reveal that the errors obtained using FS-PSOSVR are comparatively smaller than those obtained using other methods, indicating that FS-PSOSVR is an effective method for forecasting tourism demand.","3":"Computational intelligence and neuroscience","4":"30327666","5":"2018","6":"methods"},{"1":"Particle Swarm Optimization-Based Support Vector Regression for Tourist Arrivals Forecasting.","2":"The tourism industry has become one of the most important economic sectors for governments worldwide. Accurately forecasting tourism demand is crucial because it provides useful information to related industries and governments, enabling stakeholders to adjust plans and policies. To develop a forecasting tool for the tourism industry, this study proposes a method that combines feature selection (FS) and support vector regression (SVR) with particle swarm optimization (PSO), named FS-PSOSVR. To ensure high forecast accuracy, FS and a PSO algorithm are employed to, respectively, select reliable input variables and to identify the optimal initial parameters of SVR. The proposed method was tested using a data set of monthly tourist arrivals to Taiwan from January 2006 to December 2016. The results reveal that the errors obtained using FS-PSOSVR are comparatively smaller than those obtained using other methods, indicating that FS-PSOSVR is an effective method for forecasting tourism demand.","3":"Computational intelligence and neuroscience","4":"30327666","5":"2018","6":"Humans"},{"1":"Particle Swarm Optimization-Based Support Vector Regression for Tourist Arrivals Forecasting.","2":"The tourism industry has become one of the most important economic sectors for governments worldwide. Accurately forecasting tourism demand is crucial because it provides useful information to related industries and governments, enabling stakeholders to adjust plans and policies. To develop a forecasting tool for the tourism industry, this study proposes a method that combines feature selection (FS) and support vector regression (SVR) with particle swarm optimization (PSO), named FS-PSOSVR. To ensure high forecast accuracy, FS and a PSO algorithm are employed to, respectively, select reliable input variables and to identify the optimal initial parameters of SVR. The proposed method was tested using a data set of monthly tourist arrivals to Taiwan from January 2006 to December 2016. The results reveal that the errors obtained using FS-PSOSVR are comparatively smaller than those obtained using other methods, indicating that FS-PSOSVR is an effective method for forecasting tourism demand.","3":"Computational intelligence and neuroscience","4":"30327666","5":"2018","6":"Leisure Activities"},{"1":"Particle Swarm Optimization-Based Support Vector Regression for Tourist Arrivals Forecasting.","2":"The tourism industry has become one of the most important economic sectors for governments worldwide. Accurately forecasting tourism demand is crucial because it provides useful information to related industries and governments, enabling stakeholders to adjust plans and policies. To develop a forecasting tool for the tourism industry, this study proposes a method that combines feature selection (FS) and support vector regression (SVR) with particle swarm optimization (PSO), named FS-PSOSVR. To ensure high forecast accuracy, FS and a PSO algorithm are employed to, respectively, select reliable input variables and to identify the optimal initial parameters of SVR. The proposed method was tested using a data set of monthly tourist arrivals to Taiwan from January 2006 to December 2016. The results reveal that the errors obtained using FS-PSOSVR are comparatively smaller than those obtained using other methods, indicating that FS-PSOSVR is an effective method for forecasting tourism demand.","3":"Computational intelligence and neuroscience","4":"30327666","5":"2018","6":"Regression Analysis"},{"1":"Particle Swarm Optimization-Based Support Vector Regression for Tourist Arrivals Forecasting.","2":"The tourism industry has become one of the most important economic sectors for governments worldwide. Accurately forecasting tourism demand is crucial because it provides useful information to related industries and governments, enabling stakeholders to adjust plans and policies. To develop a forecasting tool for the tourism industry, this study proposes a method that combines feature selection (FS) and support vector regression (SVR) with particle swarm optimization (PSO), named FS-PSOSVR. To ensure high forecast accuracy, FS and a PSO algorithm are employed to, respectively, select reliable input variables and to identify the optimal initial parameters of SVR. The proposed method was tested using a data set of monthly tourist arrivals to Taiwan from January 2006 to December 2016. The results reveal that the errors obtained using FS-PSOSVR are comparatively smaller than those obtained using other methods, indicating that FS-PSOSVR is an effective method for forecasting tourism demand.","3":"Computational intelligence and neuroscience","4":"30327666","5":"2018","6":"Support Vector Machine"},{"1":"Particle Swarm Optimization-Based Support Vector Regression for Tourist Arrivals Forecasting.","2":"The tourism industry has become one of the most important economic sectors for governments worldwide. Accurately forecasting tourism demand is crucial because it provides useful information to related industries and governments, enabling stakeholders to adjust plans and policies. To develop a forecasting tool for the tourism industry, this study proposes a method that combines feature selection (FS) and support vector regression (SVR) with particle swarm optimization (PSO), named FS-PSOSVR. To ensure high forecast accuracy, FS and a PSO algorithm are employed to, respectively, select reliable input variables and to identify the optimal initial parameters of SVR. The proposed method was tested using a data set of monthly tourist arrivals to Taiwan from January 2006 to December 2016. The results reveal that the errors obtained using FS-PSOSVR are comparatively smaller than those obtained using other methods, indicating that FS-PSOSVR is an effective method for forecasting tourism demand.","3":"Computational intelligence and neuroscience","4":"30327666","5":"2018","6":"Taiwan"},{"1":"Particle Swarm Optimization-Based Support Vector Regression for Tourist Arrivals Forecasting.","2":"The tourism industry has become one of the most important economic sectors for governments worldwide. Accurately forecasting tourism demand is crucial because it provides useful information to related industries and governments, enabling stakeholders to adjust plans and policies. To develop a forecasting tool for the tourism industry, this study proposes a method that combines feature selection (FS) and support vector regression (SVR) with particle swarm optimization (PSO), named FS-PSOSVR. To ensure high forecast accuracy, FS and a PSO algorithm are employed to, respectively, select reliable input variables and to identify the optimal initial parameters of SVR. The proposed method was tested using a data set of monthly tourist arrivals to Taiwan from January 2006 to December 2016. The results reveal that the errors obtained using FS-PSOSVR are comparatively smaller than those obtained using other methods, indicating that FS-PSOSVR is an effective method for forecasting tourism demand.","3":"Computational intelligence and neuroscience","4":"30327666","5":"2018","6":"Travel"},{"1":"Multimodal MRI-based classification of migraine: using deep learning convolutional neural network.","2":"BACKGROUND: Recently, deep learning technologies have rapidly expanded into medical image analysis, including both disease detection and classification. As far as we know, migraine is a disabling and common neurological disorder, typically characterized by unilateral, throbbing and pulsating headaches. Unfortunately, a large number of migraineurs do not receive the accurate diagnosis when using traditional diagnostic criteria based on the guidelines of the International Headache Society. As such, there is substantial interest in developing automated methods to assist in the diagnosis of migraine.METHODS: To the best of our knowledge, no studies have evaluated the potential of deep learning technologies in assisting with the classification of migraine patients. Here, we used deep learning methods in combination with three functional measures (the amplitude of low-frequency fluctuations, regional homogeneity and regional functional correlation strength) based on rs-fMRI data to distinguish not only between migraineurs and healthy controls, but also between the two subtypes of migraine. We employed 21 migraine patients without aura, 15 migraineurs with aura, and 28 healthy controls.RESULTS: Compared with the traditional support vector machine classifier, which has an accuracy of 83.67%, our Inception module-based convolutional neural network approach showed a significant improvement in classification output (over 86.18%). Our data also indicate that the Inception module-based CNN performs better than the AlexNet-based CNN (Inception module-based CNN reached an accuracy of 99.25%). Finally, we also found that regional functional correlation strength (RFCS) could be regarded as the optimum input out of the three indices (ALFF, ReHo, RFCS).CONCLUSIONS: Overall, our study shows that combining the three functional measures of rs-fMRI with deep learning classification is a powerful method to distinguish between migraineurs and healthy individuals. Our data also highlight that deep learning-based frameworks could be used to develop more complicated models or systems to aid in clinical decision making in the future.","3":"Biomedical engineering online","4":"30314437","5":"2018","6":"Adolescent"},{"1":"Multimodal MRI-based classification of migraine: using deep learning convolutional neural network.","2":"BACKGROUND: Recently, deep learning technologies have rapidly expanded into medical image analysis, including both disease detection and classification. As far as we know, migraine is a disabling and common neurological disorder, typically characterized by unilateral, throbbing and pulsating headaches. Unfortunately, a large number of migraineurs do not receive the accurate diagnosis when using traditional diagnostic criteria based on the guidelines of the International Headache Society. As such, there is substantial interest in developing automated methods to assist in the diagnosis of migraine.METHODS: To the best of our knowledge, no studies have evaluated the potential of deep learning technologies in assisting with the classification of migraine patients. Here, we used deep learning methods in combination with three functional measures (the amplitude of low-frequency fluctuations, regional homogeneity and regional functional correlation strength) based on rs-fMRI data to distinguish not only between migraineurs and healthy controls, but also between the two subtypes of migraine. We employed 21 migraine patients without aura, 15 migraineurs with aura, and 28 healthy controls.RESULTS: Compared with the traditional support vector machine classifier, which has an accuracy of 83.67%, our Inception module-based convolutional neural network approach showed a significant improvement in classification output (over 86.18%). Our data also indicate that the Inception module-based CNN performs better than the AlexNet-based CNN (Inception module-based CNN reached an accuracy of 99.25%). Finally, we also found that regional functional correlation strength (RFCS) could be regarded as the optimum input out of the three indices (ALFF, ReHo, RFCS).CONCLUSIONS: Overall, our study shows that combining the three functional measures of rs-fMRI with deep learning classification is a powerful method to distinguish between migraineurs and healthy individuals. Our data also highlight that deep learning-based frameworks could be used to develop more complicated models or systems to aid in clinical decision making in the future.","3":"Biomedical engineering online","4":"30314437","5":"2018","6":"Adult"},{"1":"Multimodal MRI-based classification of migraine: using deep learning convolutional neural network.","2":"BACKGROUND: Recently, deep learning technologies have rapidly expanded into medical image analysis, including both disease detection and classification. As far as we know, migraine is a disabling and common neurological disorder, typically characterized by unilateral, throbbing and pulsating headaches. Unfortunately, a large number of migraineurs do not receive the accurate diagnosis when using traditional diagnostic criteria based on the guidelines of the International Headache Society. As such, there is substantial interest in developing automated methods to assist in the diagnosis of migraine.METHODS: To the best of our knowledge, no studies have evaluated the potential of deep learning technologies in assisting with the classification of migraine patients. Here, we used deep learning methods in combination with three functional measures (the amplitude of low-frequency fluctuations, regional homogeneity and regional functional correlation strength) based on rs-fMRI data to distinguish not only between migraineurs and healthy controls, but also between the two subtypes of migraine. We employed 21 migraine patients without aura, 15 migraineurs with aura, and 28 healthy controls.RESULTS: Compared with the traditional support vector machine classifier, which has an accuracy of 83.67%, our Inception module-based convolutional neural network approach showed a significant improvement in classification output (over 86.18%). Our data also indicate that the Inception module-based CNN performs better than the AlexNet-based CNN (Inception module-based CNN reached an accuracy of 99.25%). Finally, we also found that regional functional correlation strength (RFCS) could be regarded as the optimum input out of the three indices (ALFF, ReHo, RFCS).CONCLUSIONS: Overall, our study shows that combining the three functional measures of rs-fMRI with deep learning classification is a powerful method to distinguish between migraineurs and healthy individuals. Our data also highlight that deep learning-based frameworks could be used to develop more complicated models or systems to aid in clinical decision making in the future.","3":"Biomedical engineering online","4":"30314437","5":"2018","6":"Case-Control Studies"},{"1":"Multimodal MRI-based classification of migraine: using deep learning convolutional neural network.","2":"BACKGROUND: Recently, deep learning technologies have rapidly expanded into medical image analysis, including both disease detection and classification. As far as we know, migraine is a disabling and common neurological disorder, typically characterized by unilateral, throbbing and pulsating headaches. Unfortunately, a large number of migraineurs do not receive the accurate diagnosis when using traditional diagnostic criteria based on the guidelines of the International Headache Society. As such, there is substantial interest in developing automated methods to assist in the diagnosis of migraine.METHODS: To the best of our knowledge, no studies have evaluated the potential of deep learning technologies in assisting with the classification of migraine patients. Here, we used deep learning methods in combination with three functional measures (the amplitude of low-frequency fluctuations, regional homogeneity and regional functional correlation strength) based on rs-fMRI data to distinguish not only between migraineurs and healthy controls, but also between the two subtypes of migraine. We employed 21 migraine patients without aura, 15 migraineurs with aura, and 28 healthy controls.RESULTS: Compared with the traditional support vector machine classifier, which has an accuracy of 83.67%, our Inception module-based convolutional neural network approach showed a significant improvement in classification output (over 86.18%). Our data also indicate that the Inception module-based CNN performs better than the AlexNet-based CNN (Inception module-based CNN reached an accuracy of 99.25%). Finally, we also found that regional functional correlation strength (RFCS) could be regarded as the optimum input out of the three indices (ALFF, ReHo, RFCS).CONCLUSIONS: Overall, our study shows that combining the three functional measures of rs-fMRI with deep learning classification is a powerful method to distinguish between migraineurs and healthy individuals. Our data also highlight that deep learning-based frameworks could be used to develop more complicated models or systems to aid in clinical decision making in the future.","3":"Biomedical engineering online","4":"30314437","5":"2018","6":"Deep Learning"},{"1":"Multimodal MRI-based classification of migraine: using deep learning convolutional neural network.","2":"BACKGROUND: Recently, deep learning technologies have rapidly expanded into medical image analysis, including both disease detection and classification. As far as we know, migraine is a disabling and common neurological disorder, typically characterized by unilateral, throbbing and pulsating headaches. Unfortunately, a large number of migraineurs do not receive the accurate diagnosis when using traditional diagnostic criteria based on the guidelines of the International Headache Society. As such, there is substantial interest in developing automated methods to assist in the diagnosis of migraine.METHODS: To the best of our knowledge, no studies have evaluated the potential of deep learning technologies in assisting with the classification of migraine patients. Here, we used deep learning methods in combination with three functional measures (the amplitude of low-frequency fluctuations, regional homogeneity and regional functional correlation strength) based on rs-fMRI data to distinguish not only between migraineurs and healthy controls, but also between the two subtypes of migraine. We employed 21 migraine patients without aura, 15 migraineurs with aura, and 28 healthy controls.RESULTS: Compared with the traditional support vector machine classifier, which has an accuracy of 83.67%, our Inception module-based convolutional neural network approach showed a significant improvement in classification output (over 86.18%). Our data also indicate that the Inception module-based CNN performs better than the AlexNet-based CNN (Inception module-based CNN reached an accuracy of 99.25%). Finally, we also found that regional functional correlation strength (RFCS) could be regarded as the optimum input out of the three indices (ALFF, ReHo, RFCS).CONCLUSIONS: Overall, our study shows that combining the three functional measures of rs-fMRI with deep learning classification is a powerful method to distinguish between migraineurs and healthy individuals. Our data also highlight that deep learning-based frameworks could be used to develop more complicated models or systems to aid in clinical decision making in the future.","3":"Biomedical engineering online","4":"30314437","5":"2018","6":"Female"},{"1":"Multimodal MRI-based classification of migraine: using deep learning convolutional neural network.","2":"BACKGROUND: Recently, deep learning technologies have rapidly expanded into medical image analysis, including both disease detection and classification. As far as we know, migraine is a disabling and common neurological disorder, typically characterized by unilateral, throbbing and pulsating headaches. Unfortunately, a large number of migraineurs do not receive the accurate diagnosis when using traditional diagnostic criteria based on the guidelines of the International Headache Society. As such, there is substantial interest in developing automated methods to assist in the diagnosis of migraine.METHODS: To the best of our knowledge, no studies have evaluated the potential of deep learning technologies in assisting with the classification of migraine patients. Here, we used deep learning methods in combination with three functional measures (the amplitude of low-frequency fluctuations, regional homogeneity and regional functional correlation strength) based on rs-fMRI data to distinguish not only between migraineurs and healthy controls, but also between the two subtypes of migraine. We employed 21 migraine patients without aura, 15 migraineurs with aura, and 28 healthy controls.RESULTS: Compared with the traditional support vector machine classifier, which has an accuracy of 83.67%, our Inception module-based convolutional neural network approach showed a significant improvement in classification output (over 86.18%). Our data also indicate that the Inception module-based CNN performs better than the AlexNet-based CNN (Inception module-based CNN reached an accuracy of 99.25%). Finally, we also found that regional functional correlation strength (RFCS) could be regarded as the optimum input out of the three indices (ALFF, ReHo, RFCS).CONCLUSIONS: Overall, our study shows that combining the three functional measures of rs-fMRI with deep learning classification is a powerful method to distinguish between migraineurs and healthy individuals. Our data also highlight that deep learning-based frameworks could be used to develop more complicated models or systems to aid in clinical decision making in the future.","3":"Biomedical engineering online","4":"30314437","5":"2018","6":"Humans"},{"1":"Multimodal MRI-based classification of migraine: using deep learning convolutional neural network.","2":"BACKGROUND: Recently, deep learning technologies have rapidly expanded into medical image analysis, including both disease detection and classification. As far as we know, migraine is a disabling and common neurological disorder, typically characterized by unilateral, throbbing and pulsating headaches. Unfortunately, a large number of migraineurs do not receive the accurate diagnosis when using traditional diagnostic criteria based on the guidelines of the International Headache Society. As such, there is substantial interest in developing automated methods to assist in the diagnosis of migraine.METHODS: To the best of our knowledge, no studies have evaluated the potential of deep learning technologies in assisting with the classification of migraine patients. Here, we used deep learning methods in combination with three functional measures (the amplitude of low-frequency fluctuations, regional homogeneity and regional functional correlation strength) based on rs-fMRI data to distinguish not only between migraineurs and healthy controls, but also between the two subtypes of migraine. We employed 21 migraine patients without aura, 15 migraineurs with aura, and 28 healthy controls.RESULTS: Compared with the traditional support vector machine classifier, which has an accuracy of 83.67%, our Inception module-based convolutional neural network approach showed a significant improvement in classification output (over 86.18%). Our data also indicate that the Inception module-based CNN performs better than the AlexNet-based CNN (Inception module-based CNN reached an accuracy of 99.25%). Finally, we also found that regional functional correlation strength (RFCS) could be regarded as the optimum input out of the three indices (ALFF, ReHo, RFCS).CONCLUSIONS: Overall, our study shows that combining the three functional measures of rs-fMRI with deep learning classification is a powerful method to distinguish between migraineurs and healthy individuals. Our data also highlight that deep learning-based frameworks could be used to develop more complicated models or systems to aid in clinical decision making in the future.","3":"Biomedical engineering online","4":"30314437","5":"2018","6":"Image Processing, Computer-Assisted"},{"1":"Multimodal MRI-based classification of migraine: using deep learning convolutional neural network.","2":"BACKGROUND: Recently, deep learning technologies have rapidly expanded into medical image analysis, including both disease detection and classification. As far as we know, migraine is a disabling and common neurological disorder, typically characterized by unilateral, throbbing and pulsating headaches. Unfortunately, a large number of migraineurs do not receive the accurate diagnosis when using traditional diagnostic criteria based on the guidelines of the International Headache Society. As such, there is substantial interest in developing automated methods to assist in the diagnosis of migraine.METHODS: To the best of our knowledge, no studies have evaluated the potential of deep learning technologies in assisting with the classification of migraine patients. Here, we used deep learning methods in combination with three functional measures (the amplitude of low-frequency fluctuations, regional homogeneity and regional functional correlation strength) based on rs-fMRI data to distinguish not only between migraineurs and healthy controls, but also between the two subtypes of migraine. We employed 21 migraine patients without aura, 15 migraineurs with aura, and 28 healthy controls.RESULTS: Compared with the traditional support vector machine classifier, which has an accuracy of 83.67%, our Inception module-based convolutional neural network approach showed a significant improvement in classification output (over 86.18%). Our data also indicate that the Inception module-based CNN performs better than the AlexNet-based CNN (Inception module-based CNN reached an accuracy of 99.25%). Finally, we also found that regional functional correlation strength (RFCS) could be regarded as the optimum input out of the three indices (ALFF, ReHo, RFCS).CONCLUSIONS: Overall, our study shows that combining the three functional measures of rs-fMRI with deep learning classification is a powerful method to distinguish between migraineurs and healthy individuals. Our data also highlight that deep learning-based frameworks could be used to develop more complicated models or systems to aid in clinical decision making in the future.","3":"Biomedical engineering online","4":"30314437","5":"2018","6":"methods"},{"1":"Multimodal MRI-based classification of migraine: using deep learning convolutional neural network.","2":"BACKGROUND: Recently, deep learning technologies have rapidly expanded into medical image analysis, including both disease detection and classification. As far as we know, migraine is a disabling and common neurological disorder, typically characterized by unilateral, throbbing and pulsating headaches. Unfortunately, a large number of migraineurs do not receive the accurate diagnosis when using traditional diagnostic criteria based on the guidelines of the International Headache Society. As such, there is substantial interest in developing automated methods to assist in the diagnosis of migraine.METHODS: To the best of our knowledge, no studies have evaluated the potential of deep learning technologies in assisting with the classification of migraine patients. Here, we used deep learning methods in combination with three functional measures (the amplitude of low-frequency fluctuations, regional homogeneity and regional functional correlation strength) based on rs-fMRI data to distinguish not only between migraineurs and healthy controls, but also between the two subtypes of migraine. We employed 21 migraine patients without aura, 15 migraineurs with aura, and 28 healthy controls.RESULTS: Compared with the traditional support vector machine classifier, which has an accuracy of 83.67%, our Inception module-based convolutional neural network approach showed a significant improvement in classification output (over 86.18%). Our data also indicate that the Inception module-based CNN performs better than the AlexNet-based CNN (Inception module-based CNN reached an accuracy of 99.25%). Finally, we also found that regional functional correlation strength (RFCS) could be regarded as the optimum input out of the three indices (ALFF, ReHo, RFCS).CONCLUSIONS: Overall, our study shows that combining the three functional measures of rs-fMRI with deep learning classification is a powerful method to distinguish between migraineurs and healthy individuals. Our data also highlight that deep learning-based frameworks could be used to develop more complicated models or systems to aid in clinical decision making in the future.","3":"Biomedical engineering online","4":"30314437","5":"2018","6":"Magnetic Resonance Imaging"},{"1":"Multimodal MRI-based classification of migraine: using deep learning convolutional neural network.","2":"BACKGROUND: Recently, deep learning technologies have rapidly expanded into medical image analysis, including both disease detection and classification. As far as we know, migraine is a disabling and common neurological disorder, typically characterized by unilateral, throbbing and pulsating headaches. Unfortunately, a large number of migraineurs do not receive the accurate diagnosis when using traditional diagnostic criteria based on the guidelines of the International Headache Society. As such, there is substantial interest in developing automated methods to assist in the diagnosis of migraine.METHODS: To the best of our knowledge, no studies have evaluated the potential of deep learning technologies in assisting with the classification of migraine patients. Here, we used deep learning methods in combination with three functional measures (the amplitude of low-frequency fluctuations, regional homogeneity and regional functional correlation strength) based on rs-fMRI data to distinguish not only between migraineurs and healthy controls, but also between the two subtypes of migraine. We employed 21 migraine patients without aura, 15 migraineurs with aura, and 28 healthy controls.RESULTS: Compared with the traditional support vector machine classifier, which has an accuracy of 83.67%, our Inception module-based convolutional neural network approach showed a significant improvement in classification output (over 86.18%). Our data also indicate that the Inception module-based CNN performs better than the AlexNet-based CNN (Inception module-based CNN reached an accuracy of 99.25%). Finally, we also found that regional functional correlation strength (RFCS) could be regarded as the optimum input out of the three indices (ALFF, ReHo, RFCS).CONCLUSIONS: Overall, our study shows that combining the three functional measures of rs-fMRI with deep learning classification is a powerful method to distinguish between migraineurs and healthy individuals. Our data also highlight that deep learning-based frameworks could be used to develop more complicated models or systems to aid in clinical decision making in the future.","3":"Biomedical engineering online","4":"30314437","5":"2018","6":"Male"},{"1":"Multimodal MRI-based classification of migraine: using deep learning convolutional neural network.","2":"BACKGROUND: Recently, deep learning technologies have rapidly expanded into medical image analysis, including both disease detection and classification. As far as we know, migraine is a disabling and common neurological disorder, typically characterized by unilateral, throbbing and pulsating headaches. Unfortunately, a large number of migraineurs do not receive the accurate diagnosis when using traditional diagnostic criteria based on the guidelines of the International Headache Society. As such, there is substantial interest in developing automated methods to assist in the diagnosis of migraine.METHODS: To the best of our knowledge, no studies have evaluated the potential of deep learning technologies in assisting with the classification of migraine patients. Here, we used deep learning methods in combination with three functional measures (the amplitude of low-frequency fluctuations, regional homogeneity and regional functional correlation strength) based on rs-fMRI data to distinguish not only between migraineurs and healthy controls, but also between the two subtypes of migraine. We employed 21 migraine patients without aura, 15 migraineurs with aura, and 28 healthy controls.RESULTS: Compared with the traditional support vector machine classifier, which has an accuracy of 83.67%, our Inception module-based convolutional neural network approach showed a significant improvement in classification output (over 86.18%). Our data also indicate that the Inception module-based CNN performs better than the AlexNet-based CNN (Inception module-based CNN reached an accuracy of 99.25%). Finally, we also found that regional functional correlation strength (RFCS) could be regarded as the optimum input out of the three indices (ALFF, ReHo, RFCS).CONCLUSIONS: Overall, our study shows that combining the three functional measures of rs-fMRI with deep learning classification is a powerful method to distinguish between migraineurs and healthy individuals. Our data also highlight that deep learning-based frameworks could be used to develop more complicated models or systems to aid in clinical decision making in the future.","3":"Biomedical engineering online","4":"30314437","5":"2018","6":"Middle Aged"},{"1":"Multimodal MRI-based classification of migraine: using deep learning convolutional neural network.","2":"BACKGROUND: Recently, deep learning technologies have rapidly expanded into medical image analysis, including both disease detection and classification. As far as we know, migraine is a disabling and common neurological disorder, typically characterized by unilateral, throbbing and pulsating headaches. Unfortunately, a large number of migraineurs do not receive the accurate diagnosis when using traditional diagnostic criteria based on the guidelines of the International Headache Society. As such, there is substantial interest in developing automated methods to assist in the diagnosis of migraine.METHODS: To the best of our knowledge, no studies have evaluated the potential of deep learning technologies in assisting with the classification of migraine patients. Here, we used deep learning methods in combination with three functional measures (the amplitude of low-frequency fluctuations, regional homogeneity and regional functional correlation strength) based on rs-fMRI data to distinguish not only between migraineurs and healthy controls, but also between the two subtypes of migraine. We employed 21 migraine patients without aura, 15 migraineurs with aura, and 28 healthy controls.RESULTS: Compared with the traditional support vector machine classifier, which has an accuracy of 83.67%, our Inception module-based convolutional neural network approach showed a significant improvement in classification output (over 86.18%). Our data also indicate that the Inception module-based CNN performs better than the AlexNet-based CNN (Inception module-based CNN reached an accuracy of 99.25%). Finally, we also found that regional functional correlation strength (RFCS) could be regarded as the optimum input out of the three indices (ALFF, ReHo, RFCS).CONCLUSIONS: Overall, our study shows that combining the three functional measures of rs-fMRI with deep learning classification is a powerful method to distinguish between migraineurs and healthy individuals. Our data also highlight that deep learning-based frameworks could be used to develop more complicated models or systems to aid in clinical decision making in the future.","3":"Biomedical engineering online","4":"30314437","5":"2018","6":"Migraine Disorders"},{"1":"Multimodal MRI-based classification of migraine: using deep learning convolutional neural network.","2":"BACKGROUND: Recently, deep learning technologies have rapidly expanded into medical image analysis, including both disease detection and classification. As far as we know, migraine is a disabling and common neurological disorder, typically characterized by unilateral, throbbing and pulsating headaches. Unfortunately, a large number of migraineurs do not receive the accurate diagnosis when using traditional diagnostic criteria based on the guidelines of the International Headache Society. As such, there is substantial interest in developing automated methods to assist in the diagnosis of migraine.METHODS: To the best of our knowledge, no studies have evaluated the potential of deep learning technologies in assisting with the classification of migraine patients. Here, we used deep learning methods in combination with three functional measures (the amplitude of low-frequency fluctuations, regional homogeneity and regional functional correlation strength) based on rs-fMRI data to distinguish not only between migraineurs and healthy controls, but also between the two subtypes of migraine. We employed 21 migraine patients without aura, 15 migraineurs with aura, and 28 healthy controls.RESULTS: Compared with the traditional support vector machine classifier, which has an accuracy of 83.67%, our Inception module-based convolutional neural network approach showed a significant improvement in classification output (over 86.18%). Our data also indicate that the Inception module-based CNN performs better than the AlexNet-based CNN (Inception module-based CNN reached an accuracy of 99.25%). Finally, we also found that regional functional correlation strength (RFCS) could be regarded as the optimum input out of the three indices (ALFF, ReHo, RFCS).CONCLUSIONS: Overall, our study shows that combining the three functional measures of rs-fMRI with deep learning classification is a powerful method to distinguish between migraineurs and healthy individuals. Our data also highlight that deep learning-based frameworks could be used to develop more complicated models or systems to aid in clinical decision making in the future.","3":"Biomedical engineering online","4":"30314437","5":"2018","6":"diagnostic imaging"},{"1":"Multimodal MRI-based classification of migraine: using deep learning convolutional neural network.","2":"BACKGROUND: Recently, deep learning technologies have rapidly expanded into medical image analysis, including both disease detection and classification. As far as we know, migraine is a disabling and common neurological disorder, typically characterized by unilateral, throbbing and pulsating headaches. Unfortunately, a large number of migraineurs do not receive the accurate diagnosis when using traditional diagnostic criteria based on the guidelines of the International Headache Society. As such, there is substantial interest in developing automated methods to assist in the diagnosis of migraine.METHODS: To the best of our knowledge, no studies have evaluated the potential of deep learning technologies in assisting with the classification of migraine patients. Here, we used deep learning methods in combination with three functional measures (the amplitude of low-frequency fluctuations, regional homogeneity and regional functional correlation strength) based on rs-fMRI data to distinguish not only between migraineurs and healthy controls, but also between the two subtypes of migraine. We employed 21 migraine patients without aura, 15 migraineurs with aura, and 28 healthy controls.RESULTS: Compared with the traditional support vector machine classifier, which has an accuracy of 83.67%, our Inception module-based convolutional neural network approach showed a significant improvement in classification output (over 86.18%). Our data also indicate that the Inception module-based CNN performs better than the AlexNet-based CNN (Inception module-based CNN reached an accuracy of 99.25%). Finally, we also found that regional functional correlation strength (RFCS) could be regarded as the optimum input out of the three indices (ALFF, ReHo, RFCS).CONCLUSIONS: Overall, our study shows that combining the three functional measures of rs-fMRI with deep learning classification is a powerful method to distinguish between migraineurs and healthy individuals. Our data also highlight that deep learning-based frameworks could be used to develop more complicated models or systems to aid in clinical decision making in the future.","3":"Biomedical engineering online","4":"30314437","5":"2018","6":"Multimodal Imaging"},{"1":"Multimodal MRI-based classification of migraine: using deep learning convolutional neural network.","2":"BACKGROUND: Recently, deep learning technologies have rapidly expanded into medical image analysis, including both disease detection and classification. As far as we know, migraine is a disabling and common neurological disorder, typically characterized by unilateral, throbbing and pulsating headaches. Unfortunately, a large number of migraineurs do not receive the accurate diagnosis when using traditional diagnostic criteria based on the guidelines of the International Headache Society. As such, there is substantial interest in developing automated methods to assist in the diagnosis of migraine.METHODS: To the best of our knowledge, no studies have evaluated the potential of deep learning technologies in assisting with the classification of migraine patients. Here, we used deep learning methods in combination with three functional measures (the amplitude of low-frequency fluctuations, regional homogeneity and regional functional correlation strength) based on rs-fMRI data to distinguish not only between migraineurs and healthy controls, but also between the two subtypes of migraine. We employed 21 migraine patients without aura, 15 migraineurs with aura, and 28 healthy controls.RESULTS: Compared with the traditional support vector machine classifier, which has an accuracy of 83.67%, our Inception module-based convolutional neural network approach showed a significant improvement in classification output (over 86.18%). Our data also indicate that the Inception module-based CNN performs better than the AlexNet-based CNN (Inception module-based CNN reached an accuracy of 99.25%). Finally, we also found that regional functional correlation strength (RFCS) could be regarded as the optimum input out of the three indices (ALFF, ReHo, RFCS).CONCLUSIONS: Overall, our study shows that combining the three functional measures of rs-fMRI with deep learning classification is a powerful method to distinguish between migraineurs and healthy individuals. Our data also highlight that deep learning-based frameworks could be used to develop more complicated models or systems to aid in clinical decision making in the future.","3":"Biomedical engineering online","4":"30314437","5":"2018","6":"Young Adult"},{"1":"Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron<sup><U+202C><\/sup>.","2":"Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.","3":"Computational intelligence and neuroscience","4":"30298088","5":"2018","6":"Connective Tissue"},{"1":"Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron<sup><U+202C><\/sup>.","2":"Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.","3":"Computational intelligence and neuroscience","4":"30298088","5":"2018","6":"pathology"},{"1":"Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron<sup><U+202C><\/sup>.","2":"Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.","3":"Computational intelligence and neuroscience","4":"30298088","5":"2018","6":"Diagnosis, Computer-Assisted"},{"1":"Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron<sup><U+202C><\/sup>.","2":"Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.","3":"Computational intelligence and neuroscience","4":"30298088","5":"2018","6":"methods"},{"1":"Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron<sup><U+202C><\/sup>.","2":"Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.","3":"Computational intelligence and neuroscience","4":"30298088","5":"2018","6":"Epithelium"},{"1":"Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron<sup><U+202C><\/sup>.","2":"Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.","3":"Computational intelligence and neuroscience","4":"30298088","5":"2018","6":"pathology"},{"1":"Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron<sup><U+202C><\/sup>.","2":"Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.","3":"Computational intelligence and neuroscience","4":"30298088","5":"2018","6":"Humans"},{"1":"Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron<sup><U+202C><\/sup>.","2":"Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.","3":"Computational intelligence and neuroscience","4":"30298088","5":"2018","6":"Image Processing, Computer-Assisted"},{"1":"Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron<sup><U+202C><\/sup>.","2":"Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.","3":"Computational intelligence and neuroscience","4":"30298088","5":"2018","6":"methods"},{"1":"Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron<sup><U+202C><\/sup>.","2":"Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.","3":"Computational intelligence and neuroscience","4":"30298088","5":"2018","6":"Keratosis, Seborrheic"},{"1":"Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron<sup><U+202C><\/sup>.","2":"Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.","3":"Computational intelligence and neuroscience","4":"30298088","5":"2018","6":"pathology"},{"1":"Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron<sup><U+202C><\/sup>.","2":"Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.","3":"Computational intelligence and neuroscience","4":"30298088","5":"2018","6":"Machine Learning"},{"1":"Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron<sup><U+202C><\/sup>.","2":"Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.","3":"Computational intelligence and neuroscience","4":"30298088","5":"2018","6":"Melanoma"},{"1":"Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron<sup><U+202C><\/sup>.","2":"Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.","3":"Computational intelligence and neuroscience","4":"30298088","5":"2018","6":"pathology"},{"1":"Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron<sup><U+202C><\/sup>.","2":"Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.","3":"Computational intelligence and neuroscience","4":"30298088","5":"2018","6":"Muscles"},{"1":"Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron<sup><U+202C><\/sup>.","2":"Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.","3":"Computational intelligence and neuroscience","4":"30298088","5":"2018","6":"pathology"},{"1":"Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron<sup><U+202C><\/sup>.","2":"Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.","3":"Computational intelligence and neuroscience","4":"30298088","5":"2018","6":"Nerve Tissue"},{"1":"Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron<sup><U+202C><\/sup>.","2":"Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.","3":"Computational intelligence and neuroscience","4":"30298088","5":"2018","6":"pathology"},{"1":"Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron<sup><U+202C><\/sup>.","2":"Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.","3":"Computational intelligence and neuroscience","4":"30298088","5":"2018","6":"Neural Networks (Computer)"},{"1":"Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron<sup><U+202C><\/sup>.","2":"Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.","3":"Computational intelligence and neuroscience","4":"30298088","5":"2018","6":"Nevus"},{"1":"Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron<sup><U+202C><\/sup>.","2":"Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.","3":"Computational intelligence and neuroscience","4":"30298088","5":"2018","6":"pathology"},{"1":"Medical Image Classification Based on Deep Features Extracted by Deep Model and Statistic Feature Fusion with Multilayer Perceptron<sup><U+202C><\/sup>.","2":"Medical image classification is a key technique of Computer-Aided Diagnosis (CAD) systems. Traditional methods rely mainly on the shape, color, and/or texture features as well as their combinations, most of which are problem-specific and have shown to be complementary in medical images, which leads to a system that lacks the ability to make representations of high-level problem domain concepts and that has poor model generalization ability. Recent deep learning methods provide an effective way to construct an end-to-end model that can compute final classification labels with the raw pixels of medical images. However, due to the high resolution of the medical images and the small dataset size, deep learning models suffer from high computational costs and limitations in the model layers and channels. To solve these problems, in this paper, we propose a deep learning model that integrates Coding Network with Multilayer Perceptron (CNMP), which combines high-level features that are extracted from a deep convolutional neural network and some selected traditional features. The construction of the proposed model includes the following steps. First, we train a deep convolutional neural network as a coding network in a supervised manner, and the result is that it can code the raw pixels of medical images into feature vectors that represent high-level concepts for classification. Second, we extract a set of selected traditional features based on background knowledge of medical images. Finally, we design an efficient model that is based on neural networks to fuse the different feature groups obtained in the first and second step. We evaluate the proposed approach on two benchmark medical image datasets: HIS2828 and ISIC2017. We achieve an overall classification accuracy of 90.1% and 90.2%, respectively, which are higher than the current successful methods.","3":"Computational intelligence and neuroscience","4":"30298088","5":"2018","6":"Statistics as Topic"},{"1":"Automated segmentation of en face choroidal images obtained by optical coherent tomography by machine learning.","2":"PURPOSE: To develop an automated method to segment the choroidal layers of en face optical coherent tomography (OCT) images by machine learning.STUDY DESIGN: A cross-sectional, prospective study of 276 eyes of 181 healthy subjects.METHODS: OCT en face images of the choroid were obtained every 2.6 µm from the retinal pigment epithelium (RPE) to the chorioscleral border. The images at the start of the choriocapillaris, start of Sattler's layer, and start of Haller's layer were identified, and the image numbers from the RPE line were taken as the teacher data. Forty-one feature quantities of each image were extracted. A support vector machine (SVM) model was created from each feature value of the training data, and a coefficient of determination was calculated for each layer of the choroid by a fivefold cross validation. Next, the same evaluation was performed after creating a SVM model with selected effective feature quantities.RESULTS: The mean coefficient of determination using all features was 0.9853<U+2009>±<U+2009>0.0012. Nine effective feature quantities (relative choroid thickness, mean/kurtosis/variance of brightness, FFT_ skewness, k0_vessel width, k1/k2/k4_vessel area) were selected, and the mean of the coefficient of determinations with these quantities In this model was 0.9865<U+2009>±<U+2009>0.0001. The number of errors in the image number at the start of each layer was 1.01<U+2009>±<U+2009>0.79 for the choriocapillaris, 1.13<U+2009>±<U+2009>1.12 for Sattler's layer, and 3.77<U+2009>±<U+2009>2.90 for Haller's layer.CONCLUSION: Automated stratification of the choroid in en face images can be done with high accuracy through machine learning.","3":"Japanese journal of ophthalmology","4":"30293226","5":"2018","6":"Adult"},{"1":"Automated segmentation of en face choroidal images obtained by optical coherent tomography by machine learning.","2":"PURPOSE: To develop an automated method to segment the choroidal layers of en face optical coherent tomography (OCT) images by machine learning.STUDY DESIGN: A cross-sectional, prospective study of 276 eyes of 181 healthy subjects.METHODS: OCT en face images of the choroid were obtained every 2.6 µm from the retinal pigment epithelium (RPE) to the chorioscleral border. The images at the start of the choriocapillaris, start of Sattler's layer, and start of Haller's layer were identified, and the image numbers from the RPE line were taken as the teacher data. Forty-one feature quantities of each image were extracted. A support vector machine (SVM) model was created from each feature value of the training data, and a coefficient of determination was calculated for each layer of the choroid by a fivefold cross validation. Next, the same evaluation was performed after creating a SVM model with selected effective feature quantities.RESULTS: The mean coefficient of determination using all features was 0.9853<U+2009>±<U+2009>0.0012. Nine effective feature quantities (relative choroid thickness, mean/kurtosis/variance of brightness, FFT_ skewness, k0_vessel width, k1/k2/k4_vessel area) were selected, and the mean of the coefficient of determinations with these quantities In this model was 0.9865<U+2009>±<U+2009>0.0001. The number of errors in the image number at the start of each layer was 1.01<U+2009>±<U+2009>0.79 for the choriocapillaris, 1.13<U+2009>±<U+2009>1.12 for Sattler's layer, and 3.77<U+2009>±<U+2009>2.90 for Haller's layer.CONCLUSION: Automated stratification of the choroid in en face images can be done with high accuracy through machine learning.","3":"Japanese journal of ophthalmology","4":"30293226","5":"2018","6":"Aged"},{"1":"Automated segmentation of en face choroidal images obtained by optical coherent tomography by machine learning.","2":"PURPOSE: To develop an automated method to segment the choroidal layers of en face optical coherent tomography (OCT) images by machine learning.STUDY DESIGN: A cross-sectional, prospective study of 276 eyes of 181 healthy subjects.METHODS: OCT en face images of the choroid were obtained every 2.6 µm from the retinal pigment epithelium (RPE) to the chorioscleral border. The images at the start of the choriocapillaris, start of Sattler's layer, and start of Haller's layer were identified, and the image numbers from the RPE line were taken as the teacher data. Forty-one feature quantities of each image were extracted. A support vector machine (SVM) model was created from each feature value of the training data, and a coefficient of determination was calculated for each layer of the choroid by a fivefold cross validation. Next, the same evaluation was performed after creating a SVM model with selected effective feature quantities.RESULTS: The mean coefficient of determination using all features was 0.9853<U+2009>±<U+2009>0.0012. Nine effective feature quantities (relative choroid thickness, mean/kurtosis/variance of brightness, FFT_ skewness, k0_vessel width, k1/k2/k4_vessel area) were selected, and the mean of the coefficient of determinations with these quantities In this model was 0.9865<U+2009>±<U+2009>0.0001. The number of errors in the image number at the start of each layer was 1.01<U+2009>±<U+2009>0.79 for the choriocapillaris, 1.13<U+2009>±<U+2009>1.12 for Sattler's layer, and 3.77<U+2009>±<U+2009>2.90 for Haller's layer.CONCLUSION: Automated stratification of the choroid in en face images can be done with high accuracy through machine learning.","3":"Japanese journal of ophthalmology","4":"30293226","5":"2018","6":"Aged, 80 and over"},{"1":"Automated segmentation of en face choroidal images obtained by optical coherent tomography by machine learning.","2":"PURPOSE: To develop an automated method to segment the choroidal layers of en face optical coherent tomography (OCT) images by machine learning.STUDY DESIGN: A cross-sectional, prospective study of 276 eyes of 181 healthy subjects.METHODS: OCT en face images of the choroid were obtained every 2.6 µm from the retinal pigment epithelium (RPE) to the chorioscleral border. The images at the start of the choriocapillaris, start of Sattler's layer, and start of Haller's layer were identified, and the image numbers from the RPE line were taken as the teacher data. Forty-one feature quantities of each image were extracted. A support vector machine (SVM) model was created from each feature value of the training data, and a coefficient of determination was calculated for each layer of the choroid by a fivefold cross validation. Next, the same evaluation was performed after creating a SVM model with selected effective feature quantities.RESULTS: The mean coefficient of determination using all features was 0.9853<U+2009>±<U+2009>0.0012. Nine effective feature quantities (relative choroid thickness, mean/kurtosis/variance of brightness, FFT_ skewness, k0_vessel width, k1/k2/k4_vessel area) were selected, and the mean of the coefficient of determinations with these quantities In this model was 0.9865<U+2009>±<U+2009>0.0001. The number of errors in the image number at the start of each layer was 1.01<U+2009>±<U+2009>0.79 for the choriocapillaris, 1.13<U+2009>±<U+2009>1.12 for Sattler's layer, and 3.77<U+2009>±<U+2009>2.90 for Haller's layer.CONCLUSION: Automated stratification of the choroid in en face images can be done with high accuracy through machine learning.","3":"Japanese journal of ophthalmology","4":"30293226","5":"2018","6":"Choroid"},{"1":"Automated segmentation of en face choroidal images obtained by optical coherent tomography by machine learning.","2":"PURPOSE: To develop an automated method to segment the choroidal layers of en face optical coherent tomography (OCT) images by machine learning.STUDY DESIGN: A cross-sectional, prospective study of 276 eyes of 181 healthy subjects.METHODS: OCT en face images of the choroid were obtained every 2.6 µm from the retinal pigment epithelium (RPE) to the chorioscleral border. The images at the start of the choriocapillaris, start of Sattler's layer, and start of Haller's layer were identified, and the image numbers from the RPE line were taken as the teacher data. Forty-one feature quantities of each image were extracted. A support vector machine (SVM) model was created from each feature value of the training data, and a coefficient of determination was calculated for each layer of the choroid by a fivefold cross validation. Next, the same evaluation was performed after creating a SVM model with selected effective feature quantities.RESULTS: The mean coefficient of determination using all features was 0.9853<U+2009>±<U+2009>0.0012. Nine effective feature quantities (relative choroid thickness, mean/kurtosis/variance of brightness, FFT_ skewness, k0_vessel width, k1/k2/k4_vessel area) were selected, and the mean of the coefficient of determinations with these quantities In this model was 0.9865<U+2009>±<U+2009>0.0001. The number of errors in the image number at the start of each layer was 1.01<U+2009>±<U+2009>0.79 for the choriocapillaris, 1.13<U+2009>±<U+2009>1.12 for Sattler's layer, and 3.77<U+2009>±<U+2009>2.90 for Haller's layer.CONCLUSION: Automated stratification of the choroid in en face images can be done with high accuracy through machine learning.","3":"Japanese journal of ophthalmology","4":"30293226","5":"2018","6":"anatomy &amp; histology"},{"1":"Automated segmentation of en face choroidal images obtained by optical coherent tomography by machine learning.","2":"PURPOSE: To develop an automated method to segment the choroidal layers of en face optical coherent tomography (OCT) images by machine learning.STUDY DESIGN: A cross-sectional, prospective study of 276 eyes of 181 healthy subjects.METHODS: OCT en face images of the choroid were obtained every 2.6 µm from the retinal pigment epithelium (RPE) to the chorioscleral border. The images at the start of the choriocapillaris, start of Sattler's layer, and start of Haller's layer were identified, and the image numbers from the RPE line were taken as the teacher data. Forty-one feature quantities of each image were extracted. A support vector machine (SVM) model was created from each feature value of the training data, and a coefficient of determination was calculated for each layer of the choroid by a fivefold cross validation. Next, the same evaluation was performed after creating a SVM model with selected effective feature quantities.RESULTS: The mean coefficient of determination using all features was 0.9853<U+2009>±<U+2009>0.0012. Nine effective feature quantities (relative choroid thickness, mean/kurtosis/variance of brightness, FFT_ skewness, k0_vessel width, k1/k2/k4_vessel area) were selected, and the mean of the coefficient of determinations with these quantities In this model was 0.9865<U+2009>±<U+2009>0.0001. The number of errors in the image number at the start of each layer was 1.01<U+2009>±<U+2009>0.79 for the choriocapillaris, 1.13<U+2009>±<U+2009>1.12 for Sattler's layer, and 3.77<U+2009>±<U+2009>2.90 for Haller's layer.CONCLUSION: Automated stratification of the choroid in en face images can be done with high accuracy through machine learning.","3":"Japanese journal of ophthalmology","4":"30293226","5":"2018","6":"Cross-Sectional Studies"},{"1":"Automated segmentation of en face choroidal images obtained by optical coherent tomography by machine learning.","2":"PURPOSE: To develop an automated method to segment the choroidal layers of en face optical coherent tomography (OCT) images by machine learning.STUDY DESIGN: A cross-sectional, prospective study of 276 eyes of 181 healthy subjects.METHODS: OCT en face images of the choroid were obtained every 2.6 µm from the retinal pigment epithelium (RPE) to the chorioscleral border. The images at the start of the choriocapillaris, start of Sattler's layer, and start of Haller's layer were identified, and the image numbers from the RPE line were taken as the teacher data. Forty-one feature quantities of each image were extracted. A support vector machine (SVM) model was created from each feature value of the training data, and a coefficient of determination was calculated for each layer of the choroid by a fivefold cross validation. Next, the same evaluation was performed after creating a SVM model with selected effective feature quantities.RESULTS: The mean coefficient of determination using all features was 0.9853<U+2009>±<U+2009>0.0012. Nine effective feature quantities (relative choroid thickness, mean/kurtosis/variance of brightness, FFT_ skewness, k0_vessel width, k1/k2/k4_vessel area) were selected, and the mean of the coefficient of determinations with these quantities In this model was 0.9865<U+2009>±<U+2009>0.0001. The number of errors in the image number at the start of each layer was 1.01<U+2009>±<U+2009>0.79 for the choriocapillaris, 1.13<U+2009>±<U+2009>1.12 for Sattler's layer, and 3.77<U+2009>±<U+2009>2.90 for Haller's layer.CONCLUSION: Automated stratification of the choroid in en face images can be done with high accuracy through machine learning.","3":"Japanese journal of ophthalmology","4":"30293226","5":"2018","6":"Female"},{"1":"Automated segmentation of en face choroidal images obtained by optical coherent tomography by machine learning.","2":"PURPOSE: To develop an automated method to segment the choroidal layers of en face optical coherent tomography (OCT) images by machine learning.STUDY DESIGN: A cross-sectional, prospective study of 276 eyes of 181 healthy subjects.METHODS: OCT en face images of the choroid were obtained every 2.6 µm from the retinal pigment epithelium (RPE) to the chorioscleral border. The images at the start of the choriocapillaris, start of Sattler's layer, and start of Haller's layer were identified, and the image numbers from the RPE line were taken as the teacher data. Forty-one feature quantities of each image were extracted. A support vector machine (SVM) model was created from each feature value of the training data, and a coefficient of determination was calculated for each layer of the choroid by a fivefold cross validation. Next, the same evaluation was performed after creating a SVM model with selected effective feature quantities.RESULTS: The mean coefficient of determination using all features was 0.9853<U+2009>±<U+2009>0.0012. Nine effective feature quantities (relative choroid thickness, mean/kurtosis/variance of brightness, FFT_ skewness, k0_vessel width, k1/k2/k4_vessel area) were selected, and the mean of the coefficient of determinations with these quantities In this model was 0.9865<U+2009>±<U+2009>0.0001. The number of errors in the image number at the start of each layer was 1.01<U+2009>±<U+2009>0.79 for the choriocapillaris, 1.13<U+2009>±<U+2009>1.12 for Sattler's layer, and 3.77<U+2009>±<U+2009>2.90 for Haller's layer.CONCLUSION: Automated stratification of the choroid in en face images can be done with high accuracy through machine learning.","3":"Japanese journal of ophthalmology","4":"30293226","5":"2018","6":"Healthy Volunteers"},{"1":"Automated segmentation of en face choroidal images obtained by optical coherent tomography by machine learning.","2":"PURPOSE: To develop an automated method to segment the choroidal layers of en face optical coherent tomography (OCT) images by machine learning.STUDY DESIGN: A cross-sectional, prospective study of 276 eyes of 181 healthy subjects.METHODS: OCT en face images of the choroid were obtained every 2.6 µm from the retinal pigment epithelium (RPE) to the chorioscleral border. The images at the start of the choriocapillaris, start of Sattler's layer, and start of Haller's layer were identified, and the image numbers from the RPE line were taken as the teacher data. Forty-one feature quantities of each image were extracted. A support vector machine (SVM) model was created from each feature value of the training data, and a coefficient of determination was calculated for each layer of the choroid by a fivefold cross validation. Next, the same evaluation was performed after creating a SVM model with selected effective feature quantities.RESULTS: The mean coefficient of determination using all features was 0.9853<U+2009>±<U+2009>0.0012. Nine effective feature quantities (relative choroid thickness, mean/kurtosis/variance of brightness, FFT_ skewness, k0_vessel width, k1/k2/k4_vessel area) were selected, and the mean of the coefficient of determinations with these quantities In this model was 0.9865<U+2009>±<U+2009>0.0001. The number of errors in the image number at the start of each layer was 1.01<U+2009>±<U+2009>0.79 for the choriocapillaris, 1.13<U+2009>±<U+2009>1.12 for Sattler's layer, and 3.77<U+2009>±<U+2009>2.90 for Haller's layer.CONCLUSION: Automated stratification of the choroid in en face images can be done with high accuracy through machine learning.","3":"Japanese journal of ophthalmology","4":"30293226","5":"2018","6":"Humans"},{"1":"Automated segmentation of en face choroidal images obtained by optical coherent tomography by machine learning.","2":"PURPOSE: To develop an automated method to segment the choroidal layers of en face optical coherent tomography (OCT) images by machine learning.STUDY DESIGN: A cross-sectional, prospective study of 276 eyes of 181 healthy subjects.METHODS: OCT en face images of the choroid were obtained every 2.6 µm from the retinal pigment epithelium (RPE) to the chorioscleral border. The images at the start of the choriocapillaris, start of Sattler's layer, and start of Haller's layer were identified, and the image numbers from the RPE line were taken as the teacher data. Forty-one feature quantities of each image were extracted. A support vector machine (SVM) model was created from each feature value of the training data, and a coefficient of determination was calculated for each layer of the choroid by a fivefold cross validation. Next, the same evaluation was performed after creating a SVM model with selected effective feature quantities.RESULTS: The mean coefficient of determination using all features was 0.9853<U+2009>±<U+2009>0.0012. Nine effective feature quantities (relative choroid thickness, mean/kurtosis/variance of brightness, FFT_ skewness, k0_vessel width, k1/k2/k4_vessel area) were selected, and the mean of the coefficient of determinations with these quantities In this model was 0.9865<U+2009>±<U+2009>0.0001. The number of errors in the image number at the start of each layer was 1.01<U+2009>±<U+2009>0.79 for the choriocapillaris, 1.13<U+2009>±<U+2009>1.12 for Sattler's layer, and 3.77<U+2009>±<U+2009>2.90 for Haller's layer.CONCLUSION: Automated stratification of the choroid in en face images can be done with high accuracy through machine learning.","3":"Japanese journal of ophthalmology","4":"30293226","5":"2018","6":"Imaging, Three-Dimensional"},{"1":"Automated segmentation of en face choroidal images obtained by optical coherent tomography by machine learning.","2":"PURPOSE: To develop an automated method to segment the choroidal layers of en face optical coherent tomography (OCT) images by machine learning.STUDY DESIGN: A cross-sectional, prospective study of 276 eyes of 181 healthy subjects.METHODS: OCT en face images of the choroid were obtained every 2.6 µm from the retinal pigment epithelium (RPE) to the chorioscleral border. The images at the start of the choriocapillaris, start of Sattler's layer, and start of Haller's layer were identified, and the image numbers from the RPE line were taken as the teacher data. Forty-one feature quantities of each image were extracted. A support vector machine (SVM) model was created from each feature value of the training data, and a coefficient of determination was calculated for each layer of the choroid by a fivefold cross validation. Next, the same evaluation was performed after creating a SVM model with selected effective feature quantities.RESULTS: The mean coefficient of determination using all features was 0.9853<U+2009>±<U+2009>0.0012. Nine effective feature quantities (relative choroid thickness, mean/kurtosis/variance of brightness, FFT_ skewness, k0_vessel width, k1/k2/k4_vessel area) were selected, and the mean of the coefficient of determinations with these quantities In this model was 0.9865<U+2009>±<U+2009>0.0001. The number of errors in the image number at the start of each layer was 1.01<U+2009>±<U+2009>0.79 for the choriocapillaris, 1.13<U+2009>±<U+2009>1.12 for Sattler's layer, and 3.77<U+2009>±<U+2009>2.90 for Haller's layer.CONCLUSION: Automated stratification of the choroid in en face images can be done with high accuracy through machine learning.","3":"Japanese journal of ophthalmology","4":"30293226","5":"2018","6":"Machine Learning"},{"1":"Automated segmentation of en face choroidal images obtained by optical coherent tomography by machine learning.","2":"PURPOSE: To develop an automated method to segment the choroidal layers of en face optical coherent tomography (OCT) images by machine learning.STUDY DESIGN: A cross-sectional, prospective study of 276 eyes of 181 healthy subjects.METHODS: OCT en face images of the choroid were obtained every 2.6 µm from the retinal pigment epithelium (RPE) to the chorioscleral border. The images at the start of the choriocapillaris, start of Sattler's layer, and start of Haller's layer were identified, and the image numbers from the RPE line were taken as the teacher data. Forty-one feature quantities of each image were extracted. A support vector machine (SVM) model was created from each feature value of the training data, and a coefficient of determination was calculated for each layer of the choroid by a fivefold cross validation. Next, the same evaluation was performed after creating a SVM model with selected effective feature quantities.RESULTS: The mean coefficient of determination using all features was 0.9853<U+2009>±<U+2009>0.0012. Nine effective feature quantities (relative choroid thickness, mean/kurtosis/variance of brightness, FFT_ skewness, k0_vessel width, k1/k2/k4_vessel area) were selected, and the mean of the coefficient of determinations with these quantities In this model was 0.9865<U+2009>±<U+2009>0.0001. The number of errors in the image number at the start of each layer was 1.01<U+2009>±<U+2009>0.79 for the choriocapillaris, 1.13<U+2009>±<U+2009>1.12 for Sattler's layer, and 3.77<U+2009>±<U+2009>2.90 for Haller's layer.CONCLUSION: Automated stratification of the choroid in en face images can be done with high accuracy through machine learning.","3":"Japanese journal of ophthalmology","4":"30293226","5":"2018","6":"Male"},{"1":"Automated segmentation of en face choroidal images obtained by optical coherent tomography by machine learning.","2":"PURPOSE: To develop an automated method to segment the choroidal layers of en face optical coherent tomography (OCT) images by machine learning.STUDY DESIGN: A cross-sectional, prospective study of 276 eyes of 181 healthy subjects.METHODS: OCT en face images of the choroid were obtained every 2.6 µm from the retinal pigment epithelium (RPE) to the chorioscleral border. The images at the start of the choriocapillaris, start of Sattler's layer, and start of Haller's layer were identified, and the image numbers from the RPE line were taken as the teacher data. Forty-one feature quantities of each image were extracted. A support vector machine (SVM) model was created from each feature value of the training data, and a coefficient of determination was calculated for each layer of the choroid by a fivefold cross validation. Next, the same evaluation was performed after creating a SVM model with selected effective feature quantities.RESULTS: The mean coefficient of determination using all features was 0.9853<U+2009>±<U+2009>0.0012. Nine effective feature quantities (relative choroid thickness, mean/kurtosis/variance of brightness, FFT_ skewness, k0_vessel width, k1/k2/k4_vessel area) were selected, and the mean of the coefficient of determinations with these quantities In this model was 0.9865<U+2009>±<U+2009>0.0001. The number of errors in the image number at the start of each layer was 1.01<U+2009>±<U+2009>0.79 for the choriocapillaris, 1.13<U+2009>±<U+2009>1.12 for Sattler's layer, and 3.77<U+2009>±<U+2009>2.90 for Haller's layer.CONCLUSION: Automated stratification of the choroid in en face images can be done with high accuracy through machine learning.","3":"Japanese journal of ophthalmology","4":"30293226","5":"2018","6":"Middle Aged"},{"1":"Automated segmentation of en face choroidal images obtained by optical coherent tomography by machine learning.","2":"PURPOSE: To develop an automated method to segment the choroidal layers of en face optical coherent tomography (OCT) images by machine learning.STUDY DESIGN: A cross-sectional, prospective study of 276 eyes of 181 healthy subjects.METHODS: OCT en face images of the choroid were obtained every 2.6 µm from the retinal pigment epithelium (RPE) to the chorioscleral border. The images at the start of the choriocapillaris, start of Sattler's layer, and start of Haller's layer were identified, and the image numbers from the RPE line were taken as the teacher data. Forty-one feature quantities of each image were extracted. A support vector machine (SVM) model was created from each feature value of the training data, and a coefficient of determination was calculated for each layer of the choroid by a fivefold cross validation. Next, the same evaluation was performed after creating a SVM model with selected effective feature quantities.RESULTS: The mean coefficient of determination using all features was 0.9853<U+2009>±<U+2009>0.0012. Nine effective feature quantities (relative choroid thickness, mean/kurtosis/variance of brightness, FFT_ skewness, k0_vessel width, k1/k2/k4_vessel area) were selected, and the mean of the coefficient of determinations with these quantities In this model was 0.9865<U+2009>±<U+2009>0.0001. The number of errors in the image number at the start of each layer was 1.01<U+2009>±<U+2009>0.79 for the choriocapillaris, 1.13<U+2009>±<U+2009>1.12 for Sattler's layer, and 3.77<U+2009>±<U+2009>2.90 for Haller's layer.CONCLUSION: Automated stratification of the choroid in en face images can be done with high accuracy through machine learning.","3":"Japanese journal of ophthalmology","4":"30293226","5":"2018","6":"Prospective Studies"},{"1":"Automated segmentation of en face choroidal images obtained by optical coherent tomography by machine learning.","2":"PURPOSE: To develop an automated method to segment the choroidal layers of en face optical coherent tomography (OCT) images by machine learning.STUDY DESIGN: A cross-sectional, prospective study of 276 eyes of 181 healthy subjects.METHODS: OCT en face images of the choroid were obtained every 2.6 µm from the retinal pigment epithelium (RPE) to the chorioscleral border. The images at the start of the choriocapillaris, start of Sattler's layer, and start of Haller's layer were identified, and the image numbers from the RPE line were taken as the teacher data. Forty-one feature quantities of each image were extracted. A support vector machine (SVM) model was created from each feature value of the training data, and a coefficient of determination was calculated for each layer of the choroid by a fivefold cross validation. Next, the same evaluation was performed after creating a SVM model with selected effective feature quantities.RESULTS: The mean coefficient of determination using all features was 0.9853<U+2009>±<U+2009>0.0012. Nine effective feature quantities (relative choroid thickness, mean/kurtosis/variance of brightness, FFT_ skewness, k0_vessel width, k1/k2/k4_vessel area) were selected, and the mean of the coefficient of determinations with these quantities In this model was 0.9865<U+2009>±<U+2009>0.0001. The number of errors in the image number at the start of each layer was 1.01<U+2009>±<U+2009>0.79 for the choriocapillaris, 1.13<U+2009>±<U+2009>1.12 for Sattler's layer, and 3.77<U+2009>±<U+2009>2.90 for Haller's layer.CONCLUSION: Automated stratification of the choroid in en face images can be done with high accuracy through machine learning.","3":"Japanese journal of ophthalmology","4":"30293226","5":"2018","6":"Reproducibility of Results"},{"1":"Automated segmentation of en face choroidal images obtained by optical coherent tomography by machine learning.","2":"PURPOSE: To develop an automated method to segment the choroidal layers of en face optical coherent tomography (OCT) images by machine learning.STUDY DESIGN: A cross-sectional, prospective study of 276 eyes of 181 healthy subjects.METHODS: OCT en face images of the choroid were obtained every 2.6 µm from the retinal pigment epithelium (RPE) to the chorioscleral border. The images at the start of the choriocapillaris, start of Sattler's layer, and start of Haller's layer were identified, and the image numbers from the RPE line were taken as the teacher data. Forty-one feature quantities of each image were extracted. A support vector machine (SVM) model was created from each feature value of the training data, and a coefficient of determination was calculated for each layer of the choroid by a fivefold cross validation. Next, the same evaluation was performed after creating a SVM model with selected effective feature quantities.RESULTS: The mean coefficient of determination using all features was 0.9853<U+2009>±<U+2009>0.0012. Nine effective feature quantities (relative choroid thickness, mean/kurtosis/variance of brightness, FFT_ skewness, k0_vessel width, k1/k2/k4_vessel area) were selected, and the mean of the coefficient of determinations with these quantities In this model was 0.9865<U+2009>±<U+2009>0.0001. The number of errors in the image number at the start of each layer was 1.01<U+2009>±<U+2009>0.79 for the choriocapillaris, 1.13<U+2009>±<U+2009>1.12 for Sattler's layer, and 3.77<U+2009>±<U+2009>2.90 for Haller's layer.CONCLUSION: Automated stratification of the choroid in en face images can be done with high accuracy through machine learning.","3":"Japanese journal of ophthalmology","4":"30293226","5":"2018","6":"Retinal Pigment Epithelium"},{"1":"Automated segmentation of en face choroidal images obtained by optical coherent tomography by machine learning.","2":"PURPOSE: To develop an automated method to segment the choroidal layers of en face optical coherent tomography (OCT) images by machine learning.STUDY DESIGN: A cross-sectional, prospective study of 276 eyes of 181 healthy subjects.METHODS: OCT en face images of the choroid were obtained every 2.6 µm from the retinal pigment epithelium (RPE) to the chorioscleral border. The images at the start of the choriocapillaris, start of Sattler's layer, and start of Haller's layer were identified, and the image numbers from the RPE line were taken as the teacher data. Forty-one feature quantities of each image were extracted. A support vector machine (SVM) model was created from each feature value of the training data, and a coefficient of determination was calculated for each layer of the choroid by a fivefold cross validation. Next, the same evaluation was performed after creating a SVM model with selected effective feature quantities.RESULTS: The mean coefficient of determination using all features was 0.9853<U+2009>±<U+2009>0.0012. Nine effective feature quantities (relative choroid thickness, mean/kurtosis/variance of brightness, FFT_ skewness, k0_vessel width, k1/k2/k4_vessel area) were selected, and the mean of the coefficient of determinations with these quantities In this model was 0.9865<U+2009>±<U+2009>0.0001. The number of errors in the image number at the start of each layer was 1.01<U+2009>±<U+2009>0.79 for the choriocapillaris, 1.13<U+2009>±<U+2009>1.12 for Sattler's layer, and 3.77<U+2009>±<U+2009>2.90 for Haller's layer.CONCLUSION: Automated stratification of the choroid in en face images can be done with high accuracy through machine learning.","3":"Japanese journal of ophthalmology","4":"30293226","5":"2018","6":"cytology"},{"1":"Automated segmentation of en face choroidal images obtained by optical coherent tomography by machine learning.","2":"PURPOSE: To develop an automated method to segment the choroidal layers of en face optical coherent tomography (OCT) images by machine learning.STUDY DESIGN: A cross-sectional, prospective study of 276 eyes of 181 healthy subjects.METHODS: OCT en face images of the choroid were obtained every 2.6 µm from the retinal pigment epithelium (RPE) to the chorioscleral border. The images at the start of the choriocapillaris, start of Sattler's layer, and start of Haller's layer were identified, and the image numbers from the RPE line were taken as the teacher data. Forty-one feature quantities of each image were extracted. A support vector machine (SVM) model was created from each feature value of the training data, and a coefficient of determination was calculated for each layer of the choroid by a fivefold cross validation. Next, the same evaluation was performed after creating a SVM model with selected effective feature quantities.RESULTS: The mean coefficient of determination using all features was 0.9853<U+2009>±<U+2009>0.0012. Nine effective feature quantities (relative choroid thickness, mean/kurtosis/variance of brightness, FFT_ skewness, k0_vessel width, k1/k2/k4_vessel area) were selected, and the mean of the coefficient of determinations with these quantities In this model was 0.9865<U+2009>±<U+2009>0.0001. The number of errors in the image number at the start of each layer was 1.01<U+2009>±<U+2009>0.79 for the choriocapillaris, 1.13<U+2009>±<U+2009>1.12 for Sattler's layer, and 3.77<U+2009>±<U+2009>2.90 for Haller's layer.CONCLUSION: Automated stratification of the choroid in en face images can be done with high accuracy through machine learning.","3":"Japanese journal of ophthalmology","4":"30293226","5":"2018","6":"Tomography, Optical Coherence"},{"1":"Automated segmentation of en face choroidal images obtained by optical coherent tomography by machine learning.","2":"PURPOSE: To develop an automated method to segment the choroidal layers of en face optical coherent tomography (OCT) images by machine learning.STUDY DESIGN: A cross-sectional, prospective study of 276 eyes of 181 healthy subjects.METHODS: OCT en face images of the choroid were obtained every 2.6 µm from the retinal pigment epithelium (RPE) to the chorioscleral border. The images at the start of the choriocapillaris, start of Sattler's layer, and start of Haller's layer were identified, and the image numbers from the RPE line were taken as the teacher data. Forty-one feature quantities of each image were extracted. A support vector machine (SVM) model was created from each feature value of the training data, and a coefficient of determination was calculated for each layer of the choroid by a fivefold cross validation. Next, the same evaluation was performed after creating a SVM model with selected effective feature quantities.RESULTS: The mean coefficient of determination using all features was 0.9853<U+2009>±<U+2009>0.0012. Nine effective feature quantities (relative choroid thickness, mean/kurtosis/variance of brightness, FFT_ skewness, k0_vessel width, k1/k2/k4_vessel area) were selected, and the mean of the coefficient of determinations with these quantities In this model was 0.9865<U+2009>±<U+2009>0.0001. The number of errors in the image number at the start of each layer was 1.01<U+2009>±<U+2009>0.79 for the choriocapillaris, 1.13<U+2009>±<U+2009>1.12 for Sattler's layer, and 3.77<U+2009>±<U+2009>2.90 for Haller's layer.CONCLUSION: Automated stratification of the choroid in en face images can be done with high accuracy through machine learning.","3":"Japanese journal of ophthalmology","4":"30293226","5":"2018","6":"methods"},{"1":"Automated segmentation of en face choroidal images obtained by optical coherent tomography by machine learning.","2":"PURPOSE: To develop an automated method to segment the choroidal layers of en face optical coherent tomography (OCT) images by machine learning.STUDY DESIGN: A cross-sectional, prospective study of 276 eyes of 181 healthy subjects.METHODS: OCT en face images of the choroid were obtained every 2.6 µm from the retinal pigment epithelium (RPE) to the chorioscleral border. The images at the start of the choriocapillaris, start of Sattler's layer, and start of Haller's layer were identified, and the image numbers from the RPE line were taken as the teacher data. Forty-one feature quantities of each image were extracted. A support vector machine (SVM) model was created from each feature value of the training data, and a coefficient of determination was calculated for each layer of the choroid by a fivefold cross validation. Next, the same evaluation was performed after creating a SVM model with selected effective feature quantities.RESULTS: The mean coefficient of determination using all features was 0.9853<U+2009>±<U+2009>0.0012. Nine effective feature quantities (relative choroid thickness, mean/kurtosis/variance of brightness, FFT_ skewness, k0_vessel width, k1/k2/k4_vessel area) were selected, and the mean of the coefficient of determinations with these quantities In this model was 0.9865<U+2009>±<U+2009>0.0001. The number of errors in the image number at the start of each layer was 1.01<U+2009>±<U+2009>0.79 for the choriocapillaris, 1.13<U+2009>±<U+2009>1.12 for Sattler's layer, and 3.77<U+2009>±<U+2009>2.90 for Haller's layer.CONCLUSION: Automated stratification of the choroid in en face images can be done with high accuracy through machine learning.","3":"Japanese journal of ophthalmology","4":"30293226","5":"2018","6":"Young Adult"},{"1":"Estrous detection by continuous measurements of vaginal temperature and conductivity with supervised machine learning in cattle.","2":"","3":"Theriogenology","4":"30292860","5":"2018","6":"Animals"},{"1":"Estrous detection by continuous measurements of vaginal temperature and conductivity with supervised machine learning in cattle.","2":"","3":"Theriogenology","4":"30292860","5":"2018","6":"Body Temperature"},{"1":"Estrous detection by continuous measurements of vaginal temperature and conductivity with supervised machine learning in cattle.","2":"","3":"Theriogenology","4":"30292860","5":"2018","6":"physiology"},{"1":"Estrous detection by continuous measurements of vaginal temperature and conductivity with supervised machine learning in cattle.","2":"","3":"Theriogenology","4":"30292860","5":"2018","6":"Cattle"},{"1":"Estrous detection by continuous measurements of vaginal temperature and conductivity with supervised machine learning in cattle.","2":"","3":"Theriogenology","4":"30292860","5":"2018","6":"physiology"},{"1":"Estrous detection by continuous measurements of vaginal temperature and conductivity with supervised machine learning in cattle.","2":"","3":"Theriogenology","4":"30292860","5":"2018","6":"Estrus"},{"1":"Estrous detection by continuous measurements of vaginal temperature and conductivity with supervised machine learning in cattle.","2":"","3":"Theriogenology","4":"30292860","5":"2018","6":"physiology"},{"1":"Estrous detection by continuous measurements of vaginal temperature and conductivity with supervised machine learning in cattle.","2":"","3":"Theriogenology","4":"30292860","5":"2018","6":"Female"},{"1":"Estrous detection by continuous measurements of vaginal temperature and conductivity with supervised machine learning in cattle.","2":"","3":"Theriogenology","4":"30292860","5":"2018","6":"Longitudinal Studies"},{"1":"Estrous detection by continuous measurements of vaginal temperature and conductivity with supervised machine learning in cattle.","2":"","3":"Theriogenology","4":"30292860","5":"2018","6":"Monitoring, Physiologic"},{"1":"Estrous detection by continuous measurements of vaginal temperature and conductivity with supervised machine learning in cattle.","2":"","3":"Theriogenology","4":"30292860","5":"2018","6":"instrumentation"},{"1":"Estrous detection by continuous measurements of vaginal temperature and conductivity with supervised machine learning in cattle.","2":"","3":"Theriogenology","4":"30292860","5":"2018","6":"methods"},{"1":"Estrous detection by continuous measurements of vaginal temperature and conductivity with supervised machine learning in cattle.","2":"","3":"Theriogenology","4":"30292860","5":"2018","6":"veterinary"},{"1":"Estrous detection by continuous measurements of vaginal temperature and conductivity with supervised machine learning in cattle.","2":"","3":"Theriogenology","4":"30292860","5":"2018","6":"Reproducibility of Results"},{"1":"Estrous detection by continuous measurements of vaginal temperature and conductivity with supervised machine learning in cattle.","2":"","3":"Theriogenology","4":"30292860","5":"2018","6":"Sexual Behavior, Animal"},{"1":"Estrous detection by continuous measurements of vaginal temperature and conductivity with supervised machine learning in cattle.","2":"","3":"Theriogenology","4":"30292860","5":"2018","6":"Supervised Machine Learning"},{"1":"Towards enhanced metabolomic data analysis of mass spectrometry image: Multivariate Curve Resolution and Machine Learning.","2":"Large amounts of data are generally produced from mass spectrometry imaging (MSI) experiments in obtaining the molecular and spatial information of biological samples. Traditionally, MS images are constructed using manually selected ions, and it is very challenging to comprehensively analyze MSI results due to their large data sizes and highly complex data structures. To overcome these barriers, it is obligatory to develop advanced data analysis approaches to handle the increasingly large MSI data. In the current study, we focused on the method development of using Multivariate Curve Resolution (MCR) and Machine Learning (ML) approaches. We aimed to effectively extract the essential information present in the large and complex MSI data and enhance the metabolomic data analysis of biological tissues. Multivariate Curve Resolution-Alternating Least Squares (MCR-ALS) algorithm was used to obtain major patterns of spatial distribution and grouped metabolites with the same spatial distribution patterns. In addition, both supervised and unsupervised ML methods were established to analyze the MSI data. In the supervised ML approach, Random Forest method was selected, and the model was trained using the selected datasets based on the distribution pattern obtained from MCR-ALS analyses. In the unsupervised ML approach, both DBSCAN (Density-based Spatial Clustering of Applications with Noise) and CLARA (Clustering Large Applications) were applied to cluster the MSI datasets. It is worth noting that similar patterns of spatial distribution were discovered through MSI data analysis using MCR-ALS, supervised ML, and unsupervised ML. Our protocols of data analysis can be applied to process the data acquired using many other types of MSI techniques, and to extract the overall features present in MSI results that are intractable using traditional data analysis approaches.","3":"Analytica chimica acta","4":"30292295","5":"2018","6":"Algorithms"},{"1":"Towards enhanced metabolomic data analysis of mass spectrometry image: Multivariate Curve Resolution and Machine Learning.","2":"Large amounts of data are generally produced from mass spectrometry imaging (MSI) experiments in obtaining the molecular and spatial information of biological samples. Traditionally, MS images are constructed using manually selected ions, and it is very challenging to comprehensively analyze MSI results due to their large data sizes and highly complex data structures. To overcome these barriers, it is obligatory to develop advanced data analysis approaches to handle the increasingly large MSI data. In the current study, we focused on the method development of using Multivariate Curve Resolution (MCR) and Machine Learning (ML) approaches. We aimed to effectively extract the essential information present in the large and complex MSI data and enhance the metabolomic data analysis of biological tissues. Multivariate Curve Resolution-Alternating Least Squares (MCR-ALS) algorithm was used to obtain major patterns of spatial distribution and grouped metabolites with the same spatial distribution patterns. In addition, both supervised and unsupervised ML methods were established to analyze the MSI data. In the supervised ML approach, Random Forest method was selected, and the model was trained using the selected datasets based on the distribution pattern obtained from MCR-ALS analyses. In the unsupervised ML approach, both DBSCAN (Density-based Spatial Clustering of Applications with Noise) and CLARA (Clustering Large Applications) were applied to cluster the MSI datasets. It is worth noting that similar patterns of spatial distribution were discovered through MSI data analysis using MCR-ALS, supervised ML, and unsupervised ML. Our protocols of data analysis can be applied to process the data acquired using many other types of MSI techniques, and to extract the overall features present in MSI results that are intractable using traditional data analysis approaches.","3":"Analytica chimica acta","4":"30292295","5":"2018","6":"Animals"},{"1":"Towards enhanced metabolomic data analysis of mass spectrometry image: Multivariate Curve Resolution and Machine Learning.","2":"Large amounts of data are generally produced from mass spectrometry imaging (MSI) experiments in obtaining the molecular and spatial information of biological samples. Traditionally, MS images are constructed using manually selected ions, and it is very challenging to comprehensively analyze MSI results due to their large data sizes and highly complex data structures. To overcome these barriers, it is obligatory to develop advanced data analysis approaches to handle the increasingly large MSI data. In the current study, we focused on the method development of using Multivariate Curve Resolution (MCR) and Machine Learning (ML) approaches. We aimed to effectively extract the essential information present in the large and complex MSI data and enhance the metabolomic data analysis of biological tissues. Multivariate Curve Resolution-Alternating Least Squares (MCR-ALS) algorithm was used to obtain major patterns of spatial distribution and grouped metabolites with the same spatial distribution patterns. In addition, both supervised and unsupervised ML methods were established to analyze the MSI data. In the supervised ML approach, Random Forest method was selected, and the model was trained using the selected datasets based on the distribution pattern obtained from MCR-ALS analyses. In the unsupervised ML approach, both DBSCAN (Density-based Spatial Clustering of Applications with Noise) and CLARA (Clustering Large Applications) were applied to cluster the MSI datasets. It is worth noting that similar patterns of spatial distribution were discovered through MSI data analysis using MCR-ALS, supervised ML, and unsupervised ML. Our protocols of data analysis can be applied to process the data acquired using many other types of MSI techniques, and to extract the overall features present in MSI results that are intractable using traditional data analysis approaches.","3":"Analytica chimica acta","4":"30292295","5":"2018","6":"Kidney"},{"1":"Towards enhanced metabolomic data analysis of mass spectrometry image: Multivariate Curve Resolution and Machine Learning.","2":"Large amounts of data are generally produced from mass spectrometry imaging (MSI) experiments in obtaining the molecular and spatial information of biological samples. Traditionally, MS images are constructed using manually selected ions, and it is very challenging to comprehensively analyze MSI results due to their large data sizes and highly complex data structures. To overcome these barriers, it is obligatory to develop advanced data analysis approaches to handle the increasingly large MSI data. In the current study, we focused on the method development of using Multivariate Curve Resolution (MCR) and Machine Learning (ML) approaches. We aimed to effectively extract the essential information present in the large and complex MSI data and enhance the metabolomic data analysis of biological tissues. Multivariate Curve Resolution-Alternating Least Squares (MCR-ALS) algorithm was used to obtain major patterns of spatial distribution and grouped metabolites with the same spatial distribution patterns. In addition, both supervised and unsupervised ML methods were established to analyze the MSI data. In the supervised ML approach, Random Forest method was selected, and the model was trained using the selected datasets based on the distribution pattern obtained from MCR-ALS analyses. In the unsupervised ML approach, both DBSCAN (Density-based Spatial Clustering of Applications with Noise) and CLARA (Clustering Large Applications) were applied to cluster the MSI datasets. It is worth noting that similar patterns of spatial distribution were discovered through MSI data analysis using MCR-ALS, supervised ML, and unsupervised ML. Our protocols of data analysis can be applied to process the data acquired using many other types of MSI techniques, and to extract the overall features present in MSI results that are intractable using traditional data analysis approaches.","3":"Analytica chimica acta","4":"30292295","5":"2018","6":"diagnostic imaging"},{"1":"Towards enhanced metabolomic data analysis of mass spectrometry image: Multivariate Curve Resolution and Machine Learning.","2":"Large amounts of data are generally produced from mass spectrometry imaging (MSI) experiments in obtaining the molecular and spatial information of biological samples. Traditionally, MS images are constructed using manually selected ions, and it is very challenging to comprehensively analyze MSI results due to their large data sizes and highly complex data structures. To overcome these barriers, it is obligatory to develop advanced data analysis approaches to handle the increasingly large MSI data. In the current study, we focused on the method development of using Multivariate Curve Resolution (MCR) and Machine Learning (ML) approaches. We aimed to effectively extract the essential information present in the large and complex MSI data and enhance the metabolomic data analysis of biological tissues. Multivariate Curve Resolution-Alternating Least Squares (MCR-ALS) algorithm was used to obtain major patterns of spatial distribution and grouped metabolites with the same spatial distribution patterns. In addition, both supervised and unsupervised ML methods were established to analyze the MSI data. In the supervised ML approach, Random Forest method was selected, and the model was trained using the selected datasets based on the distribution pattern obtained from MCR-ALS analyses. In the unsupervised ML approach, both DBSCAN (Density-based Spatial Clustering of Applications with Noise) and CLARA (Clustering Large Applications) were applied to cluster the MSI datasets. It is worth noting that similar patterns of spatial distribution were discovered through MSI data analysis using MCR-ALS, supervised ML, and unsupervised ML. Our protocols of data analysis can be applied to process the data acquired using many other types of MSI techniques, and to extract the overall features present in MSI results that are intractable using traditional data analysis approaches.","3":"Analytica chimica acta","4":"30292295","5":"2018","6":"Machine Learning"},{"1":"Towards enhanced metabolomic data analysis of mass spectrometry image: Multivariate Curve Resolution and Machine Learning.","2":"Large amounts of data are generally produced from mass spectrometry imaging (MSI) experiments in obtaining the molecular and spatial information of biological samples. Traditionally, MS images are constructed using manually selected ions, and it is very challenging to comprehensively analyze MSI results due to their large data sizes and highly complex data structures. To overcome these barriers, it is obligatory to develop advanced data analysis approaches to handle the increasingly large MSI data. In the current study, we focused on the method development of using Multivariate Curve Resolution (MCR) and Machine Learning (ML) approaches. We aimed to effectively extract the essential information present in the large and complex MSI data and enhance the metabolomic data analysis of biological tissues. Multivariate Curve Resolution-Alternating Least Squares (MCR-ALS) algorithm was used to obtain major patterns of spatial distribution and grouped metabolites with the same spatial distribution patterns. In addition, both supervised and unsupervised ML methods were established to analyze the MSI data. In the supervised ML approach, Random Forest method was selected, and the model was trained using the selected datasets based on the distribution pattern obtained from MCR-ALS analyses. In the unsupervised ML approach, both DBSCAN (Density-based Spatial Clustering of Applications with Noise) and CLARA (Clustering Large Applications) were applied to cluster the MSI datasets. It is worth noting that similar patterns of spatial distribution were discovered through MSI data analysis using MCR-ALS, supervised ML, and unsupervised ML. Our protocols of data analysis can be applied to process the data acquired using many other types of MSI techniques, and to extract the overall features present in MSI results that are intractable using traditional data analysis approaches.","3":"Analytica chimica acta","4":"30292295","5":"2018","6":"Mass Spectrometry"},{"1":"Towards enhanced metabolomic data analysis of mass spectrometry image: Multivariate Curve Resolution and Machine Learning.","2":"Large amounts of data are generally produced from mass spectrometry imaging (MSI) experiments in obtaining the molecular and spatial information of biological samples. Traditionally, MS images are constructed using manually selected ions, and it is very challenging to comprehensively analyze MSI results due to their large data sizes and highly complex data structures. To overcome these barriers, it is obligatory to develop advanced data analysis approaches to handle the increasingly large MSI data. In the current study, we focused on the method development of using Multivariate Curve Resolution (MCR) and Machine Learning (ML) approaches. We aimed to effectively extract the essential information present in the large and complex MSI data and enhance the metabolomic data analysis of biological tissues. Multivariate Curve Resolution-Alternating Least Squares (MCR-ALS) algorithm was used to obtain major patterns of spatial distribution and grouped metabolites with the same spatial distribution patterns. In addition, both supervised and unsupervised ML methods were established to analyze the MSI data. In the supervised ML approach, Random Forest method was selected, and the model was trained using the selected datasets based on the distribution pattern obtained from MCR-ALS analyses. In the unsupervised ML approach, both DBSCAN (Density-based Spatial Clustering of Applications with Noise) and CLARA (Clustering Large Applications) were applied to cluster the MSI datasets. It is worth noting that similar patterns of spatial distribution were discovered through MSI data analysis using MCR-ALS, supervised ML, and unsupervised ML. Our protocols of data analysis can be applied to process the data acquired using many other types of MSI techniques, and to extract the overall features present in MSI results that are intractable using traditional data analysis approaches.","3":"Analytica chimica acta","4":"30292295","5":"2018","6":"Metabolomics"},{"1":"Towards enhanced metabolomic data analysis of mass spectrometry image: Multivariate Curve Resolution and Machine Learning.","2":"Large amounts of data are generally produced from mass spectrometry imaging (MSI) experiments in obtaining the molecular and spatial information of biological samples. Traditionally, MS images are constructed using manually selected ions, and it is very challenging to comprehensively analyze MSI results due to their large data sizes and highly complex data structures. To overcome these barriers, it is obligatory to develop advanced data analysis approaches to handle the increasingly large MSI data. In the current study, we focused on the method development of using Multivariate Curve Resolution (MCR) and Machine Learning (ML) approaches. We aimed to effectively extract the essential information present in the large and complex MSI data and enhance the metabolomic data analysis of biological tissues. Multivariate Curve Resolution-Alternating Least Squares (MCR-ALS) algorithm was used to obtain major patterns of spatial distribution and grouped metabolites with the same spatial distribution patterns. In addition, both supervised and unsupervised ML methods were established to analyze the MSI data. In the supervised ML approach, Random Forest method was selected, and the model was trained using the selected datasets based on the distribution pattern obtained from MCR-ALS analyses. In the unsupervised ML approach, both DBSCAN (Density-based Spatial Clustering of Applications with Noise) and CLARA (Clustering Large Applications) were applied to cluster the MSI datasets. It is worth noting that similar patterns of spatial distribution were discovered through MSI data analysis using MCR-ALS, supervised ML, and unsupervised ML. Our protocols of data analysis can be applied to process the data acquired using many other types of MSI techniques, and to extract the overall features present in MSI results that are intractable using traditional data analysis approaches.","3":"Analytica chimica acta","4":"30292295","5":"2018","6":"Mice"},{"1":"Towards enhanced metabolomic data analysis of mass spectrometry image: Multivariate Curve Resolution and Machine Learning.","2":"Large amounts of data are generally produced from mass spectrometry imaging (MSI) experiments in obtaining the molecular and spatial information of biological samples. Traditionally, MS images are constructed using manually selected ions, and it is very challenging to comprehensively analyze MSI results due to their large data sizes and highly complex data structures. To overcome these barriers, it is obligatory to develop advanced data analysis approaches to handle the increasingly large MSI data. In the current study, we focused on the method development of using Multivariate Curve Resolution (MCR) and Machine Learning (ML) approaches. We aimed to effectively extract the essential information present in the large and complex MSI data and enhance the metabolomic data analysis of biological tissues. Multivariate Curve Resolution-Alternating Least Squares (MCR-ALS) algorithm was used to obtain major patterns of spatial distribution and grouped metabolites with the same spatial distribution patterns. In addition, both supervised and unsupervised ML methods were established to analyze the MSI data. In the supervised ML approach, Random Forest method was selected, and the model was trained using the selected datasets based on the distribution pattern obtained from MCR-ALS analyses. In the unsupervised ML approach, both DBSCAN (Density-based Spatial Clustering of Applications with Noise) and CLARA (Clustering Large Applications) were applied to cluster the MSI datasets. It is worth noting that similar patterns of spatial distribution were discovered through MSI data analysis using MCR-ALS, supervised ML, and unsupervised ML. Our protocols of data analysis can be applied to process the data acquired using many other types of MSI techniques, and to extract the overall features present in MSI results that are intractable using traditional data analysis approaches.","3":"Analytica chimica acta","4":"30292295","5":"2018","6":"Multivariate Analysis"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"Adult"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"Aged"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"Aged, 80 and over"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"Algorithms"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"Carcinoma, Renal Cell"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"diagnostic imaging"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"pathology"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"Diagnosis, Differential"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"Female"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"Humans"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"Kidney Neoplasms"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"diagnostic imaging"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"pathology"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"Machine Learning"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"Male"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"Middle Aged"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"Multidetector Computed Tomography"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"methods"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"Neural Networks (Computer)"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"Reproducibility of Results"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"Retrospective Studies"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"Sensitivity and Specificity"},{"1":"Textural differences between renal cell carcinoma subtypes: Machine learning-based quantitative computed tomography texture analysis with independent external validation.","2":"OBJECTIVE: To develop externally validated, reproducible, and generalizable models for distinguishing three major subtypes of renal cell carcinomas (RCCs) using machine learning-based quantitative computed tomography (CT) texture analysis (qCT-TA).MATERIALS AND METHODS: Sixty-eight RCCs were included in this retrospective study for model development and internal validation. Another 26 RCCs were included from public databases (The Cancer Genome Atlas-TCGA) for independent external validation. Following image preparation steps (reconstruction, resampling, normalization, and discretization), 275 texture features were extracted from unenhanced and corticomedullary phase CT images. Feature selection was firstly done with reproducibility analysis by three radiologists, and; then, with a wrapper-based classifier-specific algorithm. A nested cross-validation was performed for feature selection and model optimization. Base classifiers were the artificial neural network (ANN) and support vector machine (SVM). Base classifiers were also combined with three additional algorithms to improve generalizability performance. Classifications were done with the following groups: (i), non-clear cell RCC (non-cc-RCC) versus clear cell RCC (cc-RCC) and (ii), cc-RCC versus papillary cell RCC (pc-RCC) versus chromophobe cell RCC (chc-RCC). Main performance metric for comparisons was the Matthews correlation coefficient (MCC).RESULTS: Number of the reproducible features is smaller for the unenhanced images (93 out of 275) compared to the corticomedullary phase images (232 out of 275). Overall performance metrics of the machine learning-based qCT-TA derived from corticomedullary phase images were better than those of unenhanced images. Using corticomedullary phase images, ANN with adaptive boosting algorithm performed best for discrimination of non-cc-RCCs from cc-RCCs (MCC<U+2009>=<U+2009>0.728) with an external validation accuracy, sensitivity, and specificity of 84.6%, 69.2%, and 100%, respectively. On the other hand, the performance of the machine learning-based qCT-TA is rather poor for distinguishing three major subtypes. The SVM with bagging algorithm performed best for discrimination of pc-RCC from other RCC subtypes (MCC<U+2009>=<U+2009>0.804) with an external validation accuracy, sensitivity, and specificity of 69.2%, 71.4%, and 100%, respectively.CONCLUSIONS: Machine learning-based qCT-TA can distinguish non-cc-RCCs from cc-RCCs with a satisfying performance. On the other hand, the performance of the method for distinguishing three major subtypes is rather poor. Corticomedullary phase CT images provide much more valuable texture parameters than unenhanced images.","3":"European journal of radiology","4":"30292260","5":"2018","6":"Support Vector Machine"},{"1":"Effect of machine learning methods on predicting NSCLC overall survival time based on Radiomics analysis.","2":"BACKGROUND: To investigate the effect of machine learning methods on predicting the Overall Survival (OS) for non-small cell lung cancer based on radiomics features analysis.METHODS: A total of 339 radiomic features were extracted from the segmented tumor volumes of pretreatment computed tomography (CT) images. These radiomic features quantify the tumor phenotypic characteristics on the medical images using tumor shape and size, the intensity statistics and the textures. The performance of 5 feature selection methods and 8 machine learning methods were investigated for OS prediction. The predicted performance was evaluated with concordance index between predicted and true OS for the non-small cell lung cancer patients. The survival curves were evaluated by the Kaplan-Meier algorithm and compared by the log-rank tests.RESULTS: The gradient boosting linear models based on Cox's partial likelihood method using the concordance index feature selection method obtained the best performance (Concordance Index: 0.68, 95% Confidence Interval: 0.62~<U+2009>0.74).CONCLUSIONS: The preliminary results demonstrated that certain machine learning and radiomics analysis method could predict OS of non-small cell lung cancer accuracy.","3":"Radiation oncology (London, England)","4":"30290849","5":"2018","6":"Carcinoma, Non-Small-Cell Lung"},{"1":"Effect of machine learning methods on predicting NSCLC overall survival time based on Radiomics analysis.","2":"BACKGROUND: To investigate the effect of machine learning methods on predicting the Overall Survival (OS) for non-small cell lung cancer based on radiomics features analysis.METHODS: A total of 339 radiomic features were extracted from the segmented tumor volumes of pretreatment computed tomography (CT) images. These radiomic features quantify the tumor phenotypic characteristics on the medical images using tumor shape and size, the intensity statistics and the textures. The performance of 5 feature selection methods and 8 machine learning methods were investigated for OS prediction. The predicted performance was evaluated with concordance index between predicted and true OS for the non-small cell lung cancer patients. The survival curves were evaluated by the Kaplan-Meier algorithm and compared by the log-rank tests.RESULTS: The gradient boosting linear models based on Cox's partial likelihood method using the concordance index feature selection method obtained the best performance (Concordance Index: 0.68, 95% Confidence Interval: 0.62~<U+2009>0.74).CONCLUSIONS: The preliminary results demonstrated that certain machine learning and radiomics analysis method could predict OS of non-small cell lung cancer accuracy.","3":"Radiation oncology (London, England)","4":"30290849","5":"2018","6":"diagnostic imaging"},{"1":"Effect of machine learning methods on predicting NSCLC overall survival time based on Radiomics analysis.","2":"BACKGROUND: To investigate the effect of machine learning methods on predicting the Overall Survival (OS) for non-small cell lung cancer based on radiomics features analysis.METHODS: A total of 339 radiomic features were extracted from the segmented tumor volumes of pretreatment computed tomography (CT) images. These radiomic features quantify the tumor phenotypic characteristics on the medical images using tumor shape and size, the intensity statistics and the textures. The performance of 5 feature selection methods and 8 machine learning methods were investigated for OS prediction. The predicted performance was evaluated with concordance index between predicted and true OS for the non-small cell lung cancer patients. The survival curves were evaluated by the Kaplan-Meier algorithm and compared by the log-rank tests.RESULTS: The gradient boosting linear models based on Cox's partial likelihood method using the concordance index feature selection method obtained the best performance (Concordance Index: 0.68, 95% Confidence Interval: 0.62~<U+2009>0.74).CONCLUSIONS: The preliminary results demonstrated that certain machine learning and radiomics analysis method could predict OS of non-small cell lung cancer accuracy.","3":"Radiation oncology (London, England)","4":"30290849","5":"2018","6":"mortality"},{"1":"Effect of machine learning methods on predicting NSCLC overall survival time based on Radiomics analysis.","2":"BACKGROUND: To investigate the effect of machine learning methods on predicting the Overall Survival (OS) for non-small cell lung cancer based on radiomics features analysis.METHODS: A total of 339 radiomic features were extracted from the segmented tumor volumes of pretreatment computed tomography (CT) images. These radiomic features quantify the tumor phenotypic characteristics on the medical images using tumor shape and size, the intensity statistics and the textures. The performance of 5 feature selection methods and 8 machine learning methods were investigated for OS prediction. The predicted performance was evaluated with concordance index between predicted and true OS for the non-small cell lung cancer patients. The survival curves were evaluated by the Kaplan-Meier algorithm and compared by the log-rank tests.RESULTS: The gradient boosting linear models based on Cox's partial likelihood method using the concordance index feature selection method obtained the best performance (Concordance Index: 0.68, 95% Confidence Interval: 0.62~<U+2009>0.74).CONCLUSIONS: The preliminary results demonstrated that certain machine learning and radiomics analysis method could predict OS of non-small cell lung cancer accuracy.","3":"Radiation oncology (London, England)","4":"30290849","5":"2018","6":"pathology"},{"1":"Effect of machine learning methods on predicting NSCLC overall survival time based on Radiomics analysis.","2":"BACKGROUND: To investigate the effect of machine learning methods on predicting the Overall Survival (OS) for non-small cell lung cancer based on radiomics features analysis.METHODS: A total of 339 radiomic features were extracted from the segmented tumor volumes of pretreatment computed tomography (CT) images. These radiomic features quantify the tumor phenotypic characteristics on the medical images using tumor shape and size, the intensity statistics and the textures. The performance of 5 feature selection methods and 8 machine learning methods were investigated for OS prediction. The predicted performance was evaluated with concordance index between predicted and true OS for the non-small cell lung cancer patients. The survival curves were evaluated by the Kaplan-Meier algorithm and compared by the log-rank tests.RESULTS: The gradient boosting linear models based on Cox's partial likelihood method using the concordance index feature selection method obtained the best performance (Concordance Index: 0.68, 95% Confidence Interval: 0.62~<U+2009>0.74).CONCLUSIONS: The preliminary results demonstrated that certain machine learning and radiomics analysis method could predict OS of non-small cell lung cancer accuracy.","3":"Radiation oncology (London, England)","4":"30290849","5":"2018","6":"Humans"},{"1":"Effect of machine learning methods on predicting NSCLC overall survival time based on Radiomics analysis.","2":"BACKGROUND: To investigate the effect of machine learning methods on predicting the Overall Survival (OS) for non-small cell lung cancer based on radiomics features analysis.METHODS: A total of 339 radiomic features were extracted from the segmented tumor volumes of pretreatment computed tomography (CT) images. These radiomic features quantify the tumor phenotypic characteristics on the medical images using tumor shape and size, the intensity statistics and the textures. The performance of 5 feature selection methods and 8 machine learning methods were investigated for OS prediction. The predicted performance was evaluated with concordance index between predicted and true OS for the non-small cell lung cancer patients. The survival curves were evaluated by the Kaplan-Meier algorithm and compared by the log-rank tests.RESULTS: The gradient boosting linear models based on Cox's partial likelihood method using the concordance index feature selection method obtained the best performance (Concordance Index: 0.68, 95% Confidence Interval: 0.62~<U+2009>0.74).CONCLUSIONS: The preliminary results demonstrated that certain machine learning and radiomics analysis method could predict OS of non-small cell lung cancer accuracy.","3":"Radiation oncology (London, England)","4":"30290849","5":"2018","6":"Lung Neoplasms"},{"1":"Effect of machine learning methods on predicting NSCLC overall survival time based on Radiomics analysis.","2":"BACKGROUND: To investigate the effect of machine learning methods on predicting the Overall Survival (OS) for non-small cell lung cancer based on radiomics features analysis.METHODS: A total of 339 radiomic features were extracted from the segmented tumor volumes of pretreatment computed tomography (CT) images. These radiomic features quantify the tumor phenotypic characteristics on the medical images using tumor shape and size, the intensity statistics and the textures. The performance of 5 feature selection methods and 8 machine learning methods were investigated for OS prediction. The predicted performance was evaluated with concordance index between predicted and true OS for the non-small cell lung cancer patients. The survival curves were evaluated by the Kaplan-Meier algorithm and compared by the log-rank tests.RESULTS: The gradient boosting linear models based on Cox's partial likelihood method using the concordance index feature selection method obtained the best performance (Concordance Index: 0.68, 95% Confidence Interval: 0.62~<U+2009>0.74).CONCLUSIONS: The preliminary results demonstrated that certain machine learning and radiomics analysis method could predict OS of non-small cell lung cancer accuracy.","3":"Radiation oncology (London, England)","4":"30290849","5":"2018","6":"diagnostic imaging"},{"1":"Effect of machine learning methods on predicting NSCLC overall survival time based on Radiomics analysis.","2":"BACKGROUND: To investigate the effect of machine learning methods on predicting the Overall Survival (OS) for non-small cell lung cancer based on radiomics features analysis.METHODS: A total of 339 radiomic features were extracted from the segmented tumor volumes of pretreatment computed tomography (CT) images. These radiomic features quantify the tumor phenotypic characteristics on the medical images using tumor shape and size, the intensity statistics and the textures. The performance of 5 feature selection methods and 8 machine learning methods were investigated for OS prediction. The predicted performance was evaluated with concordance index between predicted and true OS for the non-small cell lung cancer patients. The survival curves were evaluated by the Kaplan-Meier algorithm and compared by the log-rank tests.RESULTS: The gradient boosting linear models based on Cox's partial likelihood method using the concordance index feature selection method obtained the best performance (Concordance Index: 0.68, 95% Confidence Interval: 0.62~<U+2009>0.74).CONCLUSIONS: The preliminary results demonstrated that certain machine learning and radiomics analysis method could predict OS of non-small cell lung cancer accuracy.","3":"Radiation oncology (London, England)","4":"30290849","5":"2018","6":"mortality"},{"1":"Effect of machine learning methods on predicting NSCLC overall survival time based on Radiomics analysis.","2":"BACKGROUND: To investigate the effect of machine learning methods on predicting the Overall Survival (OS) for non-small cell lung cancer based on radiomics features analysis.METHODS: A total of 339 radiomic features were extracted from the segmented tumor volumes of pretreatment computed tomography (CT) images. These radiomic features quantify the tumor phenotypic characteristics on the medical images using tumor shape and size, the intensity statistics and the textures. The performance of 5 feature selection methods and 8 machine learning methods were investigated for OS prediction. The predicted performance was evaluated with concordance index between predicted and true OS for the non-small cell lung cancer patients. The survival curves were evaluated by the Kaplan-Meier algorithm and compared by the log-rank tests.RESULTS: The gradient boosting linear models based on Cox's partial likelihood method using the concordance index feature selection method obtained the best performance (Concordance Index: 0.68, 95% Confidence Interval: 0.62~<U+2009>0.74).CONCLUSIONS: The preliminary results demonstrated that certain machine learning and radiomics analysis method could predict OS of non-small cell lung cancer accuracy.","3":"Radiation oncology (London, England)","4":"30290849","5":"2018","6":"pathology"},{"1":"Effect of machine learning methods on predicting NSCLC overall survival time based on Radiomics analysis.","2":"BACKGROUND: To investigate the effect of machine learning methods on predicting the Overall Survival (OS) for non-small cell lung cancer based on radiomics features analysis.METHODS: A total of 339 radiomic features were extracted from the segmented tumor volumes of pretreatment computed tomography (CT) images. These radiomic features quantify the tumor phenotypic characteristics on the medical images using tumor shape and size, the intensity statistics and the textures. The performance of 5 feature selection methods and 8 machine learning methods were investigated for OS prediction. The predicted performance was evaluated with concordance index between predicted and true OS for the non-small cell lung cancer patients. The survival curves were evaluated by the Kaplan-Meier algorithm and compared by the log-rank tests.RESULTS: The gradient boosting linear models based on Cox's partial likelihood method using the concordance index feature selection method obtained the best performance (Concordance Index: 0.68, 95% Confidence Interval: 0.62~<U+2009>0.74).CONCLUSIONS: The preliminary results demonstrated that certain machine learning and radiomics analysis method could predict OS of non-small cell lung cancer accuracy.","3":"Radiation oncology (London, England)","4":"30290849","5":"2018","6":"Machine Learning"},{"1":"Effect of machine learning methods on predicting NSCLC overall survival time based on Radiomics analysis.","2":"BACKGROUND: To investigate the effect of machine learning methods on predicting the Overall Survival (OS) for non-small cell lung cancer based on radiomics features analysis.METHODS: A total of 339 radiomic features were extracted from the segmented tumor volumes of pretreatment computed tomography (CT) images. These radiomic features quantify the tumor phenotypic characteristics on the medical images using tumor shape and size, the intensity statistics and the textures. The performance of 5 feature selection methods and 8 machine learning methods were investigated for OS prediction. The predicted performance was evaluated with concordance index between predicted and true OS for the non-small cell lung cancer patients. The survival curves were evaluated by the Kaplan-Meier algorithm and compared by the log-rank tests.RESULTS: The gradient boosting linear models based on Cox's partial likelihood method using the concordance index feature selection method obtained the best performance (Concordance Index: 0.68, 95% Confidence Interval: 0.62~<U+2009>0.74).CONCLUSIONS: The preliminary results demonstrated that certain machine learning and radiomics analysis method could predict OS of non-small cell lung cancer accuracy.","3":"Radiation oncology (London, England)","4":"30290849","5":"2018","6":"Prognosis"},{"1":"Effect of machine learning methods on predicting NSCLC overall survival time based on Radiomics analysis.","2":"BACKGROUND: To investigate the effect of machine learning methods on predicting the Overall Survival (OS) for non-small cell lung cancer based on radiomics features analysis.METHODS: A total of 339 radiomic features were extracted from the segmented tumor volumes of pretreatment computed tomography (CT) images. These radiomic features quantify the tumor phenotypic characteristics on the medical images using tumor shape and size, the intensity statistics and the textures. The performance of 5 feature selection methods and 8 machine learning methods were investigated for OS prediction. The predicted performance was evaluated with concordance index between predicted and true OS for the non-small cell lung cancer patients. The survival curves were evaluated by the Kaplan-Meier algorithm and compared by the log-rank tests.RESULTS: The gradient boosting linear models based on Cox's partial likelihood method using the concordance index feature selection method obtained the best performance (Concordance Index: 0.68, 95% Confidence Interval: 0.62~<U+2009>0.74).CONCLUSIONS: The preliminary results demonstrated that certain machine learning and radiomics analysis method could predict OS of non-small cell lung cancer accuracy.","3":"Radiation oncology (London, England)","4":"30290849","5":"2018","6":"Radiotherapy Dosage"},{"1":"Effect of machine learning methods on predicting NSCLC overall survival time based on Radiomics analysis.","2":"BACKGROUND: To investigate the effect of machine learning methods on predicting the Overall Survival (OS) for non-small cell lung cancer based on radiomics features analysis.METHODS: A total of 339 radiomic features were extracted from the segmented tumor volumes of pretreatment computed tomography (CT) images. These radiomic features quantify the tumor phenotypic characteristics on the medical images using tumor shape and size, the intensity statistics and the textures. The performance of 5 feature selection methods and 8 machine learning methods were investigated for OS prediction. The predicted performance was evaluated with concordance index between predicted and true OS for the non-small cell lung cancer patients. The survival curves were evaluated by the Kaplan-Meier algorithm and compared by the log-rank tests.RESULTS: The gradient boosting linear models based on Cox's partial likelihood method using the concordance index feature selection method obtained the best performance (Concordance Index: 0.68, 95% Confidence Interval: 0.62~<U+2009>0.74).CONCLUSIONS: The preliminary results demonstrated that certain machine learning and radiomics analysis method could predict OS of non-small cell lung cancer accuracy.","3":"Radiation oncology (London, England)","4":"30290849","5":"2018","6":"Radiotherapy Planning, Computer-Assisted"},{"1":"Effect of machine learning methods on predicting NSCLC overall survival time based on Radiomics analysis.","2":"BACKGROUND: To investigate the effect of machine learning methods on predicting the Overall Survival (OS) for non-small cell lung cancer based on radiomics features analysis.METHODS: A total of 339 radiomic features were extracted from the segmented tumor volumes of pretreatment computed tomography (CT) images. These radiomic features quantify the tumor phenotypic characteristics on the medical images using tumor shape and size, the intensity statistics and the textures. The performance of 5 feature selection methods and 8 machine learning methods were investigated for OS prediction. The predicted performance was evaluated with concordance index between predicted and true OS for the non-small cell lung cancer patients. The survival curves were evaluated by the Kaplan-Meier algorithm and compared by the log-rank tests.RESULTS: The gradient boosting linear models based on Cox's partial likelihood method using the concordance index feature selection method obtained the best performance (Concordance Index: 0.68, 95% Confidence Interval: 0.62~<U+2009>0.74).CONCLUSIONS: The preliminary results demonstrated that certain machine learning and radiomics analysis method could predict OS of non-small cell lung cancer accuracy.","3":"Radiation oncology (London, England)","4":"30290849","5":"2018","6":"methods"},{"1":"Effect of machine learning methods on predicting NSCLC overall survival time based on Radiomics analysis.","2":"BACKGROUND: To investigate the effect of machine learning methods on predicting the Overall Survival (OS) for non-small cell lung cancer based on radiomics features analysis.METHODS: A total of 339 radiomic features were extracted from the segmented tumor volumes of pretreatment computed tomography (CT) images. These radiomic features quantify the tumor phenotypic characteristics on the medical images using tumor shape and size, the intensity statistics and the textures. The performance of 5 feature selection methods and 8 machine learning methods were investigated for OS prediction. The predicted performance was evaluated with concordance index between predicted and true OS for the non-small cell lung cancer patients. The survival curves were evaluated by the Kaplan-Meier algorithm and compared by the log-rank tests.RESULTS: The gradient boosting linear models based on Cox's partial likelihood method using the concordance index feature selection method obtained the best performance (Concordance Index: 0.68, 95% Confidence Interval: 0.62~<U+2009>0.74).CONCLUSIONS: The preliminary results demonstrated that certain machine learning and radiomics analysis method could predict OS of non-small cell lung cancer accuracy.","3":"Radiation oncology (London, England)","4":"30290849","5":"2018","6":"Radiotherapy, Intensity-Modulated"},{"1":"Effect of machine learning methods on predicting NSCLC overall survival time based on Radiomics analysis.","2":"BACKGROUND: To investigate the effect of machine learning methods on predicting the Overall Survival (OS) for non-small cell lung cancer based on radiomics features analysis.METHODS: A total of 339 radiomic features were extracted from the segmented tumor volumes of pretreatment computed tomography (CT) images. These radiomic features quantify the tumor phenotypic characteristics on the medical images using tumor shape and size, the intensity statistics and the textures. The performance of 5 feature selection methods and 8 machine learning methods were investigated for OS prediction. The predicted performance was evaluated with concordance index between predicted and true OS for the non-small cell lung cancer patients. The survival curves were evaluated by the Kaplan-Meier algorithm and compared by the log-rank tests.RESULTS: The gradient boosting linear models based on Cox's partial likelihood method using the concordance index feature selection method obtained the best performance (Concordance Index: 0.68, 95% Confidence Interval: 0.62~<U+2009>0.74).CONCLUSIONS: The preliminary results demonstrated that certain machine learning and radiomics analysis method could predict OS of non-small cell lung cancer accuracy.","3":"Radiation oncology (London, England)","4":"30290849","5":"2018","6":"methods"},{"1":"Effect of machine learning methods on predicting NSCLC overall survival time based on Radiomics analysis.","2":"BACKGROUND: To investigate the effect of machine learning methods on predicting the Overall Survival (OS) for non-small cell lung cancer based on radiomics features analysis.METHODS: A total of 339 radiomic features were extracted from the segmented tumor volumes of pretreatment computed tomography (CT) images. These radiomic features quantify the tumor phenotypic characteristics on the medical images using tumor shape and size, the intensity statistics and the textures. The performance of 5 feature selection methods and 8 machine learning methods were investigated for OS prediction. The predicted performance was evaluated with concordance index between predicted and true OS for the non-small cell lung cancer patients. The survival curves were evaluated by the Kaplan-Meier algorithm and compared by the log-rank tests.RESULTS: The gradient boosting linear models based on Cox's partial likelihood method using the concordance index feature selection method obtained the best performance (Concordance Index: 0.68, 95% Confidence Interval: 0.62~<U+2009>0.74).CONCLUSIONS: The preliminary results demonstrated that certain machine learning and radiomics analysis method could predict OS of non-small cell lung cancer accuracy.","3":"Radiation oncology (London, England)","4":"30290849","5":"2018","6":"Survival Rate"},{"1":"Effect of machine learning methods on predicting NSCLC overall survival time based on Radiomics analysis.","2":"BACKGROUND: To investigate the effect of machine learning methods on predicting the Overall Survival (OS) for non-small cell lung cancer based on radiomics features analysis.METHODS: A total of 339 radiomic features were extracted from the segmented tumor volumes of pretreatment computed tomography (CT) images. These radiomic features quantify the tumor phenotypic characteristics on the medical images using tumor shape and size, the intensity statistics and the textures. The performance of 5 feature selection methods and 8 machine learning methods were investigated for OS prediction. The predicted performance was evaluated with concordance index between predicted and true OS for the non-small cell lung cancer patients. The survival curves were evaluated by the Kaplan-Meier algorithm and compared by the log-rank tests.RESULTS: The gradient boosting linear models based on Cox's partial likelihood method using the concordance index feature selection method obtained the best performance (Concordance Index: 0.68, 95% Confidence Interval: 0.62~<U+2009>0.74).CONCLUSIONS: The preliminary results demonstrated that certain machine learning and radiomics analysis method could predict OS of non-small cell lung cancer accuracy.","3":"Radiation oncology (London, England)","4":"30290849","5":"2018","6":"Tomography, X-Ray Computed"},{"1":"Effect of machine learning methods on predicting NSCLC overall survival time based on Radiomics analysis.","2":"BACKGROUND: To investigate the effect of machine learning methods on predicting the Overall Survival (OS) for non-small cell lung cancer based on radiomics features analysis.METHODS: A total of 339 radiomic features were extracted from the segmented tumor volumes of pretreatment computed tomography (CT) images. These radiomic features quantify the tumor phenotypic characteristics on the medical images using tumor shape and size, the intensity statistics and the textures. The performance of 5 feature selection methods and 8 machine learning methods were investigated for OS prediction. The predicted performance was evaluated with concordance index between predicted and true OS for the non-small cell lung cancer patients. The survival curves were evaluated by the Kaplan-Meier algorithm and compared by the log-rank tests.RESULTS: The gradient boosting linear models based on Cox's partial likelihood method using the concordance index feature selection method obtained the best performance (Concordance Index: 0.68, 95% Confidence Interval: 0.62~<U+2009>0.74).CONCLUSIONS: The preliminary results demonstrated that certain machine learning and radiomics analysis method could predict OS of non-small cell lung cancer accuracy.","3":"Radiation oncology (London, England)","4":"30290849","5":"2018","6":"methods"},{"1":"Effect of machine learning methods on predicting NSCLC overall survival time based on Radiomics analysis.","2":"BACKGROUND: To investigate the effect of machine learning methods on predicting the Overall Survival (OS) for non-small cell lung cancer based on radiomics features analysis.METHODS: A total of 339 radiomic features were extracted from the segmented tumor volumes of pretreatment computed tomography (CT) images. These radiomic features quantify the tumor phenotypic characteristics on the medical images using tumor shape and size, the intensity statistics and the textures. The performance of 5 feature selection methods and 8 machine learning methods were investigated for OS prediction. The predicted performance was evaluated with concordance index between predicted and true OS for the non-small cell lung cancer patients. The survival curves were evaluated by the Kaplan-Meier algorithm and compared by the log-rank tests.RESULTS: The gradient boosting linear models based on Cox's partial likelihood method using the concordance index feature selection method obtained the best performance (Concordance Index: 0.68, 95% Confidence Interval: 0.62~<U+2009>0.74).CONCLUSIONS: The preliminary results demonstrated that certain machine learning and radiomics analysis method could predict OS of non-small cell lung cancer accuracy.","3":"Radiation oncology (London, England)","4":"30290849","5":"2018","6":"Tumor Burden"},{"1":"Detecting drug-resistant tuberculosis in chest radiographs.","2":"PURPOSE: Tuberculosis is a major global health threat claiming millions of lives each year. While the total number of tuberculosis cases has been decreasing over the last years, the rise of drug-resistant tuberculosis has reduced the chance of controlling the disease. The purpose is to implement a timely diagnosis of drug-resistant tuberculosis, which is essential to administering adequate treatment regimens and stopping the further transmission of drug-resistant tuberculosis.METHODS: A main tool for diagnosing tuberculosis is the conventional chest X-ray. We are investigating the possibility of discriminating automatically between drug-resistant and drug-sensitive tuberculosis in chest X-rays by means of image analysis and machine learning methods.RESULTS: For discriminating between drug-sensitive and drug-resistant tuberculosis, we achieve an area under the receiver operating characteristic curve (AUC) of up to 66%, using an artificial neural network in combination with a set of shape and texture features. We did not observe any significant difference in the results when including follow-up X-rays for each patient.CONCLUSION: Our results suggest that a chest X-ray contains information about the likelihood of a drug-resistant tuberculosis infection, which can be exploited computationally. We therefore suggest to repeat the experiments of our pilot study on a larger set of chest X-rays.","3":"International journal of computer assisted radiology and surgery","4":"30284153","5":"2018","6":"Diagnosis, Differential"},{"1":"Detecting drug-resistant tuberculosis in chest radiographs.","2":"PURPOSE: Tuberculosis is a major global health threat claiming millions of lives each year. While the total number of tuberculosis cases has been decreasing over the last years, the rise of drug-resistant tuberculosis has reduced the chance of controlling the disease. The purpose is to implement a timely diagnosis of drug-resistant tuberculosis, which is essential to administering adequate treatment regimens and stopping the further transmission of drug-resistant tuberculosis.METHODS: A main tool for diagnosing tuberculosis is the conventional chest X-ray. We are investigating the possibility of discriminating automatically between drug-resistant and drug-sensitive tuberculosis in chest X-rays by means of image analysis and machine learning methods.RESULTS: For discriminating between drug-sensitive and drug-resistant tuberculosis, we achieve an area under the receiver operating characteristic curve (AUC) of up to 66%, using an artificial neural network in combination with a set of shape and texture features. We did not observe any significant difference in the results when including follow-up X-rays for each patient.CONCLUSION: Our results suggest that a chest X-ray contains information about the likelihood of a drug-resistant tuberculosis infection, which can be exploited computationally. We therefore suggest to repeat the experiments of our pilot study on a larger set of chest X-rays.","3":"International journal of computer assisted radiology and surgery","4":"30284153","5":"2018","6":"Female"},{"1":"Detecting drug-resistant tuberculosis in chest radiographs.","2":"PURPOSE: Tuberculosis is a major global health threat claiming millions of lives each year. While the total number of tuberculosis cases has been decreasing over the last years, the rise of drug-resistant tuberculosis has reduced the chance of controlling the disease. The purpose is to implement a timely diagnosis of drug-resistant tuberculosis, which is essential to administering adequate treatment regimens and stopping the further transmission of drug-resistant tuberculosis.METHODS: A main tool for diagnosing tuberculosis is the conventional chest X-ray. We are investigating the possibility of discriminating automatically between drug-resistant and drug-sensitive tuberculosis in chest X-rays by means of image analysis and machine learning methods.RESULTS: For discriminating between drug-sensitive and drug-resistant tuberculosis, we achieve an area under the receiver operating characteristic curve (AUC) of up to 66%, using an artificial neural network in combination with a set of shape and texture features. We did not observe any significant difference in the results when including follow-up X-rays for each patient.CONCLUSION: Our results suggest that a chest X-ray contains information about the likelihood of a drug-resistant tuberculosis infection, which can be exploited computationally. We therefore suggest to repeat the experiments of our pilot study on a larger set of chest X-rays.","3":"International journal of computer assisted radiology and surgery","4":"30284153","5":"2018","6":"Humans"},{"1":"Detecting drug-resistant tuberculosis in chest radiographs.","2":"PURPOSE: Tuberculosis is a major global health threat claiming millions of lives each year. While the total number of tuberculosis cases has been decreasing over the last years, the rise of drug-resistant tuberculosis has reduced the chance of controlling the disease. The purpose is to implement a timely diagnosis of drug-resistant tuberculosis, which is essential to administering adequate treatment regimens and stopping the further transmission of drug-resistant tuberculosis.METHODS: A main tool for diagnosing tuberculosis is the conventional chest X-ray. We are investigating the possibility of discriminating automatically between drug-resistant and drug-sensitive tuberculosis in chest X-rays by means of image analysis and machine learning methods.RESULTS: For discriminating between drug-sensitive and drug-resistant tuberculosis, we achieve an area under the receiver operating characteristic curve (AUC) of up to 66%, using an artificial neural network in combination with a set of shape and texture features. We did not observe any significant difference in the results when including follow-up X-rays for each patient.CONCLUSION: Our results suggest that a chest X-ray contains information about the likelihood of a drug-resistant tuberculosis infection, which can be exploited computationally. We therefore suggest to repeat the experiments of our pilot study on a larger set of chest X-rays.","3":"International journal of computer assisted radiology and surgery","4":"30284153","5":"2018","6":"Machine Learning"},{"1":"Detecting drug-resistant tuberculosis in chest radiographs.","2":"PURPOSE: Tuberculosis is a major global health threat claiming millions of lives each year. While the total number of tuberculosis cases has been decreasing over the last years, the rise of drug-resistant tuberculosis has reduced the chance of controlling the disease. The purpose is to implement a timely diagnosis of drug-resistant tuberculosis, which is essential to administering adequate treatment regimens and stopping the further transmission of drug-resistant tuberculosis.METHODS: A main tool for diagnosing tuberculosis is the conventional chest X-ray. We are investigating the possibility of discriminating automatically between drug-resistant and drug-sensitive tuberculosis in chest X-rays by means of image analysis and machine learning methods.RESULTS: For discriminating between drug-sensitive and drug-resistant tuberculosis, we achieve an area under the receiver operating characteristic curve (AUC) of up to 66%, using an artificial neural network in combination with a set of shape and texture features. We did not observe any significant difference in the results when including follow-up X-rays for each patient.CONCLUSION: Our results suggest that a chest X-ray contains information about the likelihood of a drug-resistant tuberculosis infection, which can be exploited computationally. We therefore suggest to repeat the experiments of our pilot study on a larger set of chest X-rays.","3":"International journal of computer assisted radiology and surgery","4":"30284153","5":"2018","6":"Male"},{"1":"Detecting drug-resistant tuberculosis in chest radiographs.","2":"PURPOSE: Tuberculosis is a major global health threat claiming millions of lives each year. While the total number of tuberculosis cases has been decreasing over the last years, the rise of drug-resistant tuberculosis has reduced the chance of controlling the disease. The purpose is to implement a timely diagnosis of drug-resistant tuberculosis, which is essential to administering adequate treatment regimens and stopping the further transmission of drug-resistant tuberculosis.METHODS: A main tool for diagnosing tuberculosis is the conventional chest X-ray. We are investigating the possibility of discriminating automatically between drug-resistant and drug-sensitive tuberculosis in chest X-rays by means of image analysis and machine learning methods.RESULTS: For discriminating between drug-sensitive and drug-resistant tuberculosis, we achieve an area under the receiver operating characteristic curve (AUC) of up to 66%, using an artificial neural network in combination with a set of shape and texture features. We did not observe any significant difference in the results when including follow-up X-rays for each patient.CONCLUSION: Our results suggest that a chest X-ray contains information about the likelihood of a drug-resistant tuberculosis infection, which can be exploited computationally. We therefore suggest to repeat the experiments of our pilot study on a larger set of chest X-rays.","3":"International journal of computer assisted radiology and surgery","4":"30284153","5":"2018","6":"Middle Aged"},{"1":"Detecting drug-resistant tuberculosis in chest radiographs.","2":"PURPOSE: Tuberculosis is a major global health threat claiming millions of lives each year. While the total number of tuberculosis cases has been decreasing over the last years, the rise of drug-resistant tuberculosis has reduced the chance of controlling the disease. The purpose is to implement a timely diagnosis of drug-resistant tuberculosis, which is essential to administering adequate treatment regimens and stopping the further transmission of drug-resistant tuberculosis.METHODS: A main tool for diagnosing tuberculosis is the conventional chest X-ray. We are investigating the possibility of discriminating automatically between drug-resistant and drug-sensitive tuberculosis in chest X-rays by means of image analysis and machine learning methods.RESULTS: For discriminating between drug-sensitive and drug-resistant tuberculosis, we achieve an area under the receiver operating characteristic curve (AUC) of up to 66%, using an artificial neural network in combination with a set of shape and texture features. We did not observe any significant difference in the results when including follow-up X-rays for each patient.CONCLUSION: Our results suggest that a chest X-ray contains information about the likelihood of a drug-resistant tuberculosis infection, which can be exploited computationally. We therefore suggest to repeat the experiments of our pilot study on a larger set of chest X-rays.","3":"International journal of computer assisted radiology and surgery","4":"30284153","5":"2018","6":"Neural Networks (Computer)"},{"1":"Detecting drug-resistant tuberculosis in chest radiographs.","2":"PURPOSE: Tuberculosis is a major global health threat claiming millions of lives each year. While the total number of tuberculosis cases has been decreasing over the last years, the rise of drug-resistant tuberculosis has reduced the chance of controlling the disease. The purpose is to implement a timely diagnosis of drug-resistant tuberculosis, which is essential to administering adequate treatment regimens and stopping the further transmission of drug-resistant tuberculosis.METHODS: A main tool for diagnosing tuberculosis is the conventional chest X-ray. We are investigating the possibility of discriminating automatically between drug-resistant and drug-sensitive tuberculosis in chest X-rays by means of image analysis and machine learning methods.RESULTS: For discriminating between drug-sensitive and drug-resistant tuberculosis, we achieve an area under the receiver operating characteristic curve (AUC) of up to 66%, using an artificial neural network in combination with a set of shape and texture features. We did not observe any significant difference in the results when including follow-up X-rays for each patient.CONCLUSION: Our results suggest that a chest X-ray contains information about the likelihood of a drug-resistant tuberculosis infection, which can be exploited computationally. We therefore suggest to repeat the experiments of our pilot study on a larger set of chest X-rays.","3":"International journal of computer assisted radiology and surgery","4":"30284153","5":"2018","6":"Pilot Projects"},{"1":"Detecting drug-resistant tuberculosis in chest radiographs.","2":"PURPOSE: Tuberculosis is a major global health threat claiming millions of lives each year. While the total number of tuberculosis cases has been decreasing over the last years, the rise of drug-resistant tuberculosis has reduced the chance of controlling the disease. The purpose is to implement a timely diagnosis of drug-resistant tuberculosis, which is essential to administering adequate treatment regimens and stopping the further transmission of drug-resistant tuberculosis.METHODS: A main tool for diagnosing tuberculosis is the conventional chest X-ray. We are investigating the possibility of discriminating automatically between drug-resistant and drug-sensitive tuberculosis in chest X-rays by means of image analysis and machine learning methods.RESULTS: For discriminating between drug-sensitive and drug-resistant tuberculosis, we achieve an area under the receiver operating characteristic curve (AUC) of up to 66%, using an artificial neural network in combination with a set of shape and texture features. We did not observe any significant difference in the results when including follow-up X-rays for each patient.CONCLUSION: Our results suggest that a chest X-ray contains information about the likelihood of a drug-resistant tuberculosis infection, which can be exploited computationally. We therefore suggest to repeat the experiments of our pilot study on a larger set of chest X-rays.","3":"International journal of computer assisted radiology and surgery","4":"30284153","5":"2018","6":"Probability"},{"1":"Detecting drug-resistant tuberculosis in chest radiographs.","2":"PURPOSE: Tuberculosis is a major global health threat claiming millions of lives each year. While the total number of tuberculosis cases has been decreasing over the last years, the rise of drug-resistant tuberculosis has reduced the chance of controlling the disease. The purpose is to implement a timely diagnosis of drug-resistant tuberculosis, which is essential to administering adequate treatment regimens and stopping the further transmission of drug-resistant tuberculosis.METHODS: A main tool for diagnosing tuberculosis is the conventional chest X-ray. We are investigating the possibility of discriminating automatically between drug-resistant and drug-sensitive tuberculosis in chest X-rays by means of image analysis and machine learning methods.RESULTS: For discriminating between drug-sensitive and drug-resistant tuberculosis, we achieve an area under the receiver operating characteristic curve (AUC) of up to 66%, using an artificial neural network in combination with a set of shape and texture features. We did not observe any significant difference in the results when including follow-up X-rays for each patient.CONCLUSION: Our results suggest that a chest X-ray contains information about the likelihood of a drug-resistant tuberculosis infection, which can be exploited computationally. We therefore suggest to repeat the experiments of our pilot study on a larger set of chest X-rays.","3":"International journal of computer assisted radiology and surgery","4":"30284153","5":"2018","6":"ROC Curve"},{"1":"Detecting drug-resistant tuberculosis in chest radiographs.","2":"PURPOSE: Tuberculosis is a major global health threat claiming millions of lives each year. While the total number of tuberculosis cases has been decreasing over the last years, the rise of drug-resistant tuberculosis has reduced the chance of controlling the disease. The purpose is to implement a timely diagnosis of drug-resistant tuberculosis, which is essential to administering adequate treatment regimens and stopping the further transmission of drug-resistant tuberculosis.METHODS: A main tool for diagnosing tuberculosis is the conventional chest X-ray. We are investigating the possibility of discriminating automatically between drug-resistant and drug-sensitive tuberculosis in chest X-rays by means of image analysis and machine learning methods.RESULTS: For discriminating between drug-sensitive and drug-resistant tuberculosis, we achieve an area under the receiver operating characteristic curve (AUC) of up to 66%, using an artificial neural network in combination with a set of shape and texture features. We did not observe any significant difference in the results when including follow-up X-rays for each patient.CONCLUSION: Our results suggest that a chest X-ray contains information about the likelihood of a drug-resistant tuberculosis infection, which can be exploited computationally. We therefore suggest to repeat the experiments of our pilot study on a larger set of chest X-rays.","3":"International journal of computer assisted radiology and surgery","4":"30284153","5":"2018","6":"Radiography, Thoracic"},{"1":"Detecting drug-resistant tuberculosis in chest radiographs.","2":"PURPOSE: Tuberculosis is a major global health threat claiming millions of lives each year. While the total number of tuberculosis cases has been decreasing over the last years, the rise of drug-resistant tuberculosis has reduced the chance of controlling the disease. The purpose is to implement a timely diagnosis of drug-resistant tuberculosis, which is essential to administering adequate treatment regimens and stopping the further transmission of drug-resistant tuberculosis.METHODS: A main tool for diagnosing tuberculosis is the conventional chest X-ray. We are investigating the possibility of discriminating automatically between drug-resistant and drug-sensitive tuberculosis in chest X-rays by means of image analysis and machine learning methods.RESULTS: For discriminating between drug-sensitive and drug-resistant tuberculosis, we achieve an area under the receiver operating characteristic curve (AUC) of up to 66%, using an artificial neural network in combination with a set of shape and texture features. We did not observe any significant difference in the results when including follow-up X-rays for each patient.CONCLUSION: Our results suggest that a chest X-ray contains information about the likelihood of a drug-resistant tuberculosis infection, which can be exploited computationally. We therefore suggest to repeat the experiments of our pilot study on a larger set of chest X-rays.","3":"International journal of computer assisted radiology and surgery","4":"30284153","5":"2018","6":"methods"},{"1":"Detecting drug-resistant tuberculosis in chest radiographs.","2":"PURPOSE: Tuberculosis is a major global health threat claiming millions of lives each year. While the total number of tuberculosis cases has been decreasing over the last years, the rise of drug-resistant tuberculosis has reduced the chance of controlling the disease. The purpose is to implement a timely diagnosis of drug-resistant tuberculosis, which is essential to administering adequate treatment regimens and stopping the further transmission of drug-resistant tuberculosis.METHODS: A main tool for diagnosing tuberculosis is the conventional chest X-ray. We are investigating the possibility of discriminating automatically between drug-resistant and drug-sensitive tuberculosis in chest X-rays by means of image analysis and machine learning methods.RESULTS: For discriminating between drug-sensitive and drug-resistant tuberculosis, we achieve an area under the receiver operating characteristic curve (AUC) of up to 66%, using an artificial neural network in combination with a set of shape and texture features. We did not observe any significant difference in the results when including follow-up X-rays for each patient.CONCLUSION: Our results suggest that a chest X-ray contains information about the likelihood of a drug-resistant tuberculosis infection, which can be exploited computationally. We therefore suggest to repeat the experiments of our pilot study on a larger set of chest X-rays.","3":"International journal of computer assisted radiology and surgery","4":"30284153","5":"2018","6":"Tomography, X-Ray Computed"},{"1":"Detecting drug-resistant tuberculosis in chest radiographs.","2":"PURPOSE: Tuberculosis is a major global health threat claiming millions of lives each year. While the total number of tuberculosis cases has been decreasing over the last years, the rise of drug-resistant tuberculosis has reduced the chance of controlling the disease. The purpose is to implement a timely diagnosis of drug-resistant tuberculosis, which is essential to administering adequate treatment regimens and stopping the further transmission of drug-resistant tuberculosis.METHODS: A main tool for diagnosing tuberculosis is the conventional chest X-ray. We are investigating the possibility of discriminating automatically between drug-resistant and drug-sensitive tuberculosis in chest X-rays by means of image analysis and machine learning methods.RESULTS: For discriminating between drug-sensitive and drug-resistant tuberculosis, we achieve an area under the receiver operating characteristic curve (AUC) of up to 66%, using an artificial neural network in combination with a set of shape and texture features. We did not observe any significant difference in the results when including follow-up X-rays for each patient.CONCLUSION: Our results suggest that a chest X-ray contains information about the likelihood of a drug-resistant tuberculosis infection, which can be exploited computationally. We therefore suggest to repeat the experiments of our pilot study on a larger set of chest X-rays.","3":"International journal of computer assisted radiology and surgery","4":"30284153","5":"2018","6":"methods"},{"1":"Detecting drug-resistant tuberculosis in chest radiographs.","2":"PURPOSE: Tuberculosis is a major global health threat claiming millions of lives each year. While the total number of tuberculosis cases has been decreasing over the last years, the rise of drug-resistant tuberculosis has reduced the chance of controlling the disease. The purpose is to implement a timely diagnosis of drug-resistant tuberculosis, which is essential to administering adequate treatment regimens and stopping the further transmission of drug-resistant tuberculosis.METHODS: A main tool for diagnosing tuberculosis is the conventional chest X-ray. We are investigating the possibility of discriminating automatically between drug-resistant and drug-sensitive tuberculosis in chest X-rays by means of image analysis and machine learning methods.RESULTS: For discriminating between drug-sensitive and drug-resistant tuberculosis, we achieve an area under the receiver operating characteristic curve (AUC) of up to 66%, using an artificial neural network in combination with a set of shape and texture features. We did not observe any significant difference in the results when including follow-up X-rays for each patient.CONCLUSION: Our results suggest that a chest X-ray contains information about the likelihood of a drug-resistant tuberculosis infection, which can be exploited computationally. We therefore suggest to repeat the experiments of our pilot study on a larger set of chest X-rays.","3":"International journal of computer assisted radiology and surgery","4":"30284153","5":"2018","6":"Tuberculosis, Multidrug-Resistant"},{"1":"SAR and QSAR models of cyclooxygenase-1 (COX-1) inhibitors.","2":"","3":"SAR and QSAR in environmental research","4":"30274533","5":"2018","6":"Cyclooxygenase 1"},{"1":"SAR and QSAR models of cyclooxygenase-1 (COX-1) inhibitors.","2":"","3":"SAR and QSAR in environmental research","4":"30274533","5":"2018","6":"metabolism"},{"1":"SAR and QSAR models of cyclooxygenase-1 (COX-1) inhibitors.","2":"","3":"SAR and QSAR in environmental research","4":"30274533","5":"2018","6":"Cyclooxygenase Inhibitors"},{"1":"SAR and QSAR models of cyclooxygenase-1 (COX-1) inhibitors.","2":"","3":"SAR and QSAR in environmental research","4":"30274533","5":"2018","6":"chemistry"},{"1":"SAR and QSAR models of cyclooxygenase-1 (COX-1) inhibitors.","2":"","3":"SAR and QSAR in environmental research","4":"30274533","5":"2018","6":"Linear Models"},{"1":"SAR and QSAR models of cyclooxygenase-1 (COX-1) inhibitors.","2":"","3":"SAR and QSAR in environmental research","4":"30274533","5":"2018","6":"Models, Molecular"},{"1":"SAR and QSAR models of cyclooxygenase-1 (COX-1) inhibitors.","2":"","3":"SAR and QSAR in environmental research","4":"30274533","5":"2018","6":"Quantitative Structure-Activity Relationship"},{"1":"SAR and QSAR models of cyclooxygenase-1 (COX-1) inhibitors.","2":"","3":"SAR and QSAR in environmental research","4":"30274533","5":"2018","6":"Structure-Activity Relationship"},{"1":"SAR and QSAR models of cyclooxygenase-1 (COX-1) inhibitors.","2":"","3":"SAR and QSAR in environmental research","4":"30274533","5":"2018","6":"Support Vector Machine"},{"1":"Contribution assessment of multiparameter optimization descriptors in CNS penetration.","2":"","3":"SAR and QSAR in environmental research","4":"30274532","5":"2018","6":"Blood-Brain Barrier"},{"1":"Contribution assessment of multiparameter optimization descriptors in CNS penetration.","2":"","3":"SAR and QSAR in environmental research","4":"30274532","5":"2018","6":"physiology"},{"1":"Contribution assessment of multiparameter optimization descriptors in CNS penetration.","2":"","3":"SAR and QSAR in environmental research","4":"30274532","5":"2018","6":"Drug Design"},{"1":"Contribution assessment of multiparameter optimization descriptors in CNS penetration.","2":"","3":"SAR and QSAR in environmental research","4":"30274532","5":"2018","6":"Linear Models"},{"1":"Contribution assessment of multiparameter optimization descriptors in CNS penetration.","2":"","3":"SAR and QSAR in environmental research","4":"30274532","5":"2018","6":"Models, Molecular"},{"1":"Contribution assessment of multiparameter optimization descriptors in CNS penetration.","2":"","3":"SAR and QSAR in environmental research","4":"30274532","5":"2018","6":"Molecular Weight"},{"1":"Contribution assessment of multiparameter optimization descriptors in CNS penetration.","2":"","3":"SAR and QSAR in environmental research","4":"30274532","5":"2018","6":"Normal Distribution"},{"1":"Contribution assessment of multiparameter optimization descriptors in CNS penetration.","2":"","3":"SAR and QSAR in environmental research","4":"30274532","5":"2018","6":"Quantitative Structure-Activity Relationship"},{"1":"Contribution assessment of multiparameter optimization descriptors in CNS penetration.","2":"","3":"SAR and QSAR in environmental research","4":"30274532","5":"2018","6":"Support Vector Machine"},{"1":"Machine Learning in Health Care.","2":"","3":"National Bureau of Economic Research bulletin on aging and health","4":"30272872","5":"2018","6":"Algorithms"},{"1":"Machine Learning in Health Care.","2":"","3":"National Bureau of Economic Research bulletin on aging and health","4":"30272872","5":"2018","6":"Cost-Benefit Analysis"},{"1":"Machine Learning in Health Care.","2":"","3":"National Bureau of Economic Research bulletin on aging and health","4":"30272872","5":"2018","6":"Decision Making, Computer-Assisted"},{"1":"Machine Learning in Health Care.","2":"","3":"National Bureau of Economic Research bulletin on aging and health","4":"30272872","5":"2018","6":"Decision Support Techniques"},{"1":"Machine Learning in Health Care.","2":"","3":"National Bureau of Economic Research bulletin on aging and health","4":"30272872","5":"2018","6":"Delivery of Health Care"},{"1":"Machine Learning in Health Care.","2":"","3":"National Bureau of Economic Research bulletin on aging and health","4":"30272872","5":"2018","6":"Humans"},{"1":"Machine Learning in Health Care.","2":"","3":"National Bureau of Economic Research bulletin on aging and health","4":"30272872","5":"2018","6":"Machine Learning"},{"1":"Machine Learning in Health Care.","2":"","3":"National Bureau of Economic Research bulletin on aging and health","4":"30272872","5":"2018","6":"economics"},{"1":"Machine Learning in Health Care.","2":"","3":"National Bureau of Economic Research bulletin on aging and health","4":"30272872","5":"2018","6":"Myocardial Infarction"},{"1":"Machine Learning in Health Care.","2":"","3":"National Bureau of Economic Research bulletin on aging and health","4":"30272872","5":"2018","6":"diagnosis"},{"1":"Machine Learning in Health Care.","2":"","3":"National Bureau of Economic Research bulletin on aging and health","4":"30272872","5":"2018","6":"Risk Factors"},{"1":"Machine Learning in Health Care.","2":"","3":"National Bureau of Economic Research bulletin on aging and health","4":"30272872","5":"2018","6":"Unnecessary Procedures"},{"1":"Optical classification of neoplastic colorectal polyps - a computer-assisted approach (the COACH study).","2":"BACKGROUND AND AIMS: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.METHODS: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n<U+2009>=<U+2009>275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.RESULTS: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4<U+2009>mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p<U+2009>=<U+2009>.307 and p<U+2009>=<U+2009>1.000, respectively).CONCLUSIONS: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.","3":"Scandinavian journal of gastroenterology","4":"30270677","5":"2018","6":"Aged"},{"1":"Optical classification of neoplastic colorectal polyps - a computer-assisted approach (the COACH study).","2":"BACKGROUND AND AIMS: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.METHODS: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n<U+2009>=<U+2009>275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.RESULTS: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4<U+2009>mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p<U+2009>=<U+2009>.307 and p<U+2009>=<U+2009>1.000, respectively).CONCLUSIONS: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.","3":"Scandinavian journal of gastroenterology","4":"30270677","5":"2018","6":"Biopsy"},{"1":"Optical classification of neoplastic colorectal polyps - a computer-assisted approach (the COACH study).","2":"BACKGROUND AND AIMS: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.METHODS: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n<U+2009>=<U+2009>275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.RESULTS: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4<U+2009>mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p<U+2009>=<U+2009>.307 and p<U+2009>=<U+2009>1.000, respectively).CONCLUSIONS: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.","3":"Scandinavian journal of gastroenterology","4":"30270677","5":"2018","6":"methods"},{"1":"Optical classification of neoplastic colorectal polyps - a computer-assisted approach (the COACH study).","2":"BACKGROUND AND AIMS: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.METHODS: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n<U+2009>=<U+2009>275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.RESULTS: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4<U+2009>mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p<U+2009>=<U+2009>.307 and p<U+2009>=<U+2009>1.000, respectively).CONCLUSIONS: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.","3":"Scandinavian journal of gastroenterology","4":"30270677","5":"2018","6":"Colonic Polyps"},{"1":"Optical classification of neoplastic colorectal polyps - a computer-assisted approach (the COACH study).","2":"BACKGROUND AND AIMS: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.METHODS: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n<U+2009>=<U+2009>275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.RESULTS: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4<U+2009>mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p<U+2009>=<U+2009>.307 and p<U+2009>=<U+2009>1.000, respectively).CONCLUSIONS: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.","3":"Scandinavian journal of gastroenterology","4":"30270677","5":"2018","6":"classification"},{"1":"Optical classification of neoplastic colorectal polyps - a computer-assisted approach (the COACH study).","2":"BACKGROUND AND AIMS: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.METHODS: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n<U+2009>=<U+2009>275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.RESULTS: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4<U+2009>mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p<U+2009>=<U+2009>.307 and p<U+2009>=<U+2009>1.000, respectively).CONCLUSIONS: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.","3":"Scandinavian journal of gastroenterology","4":"30270677","5":"2018","6":"diagnosis"},{"1":"Optical classification of neoplastic colorectal polyps - a computer-assisted approach (the COACH study).","2":"BACKGROUND AND AIMS: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.METHODS: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n<U+2009>=<U+2009>275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.RESULTS: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4<U+2009>mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p<U+2009>=<U+2009>.307 and p<U+2009>=<U+2009>1.000, respectively).CONCLUSIONS: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.","3":"Scandinavian journal of gastroenterology","4":"30270677","5":"2018","6":"Colonoscopy"},{"1":"Optical classification of neoplastic colorectal polyps - a computer-assisted approach (the COACH study).","2":"BACKGROUND AND AIMS: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.METHODS: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n<U+2009>=<U+2009>275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.RESULTS: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4<U+2009>mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p<U+2009>=<U+2009>.307 and p<U+2009>=<U+2009>1.000, respectively).CONCLUSIONS: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.","3":"Scandinavian journal of gastroenterology","4":"30270677","5":"2018","6":"instrumentation"},{"1":"Optical classification of neoplastic colorectal polyps - a computer-assisted approach (the COACH study).","2":"BACKGROUND AND AIMS: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.METHODS: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n<U+2009>=<U+2009>275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.RESULTS: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4<U+2009>mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p<U+2009>=<U+2009>.307 and p<U+2009>=<U+2009>1.000, respectively).CONCLUSIONS: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.","3":"Scandinavian journal of gastroenterology","4":"30270677","5":"2018","6":"methods"},{"1":"Optical classification of neoplastic colorectal polyps - a computer-assisted approach (the COACH study).","2":"BACKGROUND AND AIMS: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.METHODS: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n<U+2009>=<U+2009>275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.RESULTS: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4<U+2009>mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p<U+2009>=<U+2009>.307 and p<U+2009>=<U+2009>1.000, respectively).CONCLUSIONS: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.","3":"Scandinavian journal of gastroenterology","4":"30270677","5":"2018","6":"Colorectal Neoplasms"},{"1":"Optical classification of neoplastic colorectal polyps - a computer-assisted approach (the COACH study).","2":"BACKGROUND AND AIMS: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.METHODS: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n<U+2009>=<U+2009>275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.RESULTS: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4<U+2009>mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p<U+2009>=<U+2009>.307 and p<U+2009>=<U+2009>1.000, respectively).CONCLUSIONS: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.","3":"Scandinavian journal of gastroenterology","4":"30270677","5":"2018","6":"pathology"},{"1":"Optical classification of neoplastic colorectal polyps - a computer-assisted approach (the COACH study).","2":"BACKGROUND AND AIMS: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.METHODS: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n<U+2009>=<U+2009>275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.RESULTS: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4<U+2009>mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p<U+2009>=<U+2009>.307 and p<U+2009>=<U+2009>1.000, respectively).CONCLUSIONS: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.","3":"Scandinavian journal of gastroenterology","4":"30270677","5":"2018","6":"Female"},{"1":"Optical classification of neoplastic colorectal polyps - a computer-assisted approach (the COACH study).","2":"BACKGROUND AND AIMS: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.METHODS: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n<U+2009>=<U+2009>275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.RESULTS: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4<U+2009>mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p<U+2009>=<U+2009>.307 and p<U+2009>=<U+2009>1.000, respectively).CONCLUSIONS: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.","3":"Scandinavian journal of gastroenterology","4":"30270677","5":"2018","6":"Germany"},{"1":"Optical classification of neoplastic colorectal polyps - a computer-assisted approach (the COACH study).","2":"BACKGROUND AND AIMS: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.METHODS: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n<U+2009>=<U+2009>275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.RESULTS: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4<U+2009>mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p<U+2009>=<U+2009>.307 and p<U+2009>=<U+2009>1.000, respectively).CONCLUSIONS: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.","3":"Scandinavian journal of gastroenterology","4":"30270677","5":"2018","6":"Hospitals, University"},{"1":"Optical classification of neoplastic colorectal polyps - a computer-assisted approach (the COACH study).","2":"BACKGROUND AND AIMS: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.METHODS: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n<U+2009>=<U+2009>275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.RESULTS: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4<U+2009>mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p<U+2009>=<U+2009>.307 and p<U+2009>=<U+2009>1.000, respectively).CONCLUSIONS: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.","3":"Scandinavian journal of gastroenterology","4":"30270677","5":"2018","6":"Humans"},{"1":"Optical classification of neoplastic colorectal polyps - a computer-assisted approach (the COACH study).","2":"BACKGROUND AND AIMS: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.METHODS: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n<U+2009>=<U+2009>275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.RESULTS: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4<U+2009>mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p<U+2009>=<U+2009>.307 and p<U+2009>=<U+2009>1.000, respectively).CONCLUSIONS: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.","3":"Scandinavian journal of gastroenterology","4":"30270677","5":"2018","6":"Image Processing, Computer-Assisted"},{"1":"Optical classification of neoplastic colorectal polyps - a computer-assisted approach (the COACH study).","2":"BACKGROUND AND AIMS: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.METHODS: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n<U+2009>=<U+2009>275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.RESULTS: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4<U+2009>mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p<U+2009>=<U+2009>.307 and p<U+2009>=<U+2009>1.000, respectively).CONCLUSIONS: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.","3":"Scandinavian journal of gastroenterology","4":"30270677","5":"2018","6":"Machine Learning"},{"1":"Optical classification of neoplastic colorectal polyps - a computer-assisted approach (the COACH study).","2":"BACKGROUND AND AIMS: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.METHODS: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n<U+2009>=<U+2009>275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.RESULTS: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4<U+2009>mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p<U+2009>=<U+2009>.307 and p<U+2009>=<U+2009>1.000, respectively).CONCLUSIONS: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.","3":"Scandinavian journal of gastroenterology","4":"30270677","5":"2018","6":"Male"},{"1":"Optical classification of neoplastic colorectal polyps - a computer-assisted approach (the COACH study).","2":"BACKGROUND AND AIMS: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.METHODS: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n<U+2009>=<U+2009>275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.RESULTS: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4<U+2009>mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p<U+2009>=<U+2009>.307 and p<U+2009>=<U+2009>1.000, respectively).CONCLUSIONS: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.","3":"Scandinavian journal of gastroenterology","4":"30270677","5":"2018","6":"Middle Aged"},{"1":"Optical classification of neoplastic colorectal polyps - a computer-assisted approach (the COACH study).","2":"BACKGROUND AND AIMS: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.METHODS: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n<U+2009>=<U+2009>275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.RESULTS: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4<U+2009>mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p<U+2009>=<U+2009>.307 and p<U+2009>=<U+2009>1.000, respectively).CONCLUSIONS: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.","3":"Scandinavian journal of gastroenterology","4":"30270677","5":"2018","6":"Narrow Band Imaging"},{"1":"Optical classification of neoplastic colorectal polyps - a computer-assisted approach (the COACH study).","2":"BACKGROUND AND AIMS: Clinical data suggest that the quality of optical diagnoses of colorectal polyps differs markedly among endoscopists. The aim of this study was to develop a computer program that was able to differentiate neoplastic from non-neoplastic polyps using unmagnified endoscopic pictures.METHODS: During colonoscopy procedures polyp photographies were performed using the unmagnified high-definition white light and narrow band image mode. All detected polyps (n<U+2009>=<U+2009>275) were resected and sent to pathology. Histopathological diagnoses served as the ground truth. Machine learning was used in order to generate a computer-assisted optical biopsy (CAOB) approach. In the test phase pictures were presented to CAOB in order to obtain optical diagnoses. Altogether 788 pictures were available (602 for training the machine learning algorithm and 186 for CAOB testing). All test pictures were also presented to two experts in optical polyp characterization. The primary endpoint of the study was the accuracy of CAOB diagnoses in the test phase.RESULTS: A total of 100 polyps (of these 52% neoplastic) were used in the CAOB test phase. The mean size of test polyps was 4<U+2009>mm. Accuracy of the CAOB approach was 78.0%. Sensitivity and negative predictive value were 92.3% and 88.2%, respectively. Accuracy obtained by two expert endoscopists was 84.0% and 77.0%. Regarding accuracy of optical diagnoses CAOB predictions did not differ significantly compared to experts (p<U+2009>=<U+2009>.307 and p<U+2009>=<U+2009>1.000, respectively).CONCLUSIONS: CAOB showed good accuracy on the basis of unmagnified endoscopic pictures. Performance of CAOB predictions did not differ significantly from experts' decisions. The concept of computer assistance for colorectal polyp characterization needs to evolve towards a real-time application prior of being used in a broader set-up.","3":"Scandinavian journal of gastroenterology","4":"30270677","5":"2018","6":"Predictive Value of Tests"},{"1":"DeepNitro: Prediction of Protein Nitration and Nitrosylation Sites by Deep Learning.","2":"Protein nitration and nitrosylation are essential post-translational modifications (PTMs) involved in many fundamental cellular processes. Recent studies have revealed that excessive levels of nitration and nitrosylation in some critical proteins are linked to numerous chronic diseases. Therefore, the identification of substrates that undergo such modifications in a site-specific manner is an important research topic in the community and will provide candidates for targeted therapy. In this study, we aimed to develop a computational tool for predicting nitration and nitrosylation sites in proteins. We first constructed four types of encoding features, including positional amino acid distributions, sequence contextual dependencies, physicochemical properties, and position-specific scoring features, to represent the modified residues. Based on these encoding features, we established a predictor called DeepNitro using deep learning methods for predicting protein nitration and nitrosylation. Using n-fold cross-validation, our evaluation shows great AUC values for DeepNitro, 0.65 for tyrosine nitration, 0.80 for tryptophan nitration, and 0.70 for cysteine nitrosylation, respectively, demonstrating the robustness and reliability of our tool. Also, when tested in the independent dataset, DeepNitro is substantially superior to other similar tools with a 7%-42% improvement in the prediction performance. Taken together, the application of deep learning method and novel encoding schemes, especially the position-specific scoring feature, greatly improves the accuracy of nitration and nitrosylation site prediction and may facilitate the prediction of other PTM sites. DeepNitro is implemented in JAVA and PHP and is freely available for academic research at http://deepnitro.renlab.org.","3":"Genomics, proteomics &amp; bioinformatics","4":"30268931","5":"2018","6":"Amino Acid Sequence"},{"1":"DeepNitro: Prediction of Protein Nitration and Nitrosylation Sites by Deep Learning.","2":"Protein nitration and nitrosylation are essential post-translational modifications (PTMs) involved in many fundamental cellular processes. Recent studies have revealed that excessive levels of nitration and nitrosylation in some critical proteins are linked to numerous chronic diseases. Therefore, the identification of substrates that undergo such modifications in a site-specific manner is an important research topic in the community and will provide candidates for targeted therapy. In this study, we aimed to develop a computational tool for predicting nitration and nitrosylation sites in proteins. We first constructed four types of encoding features, including positional amino acid distributions, sequence contextual dependencies, physicochemical properties, and position-specific scoring features, to represent the modified residues. Based on these encoding features, we established a predictor called DeepNitro using deep learning methods for predicting protein nitration and nitrosylation. Using n-fold cross-validation, our evaluation shows great AUC values for DeepNitro, 0.65 for tyrosine nitration, 0.80 for tryptophan nitration, and 0.70 for cysteine nitrosylation, respectively, demonstrating the robustness and reliability of our tool. Also, when tested in the independent dataset, DeepNitro is substantially superior to other similar tools with a 7%-42% improvement in the prediction performance. Taken together, the application of deep learning method and novel encoding schemes, especially the position-specific scoring feature, greatly improves the accuracy of nitration and nitrosylation site prediction and may facilitate the prediction of other PTM sites. DeepNitro is implemented in JAVA and PHP and is freely available for academic research at http://deepnitro.renlab.org.","3":"Genomics, proteomics &amp; bioinformatics","4":"30268931","5":"2018","6":"Amino Acids"},{"1":"DeepNitro: Prediction of Protein Nitration and Nitrosylation Sites by Deep Learning.","2":"Protein nitration and nitrosylation are essential post-translational modifications (PTMs) involved in many fundamental cellular processes. Recent studies have revealed that excessive levels of nitration and nitrosylation in some critical proteins are linked to numerous chronic diseases. Therefore, the identification of substrates that undergo such modifications in a site-specific manner is an important research topic in the community and will provide candidates for targeted therapy. In this study, we aimed to develop a computational tool for predicting nitration and nitrosylation sites in proteins. We first constructed four types of encoding features, including positional amino acid distributions, sequence contextual dependencies, physicochemical properties, and position-specific scoring features, to represent the modified residues. Based on these encoding features, we established a predictor called DeepNitro using deep learning methods for predicting protein nitration and nitrosylation. Using n-fold cross-validation, our evaluation shows great AUC values for DeepNitro, 0.65 for tyrosine nitration, 0.80 for tryptophan nitration, and 0.70 for cysteine nitrosylation, respectively, demonstrating the robustness and reliability of our tool. Also, when tested in the independent dataset, DeepNitro is substantially superior to other similar tools with a 7%-42% improvement in the prediction performance. Taken together, the application of deep learning method and novel encoding schemes, especially the position-specific scoring feature, greatly improves the accuracy of nitration and nitrosylation site prediction and may facilitate the prediction of other PTM sites. DeepNitro is implemented in JAVA and PHP and is freely available for academic research at http://deepnitro.renlab.org.","3":"Genomics, proteomics &amp; bioinformatics","4":"30268931","5":"2018","6":"metabolism"},{"1":"DeepNitro: Prediction of Protein Nitration and Nitrosylation Sites by Deep Learning.","2":"Protein nitration and nitrosylation are essential post-translational modifications (PTMs) involved in many fundamental cellular processes. Recent studies have revealed that excessive levels of nitration and nitrosylation in some critical proteins are linked to numerous chronic diseases. Therefore, the identification of substrates that undergo such modifications in a site-specific manner is an important research topic in the community and will provide candidates for targeted therapy. In this study, we aimed to develop a computational tool for predicting nitration and nitrosylation sites in proteins. We first constructed four types of encoding features, including positional amino acid distributions, sequence contextual dependencies, physicochemical properties, and position-specific scoring features, to represent the modified residues. Based on these encoding features, we established a predictor called DeepNitro using deep learning methods for predicting protein nitration and nitrosylation. Using n-fold cross-validation, our evaluation shows great AUC values for DeepNitro, 0.65 for tyrosine nitration, 0.80 for tryptophan nitration, and 0.70 for cysteine nitrosylation, respectively, demonstrating the robustness and reliability of our tool. Also, when tested in the independent dataset, DeepNitro is substantially superior to other similar tools with a 7%-42% improvement in the prediction performance. Taken together, the application of deep learning method and novel encoding schemes, especially the position-specific scoring feature, greatly improves the accuracy of nitration and nitrosylation site prediction and may facilitate the prediction of other PTM sites. DeepNitro is implemented in JAVA and PHP and is freely available for academic research at http://deepnitro.renlab.org.","3":"Genomics, proteomics &amp; bioinformatics","4":"30268931","5":"2018","6":"Deep Learning"},{"1":"DeepNitro: Prediction of Protein Nitration and Nitrosylation Sites by Deep Learning.","2":"Protein nitration and nitrosylation are essential post-translational modifications (PTMs) involved in many fundamental cellular processes. Recent studies have revealed that excessive levels of nitration and nitrosylation in some critical proteins are linked to numerous chronic diseases. Therefore, the identification of substrates that undergo such modifications in a site-specific manner is an important research topic in the community and will provide candidates for targeted therapy. In this study, we aimed to develop a computational tool for predicting nitration and nitrosylation sites in proteins. We first constructed four types of encoding features, including positional amino acid distributions, sequence contextual dependencies, physicochemical properties, and position-specific scoring features, to represent the modified residues. Based on these encoding features, we established a predictor called DeepNitro using deep learning methods for predicting protein nitration and nitrosylation. Using n-fold cross-validation, our evaluation shows great AUC values for DeepNitro, 0.65 for tyrosine nitration, 0.80 for tryptophan nitration, and 0.70 for cysteine nitrosylation, respectively, demonstrating the robustness and reliability of our tool. Also, when tested in the independent dataset, DeepNitro is substantially superior to other similar tools with a 7%-42% improvement in the prediction performance. Taken together, the application of deep learning method and novel encoding schemes, especially the position-specific scoring feature, greatly improves the accuracy of nitration and nitrosylation site prediction and may facilitate the prediction of other PTM sites. DeepNitro is implemented in JAVA and PHP and is freely available for academic research at http://deepnitro.renlab.org.","3":"Genomics, proteomics &amp; bioinformatics","4":"30268931","5":"2018","6":"Humans"},{"1":"DeepNitro: Prediction of Protein Nitration and Nitrosylation Sites by Deep Learning.","2":"Protein nitration and nitrosylation are essential post-translational modifications (PTMs) involved in many fundamental cellular processes. Recent studies have revealed that excessive levels of nitration and nitrosylation in some critical proteins are linked to numerous chronic diseases. Therefore, the identification of substrates that undergo such modifications in a site-specific manner is an important research topic in the community and will provide candidates for targeted therapy. In this study, we aimed to develop a computational tool for predicting nitration and nitrosylation sites in proteins. We first constructed four types of encoding features, including positional amino acid distributions, sequence contextual dependencies, physicochemical properties, and position-specific scoring features, to represent the modified residues. Based on these encoding features, we established a predictor called DeepNitro using deep learning methods for predicting protein nitration and nitrosylation. Using n-fold cross-validation, our evaluation shows great AUC values for DeepNitro, 0.65 for tyrosine nitration, 0.80 for tryptophan nitration, and 0.70 for cysteine nitrosylation, respectively, demonstrating the robustness and reliability of our tool. Also, when tested in the independent dataset, DeepNitro is substantially superior to other similar tools with a 7%-42% improvement in the prediction performance. Taken together, the application of deep learning method and novel encoding schemes, especially the position-specific scoring feature, greatly improves the accuracy of nitration and nitrosylation site prediction and may facilitate the prediction of other PTM sites. DeepNitro is implemented in JAVA and PHP and is freely available for academic research at http://deepnitro.renlab.org.","3":"Genomics, proteomics &amp; bioinformatics","4":"30268931","5":"2018","6":"Internet"},{"1":"DeepNitro: Prediction of Protein Nitration and Nitrosylation Sites by Deep Learning.","2":"Protein nitration and nitrosylation are essential post-translational modifications (PTMs) involved in many fundamental cellular processes. Recent studies have revealed that excessive levels of nitration and nitrosylation in some critical proteins are linked to numerous chronic diseases. Therefore, the identification of substrates that undergo such modifications in a site-specific manner is an important research topic in the community and will provide candidates for targeted therapy. In this study, we aimed to develop a computational tool for predicting nitration and nitrosylation sites in proteins. We first constructed four types of encoding features, including positional amino acid distributions, sequence contextual dependencies, physicochemical properties, and position-specific scoring features, to represent the modified residues. Based on these encoding features, we established a predictor called DeepNitro using deep learning methods for predicting protein nitration and nitrosylation. Using n-fold cross-validation, our evaluation shows great AUC values for DeepNitro, 0.65 for tyrosine nitration, 0.80 for tryptophan nitration, and 0.70 for cysteine nitrosylation, respectively, demonstrating the robustness and reliability of our tool. Also, when tested in the independent dataset, DeepNitro is substantially superior to other similar tools with a 7%-42% improvement in the prediction performance. Taken together, the application of deep learning method and novel encoding schemes, especially the position-specific scoring feature, greatly improves the accuracy of nitration and nitrosylation site prediction and may facilitate the prediction of other PTM sites. DeepNitro is implemented in JAVA and PHP and is freely available for academic research at http://deepnitro.renlab.org.","3":"Genomics, proteomics &amp; bioinformatics","4":"30268931","5":"2018","6":"Neural Networks (Computer)"},{"1":"DeepNitro: Prediction of Protein Nitration and Nitrosylation Sites by Deep Learning.","2":"Protein nitration and nitrosylation are essential post-translational modifications (PTMs) involved in many fundamental cellular processes. Recent studies have revealed that excessive levels of nitration and nitrosylation in some critical proteins are linked to numerous chronic diseases. Therefore, the identification of substrates that undergo such modifications in a site-specific manner is an important research topic in the community and will provide candidates for targeted therapy. In this study, we aimed to develop a computational tool for predicting nitration and nitrosylation sites in proteins. We first constructed four types of encoding features, including positional amino acid distributions, sequence contextual dependencies, physicochemical properties, and position-specific scoring features, to represent the modified residues. Based on these encoding features, we established a predictor called DeepNitro using deep learning methods for predicting protein nitration and nitrosylation. Using n-fold cross-validation, our evaluation shows great AUC values for DeepNitro, 0.65 for tyrosine nitration, 0.80 for tryptophan nitration, and 0.70 for cysteine nitrosylation, respectively, demonstrating the robustness and reliability of our tool. Also, when tested in the independent dataset, DeepNitro is substantially superior to other similar tools with a 7%-42% improvement in the prediction performance. Taken together, the application of deep learning method and novel encoding schemes, especially the position-specific scoring feature, greatly improves the accuracy of nitration and nitrosylation site prediction and may facilitate the prediction of other PTM sites. DeepNitro is implemented in JAVA and PHP and is freely available for academic research at http://deepnitro.renlab.org.","3":"Genomics, proteomics &amp; bioinformatics","4":"30268931","5":"2018","6":"Nitrosation"},{"1":"DeepNitro: Prediction of Protein Nitration and Nitrosylation Sites by Deep Learning.","2":"Protein nitration and nitrosylation are essential post-translational modifications (PTMs) involved in many fundamental cellular processes. Recent studies have revealed that excessive levels of nitration and nitrosylation in some critical proteins are linked to numerous chronic diseases. Therefore, the identification of substrates that undergo such modifications in a site-specific manner is an important research topic in the community and will provide candidates for targeted therapy. In this study, we aimed to develop a computational tool for predicting nitration and nitrosylation sites in proteins. We first constructed four types of encoding features, including positional amino acid distributions, sequence contextual dependencies, physicochemical properties, and position-specific scoring features, to represent the modified residues. Based on these encoding features, we established a predictor called DeepNitro using deep learning methods for predicting protein nitration and nitrosylation. Using n-fold cross-validation, our evaluation shows great AUC values for DeepNitro, 0.65 for tyrosine nitration, 0.80 for tryptophan nitration, and 0.70 for cysteine nitrosylation, respectively, demonstrating the robustness and reliability of our tool. Also, when tested in the independent dataset, DeepNitro is substantially superior to other similar tools with a 7%-42% improvement in the prediction performance. Taken together, the application of deep learning method and novel encoding schemes, especially the position-specific scoring feature, greatly improves the accuracy of nitration and nitrosylation site prediction and may facilitate the prediction of other PTM sites. DeepNitro is implemented in JAVA and PHP and is freely available for academic research at http://deepnitro.renlab.org.","3":"Genomics, proteomics &amp; bioinformatics","4":"30268931","5":"2018","6":"Proteins"},{"1":"DeepNitro: Prediction of Protein Nitration and Nitrosylation Sites by Deep Learning.","2":"Protein nitration and nitrosylation are essential post-translational modifications (PTMs) involved in many fundamental cellular processes. Recent studies have revealed that excessive levels of nitration and nitrosylation in some critical proteins are linked to numerous chronic diseases. Therefore, the identification of substrates that undergo such modifications in a site-specific manner is an important research topic in the community and will provide candidates for targeted therapy. In this study, we aimed to develop a computational tool for predicting nitration and nitrosylation sites in proteins. We first constructed four types of encoding features, including positional amino acid distributions, sequence contextual dependencies, physicochemical properties, and position-specific scoring features, to represent the modified residues. Based on these encoding features, we established a predictor called DeepNitro using deep learning methods for predicting protein nitration and nitrosylation. Using n-fold cross-validation, our evaluation shows great AUC values for DeepNitro, 0.65 for tyrosine nitration, 0.80 for tryptophan nitration, and 0.70 for cysteine nitrosylation, respectively, demonstrating the robustness and reliability of our tool. Also, when tested in the independent dataset, DeepNitro is substantially superior to other similar tools with a 7%-42% improvement in the prediction performance. Taken together, the application of deep learning method and novel encoding schemes, especially the position-specific scoring feature, greatly improves the accuracy of nitration and nitrosylation site prediction and may facilitate the prediction of other PTM sites. DeepNitro is implemented in JAVA and PHP and is freely available for academic research at http://deepnitro.renlab.org.","3":"Genomics, proteomics &amp; bioinformatics","4":"30268931","5":"2018","6":"chemistry"},{"1":"DeepNitro: Prediction of Protein Nitration and Nitrosylation Sites by Deep Learning.","2":"Protein nitration and nitrosylation are essential post-translational modifications (PTMs) involved in many fundamental cellular processes. Recent studies have revealed that excessive levels of nitration and nitrosylation in some critical proteins are linked to numerous chronic diseases. Therefore, the identification of substrates that undergo such modifications in a site-specific manner is an important research topic in the community and will provide candidates for targeted therapy. In this study, we aimed to develop a computational tool for predicting nitration and nitrosylation sites in proteins. We first constructed four types of encoding features, including positional amino acid distributions, sequence contextual dependencies, physicochemical properties, and position-specific scoring features, to represent the modified residues. Based on these encoding features, we established a predictor called DeepNitro using deep learning methods for predicting protein nitration and nitrosylation. Using n-fold cross-validation, our evaluation shows great AUC values for DeepNitro, 0.65 for tyrosine nitration, 0.80 for tryptophan nitration, and 0.70 for cysteine nitrosylation, respectively, demonstrating the robustness and reliability of our tool. Also, when tested in the independent dataset, DeepNitro is substantially superior to other similar tools with a 7%-42% improvement in the prediction performance. Taken together, the application of deep learning method and novel encoding schemes, especially the position-specific scoring feature, greatly improves the accuracy of nitration and nitrosylation site prediction and may facilitate the prediction of other PTM sites. DeepNitro is implemented in JAVA and PHP and is freely available for academic research at http://deepnitro.renlab.org.","3":"Genomics, proteomics &amp; bioinformatics","4":"30268931","5":"2018","6":"metabolism"},{"1":"DeepNitro: Prediction of Protein Nitration and Nitrosylation Sites by Deep Learning.","2":"Protein nitration and nitrosylation are essential post-translational modifications (PTMs) involved in many fundamental cellular processes. Recent studies have revealed that excessive levels of nitration and nitrosylation in some critical proteins are linked to numerous chronic diseases. Therefore, the identification of substrates that undergo such modifications in a site-specific manner is an important research topic in the community and will provide candidates for targeted therapy. In this study, we aimed to develop a computational tool for predicting nitration and nitrosylation sites in proteins. We first constructed four types of encoding features, including positional amino acid distributions, sequence contextual dependencies, physicochemical properties, and position-specific scoring features, to represent the modified residues. Based on these encoding features, we established a predictor called DeepNitro using deep learning methods for predicting protein nitration and nitrosylation. Using n-fold cross-validation, our evaluation shows great AUC values for DeepNitro, 0.65 for tyrosine nitration, 0.80 for tryptophan nitration, and 0.70 for cysteine nitrosylation, respectively, demonstrating the robustness and reliability of our tool. Also, when tested in the independent dataset, DeepNitro is substantially superior to other similar tools with a 7%-42% improvement in the prediction performance. Taken together, the application of deep learning method and novel encoding schemes, especially the position-specific scoring feature, greatly improves the accuracy of nitration and nitrosylation site prediction and may facilitate the prediction of other PTM sites. DeepNitro is implemented in JAVA and PHP and is freely available for academic research at http://deepnitro.renlab.org.","3":"Genomics, proteomics &amp; bioinformatics","4":"30268931","5":"2018","6":"Reproducibility of Results"},{"1":"DeepNitro: Prediction of Protein Nitration and Nitrosylation Sites by Deep Learning.","2":"Protein nitration and nitrosylation are essential post-translational modifications (PTMs) involved in many fundamental cellular processes. Recent studies have revealed that excessive levels of nitration and nitrosylation in some critical proteins are linked to numerous chronic diseases. Therefore, the identification of substrates that undergo such modifications in a site-specific manner is an important research topic in the community and will provide candidates for targeted therapy. In this study, we aimed to develop a computational tool for predicting nitration and nitrosylation sites in proteins. We first constructed four types of encoding features, including positional amino acid distributions, sequence contextual dependencies, physicochemical properties, and position-specific scoring features, to represent the modified residues. Based on these encoding features, we established a predictor called DeepNitro using deep learning methods for predicting protein nitration and nitrosylation. Using n-fold cross-validation, our evaluation shows great AUC values for DeepNitro, 0.65 for tyrosine nitration, 0.80 for tryptophan nitration, and 0.70 for cysteine nitrosylation, respectively, demonstrating the robustness and reliability of our tool. Also, when tested in the independent dataset, DeepNitro is substantially superior to other similar tools with a 7%-42% improvement in the prediction performance. Taken together, the application of deep learning method and novel encoding schemes, especially the position-specific scoring feature, greatly improves the accuracy of nitration and nitrosylation site prediction and may facilitate the prediction of other PTM sites. DeepNitro is implemented in JAVA and PHP and is freely available for academic research at http://deepnitro.renlab.org.","3":"Genomics, proteomics &amp; bioinformatics","4":"30268931","5":"2018","6":"Software"},{"1":"Exploring spatial-frequency-sequential relationships for motor imagery classification with recurrent neural network.","2":"BACKGROUND: Conventional methods of motor imagery brain computer interfaces (MI-BCIs) suffer from the limited number of samples and simplified features, so as to produce poor performances with spatial-frequency features and shallow classifiers.METHODS: Alternatively, this paper applies a deep recurrent neural network (RNN) with a sliding window cropping strategy (SWCS) to signal classification of MI-BCIs. The spatial-frequency features are first extracted by the filter bank common spatial pattern (FB-CSP) algorithm, and such features are cropped by the SWCS into time slices. By extracting spatial-frequency-sequential relationships, the cropped time slices are then fed into RNN for classification. In order to overcome the memory distractions, the commonly used gated recurrent unit (GRU) and long-short term memory (LSTM) unit are applied to the RNN architecture, and experimental results are used to determine which unit is more suitable for processing EEG signals.RESULTS: Experimental results on common BCI benchmark datasets show that the spatial-frequency-sequential relationships outperform all other competing spatial-frequency methods. In particular, the proposed GRU-RNN architecture achieves the lowest misclassification rates on all BCI benchmark datasets.CONCLUSION: By introducing spatial-frequency-sequential relationships with cropping time slice samples, the proposed method gives a novel way to construct and model high accuracy and robustness MI-BCIs based on limited trials of EEG signals.","3":"BMC bioinformatics","4":"30268089","5":"2018","6":"Algorithms"},{"1":"Exploring spatial-frequency-sequential relationships for motor imagery classification with recurrent neural network.","2":"BACKGROUND: Conventional methods of motor imagery brain computer interfaces (MI-BCIs) suffer from the limited number of samples and simplified features, so as to produce poor performances with spatial-frequency features and shallow classifiers.METHODS: Alternatively, this paper applies a deep recurrent neural network (RNN) with a sliding window cropping strategy (SWCS) to signal classification of MI-BCIs. The spatial-frequency features are first extracted by the filter bank common spatial pattern (FB-CSP) algorithm, and such features are cropped by the SWCS into time slices. By extracting spatial-frequency-sequential relationships, the cropped time slices are then fed into RNN for classification. In order to overcome the memory distractions, the commonly used gated recurrent unit (GRU) and long-short term memory (LSTM) unit are applied to the RNN architecture, and experimental results are used to determine which unit is more suitable for processing EEG signals.RESULTS: Experimental results on common BCI benchmark datasets show that the spatial-frequency-sequential relationships outperform all other competing spatial-frequency methods. In particular, the proposed GRU-RNN architecture achieves the lowest misclassification rates on all BCI benchmark datasets.CONCLUSION: By introducing spatial-frequency-sequential relationships with cropping time slice samples, the proposed method gives a novel way to construct and model high accuracy and robustness MI-BCIs based on limited trials of EEG signals.","3":"BMC bioinformatics","4":"30268089","5":"2018","6":"Brain-Computer Interfaces"},{"1":"Exploring spatial-frequency-sequential relationships for motor imagery classification with recurrent neural network.","2":"BACKGROUND: Conventional methods of motor imagery brain computer interfaces (MI-BCIs) suffer from the limited number of samples and simplified features, so as to produce poor performances with spatial-frequency features and shallow classifiers.METHODS: Alternatively, this paper applies a deep recurrent neural network (RNN) with a sliding window cropping strategy (SWCS) to signal classification of MI-BCIs. The spatial-frequency features are first extracted by the filter bank common spatial pattern (FB-CSP) algorithm, and such features are cropped by the SWCS into time slices. By extracting spatial-frequency-sequential relationships, the cropped time slices are then fed into RNN for classification. In order to overcome the memory distractions, the commonly used gated recurrent unit (GRU) and long-short term memory (LSTM) unit are applied to the RNN architecture, and experimental results are used to determine which unit is more suitable for processing EEG signals.RESULTS: Experimental results on common BCI benchmark datasets show that the spatial-frequency-sequential relationships outperform all other competing spatial-frequency methods. In particular, the proposed GRU-RNN architecture achieves the lowest misclassification rates on all BCI benchmark datasets.CONCLUSION: By introducing spatial-frequency-sequential relationships with cropping time slice samples, the proposed method gives a novel way to construct and model high accuracy and robustness MI-BCIs based on limited trials of EEG signals.","3":"BMC bioinformatics","4":"30268089","5":"2018","6":"Databases, Genetic"},{"1":"Exploring spatial-frequency-sequential relationships for motor imagery classification with recurrent neural network.","2":"BACKGROUND: Conventional methods of motor imagery brain computer interfaces (MI-BCIs) suffer from the limited number of samples and simplified features, so as to produce poor performances with spatial-frequency features and shallow classifiers.METHODS: Alternatively, this paper applies a deep recurrent neural network (RNN) with a sliding window cropping strategy (SWCS) to signal classification of MI-BCIs. The spatial-frequency features are first extracted by the filter bank common spatial pattern (FB-CSP) algorithm, and such features are cropped by the SWCS into time slices. By extracting spatial-frequency-sequential relationships, the cropped time slices are then fed into RNN for classification. In order to overcome the memory distractions, the commonly used gated recurrent unit (GRU) and long-short term memory (LSTM) unit are applied to the RNN architecture, and experimental results are used to determine which unit is more suitable for processing EEG signals.RESULTS: Experimental results on common BCI benchmark datasets show that the spatial-frequency-sequential relationships outperform all other competing spatial-frequency methods. In particular, the proposed GRU-RNN architecture achieves the lowest misclassification rates on all BCI benchmark datasets.CONCLUSION: By introducing spatial-frequency-sequential relationships with cropping time slice samples, the proposed method gives a novel way to construct and model high accuracy and robustness MI-BCIs based on limited trials of EEG signals.","3":"BMC bioinformatics","4":"30268089","5":"2018","6":"Datasets as Topic"},{"1":"Exploring spatial-frequency-sequential relationships for motor imagery classification with recurrent neural network.","2":"BACKGROUND: Conventional methods of motor imagery brain computer interfaces (MI-BCIs) suffer from the limited number of samples and simplified features, so as to produce poor performances with spatial-frequency features and shallow classifiers.METHODS: Alternatively, this paper applies a deep recurrent neural network (RNN) with a sliding window cropping strategy (SWCS) to signal classification of MI-BCIs. The spatial-frequency features are first extracted by the filter bank common spatial pattern (FB-CSP) algorithm, and such features are cropped by the SWCS into time slices. By extracting spatial-frequency-sequential relationships, the cropped time slices are then fed into RNN for classification. In order to overcome the memory distractions, the commonly used gated recurrent unit (GRU) and long-short term memory (LSTM) unit are applied to the RNN architecture, and experimental results are used to determine which unit is more suitable for processing EEG signals.RESULTS: Experimental results on common BCI benchmark datasets show that the spatial-frequency-sequential relationships outperform all other competing spatial-frequency methods. In particular, the proposed GRU-RNN architecture achieves the lowest misclassification rates on all BCI benchmark datasets.CONCLUSION: By introducing spatial-frequency-sequential relationships with cropping time slice samples, the proposed method gives a novel way to construct and model high accuracy and robustness MI-BCIs based on limited trials of EEG signals.","3":"BMC bioinformatics","4":"30268089","5":"2018","6":"Electroencephalography"},{"1":"Exploring spatial-frequency-sequential relationships for motor imagery classification with recurrent neural network.","2":"BACKGROUND: Conventional methods of motor imagery brain computer interfaces (MI-BCIs) suffer from the limited number of samples and simplified features, so as to produce poor performances with spatial-frequency features and shallow classifiers.METHODS: Alternatively, this paper applies a deep recurrent neural network (RNN) with a sliding window cropping strategy (SWCS) to signal classification of MI-BCIs. The spatial-frequency features are first extracted by the filter bank common spatial pattern (FB-CSP) algorithm, and such features are cropped by the SWCS into time slices. By extracting spatial-frequency-sequential relationships, the cropped time slices are then fed into RNN for classification. In order to overcome the memory distractions, the commonly used gated recurrent unit (GRU) and long-short term memory (LSTM) unit are applied to the RNN architecture, and experimental results are used to determine which unit is more suitable for processing EEG signals.RESULTS: Experimental results on common BCI benchmark datasets show that the spatial-frequency-sequential relationships outperform all other competing spatial-frequency methods. In particular, the proposed GRU-RNN architecture achieves the lowest misclassification rates on all BCI benchmark datasets.CONCLUSION: By introducing spatial-frequency-sequential relationships with cropping time slice samples, the proposed method gives a novel way to construct and model high accuracy and robustness MI-BCIs based on limited trials of EEG signals.","3":"BMC bioinformatics","4":"30268089","5":"2018","6":"classification"},{"1":"Exploring spatial-frequency-sequential relationships for motor imagery classification with recurrent neural network.","2":"BACKGROUND: Conventional methods of motor imagery brain computer interfaces (MI-BCIs) suffer from the limited number of samples and simplified features, so as to produce poor performances with spatial-frequency features and shallow classifiers.METHODS: Alternatively, this paper applies a deep recurrent neural network (RNN) with a sliding window cropping strategy (SWCS) to signal classification of MI-BCIs. The spatial-frequency features are first extracted by the filter bank common spatial pattern (FB-CSP) algorithm, and such features are cropped by the SWCS into time slices. By extracting spatial-frequency-sequential relationships, the cropped time slices are then fed into RNN for classification. In order to overcome the memory distractions, the commonly used gated recurrent unit (GRU) and long-short term memory (LSTM) unit are applied to the RNN architecture, and experimental results are used to determine which unit is more suitable for processing EEG signals.RESULTS: Experimental results on common BCI benchmark datasets show that the spatial-frequency-sequential relationships outperform all other competing spatial-frequency methods. In particular, the proposed GRU-RNN architecture achieves the lowest misclassification rates on all BCI benchmark datasets.CONCLUSION: By introducing spatial-frequency-sequential relationships with cropping time slice samples, the proposed method gives a novel way to construct and model high accuracy and robustness MI-BCIs based on limited trials of EEG signals.","3":"BMC bioinformatics","4":"30268089","5":"2018","6":"methods"},{"1":"Exploring spatial-frequency-sequential relationships for motor imagery classification with recurrent neural network.","2":"BACKGROUND: Conventional methods of motor imagery brain computer interfaces (MI-BCIs) suffer from the limited number of samples and simplified features, so as to produce poor performances with spatial-frequency features and shallow classifiers.METHODS: Alternatively, this paper applies a deep recurrent neural network (RNN) with a sliding window cropping strategy (SWCS) to signal classification of MI-BCIs. The spatial-frequency features are first extracted by the filter bank common spatial pattern (FB-CSP) algorithm, and such features are cropped by the SWCS into time slices. By extracting spatial-frequency-sequential relationships, the cropped time slices are then fed into RNN for classification. In order to overcome the memory distractions, the commonly used gated recurrent unit (GRU) and long-short term memory (LSTM) unit are applied to the RNN architecture, and experimental results are used to determine which unit is more suitable for processing EEG signals.RESULTS: Experimental results on common BCI benchmark datasets show that the spatial-frequency-sequential relationships outperform all other competing spatial-frequency methods. In particular, the proposed GRU-RNN architecture achieves the lowest misclassification rates on all BCI benchmark datasets.CONCLUSION: By introducing spatial-frequency-sequential relationships with cropping time slice samples, the proposed method gives a novel way to construct and model high accuracy and robustness MI-BCIs based on limited trials of EEG signals.","3":"BMC bioinformatics","4":"30268089","5":"2018","6":"Humans"},{"1":"Exploring spatial-frequency-sequential relationships for motor imagery classification with recurrent neural network.","2":"BACKGROUND: Conventional methods of motor imagery brain computer interfaces (MI-BCIs) suffer from the limited number of samples and simplified features, so as to produce poor performances with spatial-frequency features and shallow classifiers.METHODS: Alternatively, this paper applies a deep recurrent neural network (RNN) with a sliding window cropping strategy (SWCS) to signal classification of MI-BCIs. The spatial-frequency features are first extracted by the filter bank common spatial pattern (FB-CSP) algorithm, and such features are cropped by the SWCS into time slices. By extracting spatial-frequency-sequential relationships, the cropped time slices are then fed into RNN for classification. In order to overcome the memory distractions, the commonly used gated recurrent unit (GRU) and long-short term memory (LSTM) unit are applied to the RNN architecture, and experimental results are used to determine which unit is more suitable for processing EEG signals.RESULTS: Experimental results on common BCI benchmark datasets show that the spatial-frequency-sequential relationships outperform all other competing spatial-frequency methods. In particular, the proposed GRU-RNN architecture achieves the lowest misclassification rates on all BCI benchmark datasets.CONCLUSION: By introducing spatial-frequency-sequential relationships with cropping time slice samples, the proposed method gives a novel way to construct and model high accuracy and robustness MI-BCIs based on limited trials of EEG signals.","3":"BMC bioinformatics","4":"30268089","5":"2018","6":"Imagination"},{"1":"Exploring spatial-frequency-sequential relationships for motor imagery classification with recurrent neural network.","2":"BACKGROUND: Conventional methods of motor imagery brain computer interfaces (MI-BCIs) suffer from the limited number of samples and simplified features, so as to produce poor performances with spatial-frequency features and shallow classifiers.METHODS: Alternatively, this paper applies a deep recurrent neural network (RNN) with a sliding window cropping strategy (SWCS) to signal classification of MI-BCIs. The spatial-frequency features are first extracted by the filter bank common spatial pattern (FB-CSP) algorithm, and such features are cropped by the SWCS into time slices. By extracting spatial-frequency-sequential relationships, the cropped time slices are then fed into RNN for classification. In order to overcome the memory distractions, the commonly used gated recurrent unit (GRU) and long-short term memory (LSTM) unit are applied to the RNN architecture, and experimental results are used to determine which unit is more suitable for processing EEG signals.RESULTS: Experimental results on common BCI benchmark datasets show that the spatial-frequency-sequential relationships outperform all other competing spatial-frequency methods. In particular, the proposed GRU-RNN architecture achieves the lowest misclassification rates on all BCI benchmark datasets.CONCLUSION: By introducing spatial-frequency-sequential relationships with cropping time slice samples, the proposed method gives a novel way to construct and model high accuracy and robustness MI-BCIs based on limited trials of EEG signals.","3":"BMC bioinformatics","4":"30268089","5":"2018","6":"physiology"},{"1":"Exploring spatial-frequency-sequential relationships for motor imagery classification with recurrent neural network.","2":"BACKGROUND: Conventional methods of motor imagery brain computer interfaces (MI-BCIs) suffer from the limited number of samples and simplified features, so as to produce poor performances with spatial-frequency features and shallow classifiers.METHODS: Alternatively, this paper applies a deep recurrent neural network (RNN) with a sliding window cropping strategy (SWCS) to signal classification of MI-BCIs. The spatial-frequency features are first extracted by the filter bank common spatial pattern (FB-CSP) algorithm, and such features are cropped by the SWCS into time slices. By extracting spatial-frequency-sequential relationships, the cropped time slices are then fed into RNN for classification. In order to overcome the memory distractions, the commonly used gated recurrent unit (GRU) and long-short term memory (LSTM) unit are applied to the RNN architecture, and experimental results are used to determine which unit is more suitable for processing EEG signals.RESULTS: Experimental results on common BCI benchmark datasets show that the spatial-frequency-sequential relationships outperform all other competing spatial-frequency methods. In particular, the proposed GRU-RNN architecture achieves the lowest misclassification rates on all BCI benchmark datasets.CONCLUSION: By introducing spatial-frequency-sequential relationships with cropping time slice samples, the proposed method gives a novel way to construct and model high accuracy and robustness MI-BCIs based on limited trials of EEG signals.","3":"BMC bioinformatics","4":"30268089","5":"2018","6":"Neural Networks (Computer)"},{"1":"Exploring spatial-frequency-sequential relationships for motor imagery classification with recurrent neural network.","2":"BACKGROUND: Conventional methods of motor imagery brain computer interfaces (MI-BCIs) suffer from the limited number of samples and simplified features, so as to produce poor performances with spatial-frequency features and shallow classifiers.METHODS: Alternatively, this paper applies a deep recurrent neural network (RNN) with a sliding window cropping strategy (SWCS) to signal classification of MI-BCIs. The spatial-frequency features are first extracted by the filter bank common spatial pattern (FB-CSP) algorithm, and such features are cropped by the SWCS into time slices. By extracting spatial-frequency-sequential relationships, the cropped time slices are then fed into RNN for classification. In order to overcome the memory distractions, the commonly used gated recurrent unit (GRU) and long-short term memory (LSTM) unit are applied to the RNN architecture, and experimental results are used to determine which unit is more suitable for processing EEG signals.RESULTS: Experimental results on common BCI benchmark datasets show that the spatial-frequency-sequential relationships outperform all other competing spatial-frequency methods. In particular, the proposed GRU-RNN architecture achieves the lowest misclassification rates on all BCI benchmark datasets.CONCLUSION: By introducing spatial-frequency-sequential relationships with cropping time slice samples, the proposed method gives a novel way to construct and model high accuracy and robustness MI-BCIs based on limited trials of EEG signals.","3":"BMC bioinformatics","4":"30268089","5":"2018","6":"Signal Processing, Computer-Assisted"},{"1":"Exploring spatial-frequency-sequential relationships for motor imagery classification with recurrent neural network.","2":"BACKGROUND: Conventional methods of motor imagery brain computer interfaces (MI-BCIs) suffer from the limited number of samples and simplified features, so as to produce poor performances with spatial-frequency features and shallow classifiers.METHODS: Alternatively, this paper applies a deep recurrent neural network (RNN) with a sliding window cropping strategy (SWCS) to signal classification of MI-BCIs. The spatial-frequency features are first extracted by the filter bank common spatial pattern (FB-CSP) algorithm, and such features are cropped by the SWCS into time slices. By extracting spatial-frequency-sequential relationships, the cropped time slices are then fed into RNN for classification. In order to overcome the memory distractions, the commonly used gated recurrent unit (GRU) and long-short term memory (LSTM) unit are applied to the RNN architecture, and experimental results are used to determine which unit is more suitable for processing EEG signals.RESULTS: Experimental results on common BCI benchmark datasets show that the spatial-frequency-sequential relationships outperform all other competing spatial-frequency methods. In particular, the proposed GRU-RNN architecture achieves the lowest misclassification rates on all BCI benchmark datasets.CONCLUSION: By introducing spatial-frequency-sequential relationships with cropping time slice samples, the proposed method gives a novel way to construct and model high accuracy and robustness MI-BCIs based on limited trials of EEG signals.","3":"BMC bioinformatics","4":"30268089","5":"2018","6":"Support Vector Machine"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"Adolescent"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"Adult"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"Cause of Death"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"Female"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"Humans"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"Machine Learning"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"Male"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"Middle Aged"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"Mortality"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"Multivariate Analysis"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"Registries"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"statistics &amp; numerical data"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"Risk Factors"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"Sex Factors"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"Slovenia"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"Subject Headings"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"Suicidal Ideation"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"Suicide"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"prevention &amp; control"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"psychology"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"statistics &amp; numerical data"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"Suicide, Attempted"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"prevention &amp; control"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"psychology"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"statistics &amp; numerical data"},{"1":"Suicide and Suicide Attempt Descriptors by Multimethod Approach.","2":"BACKGROUND: Suicide is a complex action of suicidal methods and peripheral factors with seemingly threatening components representing actual cause for the suicidal actions. It is especially those, apparently unimportant factors that represent a crucial milestone in the network of all the other, personal, cultural, genetic and biochemical factors, forming the method of action consequently deciding between life and death.SUBJECTS AND METHODS: Based on the Register of Suicides in the Republic of Slovenia kept by the University Psychiatric Clinic Ljubljana, we used a combination of attributes varying within a variable and between variables. Due to limited application of standard statistical methods and analyses in such cases, we used the Machine learning method, Multimethod hybrid approach, which allows combining of different approaches to machine learning (decision trees, genetic algorithms and supplementary vectors). The research included 56712 persons attempting suicide and 21913 persons committing suicide. We chose a form of a suicide action with both possible results: attempted suicide and suicide.RESULTS: Based on the analysis of machine learning, we defined attributes of the action regarding their lethal effect: attempted suicide and suicide commitment. The suicide register kept for the last 40 years shows hanging as the most commonly used suicidal method, used by men with the purpose of causing suicidal death rather than a suicidal attempt. On the other hand, use of medicaments is linked to the suicidal attempt and mostly used by females.CONCLUSIONS: All methods of suicidal actions cannot predict suicidal death, thus we examined different methods of suicide to most accurately predict the link between the method and its effect in terms of suicide attempt or suicide. The Machine learning method confirmed the attributes of suicide methods in connection with their different outcomes. This analytical method is useful in processing large databases since it enables one variable's intensity to affect other variables in terms of result and meaning. The identification of the most decisive risk factors for suicidal behaviour can serve as basis for planning an effective prevention strategies, timely identification and adequate proffessional help to the high risk persons.","3":"Psychiatria Danubina","4":"30267524","5":"2018","6":"Young Adult"},{"1":"Feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy.","2":"This study aimed to investigate the feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy. The relationships between the reference centroids of prostate regions (CPRs) (prostate locations) and anatomical feature points were explored, and the most feasible anatomical feature points were selected based on the smallest location estimation errors of CPRs and the largest Dice's similarity coefficient (DSC) between the reference and extracted prostates. The reference CPRs were calculated according to reference prostate contours determined by radiation oncologists. Five anatomical feature points were manually determined on a prostate, bladder, and rectum in a sagittal plane of a planning computed tomography image for each case. The CPRs were estimated using three machine learning architectures [artificial neural network, random forest, and support vector machine (SVM)], which learned the relationships between the reference CPRs and anatomical feature points. The CPRs were applied for placing a prostate probabilistic atlas at the coordinates and extracting prostate regions using a Bayesian delineation framework. The average estimation errors without and with SVM using three feature points, which indicated the best performance, were 5.6<U+2009>±<U+2009>3.7 mm and 1.8<U+2009>±<U+2009>1.0 mm, respectively (the smallest error) (p<U+2009>&lt;<U+2009>0.001). The average DSCs without and with SVM using the three feature points were 0.69<U+2009>±<U+2009>0.13 and 0.82<U+2009>±<U+2009>0.055, respectively (the highest DSC) (p<U+2009>&lt;<U+2009>0.001). The anatomical feature points may be feasible for the estimation of prostate locations, which can be applied to the general Bayesian delineation frameworks for prostate cancer radiotherapy.","3":"Radiological physics and technology","4":"30267211","5":"2018","6":"Bayes Theorem"},{"1":"Feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy.","2":"This study aimed to investigate the feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy. The relationships between the reference centroids of prostate regions (CPRs) (prostate locations) and anatomical feature points were explored, and the most feasible anatomical feature points were selected based on the smallest location estimation errors of CPRs and the largest Dice's similarity coefficient (DSC) between the reference and extracted prostates. The reference CPRs were calculated according to reference prostate contours determined by radiation oncologists. Five anatomical feature points were manually determined on a prostate, bladder, and rectum in a sagittal plane of a planning computed tomography image for each case. The CPRs were estimated using three machine learning architectures [artificial neural network, random forest, and support vector machine (SVM)], which learned the relationships between the reference CPRs and anatomical feature points. The CPRs were applied for placing a prostate probabilistic atlas at the coordinates and extracting prostate regions using a Bayesian delineation framework. The average estimation errors without and with SVM using three feature points, which indicated the best performance, were 5.6<U+2009>±<U+2009>3.7 mm and 1.8<U+2009>±<U+2009>1.0 mm, respectively (the smallest error) (p<U+2009>&lt;<U+2009>0.001). The average DSCs without and with SVM using the three feature points were 0.69<U+2009>±<U+2009>0.13 and 0.82<U+2009>±<U+2009>0.055, respectively (the highest DSC) (p<U+2009>&lt;<U+2009>0.001). The anatomical feature points may be feasible for the estimation of prostate locations, which can be applied to the general Bayesian delineation frameworks for prostate cancer radiotherapy.","3":"Radiological physics and technology","4":"30267211","5":"2018","6":"Feasibility Studies"},{"1":"Feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy.","2":"This study aimed to investigate the feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy. The relationships between the reference centroids of prostate regions (CPRs) (prostate locations) and anatomical feature points were explored, and the most feasible anatomical feature points were selected based on the smallest location estimation errors of CPRs and the largest Dice's similarity coefficient (DSC) between the reference and extracted prostates. The reference CPRs were calculated according to reference prostate contours determined by radiation oncologists. Five anatomical feature points were manually determined on a prostate, bladder, and rectum in a sagittal plane of a planning computed tomography image for each case. The CPRs were estimated using three machine learning architectures [artificial neural network, random forest, and support vector machine (SVM)], which learned the relationships between the reference CPRs and anatomical feature points. The CPRs were applied for placing a prostate probabilistic atlas at the coordinates and extracting prostate regions using a Bayesian delineation framework. The average estimation errors without and with SVM using three feature points, which indicated the best performance, were 5.6<U+2009>±<U+2009>3.7 mm and 1.8<U+2009>±<U+2009>1.0 mm, respectively (the smallest error) (p<U+2009>&lt;<U+2009>0.001). The average DSCs without and with SVM using the three feature points were 0.69<U+2009>±<U+2009>0.13 and 0.82<U+2009>±<U+2009>0.055, respectively (the highest DSC) (p<U+2009>&lt;<U+2009>0.001). The anatomical feature points may be feasible for the estimation of prostate locations, which can be applied to the general Bayesian delineation frameworks for prostate cancer radiotherapy.","3":"Radiological physics and technology","4":"30267211","5":"2018","6":"Humans"},{"1":"Feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy.","2":"This study aimed to investigate the feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy. The relationships between the reference centroids of prostate regions (CPRs) (prostate locations) and anatomical feature points were explored, and the most feasible anatomical feature points were selected based on the smallest location estimation errors of CPRs and the largest Dice's similarity coefficient (DSC) between the reference and extracted prostates. The reference CPRs were calculated according to reference prostate contours determined by radiation oncologists. Five anatomical feature points were manually determined on a prostate, bladder, and rectum in a sagittal plane of a planning computed tomography image for each case. The CPRs were estimated using three machine learning architectures [artificial neural network, random forest, and support vector machine (SVM)], which learned the relationships between the reference CPRs and anatomical feature points. The CPRs were applied for placing a prostate probabilistic atlas at the coordinates and extracting prostate regions using a Bayesian delineation framework. The average estimation errors without and with SVM using three feature points, which indicated the best performance, were 5.6<U+2009>±<U+2009>3.7 mm and 1.8<U+2009>±<U+2009>1.0 mm, respectively (the smallest error) (p<U+2009>&lt;<U+2009>0.001). The average DSCs without and with SVM using the three feature points were 0.69<U+2009>±<U+2009>0.13 and 0.82<U+2009>±<U+2009>0.055, respectively (the highest DSC) (p<U+2009>&lt;<U+2009>0.001). The anatomical feature points may be feasible for the estimation of prostate locations, which can be applied to the general Bayesian delineation frameworks for prostate cancer radiotherapy.","3":"Radiological physics and technology","4":"30267211","5":"2018","6":"Machine Learning"},{"1":"Feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy.","2":"This study aimed to investigate the feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy. The relationships between the reference centroids of prostate regions (CPRs) (prostate locations) and anatomical feature points were explored, and the most feasible anatomical feature points were selected based on the smallest location estimation errors of CPRs and the largest Dice's similarity coefficient (DSC) between the reference and extracted prostates. The reference CPRs were calculated according to reference prostate contours determined by radiation oncologists. Five anatomical feature points were manually determined on a prostate, bladder, and rectum in a sagittal plane of a planning computed tomography image for each case. The CPRs were estimated using three machine learning architectures [artificial neural network, random forest, and support vector machine (SVM)], which learned the relationships between the reference CPRs and anatomical feature points. The CPRs were applied for placing a prostate probabilistic atlas at the coordinates and extracting prostate regions using a Bayesian delineation framework. The average estimation errors without and with SVM using three feature points, which indicated the best performance, were 5.6<U+2009>±<U+2009>3.7 mm and 1.8<U+2009>±<U+2009>1.0 mm, respectively (the smallest error) (p<U+2009>&lt;<U+2009>0.001). The average DSCs without and with SVM using the three feature points were 0.69<U+2009>±<U+2009>0.13 and 0.82<U+2009>±<U+2009>0.055, respectively (the highest DSC) (p<U+2009>&lt;<U+2009>0.001). The anatomical feature points may be feasible for the estimation of prostate locations, which can be applied to the general Bayesian delineation frameworks for prostate cancer radiotherapy.","3":"Radiological physics and technology","4":"30267211","5":"2018","6":"Male"},{"1":"Feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy.","2":"This study aimed to investigate the feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy. The relationships between the reference centroids of prostate regions (CPRs) (prostate locations) and anatomical feature points were explored, and the most feasible anatomical feature points were selected based on the smallest location estimation errors of CPRs and the largest Dice's similarity coefficient (DSC) between the reference and extracted prostates. The reference CPRs were calculated according to reference prostate contours determined by radiation oncologists. Five anatomical feature points were manually determined on a prostate, bladder, and rectum in a sagittal plane of a planning computed tomography image for each case. The CPRs were estimated using three machine learning architectures [artificial neural network, random forest, and support vector machine (SVM)], which learned the relationships between the reference CPRs and anatomical feature points. The CPRs were applied for placing a prostate probabilistic atlas at the coordinates and extracting prostate regions using a Bayesian delineation framework. The average estimation errors without and with SVM using three feature points, which indicated the best performance, were 5.6<U+2009>±<U+2009>3.7 mm and 1.8<U+2009>±<U+2009>1.0 mm, respectively (the smallest error) (p<U+2009>&lt;<U+2009>0.001). The average DSCs without and with SVM using the three feature points were 0.69<U+2009>±<U+2009>0.13 and 0.82<U+2009>±<U+2009>0.055, respectively (the highest DSC) (p<U+2009>&lt;<U+2009>0.001). The anatomical feature points may be feasible for the estimation of prostate locations, which can be applied to the general Bayesian delineation frameworks for prostate cancer radiotherapy.","3":"Radiological physics and technology","4":"30267211","5":"2018","6":"Prostate"},{"1":"Feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy.","2":"This study aimed to investigate the feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy. The relationships between the reference centroids of prostate regions (CPRs) (prostate locations) and anatomical feature points were explored, and the most feasible anatomical feature points were selected based on the smallest location estimation errors of CPRs and the largest Dice's similarity coefficient (DSC) between the reference and extracted prostates. The reference CPRs were calculated according to reference prostate contours determined by radiation oncologists. Five anatomical feature points were manually determined on a prostate, bladder, and rectum in a sagittal plane of a planning computed tomography image for each case. The CPRs were estimated using three machine learning architectures [artificial neural network, random forest, and support vector machine (SVM)], which learned the relationships between the reference CPRs and anatomical feature points. The CPRs were applied for placing a prostate probabilistic atlas at the coordinates and extracting prostate regions using a Bayesian delineation framework. The average estimation errors without and with SVM using three feature points, which indicated the best performance, were 5.6<U+2009>±<U+2009>3.7 mm and 1.8<U+2009>±<U+2009>1.0 mm, respectively (the smallest error) (p<U+2009>&lt;<U+2009>0.001). The average DSCs without and with SVM using the three feature points were 0.69<U+2009>±<U+2009>0.13 and 0.82<U+2009>±<U+2009>0.055, respectively (the highest DSC) (p<U+2009>&lt;<U+2009>0.001). The anatomical feature points may be feasible for the estimation of prostate locations, which can be applied to the general Bayesian delineation frameworks for prostate cancer radiotherapy.","3":"Radiological physics and technology","4":"30267211","5":"2018","6":"diagnostic imaging"},{"1":"Feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy.","2":"This study aimed to investigate the feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy. The relationships between the reference centroids of prostate regions (CPRs) (prostate locations) and anatomical feature points were explored, and the most feasible anatomical feature points were selected based on the smallest location estimation errors of CPRs and the largest Dice's similarity coefficient (DSC) between the reference and extracted prostates. The reference CPRs were calculated according to reference prostate contours determined by radiation oncologists. Five anatomical feature points were manually determined on a prostate, bladder, and rectum in a sagittal plane of a planning computed tomography image for each case. The CPRs were estimated using three machine learning architectures [artificial neural network, random forest, and support vector machine (SVM)], which learned the relationships between the reference CPRs and anatomical feature points. The CPRs were applied for placing a prostate probabilistic atlas at the coordinates and extracting prostate regions using a Bayesian delineation framework. The average estimation errors without and with SVM using three feature points, which indicated the best performance, were 5.6<U+2009>±<U+2009>3.7 mm and 1.8<U+2009>±<U+2009>1.0 mm, respectively (the smallest error) (p<U+2009>&lt;<U+2009>0.001). The average DSCs without and with SVM using the three feature points were 0.69<U+2009>±<U+2009>0.13 and 0.82<U+2009>±<U+2009>0.055, respectively (the highest DSC) (p<U+2009>&lt;<U+2009>0.001). The anatomical feature points may be feasible for the estimation of prostate locations, which can be applied to the general Bayesian delineation frameworks for prostate cancer radiotherapy.","3":"Radiological physics and technology","4":"30267211","5":"2018","6":"pathology"},{"1":"Feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy.","2":"This study aimed to investigate the feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy. The relationships between the reference centroids of prostate regions (CPRs) (prostate locations) and anatomical feature points were explored, and the most feasible anatomical feature points were selected based on the smallest location estimation errors of CPRs and the largest Dice's similarity coefficient (DSC) between the reference and extracted prostates. The reference CPRs were calculated according to reference prostate contours determined by radiation oncologists. Five anatomical feature points were manually determined on a prostate, bladder, and rectum in a sagittal plane of a planning computed tomography image for each case. The CPRs were estimated using three machine learning architectures [artificial neural network, random forest, and support vector machine (SVM)], which learned the relationships between the reference CPRs and anatomical feature points. The CPRs were applied for placing a prostate probabilistic atlas at the coordinates and extracting prostate regions using a Bayesian delineation framework. The average estimation errors without and with SVM using three feature points, which indicated the best performance, were 5.6<U+2009>±<U+2009>3.7 mm and 1.8<U+2009>±<U+2009>1.0 mm, respectively (the smallest error) (p<U+2009>&lt;<U+2009>0.001). The average DSCs without and with SVM using the three feature points were 0.69<U+2009>±<U+2009>0.13 and 0.82<U+2009>±<U+2009>0.055, respectively (the highest DSC) (p<U+2009>&lt;<U+2009>0.001). The anatomical feature points may be feasible for the estimation of prostate locations, which can be applied to the general Bayesian delineation frameworks for prostate cancer radiotherapy.","3":"Radiological physics and technology","4":"30267211","5":"2018","6":"radiation effects"},{"1":"Feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy.","2":"This study aimed to investigate the feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy. The relationships between the reference centroids of prostate regions (CPRs) (prostate locations) and anatomical feature points were explored, and the most feasible anatomical feature points were selected based on the smallest location estimation errors of CPRs and the largest Dice's similarity coefficient (DSC) between the reference and extracted prostates. The reference CPRs were calculated according to reference prostate contours determined by radiation oncologists. Five anatomical feature points were manually determined on a prostate, bladder, and rectum in a sagittal plane of a planning computed tomography image for each case. The CPRs were estimated using three machine learning architectures [artificial neural network, random forest, and support vector machine (SVM)], which learned the relationships between the reference CPRs and anatomical feature points. The CPRs were applied for placing a prostate probabilistic atlas at the coordinates and extracting prostate regions using a Bayesian delineation framework. The average estimation errors without and with SVM using three feature points, which indicated the best performance, were 5.6<U+2009>±<U+2009>3.7 mm and 1.8<U+2009>±<U+2009>1.0 mm, respectively (the smallest error) (p<U+2009>&lt;<U+2009>0.001). The average DSCs without and with SVM using the three feature points were 0.69<U+2009>±<U+2009>0.13 and 0.82<U+2009>±<U+2009>0.055, respectively (the highest DSC) (p<U+2009>&lt;<U+2009>0.001). The anatomical feature points may be feasible for the estimation of prostate locations, which can be applied to the general Bayesian delineation frameworks for prostate cancer radiotherapy.","3":"Radiological physics and technology","4":"30267211","5":"2018","6":"Prostatic Neoplasms"},{"1":"Feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy.","2":"This study aimed to investigate the feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy. The relationships between the reference centroids of prostate regions (CPRs) (prostate locations) and anatomical feature points were explored, and the most feasible anatomical feature points were selected based on the smallest location estimation errors of CPRs and the largest Dice's similarity coefficient (DSC) between the reference and extracted prostates. The reference CPRs were calculated according to reference prostate contours determined by radiation oncologists. Five anatomical feature points were manually determined on a prostate, bladder, and rectum in a sagittal plane of a planning computed tomography image for each case. The CPRs were estimated using three machine learning architectures [artificial neural network, random forest, and support vector machine (SVM)], which learned the relationships between the reference CPRs and anatomical feature points. The CPRs were applied for placing a prostate probabilistic atlas at the coordinates and extracting prostate regions using a Bayesian delineation framework. The average estimation errors without and with SVM using three feature points, which indicated the best performance, were 5.6<U+2009>±<U+2009>3.7 mm and 1.8<U+2009>±<U+2009>1.0 mm, respectively (the smallest error) (p<U+2009>&lt;<U+2009>0.001). The average DSCs without and with SVM using the three feature points were 0.69<U+2009>±<U+2009>0.13 and 0.82<U+2009>±<U+2009>0.055, respectively (the highest DSC) (p<U+2009>&lt;<U+2009>0.001). The anatomical feature points may be feasible for the estimation of prostate locations, which can be applied to the general Bayesian delineation frameworks for prostate cancer radiotherapy.","3":"Radiological physics and technology","4":"30267211","5":"2018","6":"diagnostic imaging"},{"1":"Feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy.","2":"This study aimed to investigate the feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy. The relationships between the reference centroids of prostate regions (CPRs) (prostate locations) and anatomical feature points were explored, and the most feasible anatomical feature points were selected based on the smallest location estimation errors of CPRs and the largest Dice's similarity coefficient (DSC) between the reference and extracted prostates. The reference CPRs were calculated according to reference prostate contours determined by radiation oncologists. Five anatomical feature points were manually determined on a prostate, bladder, and rectum in a sagittal plane of a planning computed tomography image for each case. The CPRs were estimated using three machine learning architectures [artificial neural network, random forest, and support vector machine (SVM)], which learned the relationships between the reference CPRs and anatomical feature points. The CPRs were applied for placing a prostate probabilistic atlas at the coordinates and extracting prostate regions using a Bayesian delineation framework. The average estimation errors without and with SVM using three feature points, which indicated the best performance, were 5.6<U+2009>±<U+2009>3.7 mm and 1.8<U+2009>±<U+2009>1.0 mm, respectively (the smallest error) (p<U+2009>&lt;<U+2009>0.001). The average DSCs without and with SVM using the three feature points were 0.69<U+2009>±<U+2009>0.13 and 0.82<U+2009>±<U+2009>0.055, respectively (the highest DSC) (p<U+2009>&lt;<U+2009>0.001). The anatomical feature points may be feasible for the estimation of prostate locations, which can be applied to the general Bayesian delineation frameworks for prostate cancer radiotherapy.","3":"Radiological physics and technology","4":"30267211","5":"2018","6":"pathology"},{"1":"Feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy.","2":"This study aimed to investigate the feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy. The relationships between the reference centroids of prostate regions (CPRs) (prostate locations) and anatomical feature points were explored, and the most feasible anatomical feature points were selected based on the smallest location estimation errors of CPRs and the largest Dice's similarity coefficient (DSC) between the reference and extracted prostates. The reference CPRs were calculated according to reference prostate contours determined by radiation oncologists. Five anatomical feature points were manually determined on a prostate, bladder, and rectum in a sagittal plane of a planning computed tomography image for each case. The CPRs were estimated using three machine learning architectures [artificial neural network, random forest, and support vector machine (SVM)], which learned the relationships between the reference CPRs and anatomical feature points. The CPRs were applied for placing a prostate probabilistic atlas at the coordinates and extracting prostate regions using a Bayesian delineation framework. The average estimation errors without and with SVM using three feature points, which indicated the best performance, were 5.6<U+2009>±<U+2009>3.7 mm and 1.8<U+2009>±<U+2009>1.0 mm, respectively (the smallest error) (p<U+2009>&lt;<U+2009>0.001). The average DSCs without and with SVM using the three feature points were 0.69<U+2009>±<U+2009>0.13 and 0.82<U+2009>±<U+2009>0.055, respectively (the highest DSC) (p<U+2009>&lt;<U+2009>0.001). The anatomical feature points may be feasible for the estimation of prostate locations, which can be applied to the general Bayesian delineation frameworks for prostate cancer radiotherapy.","3":"Radiological physics and technology","4":"30267211","5":"2018","6":"radiotherapy"},{"1":"Feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy.","2":"This study aimed to investigate the feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy. The relationships between the reference centroids of prostate regions (CPRs) (prostate locations) and anatomical feature points were explored, and the most feasible anatomical feature points were selected based on the smallest location estimation errors of CPRs and the largest Dice's similarity coefficient (DSC) between the reference and extracted prostates. The reference CPRs were calculated according to reference prostate contours determined by radiation oncologists. Five anatomical feature points were manually determined on a prostate, bladder, and rectum in a sagittal plane of a planning computed tomography image for each case. The CPRs were estimated using three machine learning architectures [artificial neural network, random forest, and support vector machine (SVM)], which learned the relationships between the reference CPRs and anatomical feature points. The CPRs were applied for placing a prostate probabilistic atlas at the coordinates and extracting prostate regions using a Bayesian delineation framework. The average estimation errors without and with SVM using three feature points, which indicated the best performance, were 5.6<U+2009>±<U+2009>3.7 mm and 1.8<U+2009>±<U+2009>1.0 mm, respectively (the smallest error) (p<U+2009>&lt;<U+2009>0.001). The average DSCs without and with SVM using the three feature points were 0.69<U+2009>±<U+2009>0.13 and 0.82<U+2009>±<U+2009>0.055, respectively (the highest DSC) (p<U+2009>&lt;<U+2009>0.001). The anatomical feature points may be feasible for the estimation of prostate locations, which can be applied to the general Bayesian delineation frameworks for prostate cancer radiotherapy.","3":"Radiological physics and technology","4":"30267211","5":"2018","6":"Radiotherapy Planning, Computer-Assisted"},{"1":"Feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy.","2":"This study aimed to investigate the feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy. The relationships between the reference centroids of prostate regions (CPRs) (prostate locations) and anatomical feature points were explored, and the most feasible anatomical feature points were selected based on the smallest location estimation errors of CPRs and the largest Dice's similarity coefficient (DSC) between the reference and extracted prostates. The reference CPRs were calculated according to reference prostate contours determined by radiation oncologists. Five anatomical feature points were manually determined on a prostate, bladder, and rectum in a sagittal plane of a planning computed tomography image for each case. The CPRs were estimated using three machine learning architectures [artificial neural network, random forest, and support vector machine (SVM)], which learned the relationships between the reference CPRs and anatomical feature points. The CPRs were applied for placing a prostate probabilistic atlas at the coordinates and extracting prostate regions using a Bayesian delineation framework. The average estimation errors without and with SVM using three feature points, which indicated the best performance, were 5.6<U+2009>±<U+2009>3.7 mm and 1.8<U+2009>±<U+2009>1.0 mm, respectively (the smallest error) (p<U+2009>&lt;<U+2009>0.001). The average DSCs without and with SVM using the three feature points were 0.69<U+2009>±<U+2009>0.13 and 0.82<U+2009>±<U+2009>0.055, respectively (the highest DSC) (p<U+2009>&lt;<U+2009>0.001). The anatomical feature points may be feasible for the estimation of prostate locations, which can be applied to the general Bayesian delineation frameworks for prostate cancer radiotherapy.","3":"Radiological physics and technology","4":"30267211","5":"2018","6":"methods"},{"1":"Feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy.","2":"This study aimed to investigate the feasibility of anatomical feature points for the estimation of prostate locations in the Bayesian delineation frameworks for prostate cancer radiotherapy. The relationships between the reference centroids of prostate regions (CPRs) (prostate locations) and anatomical feature points were explored, and the most feasible anatomical feature points were selected based on the smallest location estimation errors of CPRs and the largest Dice's similarity coefficient (DSC) between the reference and extracted prostates. The reference CPRs were calculated according to reference prostate contours determined by radiation oncologists. Five anatomical feature points were manually determined on a prostate, bladder, and rectum in a sagittal plane of a planning computed tomography image for each case. The CPRs were estimated using three machine learning architectures [artificial neural network, random forest, and support vector machine (SVM)], which learned the relationships between the reference CPRs and anatomical feature points. The CPRs were applied for placing a prostate probabilistic atlas at the coordinates and extracting prostate regions using a Bayesian delineation framework. The average estimation errors without and with SVM using three feature points, which indicated the best performance, were 5.6<U+2009>±<U+2009>3.7 mm and 1.8<U+2009>±<U+2009>1.0 mm, respectively (the smallest error) (p<U+2009>&lt;<U+2009>0.001). The average DSCs without and with SVM using the three feature points were 0.69<U+2009>±<U+2009>0.13 and 0.82<U+2009>±<U+2009>0.055, respectively (the highest DSC) (p<U+2009>&lt;<U+2009>0.001). The anatomical feature points may be feasible for the estimation of prostate locations, which can be applied to the general Bayesian delineation frameworks for prostate cancer radiotherapy.","3":"Radiological physics and technology","4":"30267211","5":"2018","6":"Tomography, X-Ray Computed"},{"1":"Screening of nutritional and genetic anemias using elastic light scattering.","2":"Anemia affects more than ¼ of the world's population, mostly concentrated in low-resource areas, and carries serious health risks. Yet current screening methods are inadequate due to their inability to separate iron deficiency anemia (IDA) from genetic anemias such as thalassemia trait (TT), thus preventing targeted supplementation of oral iron. Here we present an accurate approach to diagnose anemia and anemia type using measures of pediatric red cell morphology determined through machine learning applied to optical light scattering measurements. A partial least squares model shows that our system can accurately extract mean cell volume, red cell size heterogeneity, and mean cell hemoglobin concentration with high accuracy. These clinical parameters (or the raw data itself) can be submitted to machine learning algorithms such as quadratic discriminants or support vector machines to classify a patient into healthy, IDA, or TT. A clinical trial conducted on 268 Chinese children, of which 49 had IDA and 24 had TT, shows &gt;98% sensitivity and specificity for diagnosing anemia, with 81% sensitivity and 86% specificity for discriminating IDA and TT. The majority of the misdiagnoses are IDA patients with particularly severe anemia, possibly requiring hospital care. Therefore, in a screening paradigm where anyone testing positive for TT is sent to the hospital for gold-standard diagnosis and care, we maximize patient benefit while minimizing use of scarce resources.","3":"Lab on a chip","4":"30264831","5":"2018","6":"Anemia, Iron-Deficiency"},{"1":"Screening of nutritional and genetic anemias using elastic light scattering.","2":"Anemia affects more than ¼ of the world's population, mostly concentrated in low-resource areas, and carries serious health risks. Yet current screening methods are inadequate due to their inability to separate iron deficiency anemia (IDA) from genetic anemias such as thalassemia trait (TT), thus preventing targeted supplementation of oral iron. Here we present an accurate approach to diagnose anemia and anemia type using measures of pediatric red cell morphology determined through machine learning applied to optical light scattering measurements. A partial least squares model shows that our system can accurately extract mean cell volume, red cell size heterogeneity, and mean cell hemoglobin concentration with high accuracy. These clinical parameters (or the raw data itself) can be submitted to machine learning algorithms such as quadratic discriminants or support vector machines to classify a patient into healthy, IDA, or TT. A clinical trial conducted on 268 Chinese children, of which 49 had IDA and 24 had TT, shows &gt;98% sensitivity and specificity for diagnosing anemia, with 81% sensitivity and 86% specificity for discriminating IDA and TT. The majority of the misdiagnoses are IDA patients with particularly severe anemia, possibly requiring hospital care. Therefore, in a screening paradigm where anyone testing positive for TT is sent to the hospital for gold-standard diagnosis and care, we maximize patient benefit while minimizing use of scarce resources.","3":"Lab on a chip","4":"30264831","5":"2018","6":"diagnosis"},{"1":"Screening of nutritional and genetic anemias using elastic light scattering.","2":"Anemia affects more than ¼ of the world's population, mostly concentrated in low-resource areas, and carries serious health risks. Yet current screening methods are inadequate due to their inability to separate iron deficiency anemia (IDA) from genetic anemias such as thalassemia trait (TT), thus preventing targeted supplementation of oral iron. Here we present an accurate approach to diagnose anemia and anemia type using measures of pediatric red cell morphology determined through machine learning applied to optical light scattering measurements. A partial least squares model shows that our system can accurately extract mean cell volume, red cell size heterogeneity, and mean cell hemoglobin concentration with high accuracy. These clinical parameters (or the raw data itself) can be submitted to machine learning algorithms such as quadratic discriminants or support vector machines to classify a patient into healthy, IDA, or TT. A clinical trial conducted on 268 Chinese children, of which 49 had IDA and 24 had TT, shows &gt;98% sensitivity and specificity for diagnosing anemia, with 81% sensitivity and 86% specificity for discriminating IDA and TT. The majority of the misdiagnoses are IDA patients with particularly severe anemia, possibly requiring hospital care. Therefore, in a screening paradigm where anyone testing positive for TT is sent to the hospital for gold-standard diagnosis and care, we maximize patient benefit while minimizing use of scarce resources.","3":"Lab on a chip","4":"30264831","5":"2018","6":"genetics"},{"1":"Screening of nutritional and genetic anemias using elastic light scattering.","2":"Anemia affects more than ¼ of the world's population, mostly concentrated in low-resource areas, and carries serious health risks. Yet current screening methods are inadequate due to their inability to separate iron deficiency anemia (IDA) from genetic anemias such as thalassemia trait (TT), thus preventing targeted supplementation of oral iron. Here we present an accurate approach to diagnose anemia and anemia type using measures of pediatric red cell morphology determined through machine learning applied to optical light scattering measurements. A partial least squares model shows that our system can accurately extract mean cell volume, red cell size heterogeneity, and mean cell hemoglobin concentration with high accuracy. These clinical parameters (or the raw data itself) can be submitted to machine learning algorithms such as quadratic discriminants or support vector machines to classify a patient into healthy, IDA, or TT. A clinical trial conducted on 268 Chinese children, of which 49 had IDA and 24 had TT, shows &gt;98% sensitivity and specificity for diagnosing anemia, with 81% sensitivity and 86% specificity for discriminating IDA and TT. The majority of the misdiagnoses are IDA patients with particularly severe anemia, possibly requiring hospital care. Therefore, in a screening paradigm where anyone testing positive for TT is sent to the hospital for gold-standard diagnosis and care, we maximize patient benefit while minimizing use of scarce resources.","3":"Lab on a chip","4":"30264831","5":"2018","6":"Child"},{"1":"Screening of nutritional and genetic anemias using elastic light scattering.","2":"Anemia affects more than ¼ of the world's population, mostly concentrated in low-resource areas, and carries serious health risks. Yet current screening methods are inadequate due to their inability to separate iron deficiency anemia (IDA) from genetic anemias such as thalassemia trait (TT), thus preventing targeted supplementation of oral iron. Here we present an accurate approach to diagnose anemia and anemia type using measures of pediatric red cell morphology determined through machine learning applied to optical light scattering measurements. A partial least squares model shows that our system can accurately extract mean cell volume, red cell size heterogeneity, and mean cell hemoglobin concentration with high accuracy. These clinical parameters (or the raw data itself) can be submitted to machine learning algorithms such as quadratic discriminants or support vector machines to classify a patient into healthy, IDA, or TT. A clinical trial conducted on 268 Chinese children, of which 49 had IDA and 24 had TT, shows &gt;98% sensitivity and specificity for diagnosing anemia, with 81% sensitivity and 86% specificity for discriminating IDA and TT. The majority of the misdiagnoses are IDA patients with particularly severe anemia, possibly requiring hospital care. Therefore, in a screening paradigm where anyone testing positive for TT is sent to the hospital for gold-standard diagnosis and care, we maximize patient benefit while minimizing use of scarce resources.","3":"Lab on a chip","4":"30264831","5":"2018","6":"Child, Preschool"},{"1":"Screening of nutritional and genetic anemias using elastic light scattering.","2":"Anemia affects more than ¼ of the world's population, mostly concentrated in low-resource areas, and carries serious health risks. Yet current screening methods are inadequate due to their inability to separate iron deficiency anemia (IDA) from genetic anemias such as thalassemia trait (TT), thus preventing targeted supplementation of oral iron. Here we present an accurate approach to diagnose anemia and anemia type using measures of pediatric red cell morphology determined through machine learning applied to optical light scattering measurements. A partial least squares model shows that our system can accurately extract mean cell volume, red cell size heterogeneity, and mean cell hemoglobin concentration with high accuracy. These clinical parameters (or the raw data itself) can be submitted to machine learning algorithms such as quadratic discriminants or support vector machines to classify a patient into healthy, IDA, or TT. A clinical trial conducted on 268 Chinese children, of which 49 had IDA and 24 had TT, shows &gt;98% sensitivity and specificity for diagnosing anemia, with 81% sensitivity and 86% specificity for discriminating IDA and TT. The majority of the misdiagnoses are IDA patients with particularly severe anemia, possibly requiring hospital care. Therefore, in a screening paradigm where anyone testing positive for TT is sent to the hospital for gold-standard diagnosis and care, we maximize patient benefit while minimizing use of scarce resources.","3":"Lab on a chip","4":"30264831","5":"2018","6":"Dynamic Light Scattering"},{"1":"Screening of nutritional and genetic anemias using elastic light scattering.","2":"Anemia affects more than ¼ of the world's population, mostly concentrated in low-resource areas, and carries serious health risks. Yet current screening methods are inadequate due to their inability to separate iron deficiency anemia (IDA) from genetic anemias such as thalassemia trait (TT), thus preventing targeted supplementation of oral iron. Here we present an accurate approach to diagnose anemia and anemia type using measures of pediatric red cell morphology determined through machine learning applied to optical light scattering measurements. A partial least squares model shows that our system can accurately extract mean cell volume, red cell size heterogeneity, and mean cell hemoglobin concentration with high accuracy. These clinical parameters (or the raw data itself) can be submitted to machine learning algorithms such as quadratic discriminants or support vector machines to classify a patient into healthy, IDA, or TT. A clinical trial conducted on 268 Chinese children, of which 49 had IDA and 24 had TT, shows &gt;98% sensitivity and specificity for diagnosing anemia, with 81% sensitivity and 86% specificity for discriminating IDA and TT. The majority of the misdiagnoses are IDA patients with particularly severe anemia, possibly requiring hospital care. Therefore, in a screening paradigm where anyone testing positive for TT is sent to the hospital for gold-standard diagnosis and care, we maximize patient benefit while minimizing use of scarce resources.","3":"Lab on a chip","4":"30264831","5":"2018","6":"Female"},{"1":"Screening of nutritional and genetic anemias using elastic light scattering.","2":"Anemia affects more than ¼ of the world's population, mostly concentrated in low-resource areas, and carries serious health risks. Yet current screening methods are inadequate due to their inability to separate iron deficiency anemia (IDA) from genetic anemias such as thalassemia trait (TT), thus preventing targeted supplementation of oral iron. Here we present an accurate approach to diagnose anemia and anemia type using measures of pediatric red cell morphology determined through machine learning applied to optical light scattering measurements. A partial least squares model shows that our system can accurately extract mean cell volume, red cell size heterogeneity, and mean cell hemoglobin concentration with high accuracy. These clinical parameters (or the raw data itself) can be submitted to machine learning algorithms such as quadratic discriminants or support vector machines to classify a patient into healthy, IDA, or TT. A clinical trial conducted on 268 Chinese children, of which 49 had IDA and 24 had TT, shows &gt;98% sensitivity and specificity for diagnosing anemia, with 81% sensitivity and 86% specificity for discriminating IDA and TT. The majority of the misdiagnoses are IDA patients with particularly severe anemia, possibly requiring hospital care. Therefore, in a screening paradigm where anyone testing positive for TT is sent to the hospital for gold-standard diagnosis and care, we maximize patient benefit while minimizing use of scarce resources.","3":"Lab on a chip","4":"30264831","5":"2018","6":"Humans"},{"1":"Screening of nutritional and genetic anemias using elastic light scattering.","2":"Anemia affects more than ¼ of the world's population, mostly concentrated in low-resource areas, and carries serious health risks. Yet current screening methods are inadequate due to their inability to separate iron deficiency anemia (IDA) from genetic anemias such as thalassemia trait (TT), thus preventing targeted supplementation of oral iron. Here we present an accurate approach to diagnose anemia and anemia type using measures of pediatric red cell morphology determined through machine learning applied to optical light scattering measurements. A partial least squares model shows that our system can accurately extract mean cell volume, red cell size heterogeneity, and mean cell hemoglobin concentration with high accuracy. These clinical parameters (or the raw data itself) can be submitted to machine learning algorithms such as quadratic discriminants or support vector machines to classify a patient into healthy, IDA, or TT. A clinical trial conducted on 268 Chinese children, of which 49 had IDA and 24 had TT, shows &gt;98% sensitivity and specificity for diagnosing anemia, with 81% sensitivity and 86% specificity for discriminating IDA and TT. The majority of the misdiagnoses are IDA patients with particularly severe anemia, possibly requiring hospital care. Therefore, in a screening paradigm where anyone testing positive for TT is sent to the hospital for gold-standard diagnosis and care, we maximize patient benefit while minimizing use of scarce resources.","3":"Lab on a chip","4":"30264831","5":"2018","6":"Infant"},{"1":"Screening of nutritional and genetic anemias using elastic light scattering.","2":"Anemia affects more than ¼ of the world's population, mostly concentrated in low-resource areas, and carries serious health risks. Yet current screening methods are inadequate due to their inability to separate iron deficiency anemia (IDA) from genetic anemias such as thalassemia trait (TT), thus preventing targeted supplementation of oral iron. Here we present an accurate approach to diagnose anemia and anemia type using measures of pediatric red cell morphology determined through machine learning applied to optical light scattering measurements. A partial least squares model shows that our system can accurately extract mean cell volume, red cell size heterogeneity, and mean cell hemoglobin concentration with high accuracy. These clinical parameters (or the raw data itself) can be submitted to machine learning algorithms such as quadratic discriminants or support vector machines to classify a patient into healthy, IDA, or TT. A clinical trial conducted on 268 Chinese children, of which 49 had IDA and 24 had TT, shows &gt;98% sensitivity and specificity for diagnosing anemia, with 81% sensitivity and 86% specificity for discriminating IDA and TT. The majority of the misdiagnoses are IDA patients with particularly severe anemia, possibly requiring hospital care. Therefore, in a screening paradigm where anyone testing positive for TT is sent to the hospital for gold-standard diagnosis and care, we maximize patient benefit while minimizing use of scarce resources.","3":"Lab on a chip","4":"30264831","5":"2018","6":"Machine Learning"},{"1":"Screening of nutritional and genetic anemias using elastic light scattering.","2":"Anemia affects more than ¼ of the world's population, mostly concentrated in low-resource areas, and carries serious health risks. Yet current screening methods are inadequate due to their inability to separate iron deficiency anemia (IDA) from genetic anemias such as thalassemia trait (TT), thus preventing targeted supplementation of oral iron. Here we present an accurate approach to diagnose anemia and anemia type using measures of pediatric red cell morphology determined through machine learning applied to optical light scattering measurements. A partial least squares model shows that our system can accurately extract mean cell volume, red cell size heterogeneity, and mean cell hemoglobin concentration with high accuracy. These clinical parameters (or the raw data itself) can be submitted to machine learning algorithms such as quadratic discriminants or support vector machines to classify a patient into healthy, IDA, or TT. A clinical trial conducted on 268 Chinese children, of which 49 had IDA and 24 had TT, shows &gt;98% sensitivity and specificity for diagnosing anemia, with 81% sensitivity and 86% specificity for discriminating IDA and TT. The majority of the misdiagnoses are IDA patients with particularly severe anemia, possibly requiring hospital care. Therefore, in a screening paradigm where anyone testing positive for TT is sent to the hospital for gold-standard diagnosis and care, we maximize patient benefit while minimizing use of scarce resources.","3":"Lab on a chip","4":"30264831","5":"2018","6":"Male"},{"1":"Screening of nutritional and genetic anemias using elastic light scattering.","2":"Anemia affects more than ¼ of the world's population, mostly concentrated in low-resource areas, and carries serious health risks. Yet current screening methods are inadequate due to their inability to separate iron deficiency anemia (IDA) from genetic anemias such as thalassemia trait (TT), thus preventing targeted supplementation of oral iron. Here we present an accurate approach to diagnose anemia and anemia type using measures of pediatric red cell morphology determined through machine learning applied to optical light scattering measurements. A partial least squares model shows that our system can accurately extract mean cell volume, red cell size heterogeneity, and mean cell hemoglobin concentration with high accuracy. These clinical parameters (or the raw data itself) can be submitted to machine learning algorithms such as quadratic discriminants or support vector machines to classify a patient into healthy, IDA, or TT. A clinical trial conducted on 268 Chinese children, of which 49 had IDA and 24 had TT, shows &gt;98% sensitivity and specificity for diagnosing anemia, with 81% sensitivity and 86% specificity for discriminating IDA and TT. The majority of the misdiagnoses are IDA patients with particularly severe anemia, possibly requiring hospital care. Therefore, in a screening paradigm where anyone testing positive for TT is sent to the hospital for gold-standard diagnosis and care, we maximize patient benefit while minimizing use of scarce resources.","3":"Lab on a chip","4":"30264831","5":"2018","6":"Mass Screening"},{"1":"Research: Use of Dry Electroencephalogram and Support Vector for Objective Pain Assessment.","2":"The reliability of normal gel-based electrode electroencephalogram (EEG) for measuring pain has been validated. To date, however, few documented trials have used dry EEG for pain quantification. The primary goal of this study was to objectively quantify pain using dry EEG in conjunction with a support vector machine (SVM). SVMs have been proven accurate for classifying pain intensity. The authors believe that EEG combined with an SVM could increase the statistical power of pain assessment. Currently, clinicians primarily rely on verbal (i.e., subjective) reports for assessing pain; therefore, the research described here could offer a method to objectively monitor pain, eliminate observer error, and individualize treatment.","3":"Biomedical instrumentation &amp; technology","4":"30260658","5":"2018","6":"Adult"},{"1":"Research: Use of Dry Electroencephalogram and Support Vector for Objective Pain Assessment.","2":"The reliability of normal gel-based electrode electroencephalogram (EEG) for measuring pain has been validated. To date, however, few documented trials have used dry EEG for pain quantification. The primary goal of this study was to objectively quantify pain using dry EEG in conjunction with a support vector machine (SVM). SVMs have been proven accurate for classifying pain intensity. The authors believe that EEG combined with an SVM could increase the statistical power of pain assessment. Currently, clinicians primarily rely on verbal (i.e., subjective) reports for assessing pain; therefore, the research described here could offer a method to objectively monitor pain, eliminate observer error, and individualize treatment.","3":"Biomedical instrumentation &amp; technology","4":"30260658","5":"2018","6":"Cohort Studies"},{"1":"Research: Use of Dry Electroencephalogram and Support Vector for Objective Pain Assessment.","2":"The reliability of normal gel-based electrode electroencephalogram (EEG) for measuring pain has been validated. To date, however, few documented trials have used dry EEG for pain quantification. The primary goal of this study was to objectively quantify pain using dry EEG in conjunction with a support vector machine (SVM). SVMs have been proven accurate for classifying pain intensity. The authors believe that EEG combined with an SVM could increase the statistical power of pain assessment. Currently, clinicians primarily rely on verbal (i.e., subjective) reports for assessing pain; therefore, the research described here could offer a method to objectively monitor pain, eliminate observer error, and individualize treatment.","3":"Biomedical instrumentation &amp; technology","4":"30260658","5":"2018","6":"Electroencephalography"},{"1":"Research: Use of Dry Electroencephalogram and Support Vector for Objective Pain Assessment.","2":"The reliability of normal gel-based electrode electroencephalogram (EEG) for measuring pain has been validated. To date, however, few documented trials have used dry EEG for pain quantification. The primary goal of this study was to objectively quantify pain using dry EEG in conjunction with a support vector machine (SVM). SVMs have been proven accurate for classifying pain intensity. The authors believe that EEG combined with an SVM could increase the statistical power of pain assessment. Currently, clinicians primarily rely on verbal (i.e., subjective) reports for assessing pain; therefore, the research described here could offer a method to objectively monitor pain, eliminate observer error, and individualize treatment.","3":"Biomedical instrumentation &amp; technology","4":"30260658","5":"2018","6":"methods"},{"1":"Research: Use of Dry Electroencephalogram and Support Vector for Objective Pain Assessment.","2":"The reliability of normal gel-based electrode electroencephalogram (EEG) for measuring pain has been validated. To date, however, few documented trials have used dry EEG for pain quantification. The primary goal of this study was to objectively quantify pain using dry EEG in conjunction with a support vector machine (SVM). SVMs have been proven accurate for classifying pain intensity. The authors believe that EEG combined with an SVM could increase the statistical power of pain assessment. Currently, clinicians primarily rely on verbal (i.e., subjective) reports for assessing pain; therefore, the research described here could offer a method to objectively monitor pain, eliminate observer error, and individualize treatment.","3":"Biomedical instrumentation &amp; technology","4":"30260658","5":"2018","6":"Female"},{"1":"Research: Use of Dry Electroencephalogram and Support Vector for Objective Pain Assessment.","2":"The reliability of normal gel-based electrode electroencephalogram (EEG) for measuring pain has been validated. To date, however, few documented trials have used dry EEG for pain quantification. The primary goal of this study was to objectively quantify pain using dry EEG in conjunction with a support vector machine (SVM). SVMs have been proven accurate for classifying pain intensity. The authors believe that EEG combined with an SVM could increase the statistical power of pain assessment. Currently, clinicians primarily rely on verbal (i.e., subjective) reports for assessing pain; therefore, the research described here could offer a method to objectively monitor pain, eliminate observer error, and individualize treatment.","3":"Biomedical instrumentation &amp; technology","4":"30260658","5":"2018","6":"Humans"},{"1":"Research: Use of Dry Electroencephalogram and Support Vector for Objective Pain Assessment.","2":"The reliability of normal gel-based electrode electroencephalogram (EEG) for measuring pain has been validated. To date, however, few documented trials have used dry EEG for pain quantification. The primary goal of this study was to objectively quantify pain using dry EEG in conjunction with a support vector machine (SVM). SVMs have been proven accurate for classifying pain intensity. The authors believe that EEG combined with an SVM could increase the statistical power of pain assessment. Currently, clinicians primarily rely on verbal (i.e., subjective) reports for assessing pain; therefore, the research described here could offer a method to objectively monitor pain, eliminate observer error, and individualize treatment.","3":"Biomedical instrumentation &amp; technology","4":"30260658","5":"2018","6":"Male"},{"1":"Research: Use of Dry Electroencephalogram and Support Vector for Objective Pain Assessment.","2":"The reliability of normal gel-based electrode electroencephalogram (EEG) for measuring pain has been validated. To date, however, few documented trials have used dry EEG for pain quantification. The primary goal of this study was to objectively quantify pain using dry EEG in conjunction with a support vector machine (SVM). SVMs have been proven accurate for classifying pain intensity. The authors believe that EEG combined with an SVM could increase the statistical power of pain assessment. Currently, clinicians primarily rely on verbal (i.e., subjective) reports for assessing pain; therefore, the research described here could offer a method to objectively monitor pain, eliminate observer error, and individualize treatment.","3":"Biomedical instrumentation &amp; technology","4":"30260658","5":"2018","6":"Pain Measurement"},{"1":"Research: Use of Dry Electroencephalogram and Support Vector for Objective Pain Assessment.","2":"The reliability of normal gel-based electrode electroencephalogram (EEG) for measuring pain has been validated. To date, however, few documented trials have used dry EEG for pain quantification. The primary goal of this study was to objectively quantify pain using dry EEG in conjunction with a support vector machine (SVM). SVMs have been proven accurate for classifying pain intensity. The authors believe that EEG combined with an SVM could increase the statistical power of pain assessment. Currently, clinicians primarily rely on verbal (i.e., subjective) reports for assessing pain; therefore, the research described here could offer a method to objectively monitor pain, eliminate observer error, and individualize treatment.","3":"Biomedical instrumentation &amp; technology","4":"30260658","5":"2018","6":"methods"},{"1":"Research: Use of Dry Electroencephalogram and Support Vector for Objective Pain Assessment.","2":"The reliability of normal gel-based electrode electroencephalogram (EEG) for measuring pain has been validated. To date, however, few documented trials have used dry EEG for pain quantification. The primary goal of this study was to objectively quantify pain using dry EEG in conjunction with a support vector machine (SVM). SVMs have been proven accurate for classifying pain intensity. The authors believe that EEG combined with an SVM could increase the statistical power of pain assessment. Currently, clinicians primarily rely on verbal (i.e., subjective) reports for assessing pain; therefore, the research described here could offer a method to objectively monitor pain, eliminate observer error, and individualize treatment.","3":"Biomedical instrumentation &amp; technology","4":"30260658","5":"2018","6":"Signal Processing, Computer-Assisted"},{"1":"Research: Use of Dry Electroencephalogram and Support Vector for Objective Pain Assessment.","2":"The reliability of normal gel-based electrode electroencephalogram (EEG) for measuring pain has been validated. To date, however, few documented trials have used dry EEG for pain quantification. The primary goal of this study was to objectively quantify pain using dry EEG in conjunction with a support vector machine (SVM). SVMs have been proven accurate for classifying pain intensity. The authors believe that EEG combined with an SVM could increase the statistical power of pain assessment. Currently, clinicians primarily rely on verbal (i.e., subjective) reports for assessing pain; therefore, the research described here could offer a method to objectively monitor pain, eliminate observer error, and individualize treatment.","3":"Biomedical instrumentation &amp; technology","4":"30260658","5":"2018","6":"Support Vector Machine"},{"1":"Research: Use of Dry Electroencephalogram and Support Vector for Objective Pain Assessment.","2":"The reliability of normal gel-based electrode electroencephalogram (EEG) for measuring pain has been validated. To date, however, few documented trials have used dry EEG for pain quantification. The primary goal of this study was to objectively quantify pain using dry EEG in conjunction with a support vector machine (SVM). SVMs have been proven accurate for classifying pain intensity. The authors believe that EEG combined with an SVM could increase the statistical power of pain assessment. Currently, clinicians primarily rely on verbal (i.e., subjective) reports for assessing pain; therefore, the research described here could offer a method to objectively monitor pain, eliminate observer error, and individualize treatment.","3":"Biomedical instrumentation &amp; technology","4":"30260658","5":"2018","6":"Young Adult"},{"1":"Genome-scale MicroRNA target prediction through clustering with Dirichlet process mixture model.","2":"BACKGROUND: MicroRNA regulation is fundamentally responsible for fine-tuning the whole gene network in human and has been implicated in most physiological and pathological conditions. Studying regulatory impact of microRNA on various cellular and disease processes has resulted in numerous computational tools that investigate microRNA-mRNA interactions through the prediction of static binding site highly dependent on sequence pairing. However, what hindered the practical use of such target prediction is the interplay between competing and cooperative microRNA binding that complicates the whole regulatory process exceptionally.RESULTS: We developed a new method for improved microRNA target prediction based on Dirichlet Process Gaussian Mixture Model (DPGMM) using a large collection of molecular features associated with microRNA, mRNA, and the interaction sites. Multiple validations based on microRNA-mRNA interactions reported in recent large-scale sequencing analyses and a screening test on the entire human transcriptome show that our model outperformed several state-of-the-art tools in terms of promising predictive power on binding sites specific to transcript isoforms with reduced false positive prediction. Last, we illustrated the use of predicted targets in constructing conditional microRNA-mediated gene regulation networks in human cancer.CONCLUSION: The probability-based binding site prediction provides not only a useful tool for differentiating microRNA targets according to the estimated binding potential but also a capability highly important for exploring dynamic regulation where binding competition is involved.","3":"BMC genomics","4":"30255782","5":"2018","6":"Algorithms"},{"1":"Genome-scale MicroRNA target prediction through clustering with Dirichlet process mixture model.","2":"BACKGROUND: MicroRNA regulation is fundamentally responsible for fine-tuning the whole gene network in human and has been implicated in most physiological and pathological conditions. Studying regulatory impact of microRNA on various cellular and disease processes has resulted in numerous computational tools that investigate microRNA-mRNA interactions through the prediction of static binding site highly dependent on sequence pairing. However, what hindered the practical use of such target prediction is the interplay between competing and cooperative microRNA binding that complicates the whole regulatory process exceptionally.RESULTS: We developed a new method for improved microRNA target prediction based on Dirichlet Process Gaussian Mixture Model (DPGMM) using a large collection of molecular features associated with microRNA, mRNA, and the interaction sites. Multiple validations based on microRNA-mRNA interactions reported in recent large-scale sequencing analyses and a screening test on the entire human transcriptome show that our model outperformed several state-of-the-art tools in terms of promising predictive power on binding sites specific to transcript isoforms with reduced false positive prediction. Last, we illustrated the use of predicted targets in constructing conditional microRNA-mediated gene regulation networks in human cancer.CONCLUSION: The probability-based binding site prediction provides not only a useful tool for differentiating microRNA targets according to the estimated binding potential but also a capability highly important for exploring dynamic regulation where binding competition is involved.","3":"BMC genomics","4":"30255782","5":"2018","6":"Bayes Theorem"},{"1":"Genome-scale MicroRNA target prediction through clustering with Dirichlet process mixture model.","2":"BACKGROUND: MicroRNA regulation is fundamentally responsible for fine-tuning the whole gene network in human and has been implicated in most physiological and pathological conditions. Studying regulatory impact of microRNA on various cellular and disease processes has resulted in numerous computational tools that investigate microRNA-mRNA interactions through the prediction of static binding site highly dependent on sequence pairing. However, what hindered the practical use of such target prediction is the interplay between competing and cooperative microRNA binding that complicates the whole regulatory process exceptionally.RESULTS: We developed a new method for improved microRNA target prediction based on Dirichlet Process Gaussian Mixture Model (DPGMM) using a large collection of molecular features associated with microRNA, mRNA, and the interaction sites. Multiple validations based on microRNA-mRNA interactions reported in recent large-scale sequencing analyses and a screening test on the entire human transcriptome show that our model outperformed several state-of-the-art tools in terms of promising predictive power on binding sites specific to transcript isoforms with reduced false positive prediction. Last, we illustrated the use of predicted targets in constructing conditional microRNA-mediated gene regulation networks in human cancer.CONCLUSION: The probability-based binding site prediction provides not only a useful tool for differentiating microRNA targets according to the estimated binding potential but also a capability highly important for exploring dynamic regulation where binding competition is involved.","3":"BMC genomics","4":"30255782","5":"2018","6":"Binding Sites"},{"1":"Genome-scale MicroRNA target prediction through clustering with Dirichlet process mixture model.","2":"BACKGROUND: MicroRNA regulation is fundamentally responsible for fine-tuning the whole gene network in human and has been implicated in most physiological and pathological conditions. Studying regulatory impact of microRNA on various cellular and disease processes has resulted in numerous computational tools that investigate microRNA-mRNA interactions through the prediction of static binding site highly dependent on sequence pairing. However, what hindered the practical use of such target prediction is the interplay between competing and cooperative microRNA binding that complicates the whole regulatory process exceptionally.RESULTS: We developed a new method for improved microRNA target prediction based on Dirichlet Process Gaussian Mixture Model (DPGMM) using a large collection of molecular features associated with microRNA, mRNA, and the interaction sites. Multiple validations based on microRNA-mRNA interactions reported in recent large-scale sequencing analyses and a screening test on the entire human transcriptome show that our model outperformed several state-of-the-art tools in terms of promising predictive power on binding sites specific to transcript isoforms with reduced false positive prediction. Last, we illustrated the use of predicted targets in constructing conditional microRNA-mediated gene regulation networks in human cancer.CONCLUSION: The probability-based binding site prediction provides not only a useful tool for differentiating microRNA targets according to the estimated binding potential but also a capability highly important for exploring dynamic regulation where binding competition is involved.","3":"BMC genomics","4":"30255782","5":"2018","6":"Computational Biology"},{"1":"Genome-scale MicroRNA target prediction through clustering with Dirichlet process mixture model.","2":"BACKGROUND: MicroRNA regulation is fundamentally responsible for fine-tuning the whole gene network in human and has been implicated in most physiological and pathological conditions. Studying regulatory impact of microRNA on various cellular and disease processes has resulted in numerous computational tools that investigate microRNA-mRNA interactions through the prediction of static binding site highly dependent on sequence pairing. However, what hindered the practical use of such target prediction is the interplay between competing and cooperative microRNA binding that complicates the whole regulatory process exceptionally.RESULTS: We developed a new method for improved microRNA target prediction based on Dirichlet Process Gaussian Mixture Model (DPGMM) using a large collection of molecular features associated with microRNA, mRNA, and the interaction sites. Multiple validations based on microRNA-mRNA interactions reported in recent large-scale sequencing analyses and a screening test on the entire human transcriptome show that our model outperformed several state-of-the-art tools in terms of promising predictive power on binding sites specific to transcript isoforms with reduced false positive prediction. Last, we illustrated the use of predicted targets in constructing conditional microRNA-mediated gene regulation networks in human cancer.CONCLUSION: The probability-based binding site prediction provides not only a useful tool for differentiating microRNA targets according to the estimated binding potential but also a capability highly important for exploring dynamic regulation where binding competition is involved.","3":"BMC genomics","4":"30255782","5":"2018","6":"Gene Expression Regulation, Neoplastic"},{"1":"Genome-scale MicroRNA target prediction through clustering with Dirichlet process mixture model.","2":"BACKGROUND: MicroRNA regulation is fundamentally responsible for fine-tuning the whole gene network in human and has been implicated in most physiological and pathological conditions. Studying regulatory impact of microRNA on various cellular and disease processes has resulted in numerous computational tools that investigate microRNA-mRNA interactions through the prediction of static binding site highly dependent on sequence pairing. However, what hindered the practical use of such target prediction is the interplay between competing and cooperative microRNA binding that complicates the whole regulatory process exceptionally.RESULTS: We developed a new method for improved microRNA target prediction based on Dirichlet Process Gaussian Mixture Model (DPGMM) using a large collection of molecular features associated with microRNA, mRNA, and the interaction sites. Multiple validations based on microRNA-mRNA interactions reported in recent large-scale sequencing analyses and a screening test on the entire human transcriptome show that our model outperformed several state-of-the-art tools in terms of promising predictive power on binding sites specific to transcript isoforms with reduced false positive prediction. Last, we illustrated the use of predicted targets in constructing conditional microRNA-mediated gene regulation networks in human cancer.CONCLUSION: The probability-based binding site prediction provides not only a useful tool for differentiating microRNA targets according to the estimated binding potential but also a capability highly important for exploring dynamic regulation where binding competition is involved.","3":"BMC genomics","4":"30255782","5":"2018","6":"Gene Regulatory Networks"},{"1":"Genome-scale MicroRNA target prediction through clustering with Dirichlet process mixture model.","2":"BACKGROUND: MicroRNA regulation is fundamentally responsible for fine-tuning the whole gene network in human and has been implicated in most physiological and pathological conditions. Studying regulatory impact of microRNA on various cellular and disease processes has resulted in numerous computational tools that investigate microRNA-mRNA interactions through the prediction of static binding site highly dependent on sequence pairing. However, what hindered the practical use of such target prediction is the interplay between competing and cooperative microRNA binding that complicates the whole regulatory process exceptionally.RESULTS: We developed a new method for improved microRNA target prediction based on Dirichlet Process Gaussian Mixture Model (DPGMM) using a large collection of molecular features associated with microRNA, mRNA, and the interaction sites. Multiple validations based on microRNA-mRNA interactions reported in recent large-scale sequencing analyses and a screening test on the entire human transcriptome show that our model outperformed several state-of-the-art tools in terms of promising predictive power on binding sites specific to transcript isoforms with reduced false positive prediction. Last, we illustrated the use of predicted targets in constructing conditional microRNA-mediated gene regulation networks in human cancer.CONCLUSION: The probability-based binding site prediction provides not only a useful tool for differentiating microRNA targets according to the estimated binding potential but also a capability highly important for exploring dynamic regulation where binding competition is involved.","3":"BMC genomics","4":"30255782","5":"2018","6":"Genome, Human"},{"1":"Genome-scale MicroRNA target prediction through clustering with Dirichlet process mixture model.","2":"BACKGROUND: MicroRNA regulation is fundamentally responsible for fine-tuning the whole gene network in human and has been implicated in most physiological and pathological conditions. Studying regulatory impact of microRNA on various cellular and disease processes has resulted in numerous computational tools that investigate microRNA-mRNA interactions through the prediction of static binding site highly dependent on sequence pairing. However, what hindered the practical use of such target prediction is the interplay between competing and cooperative microRNA binding that complicates the whole regulatory process exceptionally.RESULTS: We developed a new method for improved microRNA target prediction based on Dirichlet Process Gaussian Mixture Model (DPGMM) using a large collection of molecular features associated with microRNA, mRNA, and the interaction sites. Multiple validations based on microRNA-mRNA interactions reported in recent large-scale sequencing analyses and a screening test on the entire human transcriptome show that our model outperformed several state-of-the-art tools in terms of promising predictive power on binding sites specific to transcript isoforms with reduced false positive prediction. Last, we illustrated the use of predicted targets in constructing conditional microRNA-mediated gene regulation networks in human cancer.CONCLUSION: The probability-based binding site prediction provides not only a useful tool for differentiating microRNA targets according to the estimated binding potential but also a capability highly important for exploring dynamic regulation where binding competition is involved.","3":"BMC genomics","4":"30255782","5":"2018","6":"Humans"},{"1":"Genome-scale MicroRNA target prediction through clustering with Dirichlet process mixture model.","2":"BACKGROUND: MicroRNA regulation is fundamentally responsible for fine-tuning the whole gene network in human and has been implicated in most physiological and pathological conditions. Studying regulatory impact of microRNA on various cellular and disease processes has resulted in numerous computational tools that investigate microRNA-mRNA interactions through the prediction of static binding site highly dependent on sequence pairing. However, what hindered the practical use of such target prediction is the interplay between competing and cooperative microRNA binding that complicates the whole regulatory process exceptionally.RESULTS: We developed a new method for improved microRNA target prediction based on Dirichlet Process Gaussian Mixture Model (DPGMM) using a large collection of molecular features associated with microRNA, mRNA, and the interaction sites. Multiple validations based on microRNA-mRNA interactions reported in recent large-scale sequencing analyses and a screening test on the entire human transcriptome show that our model outperformed several state-of-the-art tools in terms of promising predictive power on binding sites specific to transcript isoforms with reduced false positive prediction. Last, we illustrated the use of predicted targets in constructing conditional microRNA-mediated gene regulation networks in human cancer.CONCLUSION: The probability-based binding site prediction provides not only a useful tool for differentiating microRNA targets according to the estimated binding potential but also a capability highly important for exploring dynamic regulation where binding competition is involved.","3":"BMC genomics","4":"30255782","5":"2018","6":"Machine Learning"},{"1":"Genome-scale MicroRNA target prediction through clustering with Dirichlet process mixture model.","2":"BACKGROUND: MicroRNA regulation is fundamentally responsible for fine-tuning the whole gene network in human and has been implicated in most physiological and pathological conditions. Studying regulatory impact of microRNA on various cellular and disease processes has resulted in numerous computational tools that investigate microRNA-mRNA interactions through the prediction of static binding site highly dependent on sequence pairing. However, what hindered the practical use of such target prediction is the interplay between competing and cooperative microRNA binding that complicates the whole regulatory process exceptionally.RESULTS: We developed a new method for improved microRNA target prediction based on Dirichlet Process Gaussian Mixture Model (DPGMM) using a large collection of molecular features associated with microRNA, mRNA, and the interaction sites. Multiple validations based on microRNA-mRNA interactions reported in recent large-scale sequencing analyses and a screening test on the entire human transcriptome show that our model outperformed several state-of-the-art tools in terms of promising predictive power on binding sites specific to transcript isoforms with reduced false positive prediction. Last, we illustrated the use of predicted targets in constructing conditional microRNA-mediated gene regulation networks in human cancer.CONCLUSION: The probability-based binding site prediction provides not only a useful tool for differentiating microRNA targets according to the estimated binding potential but also a capability highly important for exploring dynamic regulation where binding competition is involved.","3":"BMC genomics","4":"30255782","5":"2018","6":"MicroRNAs"},{"1":"Genome-scale MicroRNA target prediction through clustering with Dirichlet process mixture model.","2":"BACKGROUND: MicroRNA regulation is fundamentally responsible for fine-tuning the whole gene network in human and has been implicated in most physiological and pathological conditions. Studying regulatory impact of microRNA on various cellular and disease processes has resulted in numerous computational tools that investigate microRNA-mRNA interactions through the prediction of static binding site highly dependent on sequence pairing. However, what hindered the practical use of such target prediction is the interplay between competing and cooperative microRNA binding that complicates the whole regulatory process exceptionally.RESULTS: We developed a new method for improved microRNA target prediction based on Dirichlet Process Gaussian Mixture Model (DPGMM) using a large collection of molecular features associated with microRNA, mRNA, and the interaction sites. Multiple validations based on microRNA-mRNA interactions reported in recent large-scale sequencing analyses and a screening test on the entire human transcriptome show that our model outperformed several state-of-the-art tools in terms of promising predictive power on binding sites specific to transcript isoforms with reduced false positive prediction. Last, we illustrated the use of predicted targets in constructing conditional microRNA-mediated gene regulation networks in human cancer.CONCLUSION: The probability-based binding site prediction provides not only a useful tool for differentiating microRNA targets according to the estimated binding potential but also a capability highly important for exploring dynamic regulation where binding competition is involved.","3":"BMC genomics","4":"30255782","5":"2018","6":"genetics"},{"1":"Genome-scale MicroRNA target prediction through clustering with Dirichlet process mixture model.","2":"BACKGROUND: MicroRNA regulation is fundamentally responsible for fine-tuning the whole gene network in human and has been implicated in most physiological and pathological conditions. Studying regulatory impact of microRNA on various cellular and disease processes has resulted in numerous computational tools that investigate microRNA-mRNA interactions through the prediction of static binding site highly dependent on sequence pairing. However, what hindered the practical use of such target prediction is the interplay between competing and cooperative microRNA binding that complicates the whole regulatory process exceptionally.RESULTS: We developed a new method for improved microRNA target prediction based on Dirichlet Process Gaussian Mixture Model (DPGMM) using a large collection of molecular features associated with microRNA, mRNA, and the interaction sites. Multiple validations based on microRNA-mRNA interactions reported in recent large-scale sequencing analyses and a screening test on the entire human transcriptome show that our model outperformed several state-of-the-art tools in terms of promising predictive power on binding sites specific to transcript isoforms with reduced false positive prediction. Last, we illustrated the use of predicted targets in constructing conditional microRNA-mediated gene regulation networks in human cancer.CONCLUSION: The probability-based binding site prediction provides not only a useful tool for differentiating microRNA targets according to the estimated binding potential but also a capability highly important for exploring dynamic regulation where binding competition is involved.","3":"BMC genomics","4":"30255782","5":"2018","6":"Neoplasms"},{"1":"Genome-scale MicroRNA target prediction through clustering with Dirichlet process mixture model.","2":"BACKGROUND: MicroRNA regulation is fundamentally responsible for fine-tuning the whole gene network in human and has been implicated in most physiological and pathological conditions. Studying regulatory impact of microRNA on various cellular and disease processes has resulted in numerous computational tools that investigate microRNA-mRNA interactions through the prediction of static binding site highly dependent on sequence pairing. However, what hindered the practical use of such target prediction is the interplay between competing and cooperative microRNA binding that complicates the whole regulatory process exceptionally.RESULTS: We developed a new method for improved microRNA target prediction based on Dirichlet Process Gaussian Mixture Model (DPGMM) using a large collection of molecular features associated with microRNA, mRNA, and the interaction sites. Multiple validations based on microRNA-mRNA interactions reported in recent large-scale sequencing analyses and a screening test on the entire human transcriptome show that our model outperformed several state-of-the-art tools in terms of promising predictive power on binding sites specific to transcript isoforms with reduced false positive prediction. Last, we illustrated the use of predicted targets in constructing conditional microRNA-mediated gene regulation networks in human cancer.CONCLUSION: The probability-based binding site prediction provides not only a useful tool for differentiating microRNA targets according to the estimated binding potential but also a capability highly important for exploring dynamic regulation where binding competition is involved.","3":"BMC genomics","4":"30255782","5":"2018","6":"genetics"},{"1":"Genome-scale MicroRNA target prediction through clustering with Dirichlet process mixture model.","2":"BACKGROUND: MicroRNA regulation is fundamentally responsible for fine-tuning the whole gene network in human and has been implicated in most physiological and pathological conditions. Studying regulatory impact of microRNA on various cellular and disease processes has resulted in numerous computational tools that investigate microRNA-mRNA interactions through the prediction of static binding site highly dependent on sequence pairing. However, what hindered the practical use of such target prediction is the interplay between competing and cooperative microRNA binding that complicates the whole regulatory process exceptionally.RESULTS: We developed a new method for improved microRNA target prediction based on Dirichlet Process Gaussian Mixture Model (DPGMM) using a large collection of molecular features associated with microRNA, mRNA, and the interaction sites. Multiple validations based on microRNA-mRNA interactions reported in recent large-scale sequencing analyses and a screening test on the entire human transcriptome show that our model outperformed several state-of-the-art tools in terms of promising predictive power on binding sites specific to transcript isoforms with reduced false positive prediction. Last, we illustrated the use of predicted targets in constructing conditional microRNA-mediated gene regulation networks in human cancer.CONCLUSION: The probability-based binding site prediction provides not only a useful tool for differentiating microRNA targets according to the estimated binding potential but also a capability highly important for exploring dynamic regulation where binding competition is involved.","3":"BMC genomics","4":"30255782","5":"2018","6":"metabolism"},{"1":"Genome-scale MicroRNA target prediction through clustering with Dirichlet process mixture model.","2":"BACKGROUND: MicroRNA regulation is fundamentally responsible for fine-tuning the whole gene network in human and has been implicated in most physiological and pathological conditions. Studying regulatory impact of microRNA on various cellular and disease processes has resulted in numerous computational tools that investigate microRNA-mRNA interactions through the prediction of static binding site highly dependent on sequence pairing. However, what hindered the practical use of such target prediction is the interplay between competing and cooperative microRNA binding that complicates the whole regulatory process exceptionally.RESULTS: We developed a new method for improved microRNA target prediction based on Dirichlet Process Gaussian Mixture Model (DPGMM) using a large collection of molecular features associated with microRNA, mRNA, and the interaction sites. Multiple validations based on microRNA-mRNA interactions reported in recent large-scale sequencing analyses and a screening test on the entire human transcriptome show that our model outperformed several state-of-the-art tools in terms of promising predictive power on binding sites specific to transcript isoforms with reduced false positive prediction. Last, we illustrated the use of predicted targets in constructing conditional microRNA-mediated gene regulation networks in human cancer.CONCLUSION: The probability-based binding site prediction provides not only a useful tool for differentiating microRNA targets according to the estimated binding potential but also a capability highly important for exploring dynamic regulation where binding competition is involved.","3":"BMC genomics","4":"30255782","5":"2018","6":"pathology"},{"1":"Genome-scale MicroRNA target prediction through clustering with Dirichlet process mixture model.","2":"BACKGROUND: MicroRNA regulation is fundamentally responsible for fine-tuning the whole gene network in human and has been implicated in most physiological and pathological conditions. Studying regulatory impact of microRNA on various cellular and disease processes has resulted in numerous computational tools that investigate microRNA-mRNA interactions through the prediction of static binding site highly dependent on sequence pairing. However, what hindered the practical use of such target prediction is the interplay between competing and cooperative microRNA binding that complicates the whole regulatory process exceptionally.RESULTS: We developed a new method for improved microRNA target prediction based on Dirichlet Process Gaussian Mixture Model (DPGMM) using a large collection of molecular features associated with microRNA, mRNA, and the interaction sites. Multiple validations based on microRNA-mRNA interactions reported in recent large-scale sequencing analyses and a screening test on the entire human transcriptome show that our model outperformed several state-of-the-art tools in terms of promising predictive power on binding sites specific to transcript isoforms with reduced false positive prediction. Last, we illustrated the use of predicted targets in constructing conditional microRNA-mediated gene regulation networks in human cancer.CONCLUSION: The probability-based binding site prediction provides not only a useful tool for differentiating microRNA targets according to the estimated binding potential but also a capability highly important for exploring dynamic regulation where binding competition is involved.","3":"BMC genomics","4":"30255782","5":"2018","6":"RNA, Messenger"},{"1":"Genome-scale MicroRNA target prediction through clustering with Dirichlet process mixture model.","2":"BACKGROUND: MicroRNA regulation is fundamentally responsible for fine-tuning the whole gene network in human and has been implicated in most physiological and pathological conditions. Studying regulatory impact of microRNA on various cellular and disease processes has resulted in numerous computational tools that investigate microRNA-mRNA interactions through the prediction of static binding site highly dependent on sequence pairing. However, what hindered the practical use of such target prediction is the interplay between competing and cooperative microRNA binding that complicates the whole regulatory process exceptionally.RESULTS: We developed a new method for improved microRNA target prediction based on Dirichlet Process Gaussian Mixture Model (DPGMM) using a large collection of molecular features associated with microRNA, mRNA, and the interaction sites. Multiple validations based on microRNA-mRNA interactions reported in recent large-scale sequencing analyses and a screening test on the entire human transcriptome show that our model outperformed several state-of-the-art tools in terms of promising predictive power on binding sites specific to transcript isoforms with reduced false positive prediction. Last, we illustrated the use of predicted targets in constructing conditional microRNA-mediated gene regulation networks in human cancer.CONCLUSION: The probability-based binding site prediction provides not only a useful tool for differentiating microRNA targets according to the estimated binding potential but also a capability highly important for exploring dynamic regulation where binding competition is involved.","3":"BMC genomics","4":"30255782","5":"2018","6":"genetics"},{"1":"Genome-scale MicroRNA target prediction through clustering with Dirichlet process mixture model.","2":"BACKGROUND: MicroRNA regulation is fundamentally responsible for fine-tuning the whole gene network in human and has been implicated in most physiological and pathological conditions. Studying regulatory impact of microRNA on various cellular and disease processes has resulted in numerous computational tools that investigate microRNA-mRNA interactions through the prediction of static binding site highly dependent on sequence pairing. However, what hindered the practical use of such target prediction is the interplay between competing and cooperative microRNA binding that complicates the whole regulatory process exceptionally.RESULTS: We developed a new method for improved microRNA target prediction based on Dirichlet Process Gaussian Mixture Model (DPGMM) using a large collection of molecular features associated with microRNA, mRNA, and the interaction sites. Multiple validations based on microRNA-mRNA interactions reported in recent large-scale sequencing analyses and a screening test on the entire human transcriptome show that our model outperformed several state-of-the-art tools in terms of promising predictive power on binding sites specific to transcript isoforms with reduced false positive prediction. Last, we illustrated the use of predicted targets in constructing conditional microRNA-mediated gene regulation networks in human cancer.CONCLUSION: The probability-based binding site prediction provides not only a useful tool for differentiating microRNA targets according to the estimated binding potential but also a capability highly important for exploring dynamic regulation where binding competition is involved.","3":"BMC genomics","4":"30255782","5":"2018","6":"metabolism"},{"1":"Genome-scale MicroRNA target prediction through clustering with Dirichlet process mixture model.","2":"BACKGROUND: MicroRNA regulation is fundamentally responsible for fine-tuning the whole gene network in human and has been implicated in most physiological and pathological conditions. Studying regulatory impact of microRNA on various cellular and disease processes has resulted in numerous computational tools that investigate microRNA-mRNA interactions through the prediction of static binding site highly dependent on sequence pairing. However, what hindered the practical use of such target prediction is the interplay between competing and cooperative microRNA binding that complicates the whole regulatory process exceptionally.RESULTS: We developed a new method for improved microRNA target prediction based on Dirichlet Process Gaussian Mixture Model (DPGMM) using a large collection of molecular features associated with microRNA, mRNA, and the interaction sites. Multiple validations based on microRNA-mRNA interactions reported in recent large-scale sequencing analyses and a screening test on the entire human transcriptome show that our model outperformed several state-of-the-art tools in terms of promising predictive power on binding sites specific to transcript isoforms with reduced false positive prediction. Last, we illustrated the use of predicted targets in constructing conditional microRNA-mediated gene regulation networks in human cancer.CONCLUSION: The probability-based binding site prediction provides not only a useful tool for differentiating microRNA targets according to the estimated binding potential but also a capability highly important for exploring dynamic regulation where binding competition is involved.","3":"BMC genomics","4":"30255782","5":"2018","6":"Transcriptome"},{"1":"Machine Learning for detection of viral sequences in human metagenomic datasets.","2":"BACKGROUND: Detection of highly divergent or yet unknown viruses from metagenomics sequencing datasets is a major bioinformatics challenge. When human samples are sequenced, a large proportion of assembled contigs are classified as &quot;unknown&quot;, as conventional methods find no similarity to known sequences. We wished to explore whether machine learning algorithms using Relative Synonymous Codon Usage frequency (RSCU) could improve the detection of viral sequences in metagenomic sequencing data.RESULTS: We trained Random Forest and Artificial Neural Network using metagenomic sequences taxonomically classified into virus and non-virus classes. The algorithms achieved accuracies well beyond chance level, with area under ROC curve 0.79. Two codons (TCG and CGC) were found to have a particularly strong discriminative capacity.CONCLUSION: RSCU-based machine learning techniques applied to metagenomic sequencing data can help identify a large number of putative viral sequences and provide an addition to conventional methods for taxonomic classification.","3":"BMC bioinformatics","4":"30249176","5":"2018","6":"Algorithms"},{"1":"Machine Learning for detection of viral sequences in human metagenomic datasets.","2":"BACKGROUND: Detection of highly divergent or yet unknown viruses from metagenomics sequencing datasets is a major bioinformatics challenge. When human samples are sequenced, a large proportion of assembled contigs are classified as &quot;unknown&quot;, as conventional methods find no similarity to known sequences. We wished to explore whether machine learning algorithms using Relative Synonymous Codon Usage frequency (RSCU) could improve the detection of viral sequences in metagenomic sequencing data.RESULTS: We trained Random Forest and Artificial Neural Network using metagenomic sequences taxonomically classified into virus and non-virus classes. The algorithms achieved accuracies well beyond chance level, with area under ROC curve 0.79. Two codons (TCG and CGC) were found to have a particularly strong discriminative capacity.CONCLUSION: RSCU-based machine learning techniques applied to metagenomic sequencing data can help identify a large number of putative viral sequences and provide an addition to conventional methods for taxonomic classification.","3":"BMC bioinformatics","4":"30249176","5":"2018","6":"Base Sequence"},{"1":"Machine Learning for detection of viral sequences in human metagenomic datasets.","2":"BACKGROUND: Detection of highly divergent or yet unknown viruses from metagenomics sequencing datasets is a major bioinformatics challenge. When human samples are sequenced, a large proportion of assembled contigs are classified as &quot;unknown&quot;, as conventional methods find no similarity to known sequences. We wished to explore whether machine learning algorithms using Relative Synonymous Codon Usage frequency (RSCU) could improve the detection of viral sequences in metagenomic sequencing data.RESULTS: We trained Random Forest and Artificial Neural Network using metagenomic sequences taxonomically classified into virus and non-virus classes. The algorithms achieved accuracies well beyond chance level, with area under ROC curve 0.79. Two codons (TCG and CGC) were found to have a particularly strong discriminative capacity.CONCLUSION: RSCU-based machine learning techniques applied to metagenomic sequencing data can help identify a large number of putative viral sequences and provide an addition to conventional methods for taxonomic classification.","3":"BMC bioinformatics","4":"30249176","5":"2018","6":"Computational Biology"},{"1":"Machine Learning for detection of viral sequences in human metagenomic datasets.","2":"BACKGROUND: Detection of highly divergent or yet unknown viruses from metagenomics sequencing datasets is a major bioinformatics challenge. When human samples are sequenced, a large proportion of assembled contigs are classified as &quot;unknown&quot;, as conventional methods find no similarity to known sequences. We wished to explore whether machine learning algorithms using Relative Synonymous Codon Usage frequency (RSCU) could improve the detection of viral sequences in metagenomic sequencing data.RESULTS: We trained Random Forest and Artificial Neural Network using metagenomic sequences taxonomically classified into virus and non-virus classes. The algorithms achieved accuracies well beyond chance level, with area under ROC curve 0.79. Two codons (TCG and CGC) were found to have a particularly strong discriminative capacity.CONCLUSION: RSCU-based machine learning techniques applied to metagenomic sequencing data can help identify a large number of putative viral sequences and provide an addition to conventional methods for taxonomic classification.","3":"BMC bioinformatics","4":"30249176","5":"2018","6":"Databases, Genetic"},{"1":"Machine Learning for detection of viral sequences in human metagenomic datasets.","2":"BACKGROUND: Detection of highly divergent or yet unknown viruses from metagenomics sequencing datasets is a major bioinformatics challenge. When human samples are sequenced, a large proportion of assembled contigs are classified as &quot;unknown&quot;, as conventional methods find no similarity to known sequences. We wished to explore whether machine learning algorithms using Relative Synonymous Codon Usage frequency (RSCU) could improve the detection of viral sequences in metagenomic sequencing data.RESULTS: We trained Random Forest and Artificial Neural Network using metagenomic sequences taxonomically classified into virus and non-virus classes. The algorithms achieved accuracies well beyond chance level, with area under ROC curve 0.79. Two codons (TCG and CGC) were found to have a particularly strong discriminative capacity.CONCLUSION: RSCU-based machine learning techniques applied to metagenomic sequencing data can help identify a large number of putative viral sequences and provide an addition to conventional methods for taxonomic classification.","3":"BMC bioinformatics","4":"30249176","5":"2018","6":"Humans"},{"1":"Machine Learning for detection of viral sequences in human metagenomic datasets.","2":"BACKGROUND: Detection of highly divergent or yet unknown viruses from metagenomics sequencing datasets is a major bioinformatics challenge. When human samples are sequenced, a large proportion of assembled contigs are classified as &quot;unknown&quot;, as conventional methods find no similarity to known sequences. We wished to explore whether machine learning algorithms using Relative Synonymous Codon Usage frequency (RSCU) could improve the detection of viral sequences in metagenomic sequencing data.RESULTS: We trained Random Forest and Artificial Neural Network using metagenomic sequences taxonomically classified into virus and non-virus classes. The algorithms achieved accuracies well beyond chance level, with area under ROC curve 0.79. Two codons (TCG and CGC) were found to have a particularly strong discriminative capacity.CONCLUSION: RSCU-based machine learning techniques applied to metagenomic sequencing data can help identify a large number of putative viral sequences and provide an addition to conventional methods for taxonomic classification.","3":"BMC bioinformatics","4":"30249176","5":"2018","6":"Machine Learning"},{"1":"Machine Learning for detection of viral sequences in human metagenomic datasets.","2":"BACKGROUND: Detection of highly divergent or yet unknown viruses from metagenomics sequencing datasets is a major bioinformatics challenge. When human samples are sequenced, a large proportion of assembled contigs are classified as &quot;unknown&quot;, as conventional methods find no similarity to known sequences. We wished to explore whether machine learning algorithms using Relative Synonymous Codon Usage frequency (RSCU) could improve the detection of viral sequences in metagenomic sequencing data.RESULTS: We trained Random Forest and Artificial Neural Network using metagenomic sequences taxonomically classified into virus and non-virus classes. The algorithms achieved accuracies well beyond chance level, with area under ROC curve 0.79. Two codons (TCG and CGC) were found to have a particularly strong discriminative capacity.CONCLUSION: RSCU-based machine learning techniques applied to metagenomic sequencing data can help identify a large number of putative viral sequences and provide an addition to conventional methods for taxonomic classification.","3":"BMC bioinformatics","4":"30249176","5":"2018","6":"Metagenomics"},{"1":"Machine Learning for detection of viral sequences in human metagenomic datasets.","2":"BACKGROUND: Detection of highly divergent or yet unknown viruses from metagenomics sequencing datasets is a major bioinformatics challenge. When human samples are sequenced, a large proportion of assembled contigs are classified as &quot;unknown&quot;, as conventional methods find no similarity to known sequences. We wished to explore whether machine learning algorithms using Relative Synonymous Codon Usage frequency (RSCU) could improve the detection of viral sequences in metagenomic sequencing data.RESULTS: We trained Random Forest and Artificial Neural Network using metagenomic sequences taxonomically classified into virus and non-virus classes. The algorithms achieved accuracies well beyond chance level, with area under ROC curve 0.79. Two codons (TCG and CGC) were found to have a particularly strong discriminative capacity.CONCLUSION: RSCU-based machine learning techniques applied to metagenomic sequencing data can help identify a large number of putative viral sequences and provide an addition to conventional methods for taxonomic classification.","3":"BMC bioinformatics","4":"30249176","5":"2018","6":"Neural Networks (Computer)"},{"1":"Machine Learning for detection of viral sequences in human metagenomic datasets.","2":"BACKGROUND: Detection of highly divergent or yet unknown viruses from metagenomics sequencing datasets is a major bioinformatics challenge. When human samples are sequenced, a large proportion of assembled contigs are classified as &quot;unknown&quot;, as conventional methods find no similarity to known sequences. We wished to explore whether machine learning algorithms using Relative Synonymous Codon Usage frequency (RSCU) could improve the detection of viral sequences in metagenomic sequencing data.RESULTS: We trained Random Forest and Artificial Neural Network using metagenomic sequences taxonomically classified into virus and non-virus classes. The algorithms achieved accuracies well beyond chance level, with area under ROC curve 0.79. Two codons (TCG and CGC) were found to have a particularly strong discriminative capacity.CONCLUSION: RSCU-based machine learning techniques applied to metagenomic sequencing data can help identify a large number of putative viral sequences and provide an addition to conventional methods for taxonomic classification.","3":"BMC bioinformatics","4":"30249176","5":"2018","6":"ROC Curve"},{"1":"Machine Learning for detection of viral sequences in human metagenomic datasets.","2":"BACKGROUND: Detection of highly divergent or yet unknown viruses from metagenomics sequencing datasets is a major bioinformatics challenge. When human samples are sequenced, a large proportion of assembled contigs are classified as &quot;unknown&quot;, as conventional methods find no similarity to known sequences. We wished to explore whether machine learning algorithms using Relative Synonymous Codon Usage frequency (RSCU) could improve the detection of viral sequences in metagenomic sequencing data.RESULTS: We trained Random Forest and Artificial Neural Network using metagenomic sequences taxonomically classified into virus and non-virus classes. The algorithms achieved accuracies well beyond chance level, with area under ROC curve 0.79. Two codons (TCG and CGC) were found to have a particularly strong discriminative capacity.CONCLUSION: RSCU-based machine learning techniques applied to metagenomic sequencing data can help identify a large number of putative viral sequences and provide an addition to conventional methods for taxonomic classification.","3":"BMC bioinformatics","4":"30249176","5":"2018","6":"Sequence Analysis, DNA"},{"1":"Machine Learning for detection of viral sequences in human metagenomic datasets.","2":"BACKGROUND: Detection of highly divergent or yet unknown viruses from metagenomics sequencing datasets is a major bioinformatics challenge. When human samples are sequenced, a large proportion of assembled contigs are classified as &quot;unknown&quot;, as conventional methods find no similarity to known sequences. We wished to explore whether machine learning algorithms using Relative Synonymous Codon Usage frequency (RSCU) could improve the detection of viral sequences in metagenomic sequencing data.RESULTS: We trained Random Forest and Artificial Neural Network using metagenomic sequences taxonomically classified into virus and non-virus classes. The algorithms achieved accuracies well beyond chance level, with area under ROC curve 0.79. Two codons (TCG and CGC) were found to have a particularly strong discriminative capacity.CONCLUSION: RSCU-based machine learning techniques applied to metagenomic sequencing data can help identify a large number of putative viral sequences and provide an addition to conventional methods for taxonomic classification.","3":"BMC bioinformatics","4":"30249176","5":"2018","6":"methods"},{"1":"Machine Learning for detection of viral sequences in human metagenomic datasets.","2":"BACKGROUND: Detection of highly divergent or yet unknown viruses from metagenomics sequencing datasets is a major bioinformatics challenge. When human samples are sequenced, a large proportion of assembled contigs are classified as &quot;unknown&quot;, as conventional methods find no similarity to known sequences. We wished to explore whether machine learning algorithms using Relative Synonymous Codon Usage frequency (RSCU) could improve the detection of viral sequences in metagenomic sequencing data.RESULTS: We trained Random Forest and Artificial Neural Network using metagenomic sequences taxonomically classified into virus and non-virus classes. The algorithms achieved accuracies well beyond chance level, with area under ROC curve 0.79. Two codons (TCG and CGC) were found to have a particularly strong discriminative capacity.CONCLUSION: RSCU-based machine learning techniques applied to metagenomic sequencing data can help identify a large number of putative viral sequences and provide an addition to conventional methods for taxonomic classification.","3":"BMC bioinformatics","4":"30249176","5":"2018","6":"Viruses"},{"1":"Learning to Detect Cognitive Impairment through Digital Games and Machine Learning Techniques.","2":"Alzheimer's disease (AD) is one of the most prevalent diseases among the adult population. The early detection of Mild Cognitive Impairment (MCI), which may trigger AD, is essential to slow down the cognitive decline process.<\/AbstractText>: Alzheimer's disease (AD) is one of the most prevalent diseases among the adult population. The early detection of Mild Cognitive Impairment (MCI), which may trigger AD, is essential to slow down the cognitive decline process.This paper presents a suit of serious games that aims at detecting AD and MCI overcoming the limitations of traditional tests, as they are time-consuming, affected by confounding factors that distort the result and usually administered when symptoms are evident and it is too late for preventive measures. The battery, named Panoramix, assesses the main early cognitive markers (i.e., memory, executive functions, attention and gnosias). Regarding its validation, it has been tested with a cohort study of 16 seniors, including AD, MCI and healthy individuals.<\/AbstractText>: This paper presents a suit of serious games that aims at detecting AD and MCI overcoming the limitations of traditional tests, as they are time-consuming, affected by confounding factors that distort the result and usually administered when symptoms are evident and it is too late for preventive measures. The battery, named Panoramix, assesses the main early cognitive markers (i.e., memory, executive functions, attention and gnosias). Regarding its validation, it has been tested with a cohort study of 16 seniors, including AD, MCI and healthy individuals.This first pilot study offered initial evidence about psychometric validity, and more specifically about construct, criterion and external validity. After an analysis using machine learning techniques, findings show a promising 100% rate of success in classification abilities using a subset of three games in the battery. Thus, results are encouraging as all healthy subjects were correctly discriminated from those already suffering AD or MCI.<\/AbstractText>: This first pilot study offered initial evidence about psychometric validity, and more specifically about construct, criterion and external validity. After an analysis using machine learning techniques, findings show a promising 100% rate of success in classification abilities using a subset of three games in the battery. Thus, results are encouraging as all healthy subjects were correctly discriminated from those already suffering AD or MCI.The solid potential of digital serious games and machine learning for the early detection of dementia processes is demonstrated. Such a promising performance encourages further research to eventually introduce this technique for the clinical diagnosis of cognitive impairment.<\/AbstractText>: The solid potential of digital serious games and machine learning for the early detection of dementia processes is demonstrated. Such a promising performance encourages further research to eventually introduce this technique for the clinical diagnosis of cognitive impairment.","3":"Methods of information in medicine","4":"30248709","5":"2018","6":"Aged"},{"1":"Learning to Detect Cognitive Impairment through Digital Games and Machine Learning Techniques.","2":"Alzheimer's disease (AD) is one of the most prevalent diseases among the adult population. The early detection of Mild Cognitive Impairment (MCI), which may trigger AD, is essential to slow down the cognitive decline process.<\/AbstractText>: Alzheimer's disease (AD) is one of the most prevalent diseases among the adult population. The early detection of Mild Cognitive Impairment (MCI), which may trigger AD, is essential to slow down the cognitive decline process.This paper presents a suit of serious games that aims at detecting AD and MCI overcoming the limitations of traditional tests, as they are time-consuming, affected by confounding factors that distort the result and usually administered when symptoms are evident and it is too late for preventive measures. The battery, named Panoramix, assesses the main early cognitive markers (i.e., memory, executive functions, attention and gnosias). Regarding its validation, it has been tested with a cohort study of 16 seniors, including AD, MCI and healthy individuals.<\/AbstractText>: This paper presents a suit of serious games that aims at detecting AD and MCI overcoming the limitations of traditional tests, as they are time-consuming, affected by confounding factors that distort the result and usually administered when symptoms are evident and it is too late for preventive measures. The battery, named Panoramix, assesses the main early cognitive markers (i.e., memory, executive functions, attention and gnosias). Regarding its validation, it has been tested with a cohort study of 16 seniors, including AD, MCI and healthy individuals.This first pilot study offered initial evidence about psychometric validity, and more specifically about construct, criterion and external validity. After an analysis using machine learning techniques, findings show a promising 100% rate of success in classification abilities using a subset of three games in the battery. Thus, results are encouraging as all healthy subjects were correctly discriminated from those already suffering AD or MCI.<\/AbstractText>: This first pilot study offered initial evidence about psychometric validity, and more specifically about construct, criterion and external validity. After an analysis using machine learning techniques, findings show a promising 100% rate of success in classification abilities using a subset of three games in the battery. Thus, results are encouraging as all healthy subjects were correctly discriminated from those already suffering AD or MCI.The solid potential of digital serious games and machine learning for the early detection of dementia processes is demonstrated. Such a promising performance encourages further research to eventually introduce this technique for the clinical diagnosis of cognitive impairment.<\/AbstractText>: The solid potential of digital serious games and machine learning for the early detection of dementia processes is demonstrated. Such a promising performance encourages further research to eventually introduce this technique for the clinical diagnosis of cognitive impairment.","3":"Methods of information in medicine","4":"30248709","5":"2018","6":"Algorithms"},{"1":"Learning to Detect Cognitive Impairment through Digital Games and Machine Learning Techniques.","2":"Alzheimer's disease (AD) is one of the most prevalent diseases among the adult population. The early detection of Mild Cognitive Impairment (MCI), which may trigger AD, is essential to slow down the cognitive decline process.<\/AbstractText>: Alzheimer's disease (AD) is one of the most prevalent diseases among the adult population. The early detection of Mild Cognitive Impairment (MCI), which may trigger AD, is essential to slow down the cognitive decline process.This paper presents a suit of serious games that aims at detecting AD and MCI overcoming the limitations of traditional tests, as they are time-consuming, affected by confounding factors that distort the result and usually administered when symptoms are evident and it is too late for preventive measures. The battery, named Panoramix, assesses the main early cognitive markers (i.e., memory, executive functions, attention and gnosias). Regarding its validation, it has been tested with a cohort study of 16 seniors, including AD, MCI and healthy individuals.<\/AbstractText>: This paper presents a suit of serious games that aims at detecting AD and MCI overcoming the limitations of traditional tests, as they are time-consuming, affected by confounding factors that distort the result and usually administered when symptoms are evident and it is too late for preventive measures. The battery, named Panoramix, assesses the main early cognitive markers (i.e., memory, executive functions, attention and gnosias). Regarding its validation, it has been tested with a cohort study of 16 seniors, including AD, MCI and healthy individuals.This first pilot study offered initial evidence about psychometric validity, and more specifically about construct, criterion and external validity. After an analysis using machine learning techniques, findings show a promising 100% rate of success in classification abilities using a subset of three games in the battery. Thus, results are encouraging as all healthy subjects were correctly discriminated from those already suffering AD or MCI.<\/AbstractText>: This first pilot study offered initial evidence about psychometric validity, and more specifically about construct, criterion and external validity. After an analysis using machine learning techniques, findings show a promising 100% rate of success in classification abilities using a subset of three games in the battery. Thus, results are encouraging as all healthy subjects were correctly discriminated from those already suffering AD or MCI.The solid potential of digital serious games and machine learning for the early detection of dementia processes is demonstrated. Such a promising performance encourages further research to eventually introduce this technique for the clinical diagnosis of cognitive impairment.<\/AbstractText>: The solid potential of digital serious games and machine learning for the early detection of dementia processes is demonstrated. Such a promising performance encourages further research to eventually introduce this technique for the clinical diagnosis of cognitive impairment.","3":"Methods of information in medicine","4":"30248709","5":"2018","6":"Cognitive Dysfunction"},{"1":"Learning to Detect Cognitive Impairment through Digital Games and Machine Learning Techniques.","2":"Alzheimer's disease (AD) is one of the most prevalent diseases among the adult population. The early detection of Mild Cognitive Impairment (MCI), which may trigger AD, is essential to slow down the cognitive decline process.<\/AbstractText>: Alzheimer's disease (AD) is one of the most prevalent diseases among the adult population. The early detection of Mild Cognitive Impairment (MCI), which may trigger AD, is essential to slow down the cognitive decline process.This paper presents a suit of serious games that aims at detecting AD and MCI overcoming the limitations of traditional tests, as they are time-consuming, affected by confounding factors that distort the result and usually administered when symptoms are evident and it is too late for preventive measures. The battery, named Panoramix, assesses the main early cognitive markers (i.e., memory, executive functions, attention and gnosias). Regarding its validation, it has been tested with a cohort study of 16 seniors, including AD, MCI and healthy individuals.<\/AbstractText>: This paper presents a suit of serious games that aims at detecting AD and MCI overcoming the limitations of traditional tests, as they are time-consuming, affected by confounding factors that distort the result and usually administered when symptoms are evident and it is too late for preventive measures. The battery, named Panoramix, assesses the main early cognitive markers (i.e., memory, executive functions, attention and gnosias). Regarding its validation, it has been tested with a cohort study of 16 seniors, including AD, MCI and healthy individuals.This first pilot study offered initial evidence about psychometric validity, and more specifically about construct, criterion and external validity. After an analysis using machine learning techniques, findings show a promising 100% rate of success in classification abilities using a subset of three games in the battery. Thus, results are encouraging as all healthy subjects were correctly discriminated from those already suffering AD or MCI.<\/AbstractText>: This first pilot study offered initial evidence about psychometric validity, and more specifically about construct, criterion and external validity. After an analysis using machine learning techniques, findings show a promising 100% rate of success in classification abilities using a subset of three games in the battery. Thus, results are encouraging as all healthy subjects were correctly discriminated from those already suffering AD or MCI.The solid potential of digital serious games and machine learning for the early detection of dementia processes is demonstrated. Such a promising performance encourages further research to eventually introduce this technique for the clinical diagnosis of cognitive impairment.<\/AbstractText>: The solid potential of digital serious games and machine learning for the early detection of dementia processes is demonstrated. Such a promising performance encourages further research to eventually introduce this technique for the clinical diagnosis of cognitive impairment.","3":"Methods of information in medicine","4":"30248709","5":"2018","6":"diagnosis"},{"1":"Learning to Detect Cognitive Impairment through Digital Games and Machine Learning Techniques.","2":"Alzheimer's disease (AD) is one of the most prevalent diseases among the adult population. The early detection of Mild Cognitive Impairment (MCI), which may trigger AD, is essential to slow down the cognitive decline process.<\/AbstractText>: Alzheimer's disease (AD) is one of the most prevalent diseases among the adult population. The early detection of Mild Cognitive Impairment (MCI), which may trigger AD, is essential to slow down the cognitive decline process.This paper presents a suit of serious games that aims at detecting AD and MCI overcoming the limitations of traditional tests, as they are time-consuming, affected by confounding factors that distort the result and usually administered when symptoms are evident and it is too late for preventive measures. The battery, named Panoramix, assesses the main early cognitive markers (i.e., memory, executive functions, attention and gnosias). Regarding its validation, it has been tested with a cohort study of 16 seniors, including AD, MCI and healthy individuals.<\/AbstractText>: This paper presents a suit of serious games that aims at detecting AD and MCI overcoming the limitations of traditional tests, as they are time-consuming, affected by confounding factors that distort the result and usually administered when symptoms are evident and it is too late for preventive measures. The battery, named Panoramix, assesses the main early cognitive markers (i.e., memory, executive functions, attention and gnosias). Regarding its validation, it has been tested with a cohort study of 16 seniors, including AD, MCI and healthy individuals.This first pilot study offered initial evidence about psychometric validity, and more specifically about construct, criterion and external validity. After an analysis using machine learning techniques, findings show a promising 100% rate of success in classification abilities using a subset of three games in the battery. Thus, results are encouraging as all healthy subjects were correctly discriminated from those already suffering AD or MCI.<\/AbstractText>: This first pilot study offered initial evidence about psychometric validity, and more specifically about construct, criterion and external validity. After an analysis using machine learning techniques, findings show a promising 100% rate of success in classification abilities using a subset of three games in the battery. Thus, results are encouraging as all healthy subjects were correctly discriminated from those already suffering AD or MCI.The solid potential of digital serious games and machine learning for the early detection of dementia processes is demonstrated. Such a promising performance encourages further research to eventually introduce this technique for the clinical diagnosis of cognitive impairment.<\/AbstractText>: The solid potential of digital serious games and machine learning for the early detection of dementia processes is demonstrated. Such a promising performance encourages further research to eventually introduce this technique for the clinical diagnosis of cognitive impairment.","3":"Methods of information in medicine","4":"30248709","5":"2018","6":"Female"},{"1":"Learning to Detect Cognitive Impairment through Digital Games and Machine Learning Techniques.","2":"Alzheimer's disease (AD) is one of the most prevalent diseases among the adult population. The early detection of Mild Cognitive Impairment (MCI), which may trigger AD, is essential to slow down the cognitive decline process.<\/AbstractText>: Alzheimer's disease (AD) is one of the most prevalent diseases among the adult population. The early detection of Mild Cognitive Impairment (MCI), which may trigger AD, is essential to slow down the cognitive decline process.This paper presents a suit of serious games that aims at detecting AD and MCI overcoming the limitations of traditional tests, as they are time-consuming, affected by confounding factors that distort the result and usually administered when symptoms are evident and it is too late for preventive measures. The battery, named Panoramix, assesses the main early cognitive markers (i.e., memory, executive functions, attention and gnosias). Regarding its validation, it has been tested with a cohort study of 16 seniors, including AD, MCI and healthy individuals.<\/AbstractText>: This paper presents a suit of serious games that aims at detecting AD and MCI overcoming the limitations of traditional tests, as they are time-consuming, affected by confounding factors that distort the result and usually administered when symptoms are evident and it is too late for preventive measures. The battery, named Panoramix, assesses the main early cognitive markers (i.e., memory, executive functions, attention and gnosias). Regarding its validation, it has been tested with a cohort study of 16 seniors, including AD, MCI and healthy individuals.This first pilot study offered initial evidence about psychometric validity, and more specifically about construct, criterion and external validity. After an analysis using machine learning techniques, findings show a promising 100% rate of success in classification abilities using a subset of three games in the battery. Thus, results are encouraging as all healthy subjects were correctly discriminated from those already suffering AD or MCI.<\/AbstractText>: This first pilot study offered initial evidence about psychometric validity, and more specifically about construct, criterion and external validity. After an analysis using machine learning techniques, findings show a promising 100% rate of success in classification abilities using a subset of three games in the battery. Thus, results are encouraging as all healthy subjects were correctly discriminated from those already suffering AD or MCI.The solid potential of digital serious games and machine learning for the early detection of dementia processes is demonstrated. Such a promising performance encourages further research to eventually introduce this technique for the clinical diagnosis of cognitive impairment.<\/AbstractText>: The solid potential of digital serious games and machine learning for the early detection of dementia processes is demonstrated. Such a promising performance encourages further research to eventually introduce this technique for the clinical diagnosis of cognitive impairment.","3":"Methods of information in medicine","4":"30248709","5":"2018","6":"Humans"},{"1":"Learning to Detect Cognitive Impairment through Digital Games and Machine Learning Techniques.","2":"Alzheimer's disease (AD) is one of the most prevalent diseases among the adult population. The early detection of Mild Cognitive Impairment (MCI), which may trigger AD, is essential to slow down the cognitive decline process.<\/AbstractText>: Alzheimer's disease (AD) is one of the most prevalent diseases among the adult population. The early detection of Mild Cognitive Impairment (MCI), which may trigger AD, is essential to slow down the cognitive decline process.This paper presents a suit of serious games that aims at detecting AD and MCI overcoming the limitations of traditional tests, as they are time-consuming, affected by confounding factors that distort the result and usually administered when symptoms are evident and it is too late for preventive measures. The battery, named Panoramix, assesses the main early cognitive markers (i.e., memory, executive functions, attention and gnosias). Regarding its validation, it has been tested with a cohort study of 16 seniors, including AD, MCI and healthy individuals.<\/AbstractText>: This paper presents a suit of serious games that aims at detecting AD and MCI overcoming the limitations of traditional tests, as they are time-consuming, affected by confounding factors that distort the result and usually administered when symptoms are evident and it is too late for preventive measures. The battery, named Panoramix, assesses the main early cognitive markers (i.e., memory, executive functions, attention and gnosias). Regarding its validation, it has been tested with a cohort study of 16 seniors, including AD, MCI and healthy individuals.This first pilot study offered initial evidence about psychometric validity, and more specifically about construct, criterion and external validity. After an analysis using machine learning techniques, findings show a promising 100% rate of success in classification abilities using a subset of three games in the battery. Thus, results are encouraging as all healthy subjects were correctly discriminated from those already suffering AD or MCI.<\/AbstractText>: This first pilot study offered initial evidence about psychometric validity, and more specifically about construct, criterion and external validity. After an analysis using machine learning techniques, findings show a promising 100% rate of success in classification abilities using a subset of three games in the battery. Thus, results are encouraging as all healthy subjects were correctly discriminated from those already suffering AD or MCI.The solid potential of digital serious games and machine learning for the early detection of dementia processes is demonstrated. Such a promising performance encourages further research to eventually introduce this technique for the clinical diagnosis of cognitive impairment.<\/AbstractText>: The solid potential of digital serious games and machine learning for the early detection of dementia processes is demonstrated. Such a promising performance encourages further research to eventually introduce this technique for the clinical diagnosis of cognitive impairment.","3":"Methods of information in medicine","4":"30248709","5":"2018","6":"Machine Learning"},{"1":"Learning to Detect Cognitive Impairment through Digital Games and Machine Learning Techniques.","2":"Alzheimer's disease (AD) is one of the most prevalent diseases among the adult population. The early detection of Mild Cognitive Impairment (MCI), which may trigger AD, is essential to slow down the cognitive decline process.<\/AbstractText>: Alzheimer's disease (AD) is one of the most prevalent diseases among the adult population. The early detection of Mild Cognitive Impairment (MCI), which may trigger AD, is essential to slow down the cognitive decline process.This paper presents a suit of serious games that aims at detecting AD and MCI overcoming the limitations of traditional tests, as they are time-consuming, affected by confounding factors that distort the result and usually administered when symptoms are evident and it is too late for preventive measures. The battery, named Panoramix, assesses the main early cognitive markers (i.e., memory, executive functions, attention and gnosias). Regarding its validation, it has been tested with a cohort study of 16 seniors, including AD, MCI and healthy individuals.<\/AbstractText>: This paper presents a suit of serious games that aims at detecting AD and MCI overcoming the limitations of traditional tests, as they are time-consuming, affected by confounding factors that distort the result and usually administered when symptoms are evident and it is too late for preventive measures. The battery, named Panoramix, assesses the main early cognitive markers (i.e., memory, executive functions, attention and gnosias). Regarding its validation, it has been tested with a cohort study of 16 seniors, including AD, MCI and healthy individuals.This first pilot study offered initial evidence about psychometric validity, and more specifically about construct, criterion and external validity. After an analysis using machine learning techniques, findings show a promising 100% rate of success in classification abilities using a subset of three games in the battery. Thus, results are encouraging as all healthy subjects were correctly discriminated from those already suffering AD or MCI.<\/AbstractText>: This first pilot study offered initial evidence about psychometric validity, and more specifically about construct, criterion and external validity. After an analysis using machine learning techniques, findings show a promising 100% rate of success in classification abilities using a subset of three games in the battery. Thus, results are encouraging as all healthy subjects were correctly discriminated from those already suffering AD or MCI.The solid potential of digital serious games and machine learning for the early detection of dementia processes is demonstrated. Such a promising performance encourages further research to eventually introduce this technique for the clinical diagnosis of cognitive impairment.<\/AbstractText>: The solid potential of digital serious games and machine learning for the early detection of dementia processes is demonstrated. Such a promising performance encourages further research to eventually introduce this technique for the clinical diagnosis of cognitive impairment.","3":"Methods of information in medicine","4":"30248709","5":"2018","6":"Male"},{"1":"Learning to Detect Cognitive Impairment through Digital Games and Machine Learning Techniques.","2":"Alzheimer's disease (AD) is one of the most prevalent diseases among the adult population. The early detection of Mild Cognitive Impairment (MCI), which may trigger AD, is essential to slow down the cognitive decline process.<\/AbstractText>: Alzheimer's disease (AD) is one of the most prevalent diseases among the adult population. The early detection of Mild Cognitive Impairment (MCI), which may trigger AD, is essential to slow down the cognitive decline process.This paper presents a suit of serious games that aims at detecting AD and MCI overcoming the limitations of traditional tests, as they are time-consuming, affected by confounding factors that distort the result and usually administered when symptoms are evident and it is too late for preventive measures. The battery, named Panoramix, assesses the main early cognitive markers (i.e., memory, executive functions, attention and gnosias). Regarding its validation, it has been tested with a cohort study of 16 seniors, including AD, MCI and healthy individuals.<\/AbstractText>: This paper presents a suit of serious games that aims at detecting AD and MCI overcoming the limitations of traditional tests, as they are time-consuming, affected by confounding factors that distort the result and usually administered when symptoms are evident and it is too late for preventive measures. The battery, named Panoramix, assesses the main early cognitive markers (i.e., memory, executive functions, attention and gnosias). Regarding its validation, it has been tested with a cohort study of 16 seniors, including AD, MCI and healthy individuals.This first pilot study offered initial evidence about psychometric validity, and more specifically about construct, criterion and external validity. After an analysis using machine learning techniques, findings show a promising 100% rate of success in classification abilities using a subset of three games in the battery. Thus, results are encouraging as all healthy subjects were correctly discriminated from those already suffering AD or MCI.<\/AbstractText>: This first pilot study offered initial evidence about psychometric validity, and more specifically about construct, criterion and external validity. After an analysis using machine learning techniques, findings show a promising 100% rate of success in classification abilities using a subset of three games in the battery. Thus, results are encouraging as all healthy subjects were correctly discriminated from those already suffering AD or MCI.The solid potential of digital serious games and machine learning for the early detection of dementia processes is demonstrated. Such a promising performance encourages further research to eventually introduce this technique for the clinical diagnosis of cognitive impairment.<\/AbstractText>: The solid potential of digital serious games and machine learning for the early detection of dementia processes is demonstrated. Such a promising performance encourages further research to eventually introduce this technique for the clinical diagnosis of cognitive impairment.","3":"Methods of information in medicine","4":"30248709","5":"2018","6":"Surveys and Questionnaires"},{"1":"Learning to Detect Cognitive Impairment through Digital Games and Machine Learning Techniques.","2":"Alzheimer's disease (AD) is one of the most prevalent diseases among the adult population. The early detection of Mild Cognitive Impairment (MCI), which may trigger AD, is essential to slow down the cognitive decline process.<\/AbstractText>: Alzheimer's disease (AD) is one of the most prevalent diseases among the adult population. The early detection of Mild Cognitive Impairment (MCI), which may trigger AD, is essential to slow down the cognitive decline process.This paper presents a suit of serious games that aims at detecting AD and MCI overcoming the limitations of traditional tests, as they are time-consuming, affected by confounding factors that distort the result and usually administered when symptoms are evident and it is too late for preventive measures. The battery, named Panoramix, assesses the main early cognitive markers (i.e., memory, executive functions, attention and gnosias). Regarding its validation, it has been tested with a cohort study of 16 seniors, including AD, MCI and healthy individuals.<\/AbstractText>: This paper presents a suit of serious games that aims at detecting AD and MCI overcoming the limitations of traditional tests, as they are time-consuming, affected by confounding factors that distort the result and usually administered when symptoms are evident and it is too late for preventive measures. The battery, named Panoramix, assesses the main early cognitive markers (i.e., memory, executive functions, attention and gnosias). Regarding its validation, it has been tested with a cohort study of 16 seniors, including AD, MCI and healthy individuals.This first pilot study offered initial evidence about psychometric validity, and more specifically about construct, criterion and external validity. After an analysis using machine learning techniques, findings show a promising 100% rate of success in classification abilities using a subset of three games in the battery. Thus, results are encouraging as all healthy subjects were correctly discriminated from those already suffering AD or MCI.<\/AbstractText>: This first pilot study offered initial evidence about psychometric validity, and more specifically about construct, criterion and external validity. After an analysis using machine learning techniques, findings show a promising 100% rate of success in classification abilities using a subset of three games in the battery. Thus, results are encouraging as all healthy subjects were correctly discriminated from those already suffering AD or MCI.The solid potential of digital serious games and machine learning for the early detection of dementia processes is demonstrated. Such a promising performance encourages further research to eventually introduce this technique for the clinical diagnosis of cognitive impairment.<\/AbstractText>: The solid potential of digital serious games and machine learning for the early detection of dementia processes is demonstrated. Such a promising performance encourages further research to eventually introduce this technique for the clinical diagnosis of cognitive impairment.","3":"Methods of information in medicine","4":"30248709","5":"2018","6":"Video Games"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"Adolescent"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"Adult"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"Aged"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"Aged, 80 and over"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"Aging"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"genetics"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"Blood Chemical Analysis"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"Child"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"CpG Islands"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"genetics"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"DNA Methylation"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"High-Throughput Nucleotide Sequencing"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"Humans"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"Male"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"Middle Aged"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"Models, Statistical"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"Multiplex Polymerase Chain Reaction"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"Neural Networks (Computer)"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"Reproducibility of Results"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"Saliva"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"chemistry"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"Semen"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"chemistry"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"Sequence Analysis, DNA"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"Sulfites"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"Support Vector Machine"},{"1":"DNA methylation-based age prediction using massively parallel sequencing data and multiple machine learning models.","2":"The field of DNA intelligence focuses on retrieving information from DNA evidence that can help narrow down large groups of suspects or define target groups of interest. With recent breakthroughs on the estimation of geographical ancestry and physical appearance, the estimation of chronological age comes to complete this circle of information. Recent studies have identified methylation sites in the human genome that correlate strongly with age and can be used for the development of age-estimation algorithms. In this study, 110 whole blood samples from individuals aged 11-93 years were analysed using a DNA methylation quantification assay based on bisulphite conversion and massively parallel sequencing (Illumina MiSeq) of 12 CpG sites. Using this data, 17 different statistical modelling approaches were compared based on root mean square error (RMSE) and a Support Vector Machine with polynomial function (SVMp) model was selected for further testing. For the selected model (RMSE<U+2009>=<U+2009>4.9 years) the mean average error (MAE) of the blind test (n<U+2009>=<U+2009>33) was calculated at 4.1 years, with 52% of the samples predicting with less than 4 years of error and 86% with less than 7 years. Furthermore, the sensitivity of the method was assessed both in terms of methylation quantification accuracy and prediction accuracy in the first validation of this kind. The described method retained its accuracy down to 10<U+2009>ng of initial DNA input or ~2<U+2009>ng bisulphite PCR input. Finally, 34 saliva samples were analysed and following basic normalisation, the chronological age of the donors was predicted with less than 4 years of error for 50% of the samples and with less than 7 years of error for 70%.","3":"Forensic science international. Genetics","4":"30243148","5":"2018","6":"Young Adult"},{"1":"Disrupted asymmetry of inter- and intra-hemispheric functional connectivity in patients with drug-naive, first-episode schizophrenia and their unaffected siblings.","2":"BACKGROUND: Lack of normal asymmetry in the brain has been reported in patients with schizophrenia. However, it remains unclear whether disrupted asymmetry originates from inter-hemispheric functional connectivity (FC) and/or intra-hemispheric FC in this patient population.METHODS: Forty-four patients with drug-naive, first-episode schizophrenia, 42 unaffected siblings, and 44 healthy controls underwent resting-state functional magnetic resonance imaging (fMRI) scan. The parameter of asymmetry (PAS) and support vector machine (SVM) were used to analyze the data. Patients were treated with olanzapine for 8<U+202F>weeks.FINDINGS: Compared with healthy controls, patients showed lower PAS scores in the left middle temporal gyrus (MTG)/inferior temporal gyrus (ITG), left posterior cingulate cortex (PCC)/precuneus and left angular gyrus, and higher PAS scores in the left precentral gyrus/postcentral gyrus. Unaffected siblings also showed lower PAS scores in the left MTG/ITG and left PCC/precuneus relative to healthy controls. Further, SVM analysis showed that a combination of the PAS scores in these two clusters in patients at baseline was able to predict clinical response after 8<U+202F>weeks of olanzapine treatment with 77.27% sensitivity, 72.73% specificity, and 75.00% accuracy.INTERPRETATION: The present study suggests disrupted asymmetry of inter- and intra-hemispheric FC in drug-naive, first-episode schizophrenia; in addition, a reduced asymmetry of inter-hemispheric FC in the left MTG/ITG and left PCC/precuneus may serve as an endophenotype for schizophrenia, and may have clinical utility to predict response to olanzapine treatment. FUND: The National Key R&amp;D Program of China and the National Natural Science Foundation of China.","3":"EBioMedicine","4":"30241918","5":"2018","6":"Adolescent"},{"1":"Disrupted asymmetry of inter- and intra-hemispheric functional connectivity in patients with drug-naive, first-episode schizophrenia and their unaffected siblings.","2":"BACKGROUND: Lack of normal asymmetry in the brain has been reported in patients with schizophrenia. However, it remains unclear whether disrupted asymmetry originates from inter-hemispheric functional connectivity (FC) and/or intra-hemispheric FC in this patient population.METHODS: Forty-four patients with drug-naive, first-episode schizophrenia, 42 unaffected siblings, and 44 healthy controls underwent resting-state functional magnetic resonance imaging (fMRI) scan. The parameter of asymmetry (PAS) and support vector machine (SVM) were used to analyze the data. Patients were treated with olanzapine for 8<U+202F>weeks.FINDINGS: Compared with healthy controls, patients showed lower PAS scores in the left middle temporal gyrus (MTG)/inferior temporal gyrus (ITG), left posterior cingulate cortex (PCC)/precuneus and left angular gyrus, and higher PAS scores in the left precentral gyrus/postcentral gyrus. Unaffected siblings also showed lower PAS scores in the left MTG/ITG and left PCC/precuneus relative to healthy controls. Further, SVM analysis showed that a combination of the PAS scores in these two clusters in patients at baseline was able to predict clinical response after 8<U+202F>weeks of olanzapine treatment with 77.27% sensitivity, 72.73% specificity, and 75.00% accuracy.INTERPRETATION: The present study suggests disrupted asymmetry of inter- and intra-hemispheric FC in drug-naive, first-episode schizophrenia; in addition, a reduced asymmetry of inter-hemispheric FC in the left MTG/ITG and left PCC/precuneus may serve as an endophenotype for schizophrenia, and may have clinical utility to predict response to olanzapine treatment. FUND: The National Key R&amp;D Program of China and the National Natural Science Foundation of China.","3":"EBioMedicine","4":"30241918","5":"2018","6":"Adult"},{"1":"Disrupted asymmetry of inter- and intra-hemispheric functional connectivity in patients with drug-naive, first-episode schizophrenia and their unaffected siblings.","2":"BACKGROUND: Lack of normal asymmetry in the brain has been reported in patients with schizophrenia. However, it remains unclear whether disrupted asymmetry originates from inter-hemispheric functional connectivity (FC) and/or intra-hemispheric FC in this patient population.METHODS: Forty-four patients with drug-naive, first-episode schizophrenia, 42 unaffected siblings, and 44 healthy controls underwent resting-state functional magnetic resonance imaging (fMRI) scan. The parameter of asymmetry (PAS) and support vector machine (SVM) were used to analyze the data. Patients were treated with olanzapine for 8<U+202F>weeks.FINDINGS: Compared with healthy controls, patients showed lower PAS scores in the left middle temporal gyrus (MTG)/inferior temporal gyrus (ITG), left posterior cingulate cortex (PCC)/precuneus and left angular gyrus, and higher PAS scores in the left precentral gyrus/postcentral gyrus. Unaffected siblings also showed lower PAS scores in the left MTG/ITG and left PCC/precuneus relative to healthy controls. Further, SVM analysis showed that a combination of the PAS scores in these two clusters in patients at baseline was able to predict clinical response after 8<U+202F>weeks of olanzapine treatment with 77.27% sensitivity, 72.73% specificity, and 75.00% accuracy.INTERPRETATION: The present study suggests disrupted asymmetry of inter- and intra-hemispheric FC in drug-naive, first-episode schizophrenia; in addition, a reduced asymmetry of inter-hemispheric FC in the left MTG/ITG and left PCC/precuneus may serve as an endophenotype for schizophrenia, and may have clinical utility to predict response to olanzapine treatment. FUND: The National Key R&amp;D Program of China and the National Natural Science Foundation of China.","3":"EBioMedicine","4":"30241918","5":"2018","6":"Brain"},{"1":"Disrupted asymmetry of inter- and intra-hemispheric functional connectivity in patients with drug-naive, first-episode schizophrenia and their unaffected siblings.","2":"BACKGROUND: Lack of normal asymmetry in the brain has been reported in patients with schizophrenia. However, it remains unclear whether disrupted asymmetry originates from inter-hemispheric functional connectivity (FC) and/or intra-hemispheric FC in this patient population.METHODS: Forty-four patients with drug-naive, first-episode schizophrenia, 42 unaffected siblings, and 44 healthy controls underwent resting-state functional magnetic resonance imaging (fMRI) scan. The parameter of asymmetry (PAS) and support vector machine (SVM) were used to analyze the data. Patients were treated with olanzapine for 8<U+202F>weeks.FINDINGS: Compared with healthy controls, patients showed lower PAS scores in the left middle temporal gyrus (MTG)/inferior temporal gyrus (ITG), left posterior cingulate cortex (PCC)/precuneus and left angular gyrus, and higher PAS scores in the left precentral gyrus/postcentral gyrus. Unaffected siblings also showed lower PAS scores in the left MTG/ITG and left PCC/precuneus relative to healthy controls. Further, SVM analysis showed that a combination of the PAS scores in these two clusters in patients at baseline was able to predict clinical response after 8<U+202F>weeks of olanzapine treatment with 77.27% sensitivity, 72.73% specificity, and 75.00% accuracy.INTERPRETATION: The present study suggests disrupted asymmetry of inter- and intra-hemispheric FC in drug-naive, first-episode schizophrenia; in addition, a reduced asymmetry of inter-hemispheric FC in the left MTG/ITG and left PCC/precuneus may serve as an endophenotype for schizophrenia, and may have clinical utility to predict response to olanzapine treatment. FUND: The National Key R&amp;D Program of China and the National Natural Science Foundation of China.","3":"EBioMedicine","4":"30241918","5":"2018","6":"diagnostic imaging"},{"1":"Disrupted asymmetry of inter- and intra-hemispheric functional connectivity in patients with drug-naive, first-episode schizophrenia and their unaffected siblings.","2":"BACKGROUND: Lack of normal asymmetry in the brain has been reported in patients with schizophrenia. However, it remains unclear whether disrupted asymmetry originates from inter-hemispheric functional connectivity (FC) and/or intra-hemispheric FC in this patient population.METHODS: Forty-four patients with drug-naive, first-episode schizophrenia, 42 unaffected siblings, and 44 healthy controls underwent resting-state functional magnetic resonance imaging (fMRI) scan. The parameter of asymmetry (PAS) and support vector machine (SVM) were used to analyze the data. Patients were treated with olanzapine for 8<U+202F>weeks.FINDINGS: Compared with healthy controls, patients showed lower PAS scores in the left middle temporal gyrus (MTG)/inferior temporal gyrus (ITG), left posterior cingulate cortex (PCC)/precuneus and left angular gyrus, and higher PAS scores in the left precentral gyrus/postcentral gyrus. Unaffected siblings also showed lower PAS scores in the left MTG/ITG and left PCC/precuneus relative to healthy controls. Further, SVM analysis showed that a combination of the PAS scores in these two clusters in patients at baseline was able to predict clinical response after 8<U+202F>weeks of olanzapine treatment with 77.27% sensitivity, 72.73% specificity, and 75.00% accuracy.INTERPRETATION: The present study suggests disrupted asymmetry of inter- and intra-hemispheric FC in drug-naive, first-episode schizophrenia; in addition, a reduced asymmetry of inter-hemispheric FC in the left MTG/ITG and left PCC/precuneus may serve as an endophenotype for schizophrenia, and may have clinical utility to predict response to olanzapine treatment. FUND: The National Key R&amp;D Program of China and the National Natural Science Foundation of China.","3":"EBioMedicine","4":"30241918","5":"2018","6":"physiopathology"},{"1":"Disrupted asymmetry of inter- and intra-hemispheric functional connectivity in patients with drug-naive, first-episode schizophrenia and their unaffected siblings.","2":"BACKGROUND: Lack of normal asymmetry in the brain has been reported in patients with schizophrenia. However, it remains unclear whether disrupted asymmetry originates from inter-hemispheric functional connectivity (FC) and/or intra-hemispheric FC in this patient population.METHODS: Forty-four patients with drug-naive, first-episode schizophrenia, 42 unaffected siblings, and 44 healthy controls underwent resting-state functional magnetic resonance imaging (fMRI) scan. The parameter of asymmetry (PAS) and support vector machine (SVM) were used to analyze the data. Patients were treated with olanzapine for 8<U+202F>weeks.FINDINGS: Compared with healthy controls, patients showed lower PAS scores in the left middle temporal gyrus (MTG)/inferior temporal gyrus (ITG), left posterior cingulate cortex (PCC)/precuneus and left angular gyrus, and higher PAS scores in the left precentral gyrus/postcentral gyrus. Unaffected siblings also showed lower PAS scores in the left MTG/ITG and left PCC/precuneus relative to healthy controls. Further, SVM analysis showed that a combination of the PAS scores in these two clusters in patients at baseline was able to predict clinical response after 8<U+202F>weeks of olanzapine treatment with 77.27% sensitivity, 72.73% specificity, and 75.00% accuracy.INTERPRETATION: The present study suggests disrupted asymmetry of inter- and intra-hemispheric FC in drug-naive, first-episode schizophrenia; in addition, a reduced asymmetry of inter-hemispheric FC in the left MTG/ITG and left PCC/precuneus may serve as an endophenotype for schizophrenia, and may have clinical utility to predict response to olanzapine treatment. FUND: The National Key R&amp;D Program of China and the National Natural Science Foundation of China.","3":"EBioMedicine","4":"30241918","5":"2018","6":"Case-Control Studies"},{"1":"Disrupted asymmetry of inter- and intra-hemispheric functional connectivity in patients with drug-naive, first-episode schizophrenia and their unaffected siblings.","2":"BACKGROUND: Lack of normal asymmetry in the brain has been reported in patients with schizophrenia. However, it remains unclear whether disrupted asymmetry originates from inter-hemispheric functional connectivity (FC) and/or intra-hemispheric FC in this patient population.METHODS: Forty-four patients with drug-naive, first-episode schizophrenia, 42 unaffected siblings, and 44 healthy controls underwent resting-state functional magnetic resonance imaging (fMRI) scan. The parameter of asymmetry (PAS) and support vector machine (SVM) were used to analyze the data. Patients were treated with olanzapine for 8<U+202F>weeks.FINDINGS: Compared with healthy controls, patients showed lower PAS scores in the left middle temporal gyrus (MTG)/inferior temporal gyrus (ITG), left posterior cingulate cortex (PCC)/precuneus and left angular gyrus, and higher PAS scores in the left precentral gyrus/postcentral gyrus. Unaffected siblings also showed lower PAS scores in the left MTG/ITG and left PCC/precuneus relative to healthy controls. Further, SVM analysis showed that a combination of the PAS scores in these two clusters in patients at baseline was able to predict clinical response after 8<U+202F>weeks of olanzapine treatment with 77.27% sensitivity, 72.73% specificity, and 75.00% accuracy.INTERPRETATION: The present study suggests disrupted asymmetry of inter- and intra-hemispheric FC in drug-naive, first-episode schizophrenia; in addition, a reduced asymmetry of inter-hemispheric FC in the left MTG/ITG and left PCC/precuneus may serve as an endophenotype for schizophrenia, and may have clinical utility to predict response to olanzapine treatment. FUND: The National Key R&amp;D Program of China and the National Natural Science Foundation of China.","3":"EBioMedicine","4":"30241918","5":"2018","6":"Connectome"},{"1":"Disrupted asymmetry of inter- and intra-hemispheric functional connectivity in patients with drug-naive, first-episode schizophrenia and their unaffected siblings.","2":"BACKGROUND: Lack of normal asymmetry in the brain has been reported in patients with schizophrenia. However, it remains unclear whether disrupted asymmetry originates from inter-hemispheric functional connectivity (FC) and/or intra-hemispheric FC in this patient population.METHODS: Forty-four patients with drug-naive, first-episode schizophrenia, 42 unaffected siblings, and 44 healthy controls underwent resting-state functional magnetic resonance imaging (fMRI) scan. The parameter of asymmetry (PAS) and support vector machine (SVM) were used to analyze the data. Patients were treated with olanzapine for 8<U+202F>weeks.FINDINGS: Compared with healthy controls, patients showed lower PAS scores in the left middle temporal gyrus (MTG)/inferior temporal gyrus (ITG), left posterior cingulate cortex (PCC)/precuneus and left angular gyrus, and higher PAS scores in the left precentral gyrus/postcentral gyrus. Unaffected siblings also showed lower PAS scores in the left MTG/ITG and left PCC/precuneus relative to healthy controls. Further, SVM analysis showed that a combination of the PAS scores in these two clusters in patients at baseline was able to predict clinical response after 8<U+202F>weeks of olanzapine treatment with 77.27% sensitivity, 72.73% specificity, and 75.00% accuracy.INTERPRETATION: The present study suggests disrupted asymmetry of inter- and intra-hemispheric FC in drug-naive, first-episode schizophrenia; in addition, a reduced asymmetry of inter-hemispheric FC in the left MTG/ITG and left PCC/precuneus may serve as an endophenotype for schizophrenia, and may have clinical utility to predict response to olanzapine treatment. FUND: The National Key R&amp;D Program of China and the National Natural Science Foundation of China.","3":"EBioMedicine","4":"30241918","5":"2018","6":"Female"},{"1":"Disrupted asymmetry of inter- and intra-hemispheric functional connectivity in patients with drug-naive, first-episode schizophrenia and their unaffected siblings.","2":"BACKGROUND: Lack of normal asymmetry in the brain has been reported in patients with schizophrenia. However, it remains unclear whether disrupted asymmetry originates from inter-hemispheric functional connectivity (FC) and/or intra-hemispheric FC in this patient population.METHODS: Forty-four patients with drug-naive, first-episode schizophrenia, 42 unaffected siblings, and 44 healthy controls underwent resting-state functional magnetic resonance imaging (fMRI) scan. The parameter of asymmetry (PAS) and support vector machine (SVM) were used to analyze the data. Patients were treated with olanzapine for 8<U+202F>weeks.FINDINGS: Compared with healthy controls, patients showed lower PAS scores in the left middle temporal gyrus (MTG)/inferior temporal gyrus (ITG), left posterior cingulate cortex (PCC)/precuneus and left angular gyrus, and higher PAS scores in the left precentral gyrus/postcentral gyrus. Unaffected siblings also showed lower PAS scores in the left MTG/ITG and left PCC/precuneus relative to healthy controls. Further, SVM analysis showed that a combination of the PAS scores in these two clusters in patients at baseline was able to predict clinical response after 8<U+202F>weeks of olanzapine treatment with 77.27% sensitivity, 72.73% specificity, and 75.00% accuracy.INTERPRETATION: The present study suggests disrupted asymmetry of inter- and intra-hemispheric FC in drug-naive, first-episode schizophrenia; in addition, a reduced asymmetry of inter-hemispheric FC in the left MTG/ITG and left PCC/precuneus may serve as an endophenotype for schizophrenia, and may have clinical utility to predict response to olanzapine treatment. FUND: The National Key R&amp;D Program of China and the National Natural Science Foundation of China.","3":"EBioMedicine","4":"30241918","5":"2018","6":"Humans"},{"1":"Disrupted asymmetry of inter- and intra-hemispheric functional connectivity in patients with drug-naive, first-episode schizophrenia and their unaffected siblings.","2":"BACKGROUND: Lack of normal asymmetry in the brain has been reported in patients with schizophrenia. However, it remains unclear whether disrupted asymmetry originates from inter-hemispheric functional connectivity (FC) and/or intra-hemispheric FC in this patient population.METHODS: Forty-four patients with drug-naive, first-episode schizophrenia, 42 unaffected siblings, and 44 healthy controls underwent resting-state functional magnetic resonance imaging (fMRI) scan. The parameter of asymmetry (PAS) and support vector machine (SVM) were used to analyze the data. Patients were treated with olanzapine for 8<U+202F>weeks.FINDINGS: Compared with healthy controls, patients showed lower PAS scores in the left middle temporal gyrus (MTG)/inferior temporal gyrus (ITG), left posterior cingulate cortex (PCC)/precuneus and left angular gyrus, and higher PAS scores in the left precentral gyrus/postcentral gyrus. Unaffected siblings also showed lower PAS scores in the left MTG/ITG and left PCC/precuneus relative to healthy controls. Further, SVM analysis showed that a combination of the PAS scores in these two clusters in patients at baseline was able to predict clinical response after 8<U+202F>weeks of olanzapine treatment with 77.27% sensitivity, 72.73% specificity, and 75.00% accuracy.INTERPRETATION: The present study suggests disrupted asymmetry of inter- and intra-hemispheric FC in drug-naive, first-episode schizophrenia; in addition, a reduced asymmetry of inter-hemispheric FC in the left MTG/ITG and left PCC/precuneus may serve as an endophenotype for schizophrenia, and may have clinical utility to predict response to olanzapine treatment. FUND: The National Key R&amp;D Program of China and the National Natural Science Foundation of China.","3":"EBioMedicine","4":"30241918","5":"2018","6":"Image Processing, Computer-Assisted"},{"1":"Disrupted asymmetry of inter- and intra-hemispheric functional connectivity in patients with drug-naive, first-episode schizophrenia and their unaffected siblings.","2":"BACKGROUND: Lack of normal asymmetry in the brain has been reported in patients with schizophrenia. However, it remains unclear whether disrupted asymmetry originates from inter-hemispheric functional connectivity (FC) and/or intra-hemispheric FC in this patient population.METHODS: Forty-four patients with drug-naive, first-episode schizophrenia, 42 unaffected siblings, and 44 healthy controls underwent resting-state functional magnetic resonance imaging (fMRI) scan. The parameter of asymmetry (PAS) and support vector machine (SVM) were used to analyze the data. Patients were treated with olanzapine for 8<U+202F>weeks.FINDINGS: Compared with healthy controls, patients showed lower PAS scores in the left middle temporal gyrus (MTG)/inferior temporal gyrus (ITG), left posterior cingulate cortex (PCC)/precuneus and left angular gyrus, and higher PAS scores in the left precentral gyrus/postcentral gyrus. Unaffected siblings also showed lower PAS scores in the left MTG/ITG and left PCC/precuneus relative to healthy controls. Further, SVM analysis showed that a combination of the PAS scores in these two clusters in patients at baseline was able to predict clinical response after 8<U+202F>weeks of olanzapine treatment with 77.27% sensitivity, 72.73% specificity, and 75.00% accuracy.INTERPRETATION: The present study suggests disrupted asymmetry of inter- and intra-hemispheric FC in drug-naive, first-episode schizophrenia; in addition, a reduced asymmetry of inter-hemispheric FC in the left MTG/ITG and left PCC/precuneus may serve as an endophenotype for schizophrenia, and may have clinical utility to predict response to olanzapine treatment. FUND: The National Key R&amp;D Program of China and the National Natural Science Foundation of China.","3":"EBioMedicine","4":"30241918","5":"2018","6":"Magnetic Resonance Imaging"},{"1":"Disrupted asymmetry of inter- and intra-hemispheric functional connectivity in patients with drug-naive, first-episode schizophrenia and their unaffected siblings.","2":"BACKGROUND: Lack of normal asymmetry in the brain has been reported in patients with schizophrenia. However, it remains unclear whether disrupted asymmetry originates from inter-hemispheric functional connectivity (FC) and/or intra-hemispheric FC in this patient population.METHODS: Forty-four patients with drug-naive, first-episode schizophrenia, 42 unaffected siblings, and 44 healthy controls underwent resting-state functional magnetic resonance imaging (fMRI) scan. The parameter of asymmetry (PAS) and support vector machine (SVM) were used to analyze the data. Patients were treated with olanzapine for 8<U+202F>weeks.FINDINGS: Compared with healthy controls, patients showed lower PAS scores in the left middle temporal gyrus (MTG)/inferior temporal gyrus (ITG), left posterior cingulate cortex (PCC)/precuneus and left angular gyrus, and higher PAS scores in the left precentral gyrus/postcentral gyrus. Unaffected siblings also showed lower PAS scores in the left MTG/ITG and left PCC/precuneus relative to healthy controls. Further, SVM analysis showed that a combination of the PAS scores in these two clusters in patients at baseline was able to predict clinical response after 8<U+202F>weeks of olanzapine treatment with 77.27% sensitivity, 72.73% specificity, and 75.00% accuracy.INTERPRETATION: The present study suggests disrupted asymmetry of inter- and intra-hemispheric FC in drug-naive, first-episode schizophrenia; in addition, a reduced asymmetry of inter-hemispheric FC in the left MTG/ITG and left PCC/precuneus may serve as an endophenotype for schizophrenia, and may have clinical utility to predict response to olanzapine treatment. FUND: The National Key R&amp;D Program of China and the National Natural Science Foundation of China.","3":"EBioMedicine","4":"30241918","5":"2018","6":"Male"},{"1":"Disrupted asymmetry of inter- and intra-hemispheric functional connectivity in patients with drug-naive, first-episode schizophrenia and their unaffected siblings.","2":"BACKGROUND: Lack of normal asymmetry in the brain has been reported in patients with schizophrenia. However, it remains unclear whether disrupted asymmetry originates from inter-hemispheric functional connectivity (FC) and/or intra-hemispheric FC in this patient population.METHODS: Forty-four patients with drug-naive, first-episode schizophrenia, 42 unaffected siblings, and 44 healthy controls underwent resting-state functional magnetic resonance imaging (fMRI) scan. The parameter of asymmetry (PAS) and support vector machine (SVM) were used to analyze the data. Patients were treated with olanzapine for 8<U+202F>weeks.FINDINGS: Compared with healthy controls, patients showed lower PAS scores in the left middle temporal gyrus (MTG)/inferior temporal gyrus (ITG), left posterior cingulate cortex (PCC)/precuneus and left angular gyrus, and higher PAS scores in the left precentral gyrus/postcentral gyrus. Unaffected siblings also showed lower PAS scores in the left MTG/ITG and left PCC/precuneus relative to healthy controls. Further, SVM analysis showed that a combination of the PAS scores in these two clusters in patients at baseline was able to predict clinical response after 8<U+202F>weeks of olanzapine treatment with 77.27% sensitivity, 72.73% specificity, and 75.00% accuracy.INTERPRETATION: The present study suggests disrupted asymmetry of inter- and intra-hemispheric FC in drug-naive, first-episode schizophrenia; in addition, a reduced asymmetry of inter-hemispheric FC in the left MTG/ITG and left PCC/precuneus may serve as an endophenotype for schizophrenia, and may have clinical utility to predict response to olanzapine treatment. FUND: The National Key R&amp;D Program of China and the National Natural Science Foundation of China.","3":"EBioMedicine","4":"30241918","5":"2018","6":"Schizophrenia"},{"1":"Disrupted asymmetry of inter- and intra-hemispheric functional connectivity in patients with drug-naive, first-episode schizophrenia and their unaffected siblings.","2":"BACKGROUND: Lack of normal asymmetry in the brain has been reported in patients with schizophrenia. However, it remains unclear whether disrupted asymmetry originates from inter-hemispheric functional connectivity (FC) and/or intra-hemispheric FC in this patient population.METHODS: Forty-four patients with drug-naive, first-episode schizophrenia, 42 unaffected siblings, and 44 healthy controls underwent resting-state functional magnetic resonance imaging (fMRI) scan. The parameter of asymmetry (PAS) and support vector machine (SVM) were used to analyze the data. Patients were treated with olanzapine for 8<U+202F>weeks.FINDINGS: Compared with healthy controls, patients showed lower PAS scores in the left middle temporal gyrus (MTG)/inferior temporal gyrus (ITG), left posterior cingulate cortex (PCC)/precuneus and left angular gyrus, and higher PAS scores in the left precentral gyrus/postcentral gyrus. Unaffected siblings also showed lower PAS scores in the left MTG/ITG and left PCC/precuneus relative to healthy controls. Further, SVM analysis showed that a combination of the PAS scores in these two clusters in patients at baseline was able to predict clinical response after 8<U+202F>weeks of olanzapine treatment with 77.27% sensitivity, 72.73% specificity, and 75.00% accuracy.INTERPRETATION: The present study suggests disrupted asymmetry of inter- and intra-hemispheric FC in drug-naive, first-episode schizophrenia; in addition, a reduced asymmetry of inter-hemispheric FC in the left MTG/ITG and left PCC/precuneus may serve as an endophenotype for schizophrenia, and may have clinical utility to predict response to olanzapine treatment. FUND: The National Key R&amp;D Program of China and the National Natural Science Foundation of China.","3":"EBioMedicine","4":"30241918","5":"2018","6":"diagnosis"},{"1":"Disrupted asymmetry of inter- and intra-hemispheric functional connectivity in patients with drug-naive, first-episode schizophrenia and their unaffected siblings.","2":"BACKGROUND: Lack of normal asymmetry in the brain has been reported in patients with schizophrenia. However, it remains unclear whether disrupted asymmetry originates from inter-hemispheric functional connectivity (FC) and/or intra-hemispheric FC in this patient population.METHODS: Forty-four patients with drug-naive, first-episode schizophrenia, 42 unaffected siblings, and 44 healthy controls underwent resting-state functional magnetic resonance imaging (fMRI) scan. The parameter of asymmetry (PAS) and support vector machine (SVM) were used to analyze the data. Patients were treated with olanzapine for 8<U+202F>weeks.FINDINGS: Compared with healthy controls, patients showed lower PAS scores in the left middle temporal gyrus (MTG)/inferior temporal gyrus (ITG), left posterior cingulate cortex (PCC)/precuneus and left angular gyrus, and higher PAS scores in the left precentral gyrus/postcentral gyrus. Unaffected siblings also showed lower PAS scores in the left MTG/ITG and left PCC/precuneus relative to healthy controls. Further, SVM analysis showed that a combination of the PAS scores in these two clusters in patients at baseline was able to predict clinical response after 8<U+202F>weeks of olanzapine treatment with 77.27% sensitivity, 72.73% specificity, and 75.00% accuracy.INTERPRETATION: The present study suggests disrupted asymmetry of inter- and intra-hemispheric FC in drug-naive, first-episode schizophrenia; in addition, a reduced asymmetry of inter-hemispheric FC in the left MTG/ITG and left PCC/precuneus may serve as an endophenotype for schizophrenia, and may have clinical utility to predict response to olanzapine treatment. FUND: The National Key R&amp;D Program of China and the National Natural Science Foundation of China.","3":"EBioMedicine","4":"30241918","5":"2018","6":"etiology"},{"1":"Disrupted asymmetry of inter- and intra-hemispheric functional connectivity in patients with drug-naive, first-episode schizophrenia and their unaffected siblings.","2":"BACKGROUND: Lack of normal asymmetry in the brain has been reported in patients with schizophrenia. However, it remains unclear whether disrupted asymmetry originates from inter-hemispheric functional connectivity (FC) and/or intra-hemispheric FC in this patient population.METHODS: Forty-four patients with drug-naive, first-episode schizophrenia, 42 unaffected siblings, and 44 healthy controls underwent resting-state functional magnetic resonance imaging (fMRI) scan. The parameter of asymmetry (PAS) and support vector machine (SVM) were used to analyze the data. Patients were treated with olanzapine for 8<U+202F>weeks.FINDINGS: Compared with healthy controls, patients showed lower PAS scores in the left middle temporal gyrus (MTG)/inferior temporal gyrus (ITG), left posterior cingulate cortex (PCC)/precuneus and left angular gyrus, and higher PAS scores in the left precentral gyrus/postcentral gyrus. Unaffected siblings also showed lower PAS scores in the left MTG/ITG and left PCC/precuneus relative to healthy controls. Further, SVM analysis showed that a combination of the PAS scores in these two clusters in patients at baseline was able to predict clinical response after 8<U+202F>weeks of olanzapine treatment with 77.27% sensitivity, 72.73% specificity, and 75.00% accuracy.INTERPRETATION: The present study suggests disrupted asymmetry of inter- and intra-hemispheric FC in drug-naive, first-episode schizophrenia; in addition, a reduced asymmetry of inter-hemispheric FC in the left MTG/ITG and left PCC/precuneus may serve as an endophenotype for schizophrenia, and may have clinical utility to predict response to olanzapine treatment. FUND: The National Key R&amp;D Program of China and the National Natural Science Foundation of China.","3":"EBioMedicine","4":"30241918","5":"2018","6":"physiopathology"},{"1":"Disrupted asymmetry of inter- and intra-hemispheric functional connectivity in patients with drug-naive, first-episode schizophrenia and their unaffected siblings.","2":"BACKGROUND: Lack of normal asymmetry in the brain has been reported in patients with schizophrenia. However, it remains unclear whether disrupted asymmetry originates from inter-hemispheric functional connectivity (FC) and/or intra-hemispheric FC in this patient population.METHODS: Forty-four patients with drug-naive, first-episode schizophrenia, 42 unaffected siblings, and 44 healthy controls underwent resting-state functional magnetic resonance imaging (fMRI) scan. The parameter of asymmetry (PAS) and support vector machine (SVM) were used to analyze the data. Patients were treated with olanzapine for 8<U+202F>weeks.FINDINGS: Compared with healthy controls, patients showed lower PAS scores in the left middle temporal gyrus (MTG)/inferior temporal gyrus (ITG), left posterior cingulate cortex (PCC)/precuneus and left angular gyrus, and higher PAS scores in the left precentral gyrus/postcentral gyrus. Unaffected siblings also showed lower PAS scores in the left MTG/ITG and left PCC/precuneus relative to healthy controls. Further, SVM analysis showed that a combination of the PAS scores in these two clusters in patients at baseline was able to predict clinical response after 8<U+202F>weeks of olanzapine treatment with 77.27% sensitivity, 72.73% specificity, and 75.00% accuracy.INTERPRETATION: The present study suggests disrupted asymmetry of inter- and intra-hemispheric FC in drug-naive, first-episode schizophrenia; in addition, a reduced asymmetry of inter-hemispheric FC in the left MTG/ITG and left PCC/precuneus may serve as an endophenotype for schizophrenia, and may have clinical utility to predict response to olanzapine treatment. FUND: The National Key R&amp;D Program of China and the National Natural Science Foundation of China.","3":"EBioMedicine","4":"30241918","5":"2018","6":"Schizophrenic Psychology"},{"1":"Disrupted asymmetry of inter- and intra-hemispheric functional connectivity in patients with drug-naive, first-episode schizophrenia and their unaffected siblings.","2":"BACKGROUND: Lack of normal asymmetry in the brain has been reported in patients with schizophrenia. However, it remains unclear whether disrupted asymmetry originates from inter-hemispheric functional connectivity (FC) and/or intra-hemispheric FC in this patient population.METHODS: Forty-four patients with drug-naive, first-episode schizophrenia, 42 unaffected siblings, and 44 healthy controls underwent resting-state functional magnetic resonance imaging (fMRI) scan. The parameter of asymmetry (PAS) and support vector machine (SVM) were used to analyze the data. Patients were treated with olanzapine for 8<U+202F>weeks.FINDINGS: Compared with healthy controls, patients showed lower PAS scores in the left middle temporal gyrus (MTG)/inferior temporal gyrus (ITG), left posterior cingulate cortex (PCC)/precuneus and left angular gyrus, and higher PAS scores in the left precentral gyrus/postcentral gyrus. Unaffected siblings also showed lower PAS scores in the left MTG/ITG and left PCC/precuneus relative to healthy controls. Further, SVM analysis showed that a combination of the PAS scores in these two clusters in patients at baseline was able to predict clinical response after 8<U+202F>weeks of olanzapine treatment with 77.27% sensitivity, 72.73% specificity, and 75.00% accuracy.INTERPRETATION: The present study suggests disrupted asymmetry of inter- and intra-hemispheric FC in drug-naive, first-episode schizophrenia; in addition, a reduced asymmetry of inter-hemispheric FC in the left MTG/ITG and left PCC/precuneus may serve as an endophenotype for schizophrenia, and may have clinical utility to predict response to olanzapine treatment. FUND: The National Key R&amp;D Program of China and the National Natural Science Foundation of China.","3":"EBioMedicine","4":"30241918","5":"2018","6":"Siblings"},{"1":"Disrupted asymmetry of inter- and intra-hemispheric functional connectivity in patients with drug-naive, first-episode schizophrenia and their unaffected siblings.","2":"BACKGROUND: Lack of normal asymmetry in the brain has been reported in patients with schizophrenia. However, it remains unclear whether disrupted asymmetry originates from inter-hemispheric functional connectivity (FC) and/or intra-hemispheric FC in this patient population.METHODS: Forty-four patients with drug-naive, first-episode schizophrenia, 42 unaffected siblings, and 44 healthy controls underwent resting-state functional magnetic resonance imaging (fMRI) scan. The parameter of asymmetry (PAS) and support vector machine (SVM) were used to analyze the data. Patients were treated with olanzapine for 8<U+202F>weeks.FINDINGS: Compared with healthy controls, patients showed lower PAS scores in the left middle temporal gyrus (MTG)/inferior temporal gyrus (ITG), left posterior cingulate cortex (PCC)/precuneus and left angular gyrus, and higher PAS scores in the left precentral gyrus/postcentral gyrus. Unaffected siblings also showed lower PAS scores in the left MTG/ITG and left PCC/precuneus relative to healthy controls. Further, SVM analysis showed that a combination of the PAS scores in these two clusters in patients at baseline was able to predict clinical response after 8<U+202F>weeks of olanzapine treatment with 77.27% sensitivity, 72.73% specificity, and 75.00% accuracy.INTERPRETATION: The present study suggests disrupted asymmetry of inter- and intra-hemispheric FC in drug-naive, first-episode schizophrenia; in addition, a reduced asymmetry of inter-hemispheric FC in the left MTG/ITG and left PCC/precuneus may serve as an endophenotype for schizophrenia, and may have clinical utility to predict response to olanzapine treatment. FUND: The National Key R&amp;D Program of China and the National Natural Science Foundation of China.","3":"EBioMedicine","4":"30241918","5":"2018","6":"Support Vector Machine"},{"1":"Disrupted asymmetry of inter- and intra-hemispheric functional connectivity in patients with drug-naive, first-episode schizophrenia and their unaffected siblings.","2":"BACKGROUND: Lack of normal asymmetry in the brain has been reported in patients with schizophrenia. However, it remains unclear whether disrupted asymmetry originates from inter-hemispheric functional connectivity (FC) and/or intra-hemispheric FC in this patient population.METHODS: Forty-four patients with drug-naive, first-episode schizophrenia, 42 unaffected siblings, and 44 healthy controls underwent resting-state functional magnetic resonance imaging (fMRI) scan. The parameter of asymmetry (PAS) and support vector machine (SVM) were used to analyze the data. Patients were treated with olanzapine for 8<U+202F>weeks.FINDINGS: Compared with healthy controls, patients showed lower PAS scores in the left middle temporal gyrus (MTG)/inferior temporal gyrus (ITG), left posterior cingulate cortex (PCC)/precuneus and left angular gyrus, and higher PAS scores in the left precentral gyrus/postcentral gyrus. Unaffected siblings also showed lower PAS scores in the left MTG/ITG and left PCC/precuneus relative to healthy controls. Further, SVM analysis showed that a combination of the PAS scores in these two clusters in patients at baseline was able to predict clinical response after 8<U+202F>weeks of olanzapine treatment with 77.27% sensitivity, 72.73% specificity, and 75.00% accuracy.INTERPRETATION: The present study suggests disrupted asymmetry of inter- and intra-hemispheric FC in drug-naive, first-episode schizophrenia; in addition, a reduced asymmetry of inter-hemispheric FC in the left MTG/ITG and left PCC/precuneus may serve as an endophenotype for schizophrenia, and may have clinical utility to predict response to olanzapine treatment. FUND: The National Key R&amp;D Program of China and the National Natural Science Foundation of China.","3":"EBioMedicine","4":"30241918","5":"2018","6":"Young Adult"},{"1":"NA","2":"","3":"Molecules (Basel, Switzerland)","4":"30241281","5":"2018","6":"Isoflavones"},{"1":"NA","2":"","3":"Molecules (Basel, Switzerland)","4":"30241281","5":"2018","6":"chemistry"},{"1":"NA","2":"","3":"Molecules (Basel, Switzerland)","4":"30241281","5":"2018","6":"isolation &amp; purification"},{"1":"NA","2":"","3":"Molecules (Basel, Switzerland)","4":"30241281","5":"2018","6":"Models, Statistical"},{"1":"NA","2":"","3":"Molecules (Basel, Switzerland)","4":"30241281","5":"2018","6":"Plant Extracts"},{"1":"NA","2":"","3":"Molecules (Basel, Switzerland)","4":"30241281","5":"2018","6":"chemistry"},{"1":"NA","2":"","3":"Molecules (Basel, Switzerland)","4":"30241281","5":"2018","6":"Plant Roots"},{"1":"NA","2":"","3":"Molecules (Basel, Switzerland)","4":"30241281","5":"2018","6":"chemistry"},{"1":"NA","2":"","3":"Molecules (Basel, Switzerland)","4":"30241281","5":"2018","6":"Pueraria"},{"1":"NA","2":"","3":"Molecules (Basel, Switzerland)","4":"30241281","5":"2018","6":"chemistry"},{"1":"NA","2":"","3":"Molecules (Basel, Switzerland)","4":"30241281","5":"2018","6":"Quality Control"},{"1":"NA","2":"","3":"Molecules (Basel, Switzerland)","4":"30241281","5":"2018","6":"Regression Analysis"},{"1":"NA","2":"","3":"Molecules (Basel, Switzerland)","4":"30241281","5":"2018","6":"Support Vector Machine"},{"1":"Assisting document triage for human kinome curation via machine learning.","2":"In the era of data explosion, the increasing frequency of published articles presents unorthodox challenges to fulfill specific curation requirements for bio-literature databases. Recognizing these demands, we designed a document triage system with automatic methods that can improve efficiency to retrieve the most relevant articles in curation workflows and reduce workloads for biocurators. Since the BioCreative VI (2017), we have implemented texting mining processing in our system in hopes of providing higher effectiveness for curating articles related to human kinase proteins. We tested several machine learning methods together with state-of-the-art concept extraction tools. For features, we extracted rich co-occurrence and linguistic information to model the curation process of human kinome articles by the neXtProt database. As shown in the official evaluation on the human kinome curation task in BioCreative VI, our system can effectively retrieve 5.2 and 6.5 kinase articles with the relevant disease (DIS) and biological process (BP) information, respectively, among the top 100 returned results. Comparing to neXtA5, our system demonstrates significant improvements in prioritizing kinome-related articles as follows: our system achieves 0.458 and 0.109 for the DIS axis whereas the neXtA5's best-reported mean average precision (MAP) and maximum precision observed are 0.41 and 0.04. Our system also outperforms the neXtA5 in retrieving BP axis with 0.195 for MAP and the neXtA5's reported value was 0.11. These results suggest that our system may be able to assist neXtProt biocurators in practice.","3":"Database : the journal of biological databases and curation","4":"30239677","5":"2018","6":"Data Mining"},{"1":"Assisting document triage for human kinome curation via machine learning.","2":"In the era of data explosion, the increasing frequency of published articles presents unorthodox challenges to fulfill specific curation requirements for bio-literature databases. Recognizing these demands, we designed a document triage system with automatic methods that can improve efficiency to retrieve the most relevant articles in curation workflows and reduce workloads for biocurators. Since the BioCreative VI (2017), we have implemented texting mining processing in our system in hopes of providing higher effectiveness for curating articles related to human kinase proteins. We tested several machine learning methods together with state-of-the-art concept extraction tools. For features, we extracted rich co-occurrence and linguistic information to model the curation process of human kinome articles by the neXtProt database. As shown in the official evaluation on the human kinome curation task in BioCreative VI, our system can effectively retrieve 5.2 and 6.5 kinase articles with the relevant disease (DIS) and biological process (BP) information, respectively, among the top 100 returned results. Comparing to neXtA5, our system demonstrates significant improvements in prioritizing kinome-related articles as follows: our system achieves 0.458 and 0.109 for the DIS axis whereas the neXtA5's best-reported mean average precision (MAP) and maximum precision observed are 0.41 and 0.04. Our system also outperforms the neXtA5 in retrieving BP axis with 0.195 for MAP and the neXtA5's reported value was 0.11. These results suggest that our system may be able to assist neXtProt biocurators in practice.","3":"Database : the journal of biological databases and curation","4":"30239677","5":"2018","6":"Documentation"},{"1":"Assisting document triage for human kinome curation via machine learning.","2":"In the era of data explosion, the increasing frequency of published articles presents unorthodox challenges to fulfill specific curation requirements for bio-literature databases. Recognizing these demands, we designed a document triage system with automatic methods that can improve efficiency to retrieve the most relevant articles in curation workflows and reduce workloads for biocurators. Since the BioCreative VI (2017), we have implemented texting mining processing in our system in hopes of providing higher effectiveness for curating articles related to human kinase proteins. We tested several machine learning methods together with state-of-the-art concept extraction tools. For features, we extracted rich co-occurrence and linguistic information to model the curation process of human kinome articles by the neXtProt database. As shown in the official evaluation on the human kinome curation task in BioCreative VI, our system can effectively retrieve 5.2 and 6.5 kinase articles with the relevant disease (DIS) and biological process (BP) information, respectively, among the top 100 returned results. Comparing to neXtA5, our system demonstrates significant improvements in prioritizing kinome-related articles as follows: our system achieves 0.458 and 0.109 for the DIS axis whereas the neXtA5's best-reported mean average precision (MAP) and maximum precision observed are 0.41 and 0.04. Our system also outperforms the neXtA5 in retrieving BP axis with 0.195 for MAP and the neXtA5's reported value was 0.11. These results suggest that our system may be able to assist neXtProt biocurators in practice.","3":"Database : the journal of biological databases and curation","4":"30239677","5":"2018","6":"Humans"},{"1":"Assisting document triage for human kinome curation via machine learning.","2":"In the era of data explosion, the increasing frequency of published articles presents unorthodox challenges to fulfill specific curation requirements for bio-literature databases. Recognizing these demands, we designed a document triage system with automatic methods that can improve efficiency to retrieve the most relevant articles in curation workflows and reduce workloads for biocurators. Since the BioCreative VI (2017), we have implemented texting mining processing in our system in hopes of providing higher effectiveness for curating articles related to human kinase proteins. We tested several machine learning methods together with state-of-the-art concept extraction tools. For features, we extracted rich co-occurrence and linguistic information to model the curation process of human kinome articles by the neXtProt database. As shown in the official evaluation on the human kinome curation task in BioCreative VI, our system can effectively retrieve 5.2 and 6.5 kinase articles with the relevant disease (DIS) and biological process (BP) information, respectively, among the top 100 returned results. Comparing to neXtA5, our system demonstrates significant improvements in prioritizing kinome-related articles as follows: our system achieves 0.458 and 0.109 for the DIS axis whereas the neXtA5's best-reported mean average precision (MAP) and maximum precision observed are 0.41 and 0.04. Our system also outperforms the neXtA5 in retrieving BP axis with 0.195 for MAP and the neXtA5's reported value was 0.11. These results suggest that our system may be able to assist neXtProt biocurators in practice.","3":"Database : the journal of biological databases and curation","4":"30239677","5":"2018","6":"Machine Learning"},{"1":"Assisting document triage for human kinome curation via machine learning.","2":"In the era of data explosion, the increasing frequency of published articles presents unorthodox challenges to fulfill specific curation requirements for bio-literature databases. Recognizing these demands, we designed a document triage system with automatic methods that can improve efficiency to retrieve the most relevant articles in curation workflows and reduce workloads for biocurators. Since the BioCreative VI (2017), we have implemented texting mining processing in our system in hopes of providing higher effectiveness for curating articles related to human kinase proteins. We tested several machine learning methods together with state-of-the-art concept extraction tools. For features, we extracted rich co-occurrence and linguistic information to model the curation process of human kinome articles by the neXtProt database. As shown in the official evaluation on the human kinome curation task in BioCreative VI, our system can effectively retrieve 5.2 and 6.5 kinase articles with the relevant disease (DIS) and biological process (BP) information, respectively, among the top 100 returned results. Comparing to neXtA5, our system demonstrates significant improvements in prioritizing kinome-related articles as follows: our system achieves 0.458 and 0.109 for the DIS axis whereas the neXtA5's best-reported mean average precision (MAP) and maximum precision observed are 0.41 and 0.04. Our system also outperforms the neXtA5 in retrieving BP axis with 0.195 for MAP and the neXtA5's reported value was 0.11. These results suggest that our system may be able to assist neXtProt biocurators in practice.","3":"Database : the journal of biological databases and curation","4":"30239677","5":"2018","6":"Protein Kinases"},{"1":"Assisting document triage for human kinome curation via machine learning.","2":"In the era of data explosion, the increasing frequency of published articles presents unorthodox challenges to fulfill specific curation requirements for bio-literature databases. Recognizing these demands, we designed a document triage system with automatic methods that can improve efficiency to retrieve the most relevant articles in curation workflows and reduce workloads for biocurators. Since the BioCreative VI (2017), we have implemented texting mining processing in our system in hopes of providing higher effectiveness for curating articles related to human kinase proteins. We tested several machine learning methods together with state-of-the-art concept extraction tools. For features, we extracted rich co-occurrence and linguistic information to model the curation process of human kinome articles by the neXtProt database. As shown in the official evaluation on the human kinome curation task in BioCreative VI, our system can effectively retrieve 5.2 and 6.5 kinase articles with the relevant disease (DIS) and biological process (BP) information, respectively, among the top 100 returned results. Comparing to neXtA5, our system demonstrates significant improvements in prioritizing kinome-related articles as follows: our system achieves 0.458 and 0.109 for the DIS axis whereas the neXtA5's best-reported mean average precision (MAP) and maximum precision observed are 0.41 and 0.04. Our system also outperforms the neXtA5 in retrieving BP axis with 0.195 for MAP and the neXtA5's reported value was 0.11. These results suggest that our system may be able to assist neXtProt biocurators in practice.","3":"Database : the journal of biological databases and curation","4":"30239677","5":"2018","6":"metabolism"},{"1":"Assisting document triage for human kinome curation via machine learning.","2":"In the era of data explosion, the increasing frequency of published articles presents unorthodox challenges to fulfill specific curation requirements for bio-literature databases. Recognizing these demands, we designed a document triage system with automatic methods that can improve efficiency to retrieve the most relevant articles in curation workflows and reduce workloads for biocurators. Since the BioCreative VI (2017), we have implemented texting mining processing in our system in hopes of providing higher effectiveness for curating articles related to human kinase proteins. We tested several machine learning methods together with state-of-the-art concept extraction tools. For features, we extracted rich co-occurrence and linguistic information to model the curation process of human kinome articles by the neXtProt database. As shown in the official evaluation on the human kinome curation task in BioCreative VI, our system can effectively retrieve 5.2 and 6.5 kinase articles with the relevant disease (DIS) and biological process (BP) information, respectively, among the top 100 returned results. Comparing to neXtA5, our system demonstrates significant improvements in prioritizing kinome-related articles as follows: our system achieves 0.458 and 0.109 for the DIS axis whereas the neXtA5's best-reported mean average precision (MAP) and maximum precision observed are 0.41 and 0.04. Our system also outperforms the neXtA5 in retrieving BP axis with 0.195 for MAP and the neXtA5's reported value was 0.11. These results suggest that our system may be able to assist neXtProt biocurators in practice.","3":"Database : the journal of biological databases and curation","4":"30239677","5":"2018","6":"Proteome"},{"1":"Assisting document triage for human kinome curation via machine learning.","2":"In the era of data explosion, the increasing frequency of published articles presents unorthodox challenges to fulfill specific curation requirements for bio-literature databases. Recognizing these demands, we designed a document triage system with automatic methods that can improve efficiency to retrieve the most relevant articles in curation workflows and reduce workloads for biocurators. Since the BioCreative VI (2017), we have implemented texting mining processing in our system in hopes of providing higher effectiveness for curating articles related to human kinase proteins. We tested several machine learning methods together with state-of-the-art concept extraction tools. For features, we extracted rich co-occurrence and linguistic information to model the curation process of human kinome articles by the neXtProt database. As shown in the official evaluation on the human kinome curation task in BioCreative VI, our system can effectively retrieve 5.2 and 6.5 kinase articles with the relevant disease (DIS) and biological process (BP) information, respectively, among the top 100 returned results. Comparing to neXtA5, our system demonstrates significant improvements in prioritizing kinome-related articles as follows: our system achieves 0.458 and 0.109 for the DIS axis whereas the neXtA5's best-reported mean average precision (MAP) and maximum precision observed are 0.41 and 0.04. Our system also outperforms the neXtA5 in retrieving BP axis with 0.195 for MAP and the neXtA5's reported value was 0.11. These results suggest that our system may be able to assist neXtProt biocurators in practice.","3":"Database : the journal of biological databases and curation","4":"30239677","5":"2018","6":"metabolism"},{"1":"Assisting document triage for human kinome curation via machine learning.","2":"In the era of data explosion, the increasing frequency of published articles presents unorthodox challenges to fulfill specific curation requirements for bio-literature databases. Recognizing these demands, we designed a document triage system with automatic methods that can improve efficiency to retrieve the most relevant articles in curation workflows and reduce workloads for biocurators. Since the BioCreative VI (2017), we have implemented texting mining processing in our system in hopes of providing higher effectiveness for curating articles related to human kinase proteins. We tested several machine learning methods together with state-of-the-art concept extraction tools. For features, we extracted rich co-occurrence and linguistic information to model the curation process of human kinome articles by the neXtProt database. As shown in the official evaluation on the human kinome curation task in BioCreative VI, our system can effectively retrieve 5.2 and 6.5 kinase articles with the relevant disease (DIS) and biological process (BP) information, respectively, among the top 100 returned results. Comparing to neXtA5, our system demonstrates significant improvements in prioritizing kinome-related articles as follows: our system achieves 0.458 and 0.109 for the DIS axis whereas the neXtA5's best-reported mean average precision (MAP) and maximum precision observed are 0.41 and 0.04. Our system also outperforms the neXtA5 in retrieving BP axis with 0.195 for MAP and the neXtA5's reported value was 0.11. These results suggest that our system may be able to assist neXtProt biocurators in practice.","3":"Database : the journal of biological databases and curation","4":"30239677","5":"2018","6":"Statistics as Topic"},{"1":"Deep Learning and Online Video: Advances in Transcription, Automated Indexing, and Manipulation.","2":"In recent years, the amount of video content created and uploaded to the Internet has grown exponentially. Video content has unique accessibility challenges: indexing, transcribing, and searching video has always been very labor intensive, and there were no automated ways of searching videos for specific content. New software tools that use deep learning methods are automating some of these processes, making video content more discoverable and useful. There are also many new tools for processing and manipulating video in interesting ways. This column will briefly discuss the idea of deep learning and how deep learning tools can be used to transcribe, translate, search, and even manipulate videos. It will suggest ways that librarians can use these tools to help their institutions better manage video content. It also includes a list of video-related software tools.","3":"Medical reference services quarterly","4":"30239300","5":"2018","6":"Abstracting and Indexing as Topic"},{"1":"Deep Learning and Online Video: Advances in Transcription, Automated Indexing, and Manipulation.","2":"In recent years, the amount of video content created and uploaded to the Internet has grown exponentially. Video content has unique accessibility challenges: indexing, transcribing, and searching video has always been very labor intensive, and there were no automated ways of searching videos for specific content. New software tools that use deep learning methods are automating some of these processes, making video content more discoverable and useful. There are also many new tools for processing and manipulating video in interesting ways. This column will briefly discuss the idea of deep learning and how deep learning tools can be used to transcribe, translate, search, and even manipulate videos. It will suggest ways that librarians can use these tools to help their institutions better manage video content. It also includes a list of video-related software tools.","3":"Medical reference services quarterly","4":"30239300","5":"2018","6":"methods"},{"1":"Deep Learning and Online Video: Advances in Transcription, Automated Indexing, and Manipulation.","2":"In recent years, the amount of video content created and uploaded to the Internet has grown exponentially. Video content has unique accessibility challenges: indexing, transcribing, and searching video has always been very labor intensive, and there were no automated ways of searching videos for specific content. New software tools that use deep learning methods are automating some of these processes, making video content more discoverable and useful. There are also many new tools for processing and manipulating video in interesting ways. This column will briefly discuss the idea of deep learning and how deep learning tools can be used to transcribe, translate, search, and even manipulate videos. It will suggest ways that librarians can use these tools to help their institutions better manage video content. It also includes a list of video-related software tools.","3":"Medical reference services quarterly","4":"30239300","5":"2018","6":"Deep Learning"},{"1":"Deep Learning and Online Video: Advances in Transcription, Automated Indexing, and Manipulation.","2":"In recent years, the amount of video content created and uploaded to the Internet has grown exponentially. Video content has unique accessibility challenges: indexing, transcribing, and searching video has always been very labor intensive, and there were no automated ways of searching videos for specific content. New software tools that use deep learning methods are automating some of these processes, making video content more discoverable and useful. There are also many new tools for processing and manipulating video in interesting ways. This column will briefly discuss the idea of deep learning and how deep learning tools can be used to transcribe, translate, search, and even manipulate videos. It will suggest ways that librarians can use these tools to help their institutions better manage video content. It also includes a list of video-related software tools.","3":"Medical reference services quarterly","4":"30239300","5":"2018","6":"Humans"},{"1":"Deep Learning and Online Video: Advances in Transcription, Automated Indexing, and Manipulation.","2":"In recent years, the amount of video content created and uploaded to the Internet has grown exponentially. Video content has unique accessibility challenges: indexing, transcribing, and searching video has always been very labor intensive, and there were no automated ways of searching videos for specific content. New software tools that use deep learning methods are automating some of these processes, making video content more discoverable and useful. There are also many new tools for processing and manipulating video in interesting ways. This column will briefly discuss the idea of deep learning and how deep learning tools can be used to transcribe, translate, search, and even manipulate videos. It will suggest ways that librarians can use these tools to help their institutions better manage video content. It also includes a list of video-related software tools.","3":"Medical reference services quarterly","4":"30239300","5":"2018","6":"Internet"},{"1":"Deep Learning and Online Video: Advances in Transcription, Automated Indexing, and Manipulation.","2":"In recent years, the amount of video content created and uploaded to the Internet has grown exponentially. Video content has unique accessibility challenges: indexing, transcribing, and searching video has always been very labor intensive, and there were no automated ways of searching videos for specific content. New software tools that use deep learning methods are automating some of these processes, making video content more discoverable and useful. There are also many new tools for processing and manipulating video in interesting ways. This column will briefly discuss the idea of deep learning and how deep learning tools can be used to transcribe, translate, search, and even manipulate videos. It will suggest ways that librarians can use these tools to help their institutions better manage video content. It also includes a list of video-related software tools.","3":"Medical reference services quarterly","4":"30239300","5":"2018","6":"Medical Records"},{"1":"Deep Learning and Online Video: Advances in Transcription, Automated Indexing, and Manipulation.","2":"In recent years, the amount of video content created and uploaded to the Internet has grown exponentially. Video content has unique accessibility challenges: indexing, transcribing, and searching video has always been very labor intensive, and there were no automated ways of searching videos for specific content. New software tools that use deep learning methods are automating some of these processes, making video content more discoverable and useful. There are also many new tools for processing and manipulating video in interesting ways. This column will briefly discuss the idea of deep learning and how deep learning tools can be used to transcribe, translate, search, and even manipulate videos. It will suggest ways that librarians can use these tools to help their institutions better manage video content. It also includes a list of video-related software tools.","3":"Medical reference services quarterly","4":"30239300","5":"2018","6":"Medical Records Systems, Computerized"},{"1":"Deep Learning and Online Video: Advances in Transcription, Automated Indexing, and Manipulation.","2":"In recent years, the amount of video content created and uploaded to the Internet has grown exponentially. Video content has unique accessibility challenges: indexing, transcribing, and searching video has always been very labor intensive, and there were no automated ways of searching videos for specific content. New software tools that use deep learning methods are automating some of these processes, making video content more discoverable and useful. There are also many new tools for processing and manipulating video in interesting ways. This column will briefly discuss the idea of deep learning and how deep learning tools can be used to transcribe, translate, search, and even manipulate videos. It will suggest ways that librarians can use these tools to help their institutions better manage video content. It also includes a list of video-related software tools.","3":"Medical reference services quarterly","4":"30239300","5":"2018","6":"organization &amp; administration"},{"1":"Deep Learning and Online Video: Advances in Transcription, Automated Indexing, and Manipulation.","2":"In recent years, the amount of video content created and uploaded to the Internet has grown exponentially. Video content has unique accessibility challenges: indexing, transcribing, and searching video has always been very labor intensive, and there were no automated ways of searching videos for specific content. New software tools that use deep learning methods are automating some of these processes, making video content more discoverable and useful. There are also many new tools for processing and manipulating video in interesting ways. This column will briefly discuss the idea of deep learning and how deep learning tools can be used to transcribe, translate, search, and even manipulate videos. It will suggest ways that librarians can use these tools to help their institutions better manage video content. It also includes a list of video-related software tools.","3":"Medical reference services quarterly","4":"30239300","5":"2018","6":"Video Recording"},{"1":"Characterization of relapsing-remitting multiple sclerosis patients using support vector machine classifications of functional and diffusion MRI data.","2":"Multiple Sclerosis patients' clinical symptoms do not correlate strongly with structural assessment done with traditional magnetic resonance images. However, its diagnosis and evaluation of the disease's progression are based on a combination of this imaging analysis complemented with clinical examination. Therefore, other biomarkers are necessary to better understand the disease. In this paper, we capitalize on machine learning techniques to classify relapsing-remitting multiple sclerosis patients and healthy volunteers based on machine learning techniques, and to identify relevant brain areas and connectivity measures for characterizing patients. To this end, we acquired magnetic resonance imaging data from relapsing-remitting multiple sclerosis patients and healthy subjects. Fractional anisotropy maps, structural and functional connectivity were extracted from the scans. Each of them were used as separate input features to construct support vector machine classifiers. A fourth input feature was created by combining structural and functional connectivity. Patients were divided in two groups according to their degree of disability and, together with the control group, three group pairs were formed for comparison. Twelve separate classifiers were built from the combination of these four input features and three group pairs. The classifiers were able to distinguish between patients and healthy subjects, reaching accuracy levels as high as 89%<U+202F>±<U+202F>2%. In contrast, the performance was noticeably lower when comparing the two groups of patients with different levels of disability, reaching levels below 63%<U+202F>±<U+202F>5%. The brain regions that contributed the most to the classification were the right occipital, left frontal orbital, medial frontal cortices and lingual gyrus. The developed classifiers based on MRI data were able to distinguish multiple sclerosis patients and healthy subjects reliably. Moreover, the resulting classification models identified brain regions, and functional and structural connections relevant for better understanding of the disease.","3":"NeuroImage. Clinical","4":"30238916","5":"2018","6":"Adolescent"},{"1":"Characterization of relapsing-remitting multiple sclerosis patients using support vector machine classifications of functional and diffusion MRI data.","2":"Multiple Sclerosis patients' clinical symptoms do not correlate strongly with structural assessment done with traditional magnetic resonance images. However, its diagnosis and evaluation of the disease's progression are based on a combination of this imaging analysis complemented with clinical examination. Therefore, other biomarkers are necessary to better understand the disease. In this paper, we capitalize on machine learning techniques to classify relapsing-remitting multiple sclerosis patients and healthy volunteers based on machine learning techniques, and to identify relevant brain areas and connectivity measures for characterizing patients. To this end, we acquired magnetic resonance imaging data from relapsing-remitting multiple sclerosis patients and healthy subjects. Fractional anisotropy maps, structural and functional connectivity were extracted from the scans. Each of them were used as separate input features to construct support vector machine classifiers. A fourth input feature was created by combining structural and functional connectivity. Patients were divided in two groups according to their degree of disability and, together with the control group, three group pairs were formed for comparison. Twelve separate classifiers were built from the combination of these four input features and three group pairs. The classifiers were able to distinguish between patients and healthy subjects, reaching accuracy levels as high as 89%<U+202F>±<U+202F>2%. In contrast, the performance was noticeably lower when comparing the two groups of patients with different levels of disability, reaching levels below 63%<U+202F>±<U+202F>5%. The brain regions that contributed the most to the classification were the right occipital, left frontal orbital, medial frontal cortices and lingual gyrus. The developed classifiers based on MRI data were able to distinguish multiple sclerosis patients and healthy subjects reliably. Moreover, the resulting classification models identified brain regions, and functional and structural connections relevant for better understanding of the disease.","3":"NeuroImage. Clinical","4":"30238916","5":"2018","6":"Adult"},{"1":"Characterization of relapsing-remitting multiple sclerosis patients using support vector machine classifications of functional and diffusion MRI data.","2":"Multiple Sclerosis patients' clinical symptoms do not correlate strongly with structural assessment done with traditional magnetic resonance images. However, its diagnosis and evaluation of the disease's progression are based on a combination of this imaging analysis complemented with clinical examination. Therefore, other biomarkers are necessary to better understand the disease. In this paper, we capitalize on machine learning techniques to classify relapsing-remitting multiple sclerosis patients and healthy volunteers based on machine learning techniques, and to identify relevant brain areas and connectivity measures for characterizing patients. To this end, we acquired magnetic resonance imaging data from relapsing-remitting multiple sclerosis patients and healthy subjects. Fractional anisotropy maps, structural and functional connectivity were extracted from the scans. Each of them were used as separate input features to construct support vector machine classifiers. A fourth input feature was created by combining structural and functional connectivity. Patients were divided in two groups according to their degree of disability and, together with the control group, three group pairs were formed for comparison. Twelve separate classifiers were built from the combination of these four input features and three group pairs. The classifiers were able to distinguish between patients and healthy subjects, reaching accuracy levels as high as 89%<U+202F>±<U+202F>2%. In contrast, the performance was noticeably lower when comparing the two groups of patients with different levels of disability, reaching levels below 63%<U+202F>±<U+202F>5%. The brain regions that contributed the most to the classification were the right occipital, left frontal orbital, medial frontal cortices and lingual gyrus. The developed classifiers based on MRI data were able to distinguish multiple sclerosis patients and healthy subjects reliably. Moreover, the resulting classification models identified brain regions, and functional and structural connections relevant for better understanding of the disease.","3":"NeuroImage. Clinical","4":"30238916","5":"2018","6":"Brain"},{"1":"Characterization of relapsing-remitting multiple sclerosis patients using support vector machine classifications of functional and diffusion MRI data.","2":"Multiple Sclerosis patients' clinical symptoms do not correlate strongly with structural assessment done with traditional magnetic resonance images. However, its diagnosis and evaluation of the disease's progression are based on a combination of this imaging analysis complemented with clinical examination. Therefore, other biomarkers are necessary to better understand the disease. In this paper, we capitalize on machine learning techniques to classify relapsing-remitting multiple sclerosis patients and healthy volunteers based on machine learning techniques, and to identify relevant brain areas and connectivity measures for characterizing patients. To this end, we acquired magnetic resonance imaging data from relapsing-remitting multiple sclerosis patients and healthy subjects. Fractional anisotropy maps, structural and functional connectivity were extracted from the scans. Each of them were used as separate input features to construct support vector machine classifiers. A fourth input feature was created by combining structural and functional connectivity. Patients were divided in two groups according to their degree of disability and, together with the control group, three group pairs were formed for comparison. Twelve separate classifiers were built from the combination of these four input features and three group pairs. The classifiers were able to distinguish between patients and healthy subjects, reaching accuracy levels as high as 89%<U+202F>±<U+202F>2%. In contrast, the performance was noticeably lower when comparing the two groups of patients with different levels of disability, reaching levels below 63%<U+202F>±<U+202F>5%. The brain regions that contributed the most to the classification were the right occipital, left frontal orbital, medial frontal cortices and lingual gyrus. The developed classifiers based on MRI data were able to distinguish multiple sclerosis patients and healthy subjects reliably. Moreover, the resulting classification models identified brain regions, and functional and structural connections relevant for better understanding of the disease.","3":"NeuroImage. Clinical","4":"30238916","5":"2018","6":"diagnostic imaging"},{"1":"Characterization of relapsing-remitting multiple sclerosis patients using support vector machine classifications of functional and diffusion MRI data.","2":"Multiple Sclerosis patients' clinical symptoms do not correlate strongly with structural assessment done with traditional magnetic resonance images. However, its diagnosis and evaluation of the disease's progression are based on a combination of this imaging analysis complemented with clinical examination. Therefore, other biomarkers are necessary to better understand the disease. In this paper, we capitalize on machine learning techniques to classify relapsing-remitting multiple sclerosis patients and healthy volunteers based on machine learning techniques, and to identify relevant brain areas and connectivity measures for characterizing patients. To this end, we acquired magnetic resonance imaging data from relapsing-remitting multiple sclerosis patients and healthy subjects. Fractional anisotropy maps, structural and functional connectivity were extracted from the scans. Each of them were used as separate input features to construct support vector machine classifiers. A fourth input feature was created by combining structural and functional connectivity. Patients were divided in two groups according to their degree of disability and, together with the control group, three group pairs were formed for comparison. Twelve separate classifiers were built from the combination of these four input features and three group pairs. The classifiers were able to distinguish between patients and healthy subjects, reaching accuracy levels as high as 89%<U+202F>±<U+202F>2%. In contrast, the performance was noticeably lower when comparing the two groups of patients with different levels of disability, reaching levels below 63%<U+202F>±<U+202F>5%. The brain regions that contributed the most to the classification were the right occipital, left frontal orbital, medial frontal cortices and lingual gyrus. The developed classifiers based on MRI data were able to distinguish multiple sclerosis patients and healthy subjects reliably. Moreover, the resulting classification models identified brain regions, and functional and structural connections relevant for better understanding of the disease.","3":"NeuroImage. Clinical","4":"30238916","5":"2018","6":"pathology"},{"1":"Characterization of relapsing-remitting multiple sclerosis patients using support vector machine classifications of functional and diffusion MRI data.","2":"Multiple Sclerosis patients' clinical symptoms do not correlate strongly with structural assessment done with traditional magnetic resonance images. However, its diagnosis and evaluation of the disease's progression are based on a combination of this imaging analysis complemented with clinical examination. Therefore, other biomarkers are necessary to better understand the disease. In this paper, we capitalize on machine learning techniques to classify relapsing-remitting multiple sclerosis patients and healthy volunteers based on machine learning techniques, and to identify relevant brain areas and connectivity measures for characterizing patients. To this end, we acquired magnetic resonance imaging data from relapsing-remitting multiple sclerosis patients and healthy subjects. Fractional anisotropy maps, structural and functional connectivity were extracted from the scans. Each of them were used as separate input features to construct support vector machine classifiers. A fourth input feature was created by combining structural and functional connectivity. Patients were divided in two groups according to their degree of disability and, together with the control group, three group pairs were formed for comparison. Twelve separate classifiers were built from the combination of these four input features and three group pairs. The classifiers were able to distinguish between patients and healthy subjects, reaching accuracy levels as high as 89%<U+202F>±<U+202F>2%. In contrast, the performance was noticeably lower when comparing the two groups of patients with different levels of disability, reaching levels below 63%<U+202F>±<U+202F>5%. The brain regions that contributed the most to the classification were the right occipital, left frontal orbital, medial frontal cortices and lingual gyrus. The developed classifiers based on MRI data were able to distinguish multiple sclerosis patients and healthy subjects reliably. Moreover, the resulting classification models identified brain regions, and functional and structural connections relevant for better understanding of the disease.","3":"NeuroImage. Clinical","4":"30238916","5":"2018","6":"physiopathology"},{"1":"Characterization of relapsing-remitting multiple sclerosis patients using support vector machine classifications of functional and diffusion MRI data.","2":"Multiple Sclerosis patients' clinical symptoms do not correlate strongly with structural assessment done with traditional magnetic resonance images. However, its diagnosis and evaluation of the disease's progression are based on a combination of this imaging analysis complemented with clinical examination. Therefore, other biomarkers are necessary to better understand the disease. In this paper, we capitalize on machine learning techniques to classify relapsing-remitting multiple sclerosis patients and healthy volunteers based on machine learning techniques, and to identify relevant brain areas and connectivity measures for characterizing patients. To this end, we acquired magnetic resonance imaging data from relapsing-remitting multiple sclerosis patients and healthy subjects. Fractional anisotropy maps, structural and functional connectivity were extracted from the scans. Each of them were used as separate input features to construct support vector machine classifiers. A fourth input feature was created by combining structural and functional connectivity. Patients were divided in two groups according to their degree of disability and, together with the control group, three group pairs were formed for comparison. Twelve separate classifiers were built from the combination of these four input features and three group pairs. The classifiers were able to distinguish between patients and healthy subjects, reaching accuracy levels as high as 89%<U+202F>±<U+202F>2%. In contrast, the performance was noticeably lower when comparing the two groups of patients with different levels of disability, reaching levels below 63%<U+202F>±<U+202F>5%. The brain regions that contributed the most to the classification were the right occipital, left frontal orbital, medial frontal cortices and lingual gyrus. The developed classifiers based on MRI data were able to distinguish multiple sclerosis patients and healthy subjects reliably. Moreover, the resulting classification models identified brain regions, and functional and structural connections relevant for better understanding of the disease.","3":"NeuroImage. Clinical","4":"30238916","5":"2018","6":"Brain Mapping"},{"1":"Characterization of relapsing-remitting multiple sclerosis patients using support vector machine classifications of functional and diffusion MRI data.","2":"Multiple Sclerosis patients' clinical symptoms do not correlate strongly with structural assessment done with traditional magnetic resonance images. However, its diagnosis and evaluation of the disease's progression are based on a combination of this imaging analysis complemented with clinical examination. Therefore, other biomarkers are necessary to better understand the disease. In this paper, we capitalize on machine learning techniques to classify relapsing-remitting multiple sclerosis patients and healthy volunteers based on machine learning techniques, and to identify relevant brain areas and connectivity measures for characterizing patients. To this end, we acquired magnetic resonance imaging data from relapsing-remitting multiple sclerosis patients and healthy subjects. Fractional anisotropy maps, structural and functional connectivity were extracted from the scans. Each of them were used as separate input features to construct support vector machine classifiers. A fourth input feature was created by combining structural and functional connectivity. Patients were divided in two groups according to their degree of disability and, together with the control group, three group pairs were formed for comparison. Twelve separate classifiers were built from the combination of these four input features and three group pairs. The classifiers were able to distinguish between patients and healthy subjects, reaching accuracy levels as high as 89%<U+202F>±<U+202F>2%. In contrast, the performance was noticeably lower when comparing the two groups of patients with different levels of disability, reaching levels below 63%<U+202F>±<U+202F>5%. The brain regions that contributed the most to the classification were the right occipital, left frontal orbital, medial frontal cortices and lingual gyrus. The developed classifiers based on MRI data were able to distinguish multiple sclerosis patients and healthy subjects reliably. Moreover, the resulting classification models identified brain regions, and functional and structural connections relevant for better understanding of the disease.","3":"NeuroImage. Clinical","4":"30238916","5":"2018","6":"methods"},{"1":"Characterization of relapsing-remitting multiple sclerosis patients using support vector machine classifications of functional and diffusion MRI data.","2":"Multiple Sclerosis patients' clinical symptoms do not correlate strongly with structural assessment done with traditional magnetic resonance images. However, its diagnosis and evaluation of the disease's progression are based on a combination of this imaging analysis complemented with clinical examination. Therefore, other biomarkers are necessary to better understand the disease. In this paper, we capitalize on machine learning techniques to classify relapsing-remitting multiple sclerosis patients and healthy volunteers based on machine learning techniques, and to identify relevant brain areas and connectivity measures for characterizing patients. To this end, we acquired magnetic resonance imaging data from relapsing-remitting multiple sclerosis patients and healthy subjects. Fractional anisotropy maps, structural and functional connectivity were extracted from the scans. Each of them were used as separate input features to construct support vector machine classifiers. A fourth input feature was created by combining structural and functional connectivity. Patients were divided in two groups according to their degree of disability and, together with the control group, three group pairs were formed for comparison. Twelve separate classifiers were built from the combination of these four input features and three group pairs. The classifiers were able to distinguish between patients and healthy subjects, reaching accuracy levels as high as 89%<U+202F>±<U+202F>2%. In contrast, the performance was noticeably lower when comparing the two groups of patients with different levels of disability, reaching levels below 63%<U+202F>±<U+202F>5%. The brain regions that contributed the most to the classification were the right occipital, left frontal orbital, medial frontal cortices and lingual gyrus. The developed classifiers based on MRI data were able to distinguish multiple sclerosis patients and healthy subjects reliably. Moreover, the resulting classification models identified brain regions, and functional and structural connections relevant for better understanding of the disease.","3":"NeuroImage. Clinical","4":"30238916","5":"2018","6":"Diffusion Magnetic Resonance Imaging"},{"1":"Characterization of relapsing-remitting multiple sclerosis patients using support vector machine classifications of functional and diffusion MRI data.","2":"Multiple Sclerosis patients' clinical symptoms do not correlate strongly with structural assessment done with traditional magnetic resonance images. However, its diagnosis and evaluation of the disease's progression are based on a combination of this imaging analysis complemented with clinical examination. Therefore, other biomarkers are necessary to better understand the disease. In this paper, we capitalize on machine learning techniques to classify relapsing-remitting multiple sclerosis patients and healthy volunteers based on machine learning techniques, and to identify relevant brain areas and connectivity measures for characterizing patients. To this end, we acquired magnetic resonance imaging data from relapsing-remitting multiple sclerosis patients and healthy subjects. Fractional anisotropy maps, structural and functional connectivity were extracted from the scans. Each of them were used as separate input features to construct support vector machine classifiers. A fourth input feature was created by combining structural and functional connectivity. Patients were divided in two groups according to their degree of disability and, together with the control group, three group pairs were formed for comparison. Twelve separate classifiers were built from the combination of these four input features and three group pairs. The classifiers were able to distinguish between patients and healthy subjects, reaching accuracy levels as high as 89%<U+202F>±<U+202F>2%. In contrast, the performance was noticeably lower when comparing the two groups of patients with different levels of disability, reaching levels below 63%<U+202F>±<U+202F>5%. The brain regions that contributed the most to the classification were the right occipital, left frontal orbital, medial frontal cortices and lingual gyrus. The developed classifiers based on MRI data were able to distinguish multiple sclerosis patients and healthy subjects reliably. Moreover, the resulting classification models identified brain regions, and functional and structural connections relevant for better understanding of the disease.","3":"NeuroImage. Clinical","4":"30238916","5":"2018","6":"Female"},{"1":"Characterization of relapsing-remitting multiple sclerosis patients using support vector machine classifications of functional and diffusion MRI data.","2":"Multiple Sclerosis patients' clinical symptoms do not correlate strongly with structural assessment done with traditional magnetic resonance images. However, its diagnosis and evaluation of the disease's progression are based on a combination of this imaging analysis complemented with clinical examination. Therefore, other biomarkers are necessary to better understand the disease. In this paper, we capitalize on machine learning techniques to classify relapsing-remitting multiple sclerosis patients and healthy volunteers based on machine learning techniques, and to identify relevant brain areas and connectivity measures for characterizing patients. To this end, we acquired magnetic resonance imaging data from relapsing-remitting multiple sclerosis patients and healthy subjects. Fractional anisotropy maps, structural and functional connectivity were extracted from the scans. Each of them were used as separate input features to construct support vector machine classifiers. A fourth input feature was created by combining structural and functional connectivity. Patients were divided in two groups according to their degree of disability and, together with the control group, three group pairs were formed for comparison. Twelve separate classifiers were built from the combination of these four input features and three group pairs. The classifiers were able to distinguish between patients and healthy subjects, reaching accuracy levels as high as 89%<U+202F>±<U+202F>2%. In contrast, the performance was noticeably lower when comparing the two groups of patients with different levels of disability, reaching levels below 63%<U+202F>±<U+202F>5%. The brain regions that contributed the most to the classification were the right occipital, left frontal orbital, medial frontal cortices and lingual gyrus. The developed classifiers based on MRI data were able to distinguish multiple sclerosis patients and healthy subjects reliably. Moreover, the resulting classification models identified brain regions, and functional and structural connections relevant for better understanding of the disease.","3":"NeuroImage. Clinical","4":"30238916","5":"2018","6":"Humans"},{"1":"Characterization of relapsing-remitting multiple sclerosis patients using support vector machine classifications of functional and diffusion MRI data.","2":"Multiple Sclerosis patients' clinical symptoms do not correlate strongly with structural assessment done with traditional magnetic resonance images. However, its diagnosis and evaluation of the disease's progression are based on a combination of this imaging analysis complemented with clinical examination. Therefore, other biomarkers are necessary to better understand the disease. In this paper, we capitalize on machine learning techniques to classify relapsing-remitting multiple sclerosis patients and healthy volunteers based on machine learning techniques, and to identify relevant brain areas and connectivity measures for characterizing patients. To this end, we acquired magnetic resonance imaging data from relapsing-remitting multiple sclerosis patients and healthy subjects. Fractional anisotropy maps, structural and functional connectivity were extracted from the scans. Each of them were used as separate input features to construct support vector machine classifiers. A fourth input feature was created by combining structural and functional connectivity. Patients were divided in two groups according to their degree of disability and, together with the control group, three group pairs were formed for comparison. Twelve separate classifiers were built from the combination of these four input features and three group pairs. The classifiers were able to distinguish between patients and healthy subjects, reaching accuracy levels as high as 89%<U+202F>±<U+202F>2%. In contrast, the performance was noticeably lower when comparing the two groups of patients with different levels of disability, reaching levels below 63%<U+202F>±<U+202F>5%. The brain regions that contributed the most to the classification were the right occipital, left frontal orbital, medial frontal cortices and lingual gyrus. The developed classifiers based on MRI data were able to distinguish multiple sclerosis patients and healthy subjects reliably. Moreover, the resulting classification models identified brain regions, and functional and structural connections relevant for better understanding of the disease.","3":"NeuroImage. Clinical","4":"30238916","5":"2018","6":"Image Processing, Computer-Assisted"},{"1":"Characterization of relapsing-remitting multiple sclerosis patients using support vector machine classifications of functional and diffusion MRI data.","2":"Multiple Sclerosis patients' clinical symptoms do not correlate strongly with structural assessment done with traditional magnetic resonance images. However, its diagnosis and evaluation of the disease's progression are based on a combination of this imaging analysis complemented with clinical examination. Therefore, other biomarkers are necessary to better understand the disease. In this paper, we capitalize on machine learning techniques to classify relapsing-remitting multiple sclerosis patients and healthy volunteers based on machine learning techniques, and to identify relevant brain areas and connectivity measures for characterizing patients. To this end, we acquired magnetic resonance imaging data from relapsing-remitting multiple sclerosis patients and healthy subjects. Fractional anisotropy maps, structural and functional connectivity were extracted from the scans. Each of them were used as separate input features to construct support vector machine classifiers. A fourth input feature was created by combining structural and functional connectivity. Patients were divided in two groups according to their degree of disability and, together with the control group, three group pairs were formed for comparison. Twelve separate classifiers were built from the combination of these four input features and three group pairs. The classifiers were able to distinguish between patients and healthy subjects, reaching accuracy levels as high as 89%<U+202F>±<U+202F>2%. In contrast, the performance was noticeably lower when comparing the two groups of patients with different levels of disability, reaching levels below 63%<U+202F>±<U+202F>5%. The brain regions that contributed the most to the classification were the right occipital, left frontal orbital, medial frontal cortices and lingual gyrus. The developed classifiers based on MRI data were able to distinguish multiple sclerosis patients and healthy subjects reliably. Moreover, the resulting classification models identified brain regions, and functional and structural connections relevant for better understanding of the disease.","3":"NeuroImage. Clinical","4":"30238916","5":"2018","6":"methods"},{"1":"Characterization of relapsing-remitting multiple sclerosis patients using support vector machine classifications of functional and diffusion MRI data.","2":"Multiple Sclerosis patients' clinical symptoms do not correlate strongly with structural assessment done with traditional magnetic resonance images. However, its diagnosis and evaluation of the disease's progression are based on a combination of this imaging analysis complemented with clinical examination. Therefore, other biomarkers are necessary to better understand the disease. In this paper, we capitalize on machine learning techniques to classify relapsing-remitting multiple sclerosis patients and healthy volunteers based on machine learning techniques, and to identify relevant brain areas and connectivity measures for characterizing patients. To this end, we acquired magnetic resonance imaging data from relapsing-remitting multiple sclerosis patients and healthy subjects. Fractional anisotropy maps, structural and functional connectivity were extracted from the scans. Each of them were used as separate input features to construct support vector machine classifiers. A fourth input feature was created by combining structural and functional connectivity. Patients were divided in two groups according to their degree of disability and, together with the control group, three group pairs were formed for comparison. Twelve separate classifiers were built from the combination of these four input features and three group pairs. The classifiers were able to distinguish between patients and healthy subjects, reaching accuracy levels as high as 89%<U+202F>±<U+202F>2%. In contrast, the performance was noticeably lower when comparing the two groups of patients with different levels of disability, reaching levels below 63%<U+202F>±<U+202F>5%. The brain regions that contributed the most to the classification were the right occipital, left frontal orbital, medial frontal cortices and lingual gyrus. The developed classifiers based on MRI data were able to distinguish multiple sclerosis patients and healthy subjects reliably. Moreover, the resulting classification models identified brain regions, and functional and structural connections relevant for better understanding of the disease.","3":"NeuroImage. Clinical","4":"30238916","5":"2018","6":"Male"},{"1":"Characterization of relapsing-remitting multiple sclerosis patients using support vector machine classifications of functional and diffusion MRI data.","2":"Multiple Sclerosis patients' clinical symptoms do not correlate strongly with structural assessment done with traditional magnetic resonance images. However, its diagnosis and evaluation of the disease's progression are based on a combination of this imaging analysis complemented with clinical examination. Therefore, other biomarkers are necessary to better understand the disease. In this paper, we capitalize on machine learning techniques to classify relapsing-remitting multiple sclerosis patients and healthy volunteers based on machine learning techniques, and to identify relevant brain areas and connectivity measures for characterizing patients. To this end, we acquired magnetic resonance imaging data from relapsing-remitting multiple sclerosis patients and healthy subjects. Fractional anisotropy maps, structural and functional connectivity were extracted from the scans. Each of them were used as separate input features to construct support vector machine classifiers. A fourth input feature was created by combining structural and functional connectivity. Patients were divided in two groups according to their degree of disability and, together with the control group, three group pairs were formed for comparison. Twelve separate classifiers were built from the combination of these four input features and three group pairs. The classifiers were able to distinguish between patients and healthy subjects, reaching accuracy levels as high as 89%<U+202F>±<U+202F>2%. In contrast, the performance was noticeably lower when comparing the two groups of patients with different levels of disability, reaching levels below 63%<U+202F>±<U+202F>5%. The brain regions that contributed the most to the classification were the right occipital, left frontal orbital, medial frontal cortices and lingual gyrus. The developed classifiers based on MRI data were able to distinguish multiple sclerosis patients and healthy subjects reliably. Moreover, the resulting classification models identified brain regions, and functional and structural connections relevant for better understanding of the disease.","3":"NeuroImage. Clinical","4":"30238916","5":"2018","6":"Middle Aged"},{"1":"Characterization of relapsing-remitting multiple sclerosis patients using support vector machine classifications of functional and diffusion MRI data.","2":"Multiple Sclerosis patients' clinical symptoms do not correlate strongly with structural assessment done with traditional magnetic resonance images. However, its diagnosis and evaluation of the disease's progression are based on a combination of this imaging analysis complemented with clinical examination. Therefore, other biomarkers are necessary to better understand the disease. In this paper, we capitalize on machine learning techniques to classify relapsing-remitting multiple sclerosis patients and healthy volunteers based on machine learning techniques, and to identify relevant brain areas and connectivity measures for characterizing patients. To this end, we acquired magnetic resonance imaging data from relapsing-remitting multiple sclerosis patients and healthy subjects. Fractional anisotropy maps, structural and functional connectivity were extracted from the scans. Each of them were used as separate input features to construct support vector machine classifiers. A fourth input feature was created by combining structural and functional connectivity. Patients were divided in two groups according to their degree of disability and, together with the control group, three group pairs were formed for comparison. Twelve separate classifiers were built from the combination of these four input features and three group pairs. The classifiers were able to distinguish between patients and healthy subjects, reaching accuracy levels as high as 89%<U+202F>±<U+202F>2%. In contrast, the performance was noticeably lower when comparing the two groups of patients with different levels of disability, reaching levels below 63%<U+202F>±<U+202F>5%. The brain regions that contributed the most to the classification were the right occipital, left frontal orbital, medial frontal cortices and lingual gyrus. The developed classifiers based on MRI data were able to distinguish multiple sclerosis patients and healthy subjects reliably. Moreover, the resulting classification models identified brain regions, and functional and structural connections relevant for better understanding of the disease.","3":"NeuroImage. Clinical","4":"30238916","5":"2018","6":"Multiple Sclerosis, Relapsing-Remitting"}],"options":{"columns":{"min":{},"max":[10],"total":[6]},"rows":{"min":[10],"max":[10],"total":[46975]},"pages":{}}}
  </script>
</div>
<!-- rnb-frame-end -->
<!-- rnb-chunk-end -->
<!-- rnb-text-begin -->
</div>
</div>
<div id="simple-analysis" class="section level2">
<h2>Simple analysis</h2>
<div id="abstracts-per-journal" class="section level3">
<h3>Abstracts per journal</h3>
<p>We can undertake simple analysis such as the frequency of abstracts by journal - see #Figure 4.1 which shows that the frequency of apparent relevant articles has grown in the last 3-4 years.</p>
<!-- rnb-text-end -->
<!-- rnb-chunk-begin -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuYWJzdHJhY3RzMSAlPiVcbiAgZ3JvdXBfYnkoam91cm5hbCkgJT4lXG4gIGNvdW50KCkgJT4lXG4gIGRwbHlyOjpmaWx0ZXIobiA+IDEwKSAlPiVcbiAgI3NwcmVhZCh5ZWFyLCBuLCBmaWxsID0gMCkgJT4lXG4gIGdncGxvdChhZXMocmVvcmRlcihqb3VybmFsLCBuKSwgbikpICtcbiAgZ2VvbV9jb2woKSArXG4gICAgY29vcmRfZmxpcCgpICtcbiAgbGFicyh0aXRsZSA9IFwiQWJzdHJhY3QgZnJlcXVlbmN5OiBcIiwgXG4gICAgICAgc3VidGl0bGUgPSAgc2VhcmNoKSArXG4gIHRoZW1lKHBsb3Quc3VidGl0bGUgPSBlbGVtZW50X3RleHQoc2l6ZSA9IHJlbCguNykpLFxuICAgICAgICBheGlzLnRleHQueSA9IGVsZW1lbnRfdGV4dChzaXplID0gNykpXG5gYGAifQ== -->
<pre class="r"><code>abstracts1 %&gt;%
  group_by(journal) %&gt;%
  count() %&gt;%
  dplyr::filter(n &gt; 10) %&gt;%
  #spread(year, n, fill = 0) %&gt;%
  ggplot(aes(reorder(journal, n), n)) +
  geom_col() +
    coord_flip() +
  labs(title = &quot;Abstract frequency: &quot;, 
       subtitle =  search) +
  theme(plot.subtitle = element_text(size = rel(.7)),
        axis.text.y = element_text(size = 7))</code></pre>
<!-- rnb-source-end -->
<!-- rnb-plot-begin eyJjb25kaXRpb25zIjpbXSwiaGVpZ2h0Ijo3LjQxNjYsInNpemVfYmVoYXZpb3IiOjEsIndpZHRoIjoxMn0= -->
<p><img src="data:image/png;base64,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" /></p>
<!-- rnb-plot-end -->
<!-- rnb-chunk-end -->
<!-- rnb-text-begin -->
</div>
</div>
<div id="mesh-terms" class="section level2">
<h2>Mesh terms</h2>
<p>We can look at the most frequently used Mesh terms.</p>
<!-- rnb-text-end -->
<!-- rnb-chunk-begin -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxubWVzaCA8LSBhYnN0cmFjdHNfa3cgJT4lXG4gIGNvdW50KGtleXdvcmQsIHllYXIpXG5tZXNoICU+JVxuICB0b3BfbigxMDApICU+JVxuICBhcnJhbmdlKC1uKSAlPiVcbiAgZ2dwbG90KGFlcyh5ZWFyLCByZW9yZGVyKGtleXdvcmQsIG4pLCBmaWxsID0gbikpICtcbiAgZ2VvbV90aWxlKCkgK1xuICBwaGVjaGFydHM6OnRoZW1lX3BoZSgpICtcbiAgdmlyaWRpczo6c2NhbGVfZmlsbF92aXJpZGlzKClcbmBgYCJ9 -->
<pre class="r"><code>mesh &lt;- abstracts_kw %&gt;%
  count(keyword, year)
mesh %&gt;%
  top_n(100) %&gt;%
  arrange(-n) %&gt;%
  ggplot(aes(year, reorder(keyword, n), fill = n)) +
  geom_tile() +
  phecharts::theme_phe() +
  viridis::scale_fill_viridis()</code></pre>
<!-- rnb-source-end -->
<!-- rnb-plot-begin eyJjb25kaXRpb25zIjpbXSwiaGVpZ2h0Ijo4LCJzaXplX2JlaGF2aW9yIjoxLCJ3aWR0aCI6MTIuOTQ0fQ== -->
<p><img src="data:image/png;base64,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" /></p>
<!-- rnb-plot-end -->
<!-- rnb-chunk-end -->
<!-- rnb-text-begin -->
</div>
<div id="wordcloud" class="section level2">
<h2>Wordcloud</h2>
<p>A simple way of visualising the abstracts is to <em>tokenise</em> them into 1 and 2 ngrams and then plot occurrence frequency as a wordcloud. We can easily do this with the <code>quanteda</code> pacakge.</p>
<!-- rnb-text-end -->
<!-- rnb-chunk-begin -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxubGlicmFyeShxdWFudGVkYSlcbmFic3RyYWN0czEkYWJzdHJhY3QgPC0gdG06OnJlbW92ZVdvcmRzKGFic3RyYWN0czEkYWJzdHJhY3QsIHN0b3B3b3JkcyhcImVuZ2xpc2hcIikpXG5hYnNfY29ycHVzIDwtIGNvcnB1cyhhYnN0cmFjdHMxJGFic3RyYWN0KVxuYWJzX2RmbSA8LSBkZm0oYWJzX2NvcnB1cywgcmVtb3ZlID0gc3RvcHdvcmRzKFwiZW5cIiksIG5ncmFtcyA9IDE6MiwgcmVtb3ZlX3B1bmN0ID0gVFJVRSlcbnRleHRwbG90X3dvcmRjbG91ZChhYnNfZGZtIClcbmBgYCJ9 -->
<pre class="r"><code>library(quanteda)
abstracts1$abstract &lt;- tm::removeWords(abstracts1$abstract, stopwords(&quot;english&quot;))
abs_corpus &lt;- corpus(abstracts1$abstract)
abs_dfm &lt;- dfm(abs_corpus, remove = stopwords(&quot;en&quot;), ngrams = 1:2, remove_punct = TRUE)
textplot_wordcloud(abs_dfm )</code></pre>
<!-- rnb-source-end -->
<!-- rnb-plot-begin eyJjb25kaXRpb25zIjpbXSwiaGVpZ2h0Ijo0MzIuNjMyOSwic2l6ZV9iZWhhdmlvciI6MCwid2lkdGgiOjcwMH0= -->
<p><img src="data:image/png;base64,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" /></p>
<!-- rnb-plot-end -->
<!-- rnb-chunk-end -->
<!-- rnb-text-begin -->
<p>This confirms support vector machines (SVM) as a widely used algorithm and classification and prediction as a common application. It is hard to discern any common public health themes - most of the terms seem to relate to methods.</p>
<p>We can explore further using <em>dictionary</em> and <em>topic modelling</em> methods. The former allows us to search for terms across the documents using a pre-determined dictionary. The latter is an unsupervised machine learning or clustering technique which allows us to look for common groupings or themes (aka topics across all the documents).</p>
<div id="dictionary-searching-of-abstracts" class="section level3">
<h3>Dictionary searching of abstracts</h3>
<p>We can create a list of terms of interest and use the to find which abstracts they occur in and how often.</p>
<!-- rnb-text-end -->
<!-- rnb-chunk-begin -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuYWJzX2RpY3QgPC0gZGljdGlvbmFyeShsaXN0KGFpID0gYyhcImFydGlmaWNpYWxfaW50ZWxsaWdlbmNlXCIsIFwiYWlcIiksIFxuICAgICAgICAgICAgICAgICAgICAgICAgICAgIG9iZXNpdHkgPSBcIm9iZXMqXCIsIFxuICAgICAgICAgICAgICAgICAgICAgICAgICAgIHRvYmFjY28gPSBjKFwic21vaypcIiwgXCJ0b2JhY2NvXCIsIFwiY2lnYXIqXCIpLCBcbiAgICAgICAgICAgICAgICAgICAgICAgICAgICBoZWFydF9kaXNlYXNlID0gYyhcImhlYXJ0XCIsIFwiY2FyZGkqXCIpLCBcbiAgICAgICAgICAgICAgICAgICAgICAgICAgICBkaWFiZXRlcyA9IFwiZGlhYmV0KlwiLCBcbiAgICAgICAgICAgICAgICAgICAgICAgICAgICBjYW5jZXIgPSBcImNhbmNlcipcIiAsIFxuICAgICAgICAgICAgICAgICAgICAgICAgICAgIHN2bSA9IFwic3VwcG9ydF92ZWN0b3IqXCIsIFxuICAgICAgICAgICAgICAgICAgICAgICAgICAgIHJmID0gXCJyYW5kb21fZm9yZXN0XCIsIFxuICAgICAgICAgICAgICAgICAgICAgICAgICAgIG5uID0gXCJuZXVyYWxfbmV0d29yaypcIixcbiAgICAgICAgICAgICAgICAgICAgICAgICAgICBwaCA9IFwicHVibGljX2hlYWx0aFwiLCBcbiAgICAgICAgICAgICAgICAgICAgICAgICAgICByZWdyID0gYyhcInJlZ3Jlc3Npb25cIiwgXCJ4Z2IqXCIsIFwiZ2JtXCIsICBcImxhc3NvXCIsIFwiZ2xtbmV0KlwiLCBcInBlbmFsaXNlZCpcIiksIFxuICAgICAgICAgICAgICAgICAgICAgICAgICAgIGNsdXN0ZXIgPSBjKFwiY2x1c3RlcipcIiwgXCJrbWVhbnNcIiwgXCJrLW1lYW5zXCIsIFwiaGllcmFyY2hpY2FsIGNsdXMqXCIpXG4gICAgICAgICAgICAgICAgICAgICAgICAgICAgKSlcbmFic19kaWN0XG5gYGAifQ== -->
<pre class="r"><code>abs_dict &lt;- dictionary(list(ai = c(&quot;artificial_intelligence&quot;, &quot;ai&quot;), 
                            obesity = &quot;obes*&quot;, 
                            tobacco = c(&quot;smok*&quot;, &quot;tobacco&quot;, &quot;cigar*&quot;), 
                            heart_disease = c(&quot;heart&quot;, &quot;cardi*&quot;), 
                            diabetes = &quot;diabet*&quot;, 
                            cancer = &quot;cancer*&quot; , 
                            svm = &quot;support_vector*&quot;, 
                            rf = &quot;random_forest&quot;, 
                            nn = &quot;neural_network*&quot;,
                            ph = &quot;public_health&quot;, 
                            regr = c(&quot;regression&quot;, &quot;xgb*&quot;, &quot;gbm&quot;,  &quot;lasso&quot;, &quot;glmnet*&quot;, &quot;penalised*&quot;), 
                            cluster = c(&quot;cluster*&quot;, &quot;kmeans&quot;, &quot;k-means&quot;, &quot;hierarchical clus*&quot;)
                            ))
abs_dict</code></pre>
<!-- rnb-source-end -->
<!-- rnb-output-begin eyJkYXRhIjoiRGljdGlvbmFyeSBvYmplY3Qgd2l0aCAxMiBrZXkgZW50cmllcy5cbi0gW2FpXTpcbiAgLSBhcnRpZmljaWFsX2ludGVsbGlnZW5jZSwgYWlcbi0gW29iZXNpdHldOlxuICAtIG9iZXMqXG4tIFt0b2JhY2NvXTpcbiAgLSBzbW9rKiwgdG9iYWNjbywgY2lnYXIqXG4tIFtoZWFydF9kaXNlYXNlXTpcbiAgLSBoZWFydCwgY2FyZGkqXG4tIFtkaWFiZXRlc106XG4gIC0gZGlhYmV0KlxuLSBbY2FuY2VyXTpcbiAgLSBjYW5jZXIqXG4tIFtzdm1dOlxuICAtIHN1cHBvcnRfdmVjdG9yKlxuLSBbcmZdOlxuICAtIHJhbmRvbV9mb3Jlc3Rcbi0gW25uXTpcbiAgLSBuZXVyYWxfbmV0d29yaypcbi0gW3BoXTpcbiAgLSBwdWJsaWNfaGVhbHRoXG4tIFtyZWdyXTpcbiAgLSByZWdyZXNzaW9uLCB4Z2IqLCBnYm0sIGxhc3NvLCBnbG1uZXQqLCBwZW5hbGlzZWQqXG4tIFtjbHVzdGVyXTpcbiAgLSBjbHVzdGVyKiwga21lYW5zLCBrLW1lYW5zLCBoaWVyYXJjaGljYWwgY2x1cypcbiJ9 -->
<pre><code>Dictionary object with 12 key entries.
- [ai]:
  - artificial_intelligence, ai
- [obesity]:
  - obes*
- [tobacco]:
  - smok*, tobacco, cigar*
- [heart_disease]:
  - heart, cardi*
- [diabetes]:
  - diabet*
- [cancer]:
  - cancer*
- [svm]:
  - support_vector*
- [rf]:
  - random_forest
- [nn]:
  - neural_network*
- [ph]:
  - public_health
- [regr]:
  - regression, xgb*, gbm, lasso, glmnet*, penalised*
- [cluster]:
  - cluster*, kmeans, k-means, hierarchical clus*</code></pre>
<!-- rnb-output-end -->
<!-- rnb-chunk-end -->
<!-- rnb-text-begin -->
</div>
</div>
<div id="clustering-articles" class="section level2">
<h2>Clustering articles</h2>
<!-- rnb-text-end -->
<!-- rnb-chunk-begin -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuICBcbmxvb2t1cCA8LSBkZm1fbG9va3VwKGFic19kZm0sIGRpY3Rpb25hcnkgPSBhYnNfZGljdClcbmx1MSA8LSBsb29rdXAgJT4lXG4gIGNvbnZlcnQoLiwgdG8gPSBcImRhdGEuZnJhbWVcIikgJT4lXG4gIGdhdGhlcih0aGVtZSwgdmFsdWUsIDI6bmNvbCguKSkgJT4lXG4gICNmaWx0ZXIodmFsdWUgPiAwLCB0aGVtZSAlaW4lIGMoXCJyZlwiLCBcInBoXCIpKSAlPiVcbiAgc3ByZWFkKHRoZW1lLCB2YWx1ZSwgZmlsbCA9IDApICU+JVxuICBkcGx5cjo6ZmlsdGVyKCBjbHVzdGVyPiAwLCBwaCA+MClcbmx1MVxuYGBgIn0= -->
<pre class="r"><code>  
lookup &lt;- dfm_lookup(abs_dfm, dictionary = abs_dict)
lu1 &lt;- lookup %&gt;%
  convert(., to = &quot;data.frame&quot;) %&gt;%
  gather(theme, value, 2:ncol(.)) %&gt;%
  #filter(value &gt; 0, theme %in% c(&quot;rf&quot;, &quot;ph&quot;)) %&gt;%
  spread(theme, value, fill = 0) %&gt;%
  dplyr::filter( cluster&gt; 0, ph &gt;0)
lu1</code></pre>
<!-- rnb-source-end -->
<!-- rnb-frame-begin eyJtZXRhZGF0YSI6eyJjbGFzc2VzIjpbImRhdGEuZnJhbWUiXSwibmNvbCI6MTMsIm5yb3ciOjR9LCJyZGYiOiJINHNJQUFBQUFBQUFCcVZUUFUvRE1CQjFuYVFma1ZLUVdCZ1pXQnUxcFJYcVJBZCtBVk0zNURwdUVwSGFsZTNRc3ZHVCtRVUZKL0ZGSVJKQ2JTTTU5NTd2N2psM09iODhyNmIreWtjSVllUjRIWVFkQTExc1hoM2tva0ZoRHdnNU53WUVabDBYWHV2b2EzYlFrOWxzYkhtdjVJdEYwejBmaitkTjkrUDB3Y0JocWZML2MxTGM4cjRpeXp0cis5YmVucWQzYWR6eVREM0lBL3YwZFpuZXBYR25uL3RyZkR4T3RreWhhblFDbUkxSTBIekx1TFljazlTaUxpV2NNZ2t6UTdOYzZacjJvNVNzbVRaeUZROFNScVIralZMRmlHS2d4VGxraXpWVHFmNEF4eTZ4eUpVc0JrMHNOeFk1Nm4xYno2cFlFMHBGcTVhQkZQc1E2aW11QS82MEZiZUxwaGxSVURScytoSFJKTnhJazIvWXNaWFNFenVkQ202U2NISFp5b1RTWGEybVVFYzJuS2psdk1wNThZWFJpQ1k1Znh0TldxRi80Y0JpdDRHRDZoUHh0ejFpVUZkSGFBTHQ3akllcHh5WXg2UVUwRm92TTM4cmcvcE0xeFNKSWJDM0o1S25QTFowYURwYk5qYmN5YlFlQzkvc3FsQUxUVURGcHlLRG5iS0g2UGdEVm01WXJNSUVBQUE9In0= -->
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["document"],"name":[1],"type":["chr"],"align":["left"]},{"label":["ai"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["cancer"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["cluster"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["diabetes"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["heart_disease"],"name":[6],"type":["dbl"],"align":["right"]},{"label":["nn"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["obesity"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["ph"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["regr"],"name":[10],"type":["dbl"],"align":["right"]},{"label":["rf"],"name":[11],"type":["dbl"],"align":["right"]},{"label":["svm"],"name":[12],"type":["dbl"],"align":["right"]},{"label":["tobacco"],"name":[13],"type":["dbl"],"align":["right"]}],"data":[{"1":"text1440","2":"0","3":"0","4":"10","5":"0","6":"0","7":"0","8":"0","9":"2","10":"0","11":"0","12":"0","13":"0"},{"1":"text199","2":"0","3":"0","4":"8","5":"0","6":"0","7":"0","8":"0","9":"2","10":"0","11":"0","12":"0","13":"0"},{"1":"text5005","2":"0","3":"0","4":"3","5":"0","6":"0","7":"0","8":"0","9":"1","10":"0","11":"0","12":"0","13":"0"},{"1":"text723","2":"0","3":"0","4":"6","5":"0","6":"0","7":"2","8":"0","9":"2","10":"0","11":"0","12":"2","13":"0"}],"options":{"columns":{"min":{},"max":[10],"total":[13]},"rows":{"min":[10],"max":[10],"total":[4]},"pages":{}}}
  </script>
</div>
<!-- rnb-frame-end -->
<!-- rnb-chunk-end -->
<!-- rnb-text-begin -->
</div>
<div id="look-at-a-random-sample-of-articles" class="section level2">
<h2>Look at a random sample of articles</h2>
<!-- rnb-text-end -->
<!-- rnb-chunk-begin -->
<!-- rnb-source-begin eyJkYXRhIjoiYGBgclxuXG5kb2N2YXJzKGFic19jb3JwdXMsIFwieWVhclwiKSA8LSBhYnN0cmFjdHMxJHllYXJcbmRvY3ZhcnMoYWJzX2NvcnB1cywgXCJ0aXRsZVwiKSA8LSBhYnN0cmFjdHMxJHRpdGxlXG5kb2N2YXJzKGFic19jb3JwdXMsIFwiam91cm5hbFwiKSA8LSBhYnN0cmFjdHMxJGpvdXJuYWxcbmRvY3ZhcnMoYWJzX2NvcnB1cywgXCJkb2lcIikgPC0gYWJzdHJhY3RzMSRET0lcblxuXG5jb3JwX2RmIDwtIGRvY3ZhcnMoYWJzX2NvcnB1cykgJT4lXG4gIHJvd25hbWVzX3RvX2NvbHVtbihcImRvY3VtZW50XCIpXG5cbmx1MSAlPiVcbiAgI3NhbXBsZV9mcmFjKC41KSAlPiVcbiAgbGVmdF9qb2luKGNvcnBfZGYpICU+JVxuICBhcnJhbmdlKGRvaSkgJT4lXG4gIHNlbGVjdCgtZG9jdW1lbnQpICU+JVxuICBkaXN0aW5jdCgpXG5cblxuXG5gYGAifQ== -->
<pre class="r"><code>
docvars(abs_corpus, &quot;year&quot;) &lt;- abstracts1$year
docvars(abs_corpus, &quot;title&quot;) &lt;- abstracts1$title
docvars(abs_corpus, &quot;journal&quot;) &lt;- abstracts1$journal
docvars(abs_corpus, &quot;doi&quot;) &lt;- abstracts1$DOI


corp_df &lt;- docvars(abs_corpus) %&gt;%
  rownames_to_column(&quot;document&quot;)

lu1 %&gt;%
  #sample_frac(.5) %&gt;%
  left_join(corp_df) %&gt;%
  arrange(doi) %&gt;%
  select(-document) %&gt;%
  distinct()
</code></pre>
<!-- rnb-source-end -->
<!-- rnb-chunk-end -->
<!-- rnb-text-begin -->
</div>
<div id="explore-article-content" class="section level2">
<h2>Explore article content</h2>
<p>We can use text mining techniques to extract information from articles either in pdf or web form. For example there is a useful table about the applications of deep learning in public health in <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=7801947" class="uri">https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=7801947</a>.</p>
<p>We can (attempt) to extract the relevant table from the pdf version using the <code>tabulizer</code> package or extract information from web pages</p>
<div class="figure">
<img src="data:image/gif;base64,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" />

</div>
<!-- rnb-text-end -->
</div>
</div>

<div id="rmd-source-code">---
title: "Analysing pubmed abstracts"
output: html_notebook
---

```{r setup}

knitr::opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE, echo = TRUE)
library(purrr)

```


# Searching and analysing medical literature with R

We have developed a workflow in R to extract abstracts from Pubmed and apply natural language processing techniques to rapidly extract relevant information and analysis.

To assist this we can use the `pubmedAbstractR` function from the `myScrapers` package. This searches pubmed and allows the user to download abstracts directly into R. It is based on the `RISmed` package. It takes a number of arguments:

* *search* - a search term which can be simple or complex (see below)
* *start* - a start data (or year) to begin the search
* *end* - an end data (or year) to complete the search
* *n* - number of abstracts to be downloaded - by default the first 1000 are downloaded
* *keyword* - if set to TRUE will download keywords
* *authors* - if set to TRUE will download authors and author order

## Getting started

For this exercise we need to install the `myScrapers` package as follows:

```{r install, eval=FALSE}
if(!require("myScrapers"))
devtools::install_git("https://gitlab.phe.gov.uk/packages/myScrapers", force = TRUE)
library(myScrapers)

```


## Example 

### Non-specific searching

Let us say we want to search for *machine learning in public health*. We can pass this as a search term to `pubmedAbstractR` as follows. Let's set n = 1 to begin with.

```{r search-1, message=FALSE, warning=FALSE}

library(myScrapers)
library(tidyverse)

search <- "machine learning public health"
start <- 2008
end <- 2018
n <- 1
  
  
abstracts <- pubmedAbstractR(search = search, start = start, end = end, n = 1)



```

We can see this gives a non-specific search which would return 9518 abstracts.

### Specific searching

We can make the search more specific to include only those abstracts which have Medical Subject Headings (MeSH) keywords for 'machine learning' and 'public health'.

```{r search-2, message=FALSE, warning=FALSE}

library(myScrapers)

search <- "machine learning[MeSH] and public health[MeSH]"
start <- 2008
end <- 2018
n <- 1
  
  
abstracts <- pubmedAbstractR(search = search, start = start, end = end, n = 1)

```

There are now 5502 abstracts. We will download these for future reference.

```{r search-3, message=FALSE, warning=FALSE}

library(myScrapers)

search <- "machine learning[MeSH] and public health[MeSH]"
start <- 2008
end <- 2018
n <- 5502
  
  
abstracts1 <- pubmedAbstractR(search = search, start = start, end = end, n = n)

```



Lets download the most recent 10 with associated keywords and authors (NB this may take a few minutes)

```{r search-4, message=FALSE, warning=FALSE, cache=TRUE}

library(myScrapers)

search <- "machine learning[MeSH] and public health[MeSH]"
start <- 2008
end <- 2018
n <- 10
  
  
abstracts <- pubmedAbstractR(search = search, start = start, end = end, n = n, authors = TRUE, keyword = TRUE)

abstracts

```

or the most recent 3000 with keywords

```{r}

search <- "machine learning[MeSH] and public health[MeSH]"
start <- 2008
end <- 2019
n <- 3000
  
  
abstracts_kw <- pubmedAbstractR(search = search, start = start, end = end, n = n, authors = FALSE, keyword = TRUE)

abstracts_kw

```


## Simple analysis

### Abstracts per journal

We can undertake simple analysis such as the frequency of abstracts by journal - see #Figure 4.1 which shows that the frequency of apparent relevant articles has grown in the last 3-4 years.

```{r abs-freq-chart, fig.width=12}

abstracts1 %>%
  group_by(journal) %>%
  count() %>%
  dplyr::filter(n > 10) %>%
  #spread(year, n, fill = 0) %>%
  ggplot(aes(reorder(journal, n), n)) +
  geom_col() +
    coord_flip() +
  labs(title = "Abstract frequency: ", 
       subtitle =  search) +
  theme(plot.subtitle = element_text(size = rel(.7)),
        axis.text.y = element_text(size = 7))


```


## Mesh terms

We can look at the most frequently used Mesh terms.

```{r mesh, fig.height=8}

mesh <- abstracts_kw %>%
  count(keyword, year)

mesh %>%
  top_n(100) %>%
  arrange(-n) %>%
  ggplot(aes(year, reorder(keyword, n), fill = n)) +
  geom_tile() +
  phecharts::theme_phe() +
  viridis::scale_fill_viridis()

```



## Wordcloud

A simple way of visualising the abstracts is to *tokenise* them into 1 and 2 ngrams and then plot occurrence frequency as a wordcloud. We can easily do this with the `quanteda` pacakge.

```{r wordcloud, fig.cap="Wordcloud of 5000 abstracts"}

library(quanteda)

abstracts1$abstract <- tm::removeWords(abstracts1$abstract, stopwords("english"))

abs_corpus <- corpus(abstracts1$abstract)
abs_dfm <- dfm(abs_corpus, remove = stopwords("en"), ngrams = 1:2, remove_punct = TRUE)

textplot_wordcloud(abs_dfm )


```

This confirms support vector machines (SVM) as a widely used algorithm and classification and prediction as a common application. It is hard to discern any common public health themes  - most of the terms seem to relate to methods.

We can explore further using *dictionary* and *topic modelling* methods. The former allows us to search for terms across the documents using a pre-determined dictionary. The latter is an unsupervised machine learning or clustering technique which allows us to look for common groupings or themes (aka topics across all the documents).

### Dictionary searching of abstracts

We can create a list of terms of interest and use the to find which abstracts they occur in and how often.


```{r dictionary search}

abs_dict <- dictionary(list(ai = c("artificial_intelligence", "ai"), 
                            obesity = "obes*", 
                            tobacco = c("smok*", "tobacco", "cigar*"), 
                            heart_disease = c("heart", "cardi*"), 
                            diabetes = "diabet*", 
                            cancer = "cancer*" , 
                            svm = "support_vector*", 
                            rf = "random_forest", 
                            nn = "neural_network*",
                            ph = "public_health", 
                            regr = c("regression", "xgb*", "gbm",  "lasso", "glmnet*", "penalised*"), 
                            cluster = c("cluster*", "kmeans", "k-means", "hierarchical clus*")
                            ))

abs_dict
```
## Clustering articles

```{r}
  
lookup <- dfm_lookup(abs_dfm, dictionary = abs_dict)

lu1 <- lookup %>%
  convert(., to = "data.frame") %>%
  gather(theme, value, 2:ncol(.)) %>%
  #filter(value > 0, theme %in% c("rf", "ph")) %>%
  spread(theme, value, fill = 0) %>%
  dplyr::filter( cluster> 0, ph >0)

lu1

```

## Look at a random sample of articles

```{r}

docvars(abs_corpus, "year") <- abstracts1$year
docvars(abs_corpus, "title") <- abstracts1$title
docvars(abs_corpus, "journal") <- abstracts1$journal
docvars(abs_corpus, "doi") <- abstracts1$DOI


corp_df <- docvars(abs_corpus) %>%
  rownames_to_column("document")

lu1 %>%
  #sample_frac(.5) %>%
  left_join(corp_df) %>%
  arrange(doi) %>%
  select(-document) %>%
  distinct()



```


## Explore article content

We can use text mining techniques to extract information from articles either in pdf or web form. For example there is a useful table about the applications of deep learning in public health in <https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7801947>.

We can (attempt) to extract the relevant table from the pdf version using the `tabulizer` package or extract information from web pages

![](https://ieeexplore.ieee.org/mediastore_new/IEEE/content/media/6221020/7839252/7801947/ravi.t3-2636665-large.gif)


</div>



</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});

$(document).ready(function () {
  $('.knitsql-table').addClass('kable-table');
  var container = $('.kable-table');
  container.each(function() {

    // move the caption out of the table
    var table = $(this).children('table');
    var caption = table.children('caption').detach();
    caption.insertBefore($(this)).css('display', 'inherit');
  });
});

</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
