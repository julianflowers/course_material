---
title: "Rapid literature searching"
description: |
  Using R to rapidly search the literature 
author:
  - name: Julian Flowers 
    affiliation: Public Health England
    affiliation_url: https://www.gov.uk/phe
date: "2018-10-07"
output: 
   radix::radix_article:
     keep_md: true
---


 
Searching and critical appraising the literature is an essential skill for public health practitioners. Traditionally, this involves manual searching medical or bibliographic databases or sources of grey literature, identifying relevant abstracts or full text articles, reading and appraising retrieved papers and iterating through reference lists. If you are fortunate you might have access to a librarian or information specialist who can help with searching and retrieving publications. It can be a protracted manual process, and take many months.

With the development of APIs for bibliographic databases and R packages to read them it has become possible to automate searching and literature extraction, and with mainstreamed artificial intelligence tools for natural langauge processing (NLP) it has become possible to rapidly assess large numbers of papers.

## Example

For this exercise we'll need to download the following packages

* `tidyverse`
* `tidytext`
* `myScrapers`
* `quanteda`
* `Rcrawler`
* `rvest`


<div class="layout-chunk" data-layout="l-body">

```
Please wait...Your query is "public health"[MeSH Terms] AND deep learning[tw] AND 2000[PDAT] : 2018[PDAT]. This returns 336 abstracts. By default 1000 abstracts are downloaded. You downloaded 336 abstracts. To retrieve more set 'n =' argument to the desired value
```

```
# A tibble: 336 x 5
   title            abstract            journal           DOI   year 
   <chr>            <chr>               <chr>             <chr> <chr>
 1 Deep learning a… Synovial sarcoma i… Tumour biology :… 3026… 2018 
 2 Automated chest… OBJECTIVE: In this… Biomedical engin… 2979… 2018 
 3 Deep Learning t… Early detection of… Sensors (Basel, … 2978… 2018 
 4 A survey of stu… Retrieval practice… Advances in phys… 2976… 2018 
 5 Convolutional n… With the introduct… PloS one          2973… 2018 
 6 A deep belief n… Nonlinear system m… Neural networks … 2972… 2018 
 7 The Use of Smar… The use of smartph… Journal of medic… 2970… 2018 
 8 RIDDLE: Race an… Anonymized electro… PLoS computation… 2969… 2018 
 9 Machine Learnin… The ultrasound ima… BioMed research … 2968… 2018 
10 Human Activity … In recent years, h… Journal of medic… 2966… 2018 
# ... with 326 more rows
```

```
[1] "Using deep learning and Google Street View to\nestimate the demographic makeup of neighborhoods\nacross the United States\nTimnit Gebrua,1 , Jonathan Krausea , Yilun Wanga , Duyun Chena , Jia Dengb , Erez Lieberman Aidenc,d,e , and Li Fei-Feia\na\n  Artificial Intelligence Laboratory, Computer Science Department, Stanford University, Stanford, CA 94305; b Vision and Learning Laboratory, Computer\nScience and Engineering Department, University of Michigan, Ann Arbor, MI 48109; c The Center for Genome Architecture, Department of Genetics, Baylor\nCollege of Medicine, Houston, TX 77030; d Department of Computer Science, Rice University, Houston, TX 77005; and e The Center for Genome Architecture,\nDepartment of Computational and Applied Mathematics, Rice University, Houston, TX 77005\nEdited by Kenneth W. Wachter, University of California, Berkeley, CA, and approved October 16, 2017 (received for review January 4, 2017)\nThe United States spends more than $250 million each year on                    of analyzing demographic trends in great detail, in real time, and\nthe American Community Survey (ACS), a labor-intensive door-to-                 at a fraction of the cost.\ndoor study that measures statistics relating to race, gender, edu-                  Recently, Naik et al. (7) used publicly available imagery to\ncation, occupation, unemployment, and other demographic fac-                    quantify people’s subjective perceptions of a neighborhood’s\ntors. Although a comprehensive source of data, the lag between                  physical appearance. They then showed that changes in these\ndemographic changes and their appearance in the ACS can                         perceptions correlate with changes in socioeconomic variables\nexceed several years. As digital imagery becomes ubiquitous and                 (8). Our work explores a related theme: whether socioeconomic\nmachine vision techniques improve, automated data analysis may                  statistics can be inferred from objective characteristics of images\nbecome an increasingly practical supplement to the ACS. Here,                   from a neighborhood.\nwe present a method that estimates socioeconomic characteris-                       Here, we show that it is possible to determine socioeconomic\ntics of regions spanning 200 US cities by using 50 million images               statistics and political preferences in the US population by com-\nof street scenes gathered with Google Street View cars. Using                   bining publicly available data with machine-learning methods.\ndeep learning-based computer vision techniques, we determined                   Our procedure, designed to build upon and complement the\nthe make, model, and year of all motor vehicles encountered in                  ACS, uses labor-intensive survey data for a handful of cities to\nparticular neighborhoods. Data from this census of motor vehi-                  train a model that can create nationwide demographic estimates.\ncles, which enumerated 22 million automobiles in total (8% of                   This approach allows for estimation of demographic variables\nall automobiles in the United States), were used to accurately                  with high spatial resolution and reduced lag time.\nestimate income, race, education, and voting patterns at the                        Specifically, we analyze 50 million images taken by Google\nzip code and precinct level. (The average US precinct contains                  Street View cars as they drove through 200 cities, neighborhood-\n∼1,000 people.) The resulting associations are surprisingly sim-                by-neighborhood and street-by-street. In Google Street View\nple and powerful. For instance, if the number of sedans encoun-                 images, only the exteriors of houses, landscaping, and vehicles on\ntered during a drive through a city is higher than the num-                     the street can be observed. Of these objects, vehicles are among\nber of pickup trucks, the city is likely to vote for a Democrat                 the most personalized expressions of American culture: Over\nduring the next presidential election (88% chance); otherwise,                  90% of American households own a motor vehicle (9), and their\nit is likely to vote Republican (82%). Our results suggest that                 choice of automobile is influenced by disparate demographic fac-\nautomated systems for monitoring demographics may effectively                   tors including household needs, personal preferences, and eco-\ncomplement labor-intensive approaches, with the potential to                    nomic wherewithal (10). (Note that, in principle, other factors\nmeasure demographics with fine spatial resolution, in close to                  such as spacing between houses, number of stories, and extent of\nreal time.                                                                      shrubbery could also be integrated into such models.) Such street\n                                                                                scenes are a natural data type to explore: They already cover\ncomputer vision | deep learning | social analysis | demography\n                                                                                   Significance\nF    or thousands of years, rulers and policymakers have sur-\n     veyed national populations to collect demographic statistics.\nIn the United States, the most detailed such study is the Amer-\n                                                                                   We show that socioeconomic attributes such as income, race,\n                                                                                   education, and voting patterns can be inferred from cars\nican Community Survey (ACS), which is performed by the US                          detected in Google Street View images using deep learning.\nCensus Bureau at a cost of $250 million per year (1). Each                         Our model works by discovering associations between cars\nyear, ACS reports demographic results for all cities and coun-                     and people. For example, if the number of sedans in a city\nties with a population of 65,000 or more (2). However, due to                      is higher than the number of pickup trucks, that city is likely\nthe labor-intensive data-gathering process, smaller regions are                    to vote for a Democrat in the next presidential election (88%\ninterrogated less frequently, and data for geographical areas with                 chance); if not, then the city is likely to vote for a Republican\nless than 65,000 inhabitants are typically presented with a lag of                 (82% chance).\n∼ 2.5 y. Although the ACS represents a vast improvement over\nthe earlier, decennial census (3), this lag can nonetheless impede              Author contributions: T.G., J.K., J.D., E.L.A., and L.F.-F. designed research; T.G., J.K.,\neffective policymaking. Thus, the development of complemen-                     Y.W., D.C., J.D., E.L.A., and L.F.-F. performed research; T.G. and J.K. contributed new\ntary approaches would be desirable.                                             reagents/analytic tools; T.G., J.K., Y.W., D.C., J.D., E.L.A., and L.F.-F. analyzed data; and\n                                                                                T.G., J.K., E.L.A., and L.F.-F. wrote the paper.\n   In recent years, computational methods have emerged as a\npromising tool for tackling difficult problems in social science.               The authors declare no conflict of interest.\nFor instance, Antenucci et al. (4) have predicted unemployment                  This article is a PNAS Direct Submission.\nrates from Twitter; Michel et al. (5) have analyzed culture using               This open access article is distributed under Creative Commons Attribution-\nlarge quantities of text from books; and Blumenstock et al. (6)                 NonCommercial-NoDerivatives License 4.0 (CC BY-NC-ND).\nused mobile phone metadata to predict poverty rates in Rwanda.                  1\n                                                                                  To whom correspondence should be addressed. Email: tgebru@stanford.edu.\nThese results suggest that socioeconomic studies, too, might be                 This article contains supporting information online at www.pnas.org/lookup/suppl/doi:10.\nfacilitated by computational methods, with the ultimate potential               1073/pnas.1700035114/-/DCSupplemental.\n13108–13113 | PNAS | December 12, 2017 | vol. 114 | no. 50                                                               www.pnas.org/cgi/doi/10.1073/pnas.1700035114\n\nmuch of the United States, and the emergence of self-driving                       cle, we deployed CNN (13, 14), the most successful deep learning\ncars will bring about a large increase in the frequency with which                 algorithm to date for object classification, to determine the make,\ndifferent locations are sampled.                                                   model, body type, and year of each vehicle (Fig. 1). Using our\n   We demonstrate that, by deploying a machine vision frame-                       human-annotated gold standard images, we trained the CNN to\nwork based on deep learning—specifically, Convolutional Neu-                       distinguish between different types of cars. Specifically, we were\nral Networks (CNN)—it is possible to not only recognize vehi-                      able to classify each vehicle into one of 2,657 fine-grained cate-\ncles in a complex street scene but also to reliably determine a                    gories, which form a nearly exhaustive list of all visually distinct\nwide range of vehicle characteristics, including make, model, and                  automobiles sold in the United States since 1990 (Fig. 1). For\nyear. Whereas many challenging tasks in machine vision (such as                    instance, our models accurately identified cars (identifying 95%\nphoto tagging) are easy for humans, the fine-grained object recog-                 of such vehicles in the test data), vans (83%), minivans (91%),\nnition task we perform here is one that few people could accom-                    SUVs (86%), and pickup trucks (82%). See SI Appendix, Fig. S1.\nplish for even a handful of images. Differences between cars can                      Using the resulting motor vehicle data, we estimate demo-\nbe imperceptible to an untrained person; for instance, some car                    graphic statistics and voter preferences as follows. For each geo-\nmodels can have subtle changes in tail lights (e.g., 2007 Honda                    graphical region we examined (city, zip code, or precinct), we\nAccord vs. 2008 Honda Accord) or grilles (e.g., 2001 Ford F-150                    count the number of vehicles of each make and model that were\nSupercrew LL vs. 2011 Ford F-150 Supercrew SVT). Neverthe-                         identified in images from that region. We also include addi-\nless, our system is able to classify automobiles into one of 2,657                 tional features such as aggregate counts for various vehicle types\ncategories, taking 0.2 s per vehicle image to do so. While it classi-              (trucks, vans, SUVs, etc.), the average price and fuel efficiency,\nfied the automobiles in 50 million images in 2 wk, a human expert,                 and the overall density of vehicles in the region (see Materials\nassuming 10 s per image, would take more than 15 y to perform                      and Methods).\nthe same task. Using the classified motor vehicles in each neigh-                     We then partitioned our dataset, by county, into two subsets\nborhood, we infer a wide range of demographic statistics, socio-                   (Fig. 2). The first is a “training set,” comprising all regions that\neconomic attributes, and political preferences of its residents.                   lie mostly in a county whose name starts with “A,” “B,” or “C”\n   In the first step of our analysis, we collected 50 million Google               (such as Ada County, Baldwin County, Cabarrus County, etc.).\nStreet View images from 3,068 zip codes and 39,286 voting                          This training set encompasses 35 of the 200 cities, ∼ 15% of the\nprecincts spanning 200 US cities (Fig. 1). Using these images                      zip codes, and ∼ 12% of the precincts in our data. The second is a\nand annotated photos of cars, our object recognition algorithm                     “test set,” comprising all regions in counties starting with the let-\n[a “Deformable Part Model” (DPM) (11)] learned to automati-                        ters “D” through “Z” (such as Dakota County, Maricopa County,\ncally localize motor vehicles on the street (12) (see Materials and                Yolo County). We used the test set to evaluate the model that\nMethods). This model took advantage of a gold-standard dataset                     resulted from the training process.\nwe generated by asking humans (both laypeople, recruited using                        Using ACS and presidential election voting data for regions\nAmazon Mechanical Turk, and car experts recruited through                          in our training set, we train a logistic regression model to esti-\nCraigslist) to identify cars in Google Street View scenes.                         mate race and education levels and a ridge regression model to\n   We successfully detected 22 million distinct vehicles, compris-                 estimate income and voter preferences on the basis of the col-\ning 32% of all of the vehicles in the 200 cities we studied and 8%                 lection of vehicles seen in a region. This simple linear model is\nof all vehicles in the United States. After localizing each vehi-                  sufficient to identify positive and negative associations between\n                                                                                                                                                                             COMPUTER SCIENCES\n                                                                                         200 Cities\n                                                                                         50,0000,000 Images\n                                                                                         22,000,000 Cars Analyzed\n                                                                                                                    Fig. 1. We perform a vehicular census of 200\n                                                                                                                    cities in the United States using 50 million Google\n                                                                                                                    Street View images. In each image, we detect cars\n                                                                                                                    with computer vision algorithms based on DPM\n                                                                                         2657 Car Categories\n                                                                                                                    and count an estimated 22 million cars. We then\n               Make: Nissan       Make: Ford               Make: Honda        Make: Honda                           use CNN to categorize the detected vehicles into\n               Model: Sentra      Model: Econoline-Cargo   Model: Accord      Model: Civic                          one of 2,657 classes of cars. For each type of car, we\n               Year: 2006         Year: 2003               Year: 1994         Year: 2004\n               Body Type: sedan   Body Type: van           Body Type: sedan   Body Type: sedan\n                                                                                                                    have metadata such as the make, model, year, body\n               Trim: 1.8 s        Trim: e-150              Trim: lx           Trim: ex                              type, and price of the car in 2012. Images courtesy\n               Price: $5,417      Price: $3,778            Price:$3,591       Price:$8,773                          of Google Maps/Google Earth.\nGebru et al.                                                                                               PNAS | December 12, 2017 | vol. 114 | no. 50 | 13109\n\n                    i. White (Seattle, Washington)            ii.Black (Seattle, Washington)         iii.. Asian (Seattle, Washington)\n              100%\n              0%\n                          actual              predicted           actual            predicted               actual              predicted\n                                                                                                                                                    Fig. 2. We use all of the cities in counties start-\n                                                                                                                                                    ing with A, B, and C (shown in purple on the\n                                                                                                                                                    map) to train a model estimating socioeconomic\n                                                                                                                                                    data from car attributes. Using this model, we\n                                                                                                                                                    estimate demographic variables at the zip code\n                                                                                                                                           Train\n                                                                                                                                                    level for all of the cities shown in green. We\n                                                                                                                                           Test\n                                                                                                                                                    show actual vs. predicted maps for the percent-\n                                                                                                                                                    age of Black, Asian, and White people in Seat-\n                                                                                                                                                    tle, WA (i–iii); the percentage of people with\n                                                                                                                                                    less than a high school degree in Milwaukee, WI\n                                                                                                                                                    (iv); and the percentage of people with grad-\n                                                                                                                                                    uate degrees in Milwaukee, WI (v). (vi) Maps\n                                                                                                                                                    the median household income in Tampa, FL.\n                                                                                                                                                    The ground truth values are mapped on Left,\n    iv. Less than High school (Milwaukee, Wisconsin)       v. Graduate school (Milwaukee, Wisconsin)                    vi. Income (Tampa, Florida) and our estimated results are on Right. We\n      34%                                                                                                     $111K\n                                                                                                                                                    accurately localize zip codes with the highest\n                                                        48%\n                                                                                                                                                    and lowest concentrations of each demographic\n                                                                                                                                                    variable such as the three zip codes in Eastern\n                                                                                                                                                    Seattle with high concentrations of Caucasians,\n                                                                                                                                                    one Northern zip code in Milwaukee with highly\n      0%                                                0%                                                    $7K                                   educated inhabitants, and the least wealthy zip\n                actual                 predicted                   actual               predicted                       actual            predicted\n                                                                                                                                                    code in Southern Tampa.\nthe presence of specific vehicles (such as Hondas) and particu-                                                       tic we examined. (The r values for the correlations were as fol-\nlar demographics (i.e., the percentage of Asians) or voter prefer-                                                    lows: median household income, r = 0.82; percentage of Asians,\nences (i.e., Democrat).                                                                                               r = 0.87; percentage of Blacks, r = 0.81; percentage of Whites,\n   Our model detects strong associations between vehicle distri-                                                      r = 0.77; percentage of people with a graduate degree, r = 0.70;\nbution and disparate socioeconomic factors. For instance, sev-                                                        percentage of people with a bachelor’s degree, r = 0.58; percent-\neral studies have shown that people of Asian descent are more                                                         age of people with some college degree, r = 0.62; percentage of\nlikely to drive Asian cars (15), a result we observe here as well:                                                    people with a high school degree, r = 0.65; percentage of people\nThe two brands that most strongly indicate an Asian neighbor-                                                         with less than a high school degree, r = 0.54). See SI Appendix,\nhood are Hondas and Toyotas. Cars manufactured by Chrysler,                                                           Figs. S3–S5. Taken together, these results show our ability to esti-\nBuick, and Oldsmobile are positively associated with African                                                          mate demographic parameters, as assessed by the ACS, using the\nAmerican neighborhoods, which is again consistent with exist-                                                         automated identification of vehicles in Google Street View data.\ning research (16). And vehicles like pickup trucks, Volkswagens,                                                             Although our city-level estimates serve as a proof-of-principle,\nand Aston Martins are indicative of mostly Caucasian neighbor-                                                        zip code-level ACS data provide a much more fine-grained por-\nhoods. See SI Appendix, Fig. S2.                                                                                      trait of constituencies. To investigate the accuracy of our meth-\n   In some cases, the resulting associations can be easily applied                                                    ods at zip code resolution, we compared our zip code-by-zip code\nin practice. For example, the vehicular feature that was most                                                         estimates to those generated by the ACS, confirming a close cor-\nstrongly associated with Democratic precincts was sedans,                                                             respondence between our findings and ACS values. For instance,\nwhereas Republican precincts were most strongly associated with                                                       when we looked closely at the data for Seattle, we found that\nextended-cab pickup trucks (a truck with rear-seat access). We                                                        our estimates of the percentage of people in each zip code who\nfound that by driving through a city while counting sedans and                                                        were Caucasian closely matched the values obtained by the ACS\npickup trucks, it is possible to reliably determine whether the                                                       (r = 0.84, p < 2e − 7). The results for Asians (r = 0.77, p = 1e −\ncity voted Democratic or Republican: If there are more sedans,                                                        6) and African Americans (r = 0.58, p = 7e − 4) were similar.\nit probably voted Democrat (88% chance), and if there are more                                                        Overall, our estimates accurately determined that Seattle, Wash-\npickup trucks, it probably voted Republican (82% chance). See                                                         ington is 69% Caucasian, with African Americans mostly residing\nFig. 3 A, iii.                                                                                                        in a few Southern zip codes (Fig. 2 i and ii). As another exam-\n   As a result, it is possible to apply the associations extracted                                                    ple, we estimated educational background in Milwaukee, Wis-\nfrom our training set to vehicle data from our test set regions                                                       consin zip codes, accurately determining the fraction of the pop-\nto generate estimates of demographic statistics and voter prefer-                                                     ulation with less than a high school degree (r = 0.70, p = 8e − 5),\nences, achieving high spatial resolution in over 160 cities. To be                                                    with a bachelor’s degree (r = 0.83, p < 1e − 7), and with post-\nclear, no ACS or voting data for any region in the test set were                                                      graduate education (r = 0.82, p < 1e − 7). We also accurately\nused to create the estimates for the test set.                                                                        determined the overall concentration of highly educated inhabi-\n   To confirm the accuracy of our demographic estimates, we                                                           tants near the city’s northeast border (Fig. 2 iv and v). Similarly,\nbegan by comparing them with actual ACS data, city-by-city,                                                           our income estimates closely match those of the ACS in Tampa,\nacross all 165 test set cities. We found a strong correlation                                                         Florida (r = 0.87, p < 1e −7). The lowest income zip code, at the\nbetween our results and ACS values for every demographic statis-                                                      southern tip, is readily apparent.\n13110 | www.pnas.org/cgi/doi/10.1073/pnas.1700035114                                                                                                                                       Gebru et al.\n\n   A                    i. Actual Percent of Voters for Obama in 2008\n                                                                           B                           Republican\n                                                                                                       Democrat\n                                                                                Los Angeles, California\n                                                                                   Casper, Wyoming\n    0%          100%\n                                                                                Milwaukee, Wisconsin\n                       ii. Predicted Percent of Voters for Obama in 2008\n                                                                                 Lexington, Kentucky\n                                                                                                                    Fig. 3. Actual and inferred voting patterns. A,\n                                                                                                                    i and ii map the actual and predicted percent-\n                                                                                Birmingham, Alabama                 age of people who voted for Barack Obama\n                                                                                                                    in the 2008 presidential election (r = 0.74).\n    0%          100%\n                                                                                                                    iii maps the ratio of detected pickup trucks\n                                                                                                                    to sedans in the 165 cities in our test set. As\n                       iii. Ratio of Sedans to Extended-cab Trucks\n                                                                                                                    can be seen from the map, the ratio is very\n                                                                                                                    low in Democratic cities such as those in the\n                                                                                   Garland, Texas                   East Coast and high in Republican cities such as\n                                                                                                                    those in Texas and Wyoming. (B) Shows actual\n                                                                                                                    vs. predicted voter affiliations for various cities\n                                                                                                                    in our test set at the precinct level using our\n                                                                                                                    full model. Democratic precincts are shown in\n                                                                                                                    blue, and Republican precincts are shown in\n                                                                                    Gilbert, Arizona\n                                                                                                                    red. Our model correctly classifies Casper, WY\n                                                                                                                    as a Republican city and Los Angeles, CA as a\n                                                                                                                    Democratic city. We accurately predict that Mil-\n                                                                                                                    waukee, WI is a Democratic city except for a\n                                                                                                                                                                          COMPUTER SCIENCES\n    0.7          0.4\n                                                                                                                    few Republican precincts in the southern, west-\n                                                                                                                    ern, and northeastern borders of the city.\n   While the ACS does not collect voter preference data, our                   mates and actual electoral outcomes at the single-precinct level\nautomated machine-learning procedure can infer such prefer-                    (r = 0.57, p < 1e − 7).\nences using associations between vehicles and the voters that                     These results illustrate the ability of our machine-learning algo-\nsurround them. To confirm the accuracy of our voter pref-                      rithm to accurately estimate both demographic statistics and voter\nerence estimates, we began by comparing them with the vot-                     preferences using a large database of Google Street View images.\ning results of the 2008 presidential election, city-by-city, across            They also suggest that our demographic estimates are accurate\nall 165 test set cities. We found a very strong correlation                    at higher spatial resolutions than those available for yearly ACS\nbetween our estimates and actual voter preferences (r = 0.73,                  data. Using our approach, zip code- or precinct-level survey data\np << 1e − 7). See SI Appendix, Fig. S5. These results con-                     collected for a few cities can be used to automatically provide\nfirm the ability of our approach to accurately estimate voter                  up-to-date demographic information for many American cities.\nbehavior.                                                                         Thus, we find that the application of fully automated com-\n   While city-level data provide a general picture, precinct-level             puter vision methods to publicly available street scenes can inex-\nvoter preferences identify patterns within a particular city. By               pensively determine social, economic, and political patterns in\ncomparing our precinct-by-precinct estimates to the 2008 presi-                neighborhoods across America. By collecting surveys for a few\ndential election results, we found that our estimates continued to             cities—the type of data routinely obtained via ACS—and infer-\nclosely match the ground truth data. For instance, in Milwaukee,               ring data for other regions using our model, we can quickly deter-\nWisconsin, a very Democratic city with 311 precincts, we cor-                  mine demographic patterns.\nrectly classify 264 precincts [85% accuracy (Fig. 3B)]. Most                      As self-driving cars with onboard cameras become increasingly\nnotably, we accurately determine that there are a few Republi-                 widespread, the type of data we use—footage of neighborhoods\ncan precincts in the South, West, and Northeastern borders of                  from vehicle-mounted cameras—are likely to become increas-\nthe city. Similarly, in Gilbert, Arizona, a Republican city, we cor-           ingly ubiquitous. For instance, Tesla vehicles currently take as\nrectly classify 58 out of 60 precincts (97% accuracy), identifying             many images as were studied here every single day. It is also\none out of the two small Democratic precincts in the city (Fig.                important to note that similar data can be obtained, albeit at\n3B). And in Birmingham, Alabama, a city that is 23% Republi-                   a slower pace, using low-tech methods: for instance, by walk-\ncan, we correctly classify 87 out of the 105 precincts (83% accu-              ing around a target neighborhood with a camera and a notepad.\nracy). Overall, there was a strong correlation between our esti-               Thus, street scenes stand in contrast to the massive textual\nGebru et al.                                                                                              PNAS | December 12, 2017 | vol. 114 | no. 50 | 13111\n\ncorpora presently used in many computational social science                    state-of-the-art in object detection, DPMs (11), instead of recent algorithms\nstudies, which can be constrained by privacy and copyright con-                such as ref. 23.\ncerns that prevent individual researchers from obtaining the raw                  For DPMs, there are two main parameters that influence the running time\ndata underlying published analyses.                                            and performance, which are the number of components and the number of\n   The automated method we present could be substantially                      parts in the model. SI Appendix, Table S3 provides an analysis of the perfor-\n                                                                               mance/time tradeoff on our data, measured on the validation set. Based on\nimproved by expanding our object recognition beyond vehicles\n                                                                               this analysis, using a DPM with a single component and eight parts strikes\n(17, 18) and incorporating global image features (7, 19–21).                   the right balance between performance and efficiency, allowing us to detect\nFor instance, our experiments show that global image features                  cars on all 50 million images in 2 wk. In contrast, the best performing param-\nextracted from CNN can also be used to infer demographics. But                 eters would have taken 2 months to run and only increased average preci-\nthis approach requires more data—at least 50% of our dataset—                  sion (AP) by 4.5.\nrather than the 12% to 15% we use using our current method                        As discussed in ref. 12, we also introduce a prior on the location and size\n(see SI Appendix). The model could also be improved by inte-                   of predicted bounding boxes and use it to improve detection accuracy. Incor-\ngrating other types of data, such as satellite images (22), social             porating this prior into our detection pipeline improves AP on the validation\nnetworks (4), and economic data pertaining to local consumer                   set by 1.92 at a negligible cost. SI Appendix, Fig. S6B visualizes this prior. The\nbehavior in particular geographic regions. Nevertheless, there                 output of our detection system is a set of bounding boxes and scores where\nare many characteristics that our methodology—which relies                     each score indicates the likelihood of its associated box containing a car.\n                                                                                  We converted these scores into estimated probabilities via isotonic\non publicly available data—may not be able to infer (see SI\n                                                                               regression (24) (see SI Appendix for details). We report numbers using a\nAppendix). For instance, the age of children in a neighborhood                 detection threshold of −1.5 (applied before the location prior). At test time,\ncan be estimated with moderate accuracy (r = 0.54), while the                  after applying the location prior (which lowers detection decision values),\npercentage of farmers in a neighborhood was not successfully                   we use a detection threshold of −2.3. This reduces the average number\ninferred using our method (r = 0.0).                                           of bounding boxes per image to be classified from 7.9 to 1.5 while only\n   Although automated methods could be powerful resources                      degrading AP by 0.6 (66.1 to 65.5) and decreasing the probability mass of\nfor both researchers and policymakers, their progress will raise               all detections in an image from 0.477 to 0.462 (a 3% drop). SI Appendix,\nimportant ethical concerns; it is clear that public data should not            Fig. S8 shows examples of car detections using our model. Bounding boxes\nbe used to compromise reasonable privacy expectations of indi-                 with cars have high estimated probabilities, whereas the opposite is true for\nvidual citizens, and this will be a central concern moving forward.            those containing no cars. The AP of our final model is 65.7, and its precision\nIn the future, such automated methods could lead to estimates                  recall curve is visualized in SI Appendix, Fig. S7B. We calculate chance per-\n                                                                               formance using a uniform sample of bounding boxes greater than 50 pixels\nthat are accurately updated in real time, dramatically improving\n                                                                               in width and height.\nupon the time resolution of a manual survey.\n                                                                               Car Classification. Our pipeline, described in ref. 12, classifies automobiles\nMaterials and Methods\n                                                                               into one of 2,657 visually distinct categories with an accuracy of 33.27%.\nHere, we describe our methodology for data collection, car detection, car      We use a CNN (25) following the architecture of ref. 14 to categorize cars.\nclassification, and demographic inference. Some of these methods were par-     CNNs, like other supervised machine-learning methods, perform best when\ntially developed in an earlier paper (12), which served as a proof of concept  trained on data from a similar distribution as the test data (in our case,\nfocusing on a limited set of predictions (e.g., per capita carbon emission,    Street View images). However, the cost of annotating Street View photos\nMassachusetts Department of Vehicles registration data, income segrega-        makes it infeasible to collect enough images to train our CNN only using\ntion). Our work builds on these methods to show that income, race, educa-      this source. Thus, we used a combination of Street View and the more plen-\ntion levels, and voting patterns can be predicted from cars in Google Street   tiful product shot images as training data. We modified the traditional CNN\nView images. In the sections below, we discuss our dataset and methodology     training procedure in a number of ways.\nin more detail.                                                                   First, taking inspiration from domain adaptation, we approximated the\n                                                                               WEIGHTED method of Daumé (26) by duplicating each Street View image 10\nDataset. While learning to recognize automobiles, a model needs to be          times during training. This roughly equalizes the number of training Street\ntrained with many images of vehicles annotated with category labels. To        View and product shot images, preventing the classifier from overfitting on\nthis end, we used Amazon Mechanical Turk to gather a dataset of labeled        product shot images.\ncar images obtained from edmunds.com, cars.com, and craigslist.org. Our           Product shot and Street View images differ significantly in image resolu-\ndataset consists of 2,657 visually distinct car categories, covering all com-  tion: Cars in product shot images occupy many more pixels in the image.\nmonly used automobiles in the United States produced from 1990 onward.         To compensate for this difference, we first measured the distribution of\nWe refer to these images as product shot images. We also hired experts         bounding box resolutions in Street View images used for training. Then,\nto annotate a subset of our Google Street View images. The annotations         during training, we dynamically downsized each input image according to\ninclude a bounding box around each car in the image and the type of car        this distribution before rescaling it to fit the input dimensions of the CNN.\ncontained in the box. We partition the images into training, validation,       Resolutions are parameterized by the geometric mean of the bounding box\nand test sets. In addition to our annotated images, we gathered 50 mil-        width and height, and the probability distribution is given as a histogram\nlion Google Street View images from 200 cities, sampling GPS points every      over 35 different such resolutions. The largest resolution is 256, which is the\n25 miles. We captured 6 images per GPS point, corresponding to different       input resolution of the CNN (see SI Appendix for additional details).\ncamera rotations. Each Street View image has dimensions 860 by 573 pixels         At test time, we input each detected bounding box into the CNN and\nand a horizontal field of view of ∼90◦ . Since the horizontal field of view is obtain softmax probabilities for each car category through a single for-\nlarger than the change in viewpoint between the 6 images per GPS point,        ward pass. We only keep the top 20 predictions, since storing a full 2, 657-\nthe images have some overlapping content. In total, we collected 50,881,098    dimensional floating point vector for each bounding box is prohibitively\nGoogle Street View images for our 200 cities. They were primarily acquired     expensive in terms of storage. On average, these top 20 predictions account\nbetween June and December of 2013 with a small fraction (3.1%) obtained        for 85.5% of the softmax layer activations’ probability mass. After extensive\nin November and December of 2014. See SI Appendix for more detail on the       code optimization to make this classification step as fast as possible, we\ndata collection process.                                                       are primarily limited by the time spent reading images from disk, espe-\n                                                                               cially when using multiple GPUs to perform classification. At the most fine-\nCar Detection. In computer vision, detection is the task of localizing objects grained level (2, 657 classes), we achieve a surprisingly high accuracy of\nwithin an image and is most commonly framed as predicting the x, y, width,     33.27%. We classify the car make and model with 66.38% and 51.83% accu-\nand height coordinates of an axis-aligned bounding box around an object of     racy respectively. Whether it was manufactured in or outside of the United\ninterest. The central challenge for our work is designing an object detector   States can be determined with 87.71% accuracy.\nthat is fast enough to run on 50 million images within a reasonable amount        We show confusion matrices for classifying the make, model, body type,\nof time and accurate enough to be useful for demographic inference. Our        and manufacturing country of the car (SI Appendix, Fig. S9 A–D). Body\ncomputation resources consisted of 4 T K40 graphics processing units and       type misclassifications tend to occur among similar categories. For exam-\n200 2.1 GHz central processing unit cores. As we were willing to trade a cou-  ple, the most frequent misclassification for “coupe” is “sedan,” and the\nple of percentages in accuracy for efficiency (12), we turned to the previous  most frequent misclassification for trucks with a regular cab is trucks with an\n13112 | www.pnas.org/cgi/doi/10.1073/pnas.1700035114                                                                                                 Gebru et al.\n\nextended cab. On the other hand, there are no two makes (such as Honda                           We compute the probability of voting Democrat/Republican conditioned\nand Mercedes-Benz) that are more visually similar than others. Thus, when                     on being in a city with more pickup trucks than sedans as follows. Let\na car’s make is misclassified, it is mostly to a more popular make. Similarly,                r be the ratio of pickup trucks to sedans. We would like to estimate\nmost errors at the manufacturing country level occur by misclassifying the                    P(Democrat|r > 1) and P(Republican|r < 1):\nmanufacturing country as either “Japan” or “USA,” the two most popular\ncountries. Due to the large number of classes, the only clear pattern in the                                                                    P(Democrat, r > 1)\n                                                                                                                     P(Democrat|r > 1) =                                                  [1]\nmodel-level confusion matrix is a strong diagonal, indicative of our correct                                                                        P(r > 1)\npredictions.\n                                                                                                                                                P(Republican, r < 1)\nDemographic Estimation. In all of our demographic estimations, we use the                                          P(Republican|r < 1) =                                                  [2]\n                                                                                                                                                     P(r < 1)\nfollowing set of 88 car-related attributes: the average number of detected\ncars per image; average car price; miles per gallon (city and highway); per-                     We estimate P(Democrat, r > 1), P(Republican, r < 1), P(r > 1), and\ncent of total cars that are hybrids; percent of total cars that are electric;                 P(r < 1) as follows. Let Sd = {ci } be the set of cities with more votes for\npercent of total cars that are from each of seven countries; percent of total                 Barack Obama than John McCain. Let Ss = {cj } be the set of cities with more\ncars that are foreign (not from the USA); percent of total cars from each of                  sedans than pickup trucks. Let ns be the number of elements in Ss and let\n11 body types; percent of total cars whose year (selected as the minimum                      nd s be the number of elements in Sd ∩ Ss . Similarly, let Sp be the set of cities\nof possible year values for the car) fall within each of 5 year ranges (1990–                 with more pickup trucks than sedans, Sr the set of cities with more votes\n1994, 1995–1999, 2000–2004, 2005–2009, and 2010–2014); and percent of                         for John McCain than Barack Obama, and nr p the number of elements in\ntotal cars whose make is each of 58 makes in our dataset.                                     Sr ∩ Sp . Finally, let C be the number of cities in our test set:\n    Socioeconomic data were obtained from the ACS (2) and were collected                                                                                   nd s\nbetween 2008–2012. See SI Appendix for more detail on ground truth data                                                       P(Democrat, r > 1) ≈                                        [3]\n                                                                                                                                                            C\nused in our analysis (e.g., census codes). Data for the 2008 US presidential\nelection were provided to us by the authors of ref. 27 and consist of precinct-                                                                            nr p\nlevel vote counts for Barack Obama and John McCain. We ignore votes cast                                                     P(Republican, r < 1) ≈                                       [4]\n                                                                                                                                                            C\nfor any other person; that is, the count of total votes is determined solely by\nvotes for Obama and McCain.                                                                                                                         ns\n    To perform our experiments, we partitioned the zip codes, precincts, and                                                          P(r > 1) ≈                                          [5]\n                                                                                                                                                    C\ncities in our dataset into training and test sets as discussed in the main text,\ntraining a model on the training set and predicting on the test set. We used                                                                        np\na ridge regression model for income and voter affiliation estimation. For                                                             P(r < 1) ≈                                          [6]\n                                                                                                                                                    C\nrace and education, we used logistic regression to use structure inherent in\nthe data. Specifically, for each region, summing the percentage of people                     Using these estimates, we calculate P(Democrat|r > 1) and P(Republican|r <\nwith each of the 5 possible educational backgrounds (or each race) should                     1) according to Eqs. 1 and 2.\nyield 100%. In all cases, we trained 5 models using fivefold cross-validation\nto select the regularization parameter and averaged the trained models. We                    ACKNOWLEDGMENTS. We thank Neal Jean, Stefano Ermon, and Marshall\n                                                                                              Burke for helpful suggestions and edits; everyone who worked on anno-\nnormalize the features to have zero mean and unit SD (parameters deter-\n                                                                                              tating our car dataset for their dedication; and our friends and family and\nmined on the training set). We also clip predictions to stay within the range                 the entire Stanford Vision lab, especially Brendan Marten, Serena Yeung,\nof the training data, preventing our estimates from having extreme values.                    and Selome Tewoderos for their support, input, and encouragement. This\nThe geographical regions of interest are restricted to be ones with a popu-                   research is partially supported by NSF Grant IIS-1115493, the Stanford DARE\nlation of at least 500 and at least 50 detected cars.                                         fellowship (to T.G.), and NVIDIA (through donated GPUs).\n 1. Department of Commerce, US Census Bureau (2013) US census bureau’s bud-                         able at papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-\n                                                                                                                                                                                                 COMPUTER SCIENCES\n    get estimates. Available at www.osec.doc.gov/bmi/budget/fy13cbj/Census FY2013                   neural-networks.pdf. Accessed November 9, 2017.\n    CongressionalJustification-FINAL.pdf. Accessed September 13, 2014.                        15.   Bland M (2012) Asian consumers and the automotive market. Available at app.\n 2. Department of Commerce, US Census Bureau (2012) American community survey 5                     compendium.com/uploads/user/a33eed35-8a44-4da7-84c4-16f3751fe303/9855ee60-\n    year data (2008-2012). Available at https://factfinder.census.gov/faces/tableservices/          f764-43b4-84c4-40950ff36307/File/3e1e2e5d8d20fad49eaac919e38abc8e/polk 3af 05\n    jsf/pages/productview.xhtml?src=bkmk. Accessed September 13, 2014.                              17 2012 presentation.pdf. Accessed November 6, 2017.\n 3. Department of Commerce, US Census Bureau (2010) Decennial census. Available               16.   Auto Remarketing Staff (2011) Which brands most attract African-American buyers?\n    at https://www.census.gov/data/developers/data-sets/decennial-census.html. Access-              Available at www.autoremarketing.com/content/trends/which-brands-most-attract-\n    ed September 13, 2014.                                                                          african-american-buyers. Accessed October 24, 2016.\n 4. Antenucci D, Cafarella M, Levenstein M, Ré C, Shapiro MD (2014) Using Social Media       17.   Simo-Serra E, Fidler S, Moreno-Noguer F, Urtasun R (2015) Neuroaesthetics in fashion:\n    to Measure Labor Market Flows (National Bureau of Economic Research, Cambridge,                 Modeling the perception of beauty. Proceedings of the IEEE Conference on Computer\n    MA), Technical Report 20010.                                                                    Vision and Pattern Recognition (IEEE, New York), pp 869–877.\n 5. Michel JB, et al. (2011) Quantitative analysis of culture using millions of digitized     18.   Matzen K, Bala K, Snavely N (2017) Streetstyle: Exploring world-wide clothing styles\n    books. Science 331:176–182.                                                                     from millions of photos. arXiv:1706.01869.\n 6. Blumenstock J, Cadamuro G, On R (2015) Predicting poverty and wealth from mobile          19.   Ordonez V, Berg TL (2014) Learning high-level judgments of urban percep-\n    phone metadata. Science 350:1073–1076.                                                          tion. European Conference on Computer Vision (Springer, Boston), pp 494–\n 7. Naik N, Philipoom J, Raskar R, Hidalgo C (2014) Streetscore–Predicting the perceived            510.\n    safety of one million streetscapes. 2014 IEEE Conference on Computer Vision and           20.   Khosla A, An B, Lim JJ, Torralba A (2014) Looking beyond the visible scene. 2014 IEEE\n    Pattern Recognition Workshops (IEEE, New York), pp 793–799.                                     Conference on Computer Vision and Pattern Recognition (IEEE, New York), pp 3710–\n 8. Naik N, Kominers SD, Raskar R, Glaeser EL, Hidalgo CA (2017) Computer vision                    3717.\n    uncovers predictors of physical urban change. Proc Natl Acad Sci USA 114:7571–            21.   Zhou B, Liu L, Oliva A, Torralba A (2014) Recognizing city identity via attribute analysis\n    7576.                                                                                           of geo-tagged images. European Conference on Computer Vision (Springer, Boston),\n 9. American Association of State Highway and Transportation Officials (2013) Vehicle               pp 519–534.\n    and Transit Availability. Commuting in America 2013 (American Association of State        22.   Jean N, et al. (2016) Combining satellite imagery and machine learning to predict\n    Highway and Transportation Officials, Washington, DC), Report 7.                                poverty. Science 353:790–794.\n10. Choo S, Mokhtarian PL (2004) What type of vehicle do people drive? The role of            23.   Ren S, He K, Girshick R, Sun J (2017) Faster r-CNN: Towards real-time object detec-\n    attitude and lifestyle in influencing vehicle type choice. Transport Res Pol Pract 38:          tion with region proposal networks. IEEE Trans Pattern Anal Mach Intell 39:1137–\n    201–222.                                                                                        1149.\n11. Felzenszwalb P, Girshick R, McAllester D, Ramanan D (2010) Object detection with          24.   Barlow RE, Bartholomew DJ, Bremner J, Brunk HD (1972) Statistical Inference\n    discriminatively trained part based models. IEEE Trans Pattern Anal Mach Intell 32:             under Order Restrictions: The Theory and Application of Isotonic Regression (Wiley,\n    1627–1645.                                                                                      New York).\n12. Gebru T, et al. (2017) Fine-grained car detection for visual census estimation in AAAI,   25.   LeCun Y, Bottou L, Bengio Y, Haffner P (1998) Gradient-based learning applied to\n    in press.                                                                                       document recognition. Proc IEEE 86:2278–2324.\n13. LeCun Y, Bottou L, Bengio Y, Haffner P (1998) Gradient-based learning applied to          26.   Daumé H III (2007) Frustratingly easy domain adaptation. Conference of the Associ-\n    document recognition. Proc IEEE 86:2278–2324.                                                   ation for Computational Linguistics (ACL, Prague, Czech Republic).\n14. Krizhevsky A, Sutskever I, Hinton GE (2012) ImageNet classification with deep convo-      27.   Ansolabehere S, Palmer M, Lee A (2014) Precinct-Level Election Data. Available at\n    lutional neural networks. Advances in Neural Information Processing Systems. Avail-             hdl.handle.net/1903.1/21919. Accessed January 13, 2015.\nGebru et al.                                                                                                         PNAS | December 12, 2017 | vol. 114 | no. 50 | 13113\n"
```

</div>



## Google searching

<div class="layout-chunk" data-layout="l-body">

```
[[1]]
[1] "https://www.ncbi.nlm.nih.gov/pubmed/29183967"
```

</div>


## Searching Pubmed

<div class="layout-chunk" data-layout="l-body">


</div>




### Searching Medline




